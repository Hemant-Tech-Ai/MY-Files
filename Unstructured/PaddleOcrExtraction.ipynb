{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r recog_requirments.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install paddlepaddle\n",
    "# %pip install paddleocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/02/11 10:45:11] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\Hemant.Singhsidar/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\Hemant.Singhsidar/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='c:\\\\Users\\\\Hemant.Singhsidar\\\\Desktop\\\\Assignments\\\\DATP\\\\PDF Extraction\\\\Unstructured\\\\comb_env\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\Hemant.Singhsidar/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2025/02/11 10:45:12] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
      "[2025/02/11 10:45:12] ppocr DEBUG: dt_boxes num : 9, elapsed : 0.2761800289154053\n",
      "[2025/02/11 10:45:13] ppocr DEBUG: rec_res num  : 9, elapsed : 0.5770938396453857\n"
     ]
    }
   ],
   "source": [
    "ocr = PaddleOCR(lang='en')\n",
    "image_path = 'PDF1 Cropped Tables\\page_1_Table_1.png'\n",
    "image_cv = cv2.imread(image_path)\n",
    "image_height = image_cv.shape[0]\n",
    "image_width = image_cv.shape[1]\n",
    "output = ocr.ocr(image_path)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[15.0, 12.0], [101.0, 8.0], [103.0, 45.0], [16.0, 49.0]], ('Sr.No', 0.9986014366149902)], [[[136.0, 14.0], [280.0, 14.0], [280.0, 44.0], [136.0, 44.0]], ('Particulars', 0.9996967911720276)], [[[963.0, 16.0], [1175.0, 16.0], [1175.0, 44.0], [963.0, 44.0]], ('Amount in Lacs.', 0.9693554043769836)], [[[16.0, 51.0], [41.0, 51.0], [41.0, 91.0], [16.0, 91.0]], ('1', 0.8809970617294312)], [[[131.0, 54.0], [207.0, 54.0], [207.0, 85.0], [131.0, 85.0]], ('Land', 0.9999060034751892)], [[[1157.0, 52.0], [1222.0, 52.0], [1222.0, 85.0], [1157.0, 85.0]], ('3.00', 0.988105058670044)], [[[18.0, 94.0], [40.0, 94.0], [40.0, 128.0], [18.0, 128.0]], ('2', 0.9904012084007263)], [[[135.0, 93.0], [669.0, 95.0], [669.0, 125.0], [135.0, 123.0]], ('Construction of premises and electricity', 0.9919567108154297)], [[[1156.0, 92.0], [1223.0, 92.0], [1223.0, 129.0], [1156.0, 129.0]], ('8.00', 0.9998969435691833)]]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = [line[0] for line in output]\n",
    "texts = [line[1][0] for line in output]\n",
    "probabilities = [line[1][1] for line in output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[15.0, 12.0], [101.0, 8.0], [103.0, 45.0], [16.0, 49.0]], [[136.0, 14.0], [280.0, 14.0], [280.0, 44.0], [136.0, 44.0]], [[963.0, 16.0], [1175.0, 16.0], [1175.0, 44.0], [963.0, 44.0]], [[16.0, 51.0], [41.0, 51.0], [41.0, 91.0], [16.0, 91.0]], [[131.0, 54.0], [207.0, 54.0], [207.0, 85.0], [131.0, 85.0]], [[1157.0, 52.0], [1222.0, 52.0], [1222.0, 85.0], [1157.0, 85.0]], [[18.0, 94.0], [40.0, 94.0], [40.0, 128.0], [18.0, 128.0]], [[135.0, 93.0], [669.0, 95.0], [669.0, 125.0], [135.0, 123.0]], [[1156.0, 92.0], [1223.0, 92.0], [1223.0, 129.0], [1156.0, 129.0]]]\n",
      "['Sr.No', 'Particulars', 'Amount in Lacs.', '1', 'Land', '3.00', '2', 'Construction of premises and electricity', '8.00']\n",
      "[0.9986014366149902, 0.9996967911720276, 0.9693554043769836, 0.8809970617294312, 0.9999060034751892, 0.988105058670044, 0.9904012084007263, 0.9919567108154297, 0.9998969435691833]\n"
     ]
    }
   ],
   "source": [
    "print(boxes)\n",
    "print(texts)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_boxes = image_cv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not mendatory\n",
    "\n",
    "for box,text in zip(boxes,texts):\n",
    "  cv2.rectangle(image_boxes, (int(box[0][0]),int(box[0][1])), (int(box[2][0]),int(box[2][1])),(0,0,255),1)\n",
    "  cv2.putText(image_boxes, text,(int(box[0][0]),int(box[0][1])),cv2.FONT_HERSHEY_SIMPLEX,1,(222,0,0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('TESTING\\detections.jpg', image_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = image_cv.copy()\n",
    "\n",
    "horiz_boxes = []\n",
    "vert_boxes = []\n",
    "\n",
    "for box in boxes:\n",
    "  x_h, x_v = 0,int(box[0][0])\n",
    "  y_h, y_v = int(box[0][1]),0\n",
    "  width_h,width_v = image_width, int(box[2][0]-box[0][0])\n",
    "  height_h,height_v = int(box[2][1]-box[0][1]),image_height\n",
    "\n",
    "  horiz_boxes.append([x_h,y_h,x_h+width_h,y_h+height_h])\n",
    "  vert_boxes.append([x_v,y_v,x_v+width_v,y_v+height_v])\n",
    "\n",
    "  cv2.rectangle(im,(x_h,y_h), (x_h+width_h,y_h+height_h),(0,0,255),1)\n",
    "  cv2.rectangle(im,(x_v,y_v), (x_v+width_v,y_v+height_v),(0,255,0),1)\n",
    "  # cv2.imwrite('TESTING\\horiz_vert.jpg',im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Max Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.18.0-cp310-cp310-win_amd64.whl (7.5 kB)\n",
      "Collecting tensorflow-intel==2.18.0\n",
      "  Using cached tensorflow_intel-2.18.0-cp310-cp310-win_amd64.whl (390.0 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting keras>=3.5.0\n",
      "  Using cached keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0\n",
      "  Using cached ml_dtypes-0.4.1-cp310-cp310-win_amd64.whl (126 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.70.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Collecting tensorboard<2.19,>=2.18\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.3.0)\n",
      "Collecting h5py>=3.11.0\n",
      "  Using cached h5py-3.12.1-cp310-cp310-win_amd64.whl (3.0 MB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (65.5.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Collecting optree\n",
      "  Using cached optree-0.14.0-cp310-cp310-win_amd64.whl (290 kB)\n",
      "Collecting rich\n",
      "  Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Requirement already satisfied: namex in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2025.1.31)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.19.1)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: optree, ml-dtypes, mdurl, MarkupSafe, markdown, h5py, grpcio, google-pasta, gast, astunparse, absl-py, werkzeug, markdown-it-py, tensorboard, rich, keras, tensorflow-intel, tensorflow\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'c:\\\\Users\\\\Hemant.Singhsidar\\\\Desktop\\\\Assignments\\\\DATP\\\\PDF Extraction\\\\Unstructured\\\\comb_env\\\\Lib\\\\site-packages\\\\tensorflow\\\\include\\\\tensorflow\\\\compiler\\\\xla\\\\mlir_hlo\\\\_virtual_includes\\\\chlo_legalize_to_hlo_inc_gen\\\\chlo_legalize_to_hlo\\\\generated_chlo_legalize_to_hlo.inc'\n",
      "HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
      "\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hemant.singhsidar\\desktop\\assignments\\datp\\pdf extraction\\unstructured\\comb_env\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horiz_out = tf.image.non_max_suppression(\n",
    "    horiz_boxes,\n",
    "    probabilities,\n",
    "    max_output_size = 1000,\n",
    "    iou_threshold=0.1,\n",
    "    score_threshold=float('-inf'),\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(horiz_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horiz_lines = np.sort(np.array(horiz_out))\n",
    "print(horiz_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_nms = image_cv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in horiz_lines:\n",
    "  cv2.rectangle(im_nms, (int(horiz_boxes[val][0]),int(horiz_boxes[val][1])), (int(horiz_boxes[val][2]),int(horiz_boxes[val][3])),(0,0,255),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('TESTING\\im_nms.jpg',im_nms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_out = tf.image.non_max_suppression(\n",
    "    vert_boxes,\n",
    "    probabilities,\n",
    "    max_output_size = 1000,\n",
    "    iou_threshold=0.1,\n",
    "    score_threshold=float('-inf'),\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vert_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_lines = np.sort(np.array(vert_out))\n",
    "print(vert_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in vert_lines:\n",
    "  cv2.rectangle(im_nms, (int(vert_boxes[val][0]),int(vert_boxes[val][1])), (int(vert_boxes[val][2]),int(vert_boxes[val][3])),(255,0,0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('TESTING\\im_nms.jpg',im_nms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_array = [[\"\" for i in range(len(vert_lines))] for j in range(len(horiz_lines))]\n",
    "print(np.array(out_array).shape)\n",
    "print(out_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unordered_boxes = []\n",
    "\n",
    "for i in vert_lines:\n",
    "  print(vert_boxes[i])\n",
    "  unordered_boxes.append(vert_boxes[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unordered_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_boxes = np.argsort(unordered_boxes)\n",
    "print(ordered_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(box_1, box_2):\n",
    "  return [box_2[0], box_1[1],box_2[2], box_1[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box_1, box_2):\n",
    "\n",
    "  x_1 = max(box_1[0], box_2[0])\n",
    "  y_1 = max(box_1[1], box_2[1])\n",
    "  x_2 = min(box_1[2], box_2[2])\n",
    "  y_2 = min(box_1[3], box_2[3])\n",
    "\n",
    "  inter = abs(max((x_2 - x_1, 0)) * max((y_2 - y_1), 0))\n",
    "  if inter == 0:\n",
    "      return 0\n",
    "\n",
    "  box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))\n",
    "  box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))\n",
    "\n",
    "  return inter / float(box_1_area + box_2_area - inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Assigning to Relevant Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(horiz_lines)):\n",
    "  for j in range(len(vert_lines)):\n",
    "    resultant = intersection(horiz_boxes[horiz_lines[i]], vert_boxes[vert_lines[ordered_boxes[j]]] )\n",
    "    \n",
    "    for b in range(len(boxes)):\n",
    "      the_box = [boxes[b][0][0],boxes[b][0][1],boxes[b][2][0],boxes[b][2][1]]\n",
    "      if(iou(resultant,the_box)>0.1):\n",
    "        out_array[i][j] = texts[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_array=np.array(out_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(out_array).to_csv('sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('sample.csv')\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = image_cv.copy()\n",
    "\n",
    "horiz_boxes = []\n",
    "vert_boxes = []\n",
    "\n",
    "for box in boxes:\n",
    "  x_h, x_v = 0,int(box[0][0])\n",
    "  y_h, y_v = int(box[0][1]),0\n",
    "  width_h,width_v = image_width, int(box[2][0]-box[0][0])\n",
    "  height_h,height_v = int(box[2][1]-box[0][1]),image_height\n",
    "\n",
    "  horiz_boxes.append([x_h,y_h,x_h+width_h,y_h+height_h])\n",
    "  vert_boxes.append([x_v,y_v,x_v+width_v,y_v+height_v])\n",
    "\n",
    "  cv2.rectangle(im,(x_h,y_h), (x_h+width_h,y_h+height_h),(0,0,255),1)\n",
    "  cv2.rectangle(im,(x_v,y_v), (x_v+width_v,y_v+height_v),(0,255,0),1)\n",
    "  # cv2.imwrite('TESTING\\horiz_vert.jpg',im)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "horiz_out = tf.image.non_max_suppression(\n",
    "    horiz_boxes,\n",
    "    probabilities,\n",
    "    max_output_size = 1000,\n",
    "    iou_threshold=0.1,\n",
    "    score_threshold=float('-inf'),\n",
    "    name=None\n",
    ")\n",
    "\n",
    "horiz_lines = np.sort(np.array(horiz_out))\n",
    "\n",
    "im_nms = image_cv.copy()\n",
    "\n",
    "for val in horiz_lines:\n",
    "  cv2.rectangle(im_nms, (int(horiz_boxes[val][0]),int(horiz_boxes[val][1])), (int(horiz_boxes[val][2]),int(horiz_boxes[val][3])),(0,0,255),1)\n",
    "\n",
    "cv2.imwrite('TESTING\\im_nms.jpg',im_nms)\n",
    "\n",
    "vert_out = tf.image.non_max_suppression(\n",
    "    vert_boxes,\n",
    "    probabilities,\n",
    "    max_output_size = 1000,\n",
    "    iou_threshold=0.1,\n",
    "    score_threshold=float('-inf'),\n",
    "    name=None\n",
    ")\n",
    "\n",
    "vert_lines = np.sort(np.array(vert_out))\n",
    "\n",
    "for val in vert_lines:\n",
    "  cv2.rectangle(im_nms, (int(vert_boxes[val][0]),int(vert_boxes[val][1])), (int(vert_boxes[val][2]),int(vert_boxes[val][3])),(255,0,0),1)\n",
    "\n",
    "cv2.imwrite('TESTING\\im_nms.jpg',im_nms)\n",
    "\n",
    "out_array = [[\"\" for i in range(len(vert_lines))] for j in range(len(horiz_lines))]\n",
    "\n",
    "unordered_boxes = []\n",
    "\n",
    "for i in vert_lines:\n",
    "  print(vert_boxes[i])\n",
    "  unordered_boxes.append(vert_boxes[i][0])\n",
    "\n",
    "ordered_boxes = np.argsort(unordered_boxes)\n",
    "\n",
    "def intersection(box_1, box_2):\n",
    "  return [box_2[0], box_1[1],box_2[2], box_1[3]]\n",
    "\n",
    " def iou(box_1, box_2):\n",
    "\n",
    "  x_1 = max(box_1[0], box_2[0])\n",
    "  y_1 = max(box_1[1], box_2[1])\n",
    "  x_2 = min(box_1[2], box_2[2])\n",
    "  y_2 = min(box_1[3], box_2[3])\n",
    "\n",
    "  inter = abs(max((x_2 - x_1, 0)) * max((y_2 - y_1), 0))\n",
    "  if inter == 0:\n",
    "      return 0\n",
    "\n",
    "  box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))\n",
    "  box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))\n",
    "\n",
    "  return inter / float(box_1_area + box_2_area - inter)\n",
    "\n",
    "for i in range(len(horiz_lines)):\n",
    "  for j in range(len(vert_lines)):\n",
    "    resultant = intersection(horiz_boxes[horiz_lines[i]], vert_boxes[vert_lines[ordered_boxes[j]]] )\n",
    "    \n",
    "    for b in range(len(boxes)):\n",
    "      the_box = [boxes[b][0][0],boxes[b][0][1],boxes[b][2][0],boxes[b][2][1]]\n",
    "      if(iou(resultant,the_box)>0.1):\n",
    "        out_array[i][j] = texts[b]\n",
    "\n",
    "out_array=np.array(out_array)\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "pd.DataFrame(out_array).to_csv('sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "# Initialize PaddleOCR for English\n",
    "ocr = PaddleOCR(lang='en')\n",
    "\n",
    "# Define input and output directories\n",
    "image_folder = \"Cropped Tables 1\"\n",
    "output_folder = \"Processed_Results\"\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to compute intersection of two bounding boxes\n",
    "def intersection(box_1, box_2):\n",
    "    return [box_2[0], box_1[1], box_2[2], box_1[3]]\n",
    "\n",
    "# Function to compute IoU (Intersection over Union)\n",
    "def iou(box_1, box_2):\n",
    "    x_1 = max(box_1[0], box_2[0])\n",
    "    y_1 = max(box_1[1], box_2[1])\n",
    "    x_2 = min(box_1[2], box_2[2])\n",
    "    y_2 = min(box_1[3], box_2[3])\n",
    "\n",
    "    inter = abs(max((x_2 - x_1, 0)) * max((y_2 - y_1), 0))\n",
    "    if inter == 0:\n",
    "        return 0\n",
    "\n",
    "    box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))\n",
    "    box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))\n",
    "\n",
    "    return inter / float(box_1_area + box_2_area - inter)\n",
    "\n",
    "# Get all image files from the folder\n",
    "image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Process each image\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    image_cv = cv2.imread(image_path)\n",
    "\n",
    "    # Ensure the image was loaded correctly\n",
    "    if image_cv is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    image_height, image_width = image_cv.shape[:2]\n",
    "\n",
    "    # Perform OCR\n",
    "    output = ocr.ocr(image_path)[0]\n",
    "\n",
    "    # Extract bounding boxes, detected text, and confidence scores\n",
    "    boxes = [line[0] for line in output]\n",
    "    texts = [line[1][0] for line in output]\n",
    "    probabilities = [line[1][1] for line in output]\n",
    "\n",
    "    # Create an output folder for the current image\n",
    "    image_output_folder = os.path.join(output_folder, os.path.splitext(image_file)[0])\n",
    "    os.makedirs(image_output_folder, exist_ok=True)\n",
    "\n",
    "    # Copy image for processing\n",
    "    im = image_cv.copy()\n",
    "\n",
    "    horiz_boxes = []\n",
    "    vert_boxes = []\n",
    "\n",
    "    # Generate horizontal and vertical bounding boxes\n",
    "    for box in boxes:\n",
    "        x_h, x_v = 0, int(box[0][0])\n",
    "        y_h, y_v = int(box[0][1]), 0\n",
    "        width_h, width_v = image_width, int(box[2][0] - box[0][0])\n",
    "        height_h, height_v = int(box[2][1] - box[0][1]), image_height\n",
    "\n",
    "        horiz_boxes.append([x_h, y_h, x_h + width_h, y_h + height_h])\n",
    "        vert_boxes.append([x_v, y_v, x_v + width_v, y_v + height_v])\n",
    "\n",
    "        cv2.rectangle(im, (x_h, y_h), (x_h + width_h, y_h + height_h), (0, 0, 255), 1)\n",
    "        cv2.rectangle(im, (x_v, y_v), (x_v + width_v, y_v + height_v), (0, 255, 0), 1)\n",
    "\n",
    "    # Save intermediate bounding box image\n",
    "    cv2.imwrite(os.path.join(image_output_folder, \"horiz_vert.jpg\"), im)\n",
    "\n",
    "    # Apply Non-Maximum Suppression (NMS) for horizontal boxes\n",
    "    horiz_out = tf.image.non_max_suppression(\n",
    "        horiz_boxes, probabilities, max_output_size=1000, iou_threshold=0.1, score_threshold=float('-inf')\n",
    "    )\n",
    "    horiz_lines = np.sort(np.array(horiz_out))\n",
    "\n",
    "    im_nms = image_cv.copy()\n",
    "\n",
    "    for val in horiz_lines:\n",
    "        cv2.rectangle(im_nms, (int(horiz_boxes[val][0]), int(horiz_boxes[val][1])),\n",
    "                      (int(horiz_boxes[val][2]), int(horiz_boxes[val][3])), (0, 0, 255), 1)\n",
    "\n",
    "    # Apply Non-Maximum Suppression (NMS) for vertical boxes\n",
    "    vert_out = tf.image.non_max_suppression(\n",
    "        vert_boxes, probabilities, max_output_size=1000, iou_threshold=0.1, score_threshold=float('-inf')\n",
    "    )\n",
    "    vert_lines = np.sort(np.array(vert_out))\n",
    "\n",
    "    for val in vert_lines:\n",
    "        cv2.rectangle(im_nms, (int(vert_boxes[val][0]), int(vert_boxes[val][1])),\n",
    "                      (int(vert_boxes[val][2]), int(vert_boxes[val][3])), (255, 0, 0), 1)\n",
    "\n",
    "    # Save the final NMS image\n",
    "    cv2.imwrite(os.path.join(image_output_folder, \"im_nms.jpg\"), im_nms)\n",
    "\n",
    "    # Create an empty table structure\n",
    "    out_array = [[\"\" for _ in range(len(vert_lines))] for _ in range(len(horiz_lines))]\n",
    "\n",
    "    # Sort bounding boxes based on vertical position\n",
    "    unordered_boxes = [vert_boxes[i][0] for i in vert_lines]\n",
    "    ordered_boxes = np.argsort(unordered_boxes)\n",
    "\n",
    "    # Fill the table using intersection and IoU logic\n",
    "    for i in range(len(horiz_lines)):\n",
    "        for j in range(len(vert_lines)):\n",
    "            resultant = intersection(horiz_boxes[horiz_lines[i]], vert_boxes[vert_lines[ordered_boxes[j]]])\n",
    "\n",
    "            for b in range(len(boxes)):\n",
    "                the_box = [boxes[b][0][0], boxes[b][0][1], boxes[b][2][0], boxes[b][2][1]]\n",
    "                if iou(resultant, the_box) > 0.1:\n",
    "                    out_array[i][j] = texts[b]\n",
    "\n",
    "    # Convert to a structured array\n",
    "    out_array = np.array(out_array)\n",
    "\n",
    "    # Save extracted text and structure as a CSV file\n",
    "    csv_output_path = os.path.join(image_output_folder, \"extracted_table.csv\")\n",
    "    pd.DataFrame(out_array).to_csv(csv_output_path, index=False, header=False)\n",
    "\n",
    "    print(f\"Processing completed for {image_file}. Results saved in {image_output_folder}\")\n",
    "\n",
    "print(\"\\nAll images processed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
