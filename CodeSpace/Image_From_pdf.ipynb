{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unstructured\n",
    "- https://unstructured.io/\n",
    "- https://unstructured-io.github.io/unstructured/index.html\n",
    "- https://docs.unstructured.io/api-reference/api-services/python-sdk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# %pip install \"unstructured[all-docs]\" unstructured-client watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Warning control\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hemant.Singhsidar\\Desktop\\CodeSpace\\.env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import JSON\n",
    "\n",
    "import json\n",
    "\n",
    "from unstructured_client import UnstructuredClient\n",
    "from unstructured_client.models import shared\n",
    "from unstructured_client.models.errors import SDKError\n",
    "\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.staging.base import dict_to_elements, elements_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial exploration ( extract elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unstructured.partition\n",
    "\n",
    "help(unstructured.partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hemant.Singhsidar\\Desktop\\CodeSpace\\.env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Specify the path to your PDF file\n",
    "filename = \"PDF STORE/2501.00663v1.pdf\"\n",
    "\n",
    "# Call the partition_pdf function\n",
    "# Returns a List[Element] present in the pages of the parsed pdf document\n",
    "elements = partition_pdf(filename)\n",
    "\n",
    "# Now, elements is a list of all elements present in the pages of the parsed pdf document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We don't see `Image`, image information is not extracted as we expected, lets use different strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image extraction from PDF\n",
    "- Now let’s say that your PDF has tables and let’s say you want to preserve the image data. \n",
    "- You will have to specify the [strategy](https://unstructured-io.github.io/unstructured/best_practices/strategies.html) parameter as `hi_res`. This will use a combination of computer vision and Optical Character Recognition (OCR) to extract the tables and maintain the structure. \n",
    "\n",
    "> Note: For even better image extraction Unstructured offers an API that improves upon the existing open source models.\n",
    "\n",
    "> Depending upon machine, you might face different module / library issues, these links might help\n",
    "- https://stackoverflow.com/questions/59690698/modulenotfounderror-no-module-named-lzma-when-building-python-using-pyenv-on\n",
    "- https://unstructured-io.github.io/unstructured/installation/full_installation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "elements = partition_pdf(filename=filename,\n",
    "                     strategy='hi_res',\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Header', 'FigureCaption', 'ListItem', 'UncategorizedText', 'Image', 'NarrativeText', 'Formula', 'Table', 'Title'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "element_dict = [el.to_dict() for el in elements]\n",
    "output = json.dumps(element_dict, indent=2)\n",
    "unique_types = set()\n",
    "\n",
    "for item in element_dict:\n",
    "    unique_types.add(item['type'])\n",
    "\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [el for el in elements if el.category == \"Image\"]\n",
    "\n",
    "# print(images[2].text)\n",
    "# print(images[2].metadata.text_as_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Image at 0x1ffdba814b0>,\n",
       " <unstructured.documents.elements.Image at 0x1ffdba837f0>,\n",
       " <unstructured.documents.elements.Image at 0x1ffdabbda20>,\n",
       " <unstructured.documents.elements.Image at 0x1ffdabbcaf0>,\n",
       " <unstructured.documents.elements.Image at 0x1ffdabbcc40>,\n",
       " <unstructured.documents.elements.Image at 0x1ffeb2627a0>,\n",
       " <unstructured.documents.elements.Image at 0x1ffeb318a90>,\n",
       " <unstructured.documents.elements.Image at 0x1ffeb318c10>,\n",
       " <unstructured.documents.elements.Image at 0x1ffeb3198a0>,\n",
       " <unstructured.documents.elements.Image at 0x1ffeb319960>,\n",
       " <unstructured.documents.elements.Image at 0x1ffeb319b40>,\n",
       " <unstructured.documents.elements.Image at 0x1ffeb319c60>,\n",
       " <unstructured.documents.elements.Image at 0x1ffeb31acb0>,\n",
       " <unstructured.documents.elements.Image at 0x1ffeab2fd90>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another way ( extract / display images + elements )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get elements\n",
    "path = \"images\"\n",
    "raw_pdf_elements = partition_pdf(filename=filename,\n",
    "                                 # Unstructured first finds embedded image blocks\n",
    "                                 # Only applicable if `strategy=hi_res`\n",
    "                                 extract_images_in_pdf=True,\n",
    "                                 strategy = \"hi_res\",\n",
    "                                 infer_table_structure=True,\n",
    "                                 # Only applicable if `strategy=hi_res`\n",
    "                                 extract_image_block_output_dir = path,\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"ae76beb8b6ba3840cf7c218ebd451188\",\n",
      "    \"text\": \"4\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            583.4999999999998\n",
      "          ],\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            611.2777777777776\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            611.2777777777776\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            583.4999999999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"3b3b7b2f2b303144b9b46b127b608af2\",\n",
      "    \"text\": \"2024\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            51.0,\n",
      "            585.0\n",
      "          ],\n",
      "          [\n",
      "            51.0,\n",
      "            692.0\n",
      "          ],\n",
      "          [\n",
      "            88.0,\n",
      "            692.0\n",
      "          ],\n",
      "          [\n",
      "            88.0,\n",
      "            585.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"98444d1a397190296801f0122c0b0fa0\",\n",
      "    \"text\": \"2\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            611.2777777777776\n",
      "          ],\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            639.0555555555554\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            639.0555555555554\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            611.2777777777776\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"ebc8aef60edf874ef0c26276dbe0bf9e\",\n",
      "    \"text\": \"0\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            639.0555555555554\n",
      "          ],\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            666.8333333333331\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            666.8333333333331\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            639.0555555555554\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"a61efef3b4d0a1cb062ec015097b08b7\",\n",
      "    \"text\": \"2\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            666.8333333333331\n",
      "          ],\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            694.611111111111\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            694.611111111111\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            666.8333333333331\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Header\",\n",
      "    \"element_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "    \"text\": \"c e D 1 3 ] G L . s c [ 1 v 3 6 6 0 0 . 1 0 5 2\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5007292628288269,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            691.5743408203125\n",
      "          ],\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            1413.611111111111\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            1413.611111111111\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            691.5743408203125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"64051a16861382fe6b4ad393d82bae48\",\n",
      "    \"text\": \":\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            1413.611111111111\n",
      "          ],\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            1429.0555555555557\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            1429.0555555555557\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            1413.611111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"0434bbf276c234f08789b90f8b6b1d6f\",\n",
      "    \"text\": \"v\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            1429.0555555555557\n",
      "          ],\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            1456.8333333333335\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            1456.8333333333335\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            1429.0555555555557\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"9179d8cc861adb2b5257c86d2f5031fd\",\n",
      "    \"text\": \"arXiv\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            50.0,\n",
      "            1429.0\n",
      "          ],\n",
      "          [\n",
      "            50.0,\n",
      "            1553.0\n",
      "          ],\n",
      "          [\n",
      "            88.0,\n",
      "            1553.0\n",
      "          ],\n",
      "          [\n",
      "            88.0,\n",
      "            1429.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"f80706bc38d55a50473e05f7d0d9f439\",\n",
      "    \"text\": \"i\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            1456.8333333333335\n",
      "          ],\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            1472.2777777777776\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            1472.2777777777776\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            1456.8333333333335\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"2805cbe3fd490af78b39effe65221df5\",\n",
      "    \"text\": \"X\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            1472.2777777777776\n",
      "          ],\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            1512.388888888889\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            1512.388888888889\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            1472.2777777777776\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"b06ceacb4e1b1372c5e61f3dc87c5564\",\n",
      "    \"text\": \"r\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            1512.388888888889\n",
      "          ],\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            1530.888888888889\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            1530.888888888889\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            1512.388888888889\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"ab01bd2ddd49b583abac6f2aa190bbb2\",\n",
      "    \"text\": \"a\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            1530.888888888889\n",
      "          ],\n",
      "          [\n",
      "            45.388888888888886,\n",
      "            1555.5555555555554\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            1555.5555555555554\n",
      "          ],\n",
      "          [\n",
      "            100.94444444444446,\n",
      "            1530.888888888889\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"dc616f19f1c3b5c6044b3791dca01fb2\",\n",
      "    \"text\": \"Titans: Learning to Memorize at Test Time\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            461.83888888888885,\n",
      "            298.4794444444443\n",
      "          ],\n",
      "          [\n",
      "            461.83888888888885,\n",
      "            346.3\n",
      "          ],\n",
      "          [\n",
      "            1298.1725850000003,\n",
      "            346.3\n",
      "          ],\n",
      "          [\n",
      "            1298.1725850000003,\n",
      "            298.4794444444443\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"7556ea94cf4df7dc9b7d89e0db26dc96\",\n",
      "    \"text\": \"Ali Behrouz\\u2020, Peilin Zhong\\u2020, and Vahab Mirrokni\\u2020\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            541.9361111111111,\n",
      "            412.62444444444446\n",
      "          ],\n",
      "          [\n",
      "            541.9361111111111,\n",
      "            448.5944444444445\n",
      "          ],\n",
      "          [\n",
      "            1215.2972222222222,\n",
      "            448.5944444444445\n",
      "          ],\n",
      "          [\n",
      "            1215.2972222222222,\n",
      "            412.62444444444446\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"be258a5f527696ad84c3fdd838869dbc\",\n",
      "    \"text\": \"\\u2020Google Research\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            760.9472222222223,\n",
      "            497.6355555555557\n",
      "          ],\n",
      "          [\n",
      "            760.9472222222223,\n",
      "            533.6055555555557\n",
      "          ],\n",
      "          [\n",
      "            999.0541911111113,\n",
      "            533.6055555555557\n",
      "          ],\n",
      "          [\n",
      "            999.0541911111113,\n",
      "            497.6355555555557\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"fbcc8565ecdc4b03f3ca02d5be2f1660\",\n",
      "    \"text\": \"{alibehrouz, peilinz, mirrokni}@google.com\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5302138924598694,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            612.71728515625,\n",
      "            551.7770933333335\n",
      "          ],\n",
      "          [\n",
      "            612.71728515625,\n",
      "            577.0736694335938\n",
      "          ],\n",
      "          [\n",
      "            1153.0628662109375,\n",
      "            577.0736694335938\n",
      "          ],\n",
      "          [\n",
      "            1153.0628662109375,\n",
      "            551.7770933333335\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"be258a5f527696ad84c3fdd838869dbc\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"2fa0072307b127b5887126f2e385aac8\",\n",
      "    \"text\": \"Abstract\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8325791358947754,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            831.1800537109375,\n",
      "            652.8217733333333\n",
      "          ],\n",
      "          [\n",
      "            831.1800537109375,\n",
      "            677.7284400000001\n",
      "          ],\n",
      "          [\n",
      "            931.5001831054688,\n",
      "            677.7284400000001\n",
      "          ],\n",
      "          [\n",
      "            931.5001831054688,\n",
      "            652.8217733333333\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"06457ac1dfb6f5852dcfb21fd70c9360\",\n",
      "    \"text\": \"Over more than a decade there has been an extensive research effort of how effectively utilize recurrent models and\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            306.5444444444444,\n",
      "            692.7294444444445\n",
      "          ],\n",
      "          [\n",
      "            306.5444444444444,\n",
      "            717.6361111111112\n",
      "          ],\n",
      "          [\n",
      "            1490.8157967644447,\n",
      "            717.6361111111112\n",
      "          ],\n",
      "          [\n",
      "            1490.8157967644447,\n",
      "            692.7294444444445\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"2fa0072307b127b5887126f2e385aac8\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3bd58d1d430055d1faea37ff4f843dae\",\n",
      "    \"text\": \"attentions. While recurrent models aim to compress the data into a fixed-size memory (called hidden state), attention allows attending to the entire context window, capturing the direct dependencies of all tokens. This more accurate modeling of dependencies, however, comes with a quadratic cost, limiting the model to a fixed-length context. We present a new neural long-term memory module that learns to memorize historical context and helps an attention to attend to the current context while utilizing long past information. We show that this neural memory has the advantage of a fast parallelizable training while maintaining a fast inference. From a memory perspective, we argue that attention due to its limited context but accurate dependency modeling performs as a short-term memory, while neural memory due to its ability to memorize the data, acts as a long-term, more persistent, memory. Based on these two modules, we introduce a new family of architectures, called Titans, and present three variants to address how one can effectively incorporate memory into this architecture. Our experimental results on language modeling, common-sense reasoning, genomics, and time series tasks show that Titans are more effective than Transformers and recent modern linear recurrent models. They further can effectively scale to larger than 2M context window size with higher accuracy in needle-in-haystack tasks compared to baselines.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.951355516910553,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            268.43888888888887,\n",
      "            699.8678588867188\n",
      "          ],\n",
      "          [\n",
      "            268.43888888888887,\n",
      "            1118.1175537109375\n",
      "          ],\n",
      "          [\n",
      "            1498.198974609375,\n",
      "            1118.1175537109375\n",
      "          ],\n",
      "          [\n",
      "            1498.198974609375,\n",
      "            699.8678588867188\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"2fa0072307b127b5887126f2e385aac8\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9e61532d939b64b4ef05f4fe075cbcc8\",\n",
      "    \"text\": \"\\u201cThe true art of memory is the art of attention!\\\"\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1013.1944444444445,\n",
      "            1221.0655555555554\n",
      "          ],\n",
      "          [\n",
      "            1013.1944444444445,\n",
      "            1245.9722222222222\n",
      "          ],\n",
      "          [\n",
      "            1499.3974844444444,\n",
      "            1245.9722222222222\n",
      "          ],\n",
      "          [\n",
      "            1499.3974844444444,\n",
      "            1221.0655555555554\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"2fa0072307b127b5887126f2e385aac8\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"cc4877da7b2209d6a9dfb8e4d7cfaefe\",\n",
      "    \"text\": \"1 Introduction\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8291983604431152,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1244.527145\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1284.3777005555555\n",
      "          ],\n",
      "          [\n",
      "            490.7098027777778,\n",
      "            1284.3777005555555\n",
      "          ],\n",
      "          [\n",
      "            490.7098027777778,\n",
      "            1244.527145\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"0b18fdcaf3c5c667694ea193f6859363\",\n",
      "    \"text\": \"\\u2014 Samuel Johnson, 1787\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1314.2972222222222,\n",
      "            1271.385\n",
      "          ],\n",
      "          [\n",
      "            1314.2972222222222,\n",
      "            1296.2916666666667\n",
      "          ],\n",
      "          [\n",
      "            1560.5743422222224,\n",
      "            1296.2916666666667\n",
      "          ],\n",
      "          [\n",
      "            1560.5743422222224,\n",
      "            1271.385\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1b4526c12c274aa7bced0ee07a49325d\",\n",
      "    \"text\": \"Transformers, pure attention-based architectures (Vaswani et al. 2017), have been firmly established as state-of- the-art models in sequence modeling, mainly due to their in-context learning and ability to learn at scale (Kaplan et al. 2020). The primary building blocks of Transformers\\u2013attention modules\\u2014function as associative memory blocks (Bietti et al. 2024), where they learn to store key-value associations and retrieve them by computing pairwise similarity between queries (i.e., search signals) and keys (i.e., contexts). Accordingly, by design, the output of a Transformer is exclusively conditioned on the direct dependencies of tokens in the current context window. This accurate modeling of dependencies, however, comes with quadratic time and memory complexity in terms of the context length. In complex real-world tasks (e.g., language modeling (N. F. Liu et al. 2024), video understanding (C.-Y. Wu et al. 2019), long-term time series forecasting (H. Zhou et al. 2021)), the context window can become extremely large, making the applicability of Transformers challenging in these downstream tasks.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9560855031013489,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1329.0083333333334\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1669.036865234375\n",
      "          ],\n",
      "          [\n",
      "            1566.0584716796875,\n",
      "            1669.036865234375\n",
      "          ],\n",
      "          [\n",
      "            1566.0584716796875,\n",
      "            1329.0083333333334\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2017\",\n",
      "          \"url\": \"cite.0@transformers\",\n",
      "          \"start_index\": 65\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2020\",\n",
      "          \"url\": \"cite.0@kaplan2020scaling\",\n",
      "          \"start_index\": 122\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@bietti2024birth\",\n",
      "          \"start_index\": 244\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@liu2024lost\",\n",
      "          \"start_index\": 764\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.0@wu2019long\",\n",
      "          \"start_index\": 808\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@zhou2021informer\",\n",
      "          \"start_index\": 865\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"0b18fdcaf3c5c667694ea193f6859363\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4ff7bc09f97313a9d922c70e7cf43dbb\",\n",
      "    \"text\": \"To overcome the scalability issue of Transformers, recent studies aim to design different variants of linear Transform-\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1686.1983333333333\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1713.8722222222223\n",
      "          ],\n",
      "          [\n",
      "            1564.668306944445,\n",
      "            1713.8722222222223\n",
      "          ],\n",
      "          [\n",
      "            1564.668306944445,\n",
      "            1686.1983333333333\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"0b18fdcaf3c5c667694ea193f6859363\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a40741f6d6f96bee12b6e002a3c03fd9\",\n",
      "    \"text\": \"ers (Kacham, Mirrokni, and P. Zhong 2024; Katharopoulos et al. 2020; S. Yang, B. Wang, Shen, et al. 2024), where softmax is replaced by a kernel function in the attention (see \\u00a72.1 for details), resulting in a significant drop in memory consumption. Despite efficiency and the ability to scale to longer context, linear Transformers do not show competitive performance compared to Transformers as the kernel trick makes the model a linear recurrent network, in which the data is compressed into a matrix-valued states (Katharopoulos et al. 2020). This, however, brings a contradictory fact about linear recurrent (or linear Transformers) models: On one hand, we use these linear models to enhance scalability and efficiency (linear vs. quadratic complexity), whose advantages is appeared for very long context; On the other hand, a very long context cannot be properly compressed in a small vector-valued or matrix-valued states (S. Wang 2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9531335234642029,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1693.3958740234375\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1982.5596923828125\n",
      "          ],\n",
      "          [\n",
      "            1569.8333740234375,\n",
      "            1982.5596923828125\n",
      "          ],\n",
      "          [\n",
      "            1569.8333740234375,\n",
      "            1693.3958740234375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@kacham2024polysketchformer\",\n",
      "          \"start_index\": 155\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2020\",\n",
      "          \"url\": \"cite.0@katharopoulos2020transformers\",\n",
      "          \"start_index\": 182\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024gatedattn\",\n",
      "          \"start_index\": 219\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2 . 1\",\n",
      "          \"url\": \"subsection.2.1\",\n",
      "          \"start_index\": 296\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2020\",\n",
      "          \"url\": \"cite.0@katharopoulos2020transformers\",\n",
      "          \"start_index\": 656\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"0b18fdcaf3c5c667694ea193f6859363\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"007a240dc57502b974430836e347dcf8\",\n",
      "    \"text\": \"1\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            873.5666666666667,\n",
      "            2057.7427777777775\n",
      "          ],\n",
      "          [\n",
      "            873.5666666666667,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350250000001,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350250000001,\n",
      "            2057.7427777777775\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"0b18fdcaf3c5c667694ea193f6859363\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"bfd6020af4ea5e1297b2a1c971d2d239\",\n",
      "    \"text\": \"Furthermore, beyond efficiency, most existing architectures\\u2013ranging from Hopfield Networks (Hopfield 1982) to LSTMs (J\\u00fcr- gen Schmidhuber and Hochreiter 1997) and Transformers (Vaswani et al. 2017)\\u2013face challenges when dealing with general- ization, length extrapolation, and/or reasoning (Anil et al. 2022; Qin, Y. Zhong, and Deng 2024), all of which are inseparable parts of many hard real-world tasks. Although these architectures draw inspiration from the human brain, each of which are missing: (1) a crucial component for learning process\\u2014such as short-term memory, long-term memory, meta-memory, attending to current context, etc. (Cowan 2008); (2) how these components are interconnected systems that can operate independently; and/or (3) the ability to actively learn from data and memorize the abstraction of past history. We argue that in an effective learning paradigm, similar to human brain, there are distinct yet interconnected modules, each of which is responsible for a component crucial to the learning process.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9529550075531006,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            202.39277777777778\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            501.5894470214844\n",
      "          ],\n",
      "          [\n",
      "            1571.102783203125,\n",
      "            501.5894470214844\n",
      "          ],\n",
      "          [\n",
      "            1571.102783203125,\n",
      "            202.39277777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"1982\",\n",
      "          \"url\": \"cite.0@hopfield1982neural\",\n",
      "          \"start_index\": 97\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"1997\",\n",
      "          \"url\": \"cite.0@LSTM\",\n",
      "          \"start_index\": 149\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2017\",\n",
      "          \"url\": \"cite.0@transformers\",\n",
      "          \"start_index\": 188\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.0@anil2022exploring\",\n",
      "          \"start_index\": 298\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@qin2024exploring\",\n",
      "          \"start_index\": 328\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2008\",\n",
      "          \"url\": \"cite.0@cowan2008differences\",\n",
      "          \"start_index\": 641\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"0b18fdcaf3c5c667694ea193f6859363\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"0fbf17e1930416d8476ab4bf94d006ea\",\n",
      "    \"text\": \"Memory Perspective\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8467845916748047,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.60475158691406,\n",
      "            547.529031111111\n",
      "          ],\n",
      "          [\n",
      "            198.60475158691406,\n",
      "            580.7379199999998\n",
      "          ],\n",
      "          [\n",
      "            512.2913818359375,\n",
      "            580.7379199999998\n",
      "          ],\n",
      "          [\n",
      "            512.2913818359375,\n",
      "            547.529031111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"da65c0ed91096c0827b75a3a3ba8fcc4\",\n",
      "    \"text\": \"Memory is a fundamental mental process and is an inseparable component of human learning (Terry 2017). Without a properly functioning memory system, humans and animals would be restricted to basic reflexes and stereotyped behaviors. Accordingly, memory has been the inspiration for many seminal research in machine learning literature; e.g., Hopfield Networks (Hopfield 1982), LSTMs (J\\u00fcrgen Schmidhuber and Hochreiter 1997), and Transformers (Vaswani et al. 2017).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9497999548912048,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            596.4094444444445\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            759.14794921875\n",
      "          ],\n",
      "          [\n",
      "            1568.2139892578125,\n",
      "            759.14794921875\n",
      "          ],\n",
      "          [\n",
      "            1568.2139892578125,\n",
      "            596.4094444444445\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2017\",\n",
      "          \"url\": \"cite.0@terry2017learning\",\n",
      "          \"start_index\": 115\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"1982\",\n",
      "          \"url\": \"cite.0@hopfield1982neural\",\n",
      "          \"start_index\": 386\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"1997\",\n",
      "          \"url\": \"cite.0@LSTM\",\n",
      "          \"start_index\": 434\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"0fbf17e1930416d8476ab4bf94d006ea\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"031b49a6b702802dd96a79a4a9fcb3b8\",\n",
      "    \"text\": \"Taking inspiration from the common definitions of memory and learning in neuropsychology literature (Okano, Hirano, and Balaban 2000), most existing architectures consider memory as a neural update caused by an input, and define learning as a process for acquiring effective and useful memory, given an objective. In this perspective, Recurrent Neural Networks (RNNs) (Williams and Zipser 1989) can be defined as models with a vector-valued memory module M (also called hidden state) with two main steps: Given a new input \\ud835\\udc65\\ud835\\udc61 at time \\ud835\\udc61, the model (1) updates the memory using a function \\ud835\\udc53 (M\\ud835\\udc61 \\u22121, \\ud835\\udc65\\ud835\\udc61 ) (with compression); and (2) retrieves the corresponding memory of input using a function \\ud835\\udc54(M\\ud835\\udc61, \\ud835\\udc65\\ud835\\udc61 ) (see \\u00a72.1 for details). Similarly, Transformers can be seen as architectures with a growing memory and two similar steps. That is, the pair of key and value matrices acts as the model\\u2019s memory, and the model: (1) updates the memory by appending the key and value to the memory (without compression), and (2) retrieves query vectors\\u2019 corresponding memory by finding the similarity of query and key vectors, which is then used to weight the value vectors for the output.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9545361399650574,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            779.0566666666666\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1111.074462890625\n",
      "          ],\n",
      "          [\n",
      "            1572.758544921875,\n",
      "            1111.074462890625\n",
      "          ],\n",
      "          [\n",
      "            1572.758544921875,\n",
      "            779.0566666666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2000\",\n",
      "          \"url\": \"cite.0@okano2000learning\",\n",
      "          \"start_index\": 127\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"1989\",\n",
      "          \"url\": \"cite.0@williams1989learning\",\n",
      "          \"start_index\": 386\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2 . 1\",\n",
      "          \"url\": \"subsection.2.1\",\n",
      "          \"start_index\": 704\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"0fbf17e1930416d8476ab4bf94d006ea\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1788f2c1c7686bab2f3c13a69a9d593f\",\n",
      "    \"text\": \"This perspective, can help us better understand existing paradigms, their critical differences, and design more effective architectures. For example, the main difference between Transformers (Vaswani et al. 2017) and linear Transform- ers (Katharopoulos et al. 2020) is the memory structure as well as the memory updating step, in which linear Transformers compress the historical data into a fixed-size matrix-valued memory while Transformers keep all historical data (within the context length) without any compression. While both linear Transformers and linear RNNs (including state space models) compress the information in memory update step, the critical difference lies in the structure of the memory, where linear RNNs (vs. linear Transformers) use a vector-valued memory (vs. matrix-valued memory). Therefore, this perspective motivates us to ask: (Q1) What constitute a good structure for the memory? (Q2) What is a proper memory update mechanism? and (Q3) What is a good memory retrieval process?\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9561518430709839,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            1127.751111111111\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            1427.4871127777778\n",
      "          ],\n",
      "          [\n",
      "            1572.2919921875,\n",
      "            1427.4871127777778\n",
      "          ],\n",
      "          [\n",
      "            1572.2919921875,\n",
      "            1127.751111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2017\",\n",
      "          \"url\": \"cite.0@transformers\",\n",
      "          \"start_index\": 204\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2020\",\n",
      "          \"url\": \"cite.0@katharopoulos2020transformers\",\n",
      "          \"start_index\": 258\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"0fbf17e1930416d8476ab4bf94d006ea\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"8aabbe8092457b66f46195f13ef080f4\",\n",
      "    \"text\": \"Revisiting our understanding of human memory, it is neither a unitary process nor it serves a single function (Cowan 2008). In fact, memory is a confederation of systems\\u2013e.g., short-term, working, and long-term memory\\u2013each serving a different function with different neural structures, and each capable of operating independently (Willingham 1997). This fact motivates us to ask: (Q4) How to design an efficient architecture that incorporates different interconnected memory modules. Finally, storing a memory is a neural process that requires to encode and store the abstraction of the past. It can be over-simplification to assume a single vector or a matrix, whose parameters are encoding the data in a linear manner, are enough for storing long-term history. (Q5) Is a deep memory module needed to effectively store/remember long past?\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9537711143493652,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1443.2344444444443\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1706.5540771484375\n",
      "          ],\n",
      "          [\n",
      "            1571.5101318359375,\n",
      "            1706.5540771484375\n",
      "          ],\n",
      "          [\n",
      "            1571.5101318359375,\n",
      "            1443.2344444444443\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2008\",\n",
      "          \"url\": \"cite.0@cowan2008differences\",\n",
      "          \"start_index\": 1120\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"1997\",\n",
      "          \"url\": \"cite.0@willingham1997systems\",\n",
      "          \"start_index\": 1343\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"0fbf17e1930416d8476ab4bf94d006ea\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"dafd65efc97d54029818f315014c9303\",\n",
      "    \"text\": \"Contributions and Roadmap\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8583268523216248,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1754.059814453125\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1788.3684755555555\n",
      "          ],\n",
      "          [\n",
      "            628.5275022222222,\n",
      "            1788.3684755555555\n",
      "          ],\n",
      "          [\n",
      "            628.5275022222222,\n",
      "            1754.059814453125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"d044351a8edb5f7286807da54e5a69c2\",\n",
      "    \"text\": \"In this paper, we aim to answer the above five questions by designing a long-term neural memory module, that can efficiently and effectively learn to memorize at test time. Building upon its design, we discuss how it can be incorporated into an architecture.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9365269541740417,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1804.0399999999997\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1899.3616943359375\n",
      "          ],\n",
      "          [\n",
      "            1565.8660888671875,\n",
      "            1899.3616943359375\n",
      "          ],\n",
      "          [\n",
      "            1565.8660888671875,\n",
      "            1804.0399999999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"dafd65efc97d54029818f315014c9303\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c06bcb6d47e9e25fbd9feb29b4585b44\",\n",
      "    \"text\": \"Neural Memory (\\u00a73). We present a (deep) neural long-term memory that (as a meta in-context model) learns how to memorize/store the data into its parameters at test time. Inspired by human long-term memory system (Mandler 2014),\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9253687858581543,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1920.2705555555556\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1984.8072509765625\n",
      "          ],\n",
      "          [\n",
      "            1563.0466792055547,\n",
      "            1984.8072509765625\n",
      "          ],\n",
      "          [\n",
      "            1563.0466792055547,\n",
      "            1920.2705555555556\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"3\",\n",
      "          \"url\": \"section.3\",\n",
      "          \"start_index\": 16\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"dafd65efc97d54029818f315014c9303\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"eed5f55e0cf28b104b73550a502d0e7b\",\n",
      "    \"text\": \"2\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            873.5666666666666,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            873.5666666666666,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350249999999,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350249999999,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"dafd65efc97d54029818f315014c9303\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b10095f7042651ad33667419f5261c7a\",\n",
      "    \"text\": \"we design this memory module so an event that violates the expectations (being surprising) is more memorable. To this end, we measure the surprise of an input with the gradient of the neural network with respect to the input in associative memory loss (see \\u00a73.1 for details). To better handle the limited memory, we present a decaying mechanism that consider the proportion of memory size and the amount of data surprise, resulting in better memory management. We show that this decay mechanism is in fact the generalization of forgetting mechanism in modern recurrent models (Dao and Gu 2024; Gu and Dao 2024; S. Yang, Kautz, and Hatamizadeh 2024). Interestingly, we find that this mechanism is equivalent to optimizing a meta neural network with mini-batch gradient descent, momentum, and weight decay. Building upon tensorizing mini-batch gradient descent to use more matmul operations (Yu Sun et al. 2024), we present a fast and parallelizable algorithm to train our deep neural long-term memory.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9539293050765991,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            202.39277777777778\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            500.7691955566406\n",
      "          ],\n",
      "          [\n",
      "            1569.88037109375,\n",
      "            500.7691955566406\n",
      "          ],\n",
      "          [\n",
      "            1569.88037109375,\n",
      "            202.39277777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"3 . 1\",\n",
      "          \"url\": \"subsection.3.1\",\n",
      "          \"start_index\": 258\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@dao2024transformers\",\n",
      "          \"start_index\": 588\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@gu2024mamba\",\n",
      "          \"start_index\": 605\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024gated\",\n",
      "          \"start_index\": 643\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@sun2024learning\",\n",
      "          \"start_index\": 903\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"dafd65efc97d54029818f315014c9303\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"20a2f94f10d8f87c8b497d9fc0799517\",\n",
      "    \"text\": \"Titans Architectures (\\u00a74). After designing the long-term neural memory, an important remaining question is how to effectively and efficiently incorporate memory into a deep learning architecture. We present Titans, a family of deep models that consists of three hyper-heads: (1) Core: this module consists of the short-term memory, and is responsible for the main flow of processing the data (we use attention with limited window size); (2) Long-term Memory: this branch is our neural long-term memory module that is responsible to store/remember long past; (3) Persistent Memory: this is a set of learnable but date-independent parameters that encodes the knowledge about a task. Finally, as a proof of concept, we present three variants of Titans, in which we incorporate memory as: (i) a context, (ii) a layer, and (iii) a gated branch.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9561544060707092,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.0861111111111,\n",
      "            517.878888888889\n",
      "          ],\n",
      "          [\n",
      "            199.0861111111111,\n",
      "            751.0279541015625\n",
      "          ],\n",
      "          [\n",
      "            1572.8656005859375,\n",
      "            751.0279541015625\n",
      "          ],\n",
      "          [\n",
      "            1572.8656005859375,\n",
      "            517.878888888889\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"4\",\n",
      "          \"url\": \"section.4\",\n",
      "          \"start_index\": 23\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"dafd65efc97d54029818f315014c9303\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0bc9ea02c9460b8e0563e9a001a63eff\",\n",
      "    \"text\": \"Experimental Results (\\u00a75). We perform experimental evaluations on language modeling, commonsense reasoning, recall- intensive, needle in haystack, time series forecasting, and DNA modeling tasks. We observe that our Titan architecture outperforms all modern recurrent models as well as their hybrid variants (combining with sliding-window attention) across a comprehensive set of benchmarks. Furthermore, Titans outperforms Transformers with the same context window, and show competitive performance with Transformers that use the entire context. This results are achieved while, contrary to Transformers, Titans scale to larger than 2M context window size.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9531001448631287,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            766.9427777777779\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            965.3643798828125\n",
      "          ],\n",
      "          [\n",
      "            1568.655029296875,\n",
      "            965.3643798828125\n",
      "          ],\n",
      "          [\n",
      "            1568.655029296875,\n",
      "            766.9427777777779\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"5\",\n",
      "          \"url\": \"section.5\",\n",
      "          \"start_index\": 23\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"dafd65efc97d54029818f315014c9303\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"737bbf88de406398ae1aa6597e489690\",\n",
      "    \"text\": \"2 Preliminaries\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8539012670516968,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1016.1132202148438\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1058.9138116666668\n",
      "          ],\n",
      "          [\n",
      "            508.08966064453125,\n",
      "            1058.9138116666668\n",
      "          ],\n",
      "          [\n",
      "            508.08966064453125,\n",
      "            1016.1132202148438\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4b22948a2b1bcbd7e5716129d49253a4\",\n",
      "    \"text\": \"In this section, we discuss the notation and some background concepts that we use though the paper. We let \\ud835\\udc65 \\u2208 R\\ud835\\udc41 \\u00d7\\ud835\\udc51in be the input, M be a neural network (neural memory module), Q, K, V be the query, key and value of the attention mechanism, and M be the attention mask. When segmenting the sequence, we use S(\\ud835\\udc56 ) to refer to the \\ud835\\udc56-th segment. Through the paper, we abuse the notation and use subscripts to refer to a specific element of a matrix, vector, or segments. For example, we let S(\\ud835\\udc56 ) \\ud835\\udc57 be the \\ud835\\udc57-th token in the \\ud835\\udc56-th segment. The only exception is subscripts with \\ud835\\udc61, which we reserved to index recurrence over time, or the state of a neural network at time \\ud835\\udc61. Given a neural network N and a data sample \\ud835\\udc65, we use N (\\ud835\\udc65) (resp. N \\u2217 (\\ud835\\udc65)) to refer to the forward pass with (resp. without) weight adjustment. Also, we abuse the notation and use N (\\ud835\\udc58 ) to refer to the \\ud835\\udc58-th layer of the neural network. In the following, we first, discuss the backgrounds for attention and its efficient variants followed by a review of modern linear RNNs. Finally, we discuss a memory perspective of these architectures that motivates us to design Titans.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9555183053016663,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            197.6663360595703,\n",
      "            1074.0472222222222\n",
      "          ],\n",
      "          [\n",
      "            197.6663360595703,\n",
      "            1419.557373046875\n",
      "          ],\n",
      "          [\n",
      "            1569.7445068359375,\n",
      "            1419.557373046875\n",
      "          ],\n",
      "          [\n",
      "            1569.7445068359375,\n",
      "            1074.0472222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"737bbf88de406398ae1aa6597e489690\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"091a2cbb405d72b4a0b75ca0b2d41adb\",\n",
      "    \"text\": \"2.1 Backgrounds\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8662165999412537,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            197.19955444335938,\n",
      "            1460.4884033203125\n",
      "          ],\n",
      "          [\n",
      "            197.19955444335938,\n",
      "            1495.896253333333\n",
      "          ],\n",
      "          [\n",
      "            474.5708923339844,\n",
      "            1495.896253333333\n",
      "          ],\n",
      "          [\n",
      "            474.5708923339844,\n",
      "            1460.4884033203125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"3cc0a534c93b72edb6760710ec586c98\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"21d60257a47fb5bd9b6f7d93b265cdb8\",\n",
      "    \"text\": \"Attention. Transformers (Vaswani et al. 2017) as the de facto backbone for many deep learning models are based on attention mechanism. Given input \\ud835\\udc65 \\u2208 R\\ud835\\udc41 \\u00d7\\ud835\\udc51in, causal attention computes output y \\u2208 R\\ud835\\udc41 \\u00d7\\ud835\\udc51in based on softmax over input dependent key, value, and query matrices:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9318703413009644,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            1524.9538888888887\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            1625.5074462890625\n",
      "          ],\n",
      "          [\n",
      "            1563.1890869140625,\n",
      "            1625.5074462890625\n",
      "          ],\n",
      "          [\n",
      "            1563.1890869140625,\n",
      "            1524.9538888888887\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2017\",\n",
      "          \"url\": \"cite.0@transformers\",\n",
      "          \"start_index\": 40\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"091a2cbb405d72b4a0b75ca0b2d41adb\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"47db4f5ec96d73e78ba59a4221c628c0\",\n",
      "    \"text\": \"Q = \\ud835\\udc65WQ, K = \\ud835\\udc65WK, V = \\ud835\\udc65WV, (1)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5782061219215393,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            640.1288452148438,\n",
      "            1638.7344444444443\n",
      "          ],\n",
      "          [\n",
      "            640.1288452148438,\n",
      "            1679.1483154296875\n",
      "          ],\n",
      "          [\n",
      "            1565.36767578125,\n",
      "            1679.1483154296875\n",
      "          ],\n",
      "          [\n",
      "            1565.36767578125,\n",
      "            1638.7344444444443\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"a876e96f110f4ad18223db3ba933c162\",\n",
      "    \"text\": \"\\u221a\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            993.2083333333331,\n",
      "            1674.418653333333\n",
      "          ],\n",
      "          [\n",
      "            993.2083333333331,\n",
      "            1702.0925422222217\n",
      "          ],\n",
      "          [\n",
      "            1012.6630772222221,\n",
      "            1702.0925422222217\n",
      "          ],\n",
      "          [\n",
      "            1012.6630772222221,\n",
      "            1674.418653333333\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"b0a476468d8936b39a0c798f7713cc08\",\n",
      "    \"text\": \"exp\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            858.1055555555554,\n",
      "            1678.2541977777776\n",
      "          ],\n",
      "          [\n",
      "            858.1055555555554,\n",
      "            1719.5694444444443\n",
      "          ],\n",
      "          [\n",
      "            914.8824599999997,\n",
      "            1719.5694444444443\n",
      "          ],\n",
      "          [\n",
      "            914.8824599999997,\n",
      "            1678.2541977777776\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"0022a45afbe87b763836f5cdb33a9c34\",\n",
      "    \"text\": \"i exp (Q7K;/Van) Vi 2) yi= i 2 F=1 Deas exp (Q7K:/ Van)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.7841492891311646,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            732.2149658203125,\n",
      "            1692.1999683333333\n",
      "          ],\n",
      "          [\n",
      "            732.2149658203125,\n",
      "            1795.6583251953125\n",
      "          ],\n",
      "          [\n",
      "            1565.05322265625,\n",
      "            1795.6583251953125\n",
      "          ],\n",
      "          [\n",
      "            1565.05322265625,\n",
      "            1692.1999683333333\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"33031730ba5795853b6a5c7a86c98dd3\",\n",
      "    \"text\": \"where WQ, WK, and WV \\u2208 R\\ud835\\udc51in \\u00d7\\ud835\\udc51in are learnable parameters. Despite the power and effectiveness in recall, transformers need at least \\ud835\\udc41 \\u00d7 \\ud835\\udc51 operators to calculate the output, resulting in larger memory consumption and lower-throughput for longer sequences.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9345545768737793,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            1809.5424991666666\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            1909.30224609375\n",
      "          ],\n",
      "          [\n",
      "            1566.3614501953125,\n",
      "            1909.30224609375\n",
      "          ],\n",
      "          [\n",
      "            1566.3614501953125,\n",
      "            1809.5424991666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"be6359e16c77300785bb6795868935b8\",\n",
      "    \"text\": \"Efficient Attentions. To improve the memory consumption and throughput of softmax attention for longer sequences,\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1941.5122222222221\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1975.5787794444443\n",
      "          ],\n",
      "          [\n",
      "            1563.0456752305554,\n",
      "            1975.5787794444443\n",
      "          ],\n",
      "          [\n",
      "            1563.0456752305554,\n",
      "            1941.5122222222221\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"d6fa1c186ddac79feec9a12f6ef82464\",\n",
      "    \"text\": \"various studies focused on I/O aware implementations of attention (Dao 2024; Dao, D. Fu, et al. 2022), designing more\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9241685271263123,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.30833333333334,\n",
      "            1950.0816650390625\n",
      "          ],\n",
      "          [\n",
      "            199.30833333333334,\n",
      "            2006.7880859375\n",
      "          ],\n",
      "          [\n",
      "            1563.4503173828125,\n",
      "            2006.7880859375\n",
      "          ],\n",
      "          [\n",
      "            1563.4503173828125,\n",
      "            1950.0816650390625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"c7742d6152097208b9ec5bbc8d78f3d7\",\n",
      "    \"text\": \"3\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            873.5666666666666,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            873.5666666666666,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350249999999,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350249999999,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"31b1c3e59075b89f001b06d485e078e1\",\n",
      "    \"text\": \"efficient attention mechanisms by sparsifying the attention matrix (B. Chen et al. 2021; Choromanski et al. 2021; Dai et al.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            202.39277777777778\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            230.06666666666652\n",
      "          ],\n",
      "          [\n",
      "            1564.2516003277779,\n",
      "            230.06666666666652\n",
      "          ],\n",
      "          [\n",
      "            1564.2516003277779,\n",
      "            202.39277777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@chen2021scatterbrain\",\n",
      "          \"start_index\": 81\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@choromanski2021rethinking\",\n",
      "          \"start_index\": 106\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2d8adbe6141634652dcfcdab0ee926d0\",\n",
      "    \"text\": \"2019), approximating the softmax (Arora et al. 2024), or developing kernel-based (linear) attentions (Aksenov et al. 2024; Kacham, Mirrokni, and P. Zhong 2024; Schlag, Irie, and J\\u00fcrgen Schmidhuber 2021; S. Yang, B. Wang, Shen, et al. 2024). In this part, we focus on the later, i.e., linear attentions, where the softmax in standard attention is replaced with an alternative kernel function \\ud835\\udf19 (., .), such that \\ud835\\udf19 (\\ud835\\udc65, \\ud835\\udc66) = \\ud835\\udf19 (\\ud835\\udc65)\\ud835\\udf19 (\\ud835\\udc66). Accordingly, the attention can be written as:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9403567910194397,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            211.0892791748047\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            369.2322082519531\n",
      "          ],\n",
      "          [\n",
      "            1568.9061279296875,\n",
      "            369.2322082519531\n",
      "          ],\n",
      "          [\n",
      "            1568.9061279296875,\n",
      "            211.0892791748047\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@chen2021scatterbrain\",\n",
      "          \"start_index\": 81\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@choromanski2021rethinking\",\n",
      "          \"start_index\": 106\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.0@dai2019transformerxl\",\n",
      "          \"start_index\": 123\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@arora2024simple\",\n",
      "          \"start_index\": 170\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@aksenov2024linear\",\n",
      "          \"start_index\": 240\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@kacham2024polysketchformer\",\n",
      "          \"start_index\": 277\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@schlag2021linear\",\n",
      "          \"start_index\": 320\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024gatedattn\",\n",
      "          \"start_index\": 357\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"820d81d701e72e294c7df161b385a055\",\n",
      "    \"text\": \"y= y $QIK) 8 y $Q)*HK) \\u2014 y, _ 9QI\\\" Dhan HRV) 6) 44 GOK) 9 AYE GQ) OK) 7 GQ) Diy (KD) *\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8185433745384216,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            428.2182312011719,\n",
      "            390.1174991666671\n",
      "          ],\n",
      "          [\n",
      "            428.2182312011719,\n",
      "            482.94342041015625\n",
      "          ],\n",
      "          [\n",
      "            1580.0831298828125,\n",
      "            482.94342041015625\n",
      "          ],\n",
      "          [\n",
      "            1580.0831298828125,\n",
      "            390.1174991666671\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"781fb1a5e2db41e37d462c3779de8705\",\n",
      "    \"text\": \"resulting in a higher-throughput as terms ));_, $(Kj) and D/_, $(Kr) are re-using in each step. When choosing the kernel as identity matrix (Yutao Sun et al. 2023), the above formulation can also be written in a recurrent format:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9172530770301819,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            502.54527694444465\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            573.5322875976562\n",
      "          ],\n",
      "          [\n",
      "            1559.9925452044442,\n",
      "            573.5322875976562\n",
      "          ],\n",
      "          [\n",
      "            1559.9925452044442,\n",
      "            502.54527694444465\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"d7dbd1f0358b6cd65332e8937120ba04\",\n",
      "    \"text\": \"M\\ud835\\udc61 = M\\ud835\\udc61 \\u22121 + \\ud835\\udc3e \\u22a4 \\ud835\\udc61 \\ud835\\udc49\\ud835\\udc61 , y\\ud835\\udc61 = \\ud835\\udc44\\ud835\\udc61 M\\ud835\\udc61 , (4) (5)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5836780071258545,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            762.4777777777775,\n",
      "            596.0965288888888\n",
      "          ],\n",
      "          [\n",
      "            762.4777777777775,\n",
      "            681.5372924804688\n",
      "          ],\n",
      "          [\n",
      "            1572.57421875,\n",
      "            681.5372924804688\n",
      "          ],\n",
      "          [\n",
      "            1572.57421875,\n",
      "            596.0965288888888\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"d452334e1d09d58aeb47d41f975c17c9\",\n",
      "    \"text\": \"which allows efficient inference for linear attentions.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.97499999999977,\n",
      "            695.8455555555553\n",
      "          ],\n",
      "          [\n",
      "            198.97499999999977,\n",
      "            723.519444444444\n",
      "          ],\n",
      "          [\n",
      "            796.1498483333329,\n",
      "            723.519444444444\n",
      "          ],\n",
      "          [\n",
      "            796.1498483333329,\n",
      "            695.8455555555553\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b8d96e998e21df57af4e0f807e3bf5b1\",\n",
      "    \"text\": \"Modern Linear Models and Their Memory Perspective. As discussed earlier, one can define learning as a process for acquiring effective and useful memory. Building upon this, one can see the hidden state of Recurrent Neural Networks (RNNs) as a memory unit, which the model aims to compress the information into. Accordingly, in a general form of recurrent neural network, the hidden state can be treated as a memory unit and the recurrence process can be split into the read and write operations in the memory unit. That is, we let \\ud835\\udc65 \\u2208 R\\ud835\\udc41 \\u00d7\\ud835\\udc51in be the input, M \\u2208 R\\ud835\\udc51 is the memory unit, and y \\u2208 R\\ud835\\udc51in is the output, then the general form of the recurrent neural network is defined as:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9501790404319763,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            759.0455555555554\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            959.1288833333333\n",
      "          ],\n",
      "          [\n",
      "            1564.4229736328125,\n",
      "            959.1288833333333\n",
      "          ],\n",
      "          [\n",
      "            1564.4229736328125,\n",
      "            759.0455555555554\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"0df1f91352937b2bedfce59e94888cf0\",\n",
      "    \"text\": \"M\\ud835\\udc61 = \\ud835\\udc53 (M\\ud835\\udc61 \\u22121, \\ud835\\udc65\\ud835\\udc61 ), Write Operation y\\ud835\\udc61 = \\ud835\\udc54(M\\ud835\\udc61, \\ud835\\udc65\\ud835\\udc61 ), Read Operation (6) (7)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.7139307856559753,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            627.1306762695312,\n",
      "            982.4399999999999\n",
      "          ],\n",
      "          [\n",
      "            627.1306762695312,\n",
      "            1059.58935546875\n",
      "          ],\n",
      "          [\n",
      "            1564.5587158203125,\n",
      "            1059.58935546875\n",
      "          ],\n",
      "          [\n",
      "            1564.5587158203125,\n",
      "            982.4399999999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"79c29d607ace971c4882534a8fbf2e72\",\n",
      "    \"text\": \"where \\ud835\\udc53 (., .) is the read and \\ud835\\udc54(., .) is the write corresponding functions. Note that here the subscript of M\\ud835\\udc61 shows the state of the memory at time \\ud835\\udc61.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9162834882736206,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            1081.3011111111111\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            1146.170654296875\n",
      "          ],\n",
      "          [\n",
      "            1562.2532958984375,\n",
      "            1146.170654296875\n",
      "          ],\n",
      "          [\n",
      "            1562.2532958984375,\n",
      "            1081.3011111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9608ee09dca151e2488e2fa42deb50e8\",\n",
      "    \"text\": \"In this perspective, the recurrence formula of linear Transformers (see Equation 4) is equivalent to additively compress and write keys and values, (\\ud835\\udc3e\\ud835\\udc61, \\ud835\\udc49\\ud835\\udc61 ), into a matrix-valued memory unit M\\ud835\\udc61 . Therefore, when dealing with long context data, this additive nature of the process results in memory overflow, significantly damaging the performance of the model. To address this, studies have focused on two promising directions: (1) Adding forget mechanism: several studies have presented adaptive (data-dependent) forgetting gate mechanisms for linear models, where it can erase the memory when it is needed. As examples of such models, we refer to GLA (S. Yang, B. Wang, Shen, et al. 2024), LRU (Orvieto et al. 2023), Griffin (De et al. 2024), xLSTM (Beck et al. 2024), and Mamba2 (Dao and Gu 2024), which the later is also connected to the discretized version of traditional state space models (Gu and Dao 2024).(2) Improving the write operation: To overcome the additive nature of memory write operation in traditional recurrent models, Widrow and Hoff (1988) presented Delta Rule, in which before adding a memory (i.e., a pair of key and value), the model first removes its past value. To enhance the parallelizable training and scaling, S. Yang, B. Wang, Yu Zhang, et al. (2024) present a fast paralellizable algorithm. Finally, very recently, S. Yang, Kautz, and Hatamizadeh (2024) improved the DeltaNets by adding a forget gate.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9542672634124756,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1164.3233333333333\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1563.8302001953125\n",
      "          ],\n",
      "          [\n",
      "            1564.2681493133327,\n",
      "            1563.8302001953125\n",
      "          ],\n",
      "          [\n",
      "            1564.2681493133327,\n",
      "            1164.3233333333333\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Equation 4\",\n",
      "          \"url\": \"equation.2.4\",\n",
      "          \"start_index\": 72\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024gatedattn\",\n",
      "          \"start_index\": 684\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@orvieto2023resurrecting\",\n",
      "          \"start_index\": 711\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@de2024griffin\",\n",
      "          \"start_index\": 735\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@beck2024xlstm\",\n",
      "          \"start_index\": 761\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@dao2024transformers\",\n",
      "          \"start_index\": 791\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@gu2024mamba\",\n",
      "          \"start_index\": 905\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"1988\",\n",
      "          \"url\": \"cite.0@widrow1988adaptive\",\n",
      "          \"start_index\": 1053\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024parallelizing\",\n",
      "          \"start_index\": 1273\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"02f1078d9260e62223ea138eb40b265b\",\n",
      "    \"text\": \"Memory Modules. Memory has always been one of the core parts of the neural network designs (Graves, Wayne, and Danihelka 2014; JH Schmidhuber 1992; J\\u00fcrgen Schmidhuber and Hochreiter 1997; J. Zhang et al. 2024). The idea of seeing linear layers as the key-value (associative) memory system backs to fast weight programs, in which dynamic fast programs are incorporated into recurrent neural networks to serve as writable memory (JH Schmidhuber 1992). The two learning rules of Hebbian (Hebb 2005) and delta (Prados and Kak 1989) are the most popular learning rules for fast weight programs, which have been extensively explored in various studies (Irie, Schlag, et al. 2021; Munkhdalai, Sordoni, et al. 2019; Munkhdalai and H. Yu 2017; Schlag, Irie, and J\\u00fcrgen Schmidhuber 2021; JH Schmidhuber 1992; S. Yang, Kautz, and Hatamizadeh 2024; S. Yang, B. Wang, Yu Zhang, et al. 2024). All these models, however, are based on momentary surprise, missing the token flow in the sequences (see Section 3.1), and most of them lacks a forgetting gate, resulting in a poor memory management.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9524841904640198,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1592.8177777777778\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1924.157470703125\n",
      "          ],\n",
      "          [\n",
      "            1564.601318359375,\n",
      "            1924.157470703125\n",
      "          ],\n",
      "          [\n",
      "            1564.601318359375,\n",
      "            1592.8177777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2014\",\n",
      "          \"url\": \"cite.0@graves2014neuralturingmachines\",\n",
      "          \"start_index\": 121\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"1992\",\n",
      "          \"url\": \"cite.0@schmidhuber1992learning\",\n",
      "          \"start_index\": 142\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"1997\",\n",
      "          \"url\": \"cite.0@LSTM\",\n",
      "          \"start_index\": 182\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@zhang2024memory\",\n",
      "          \"start_index\": 204\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"1992\",\n",
      "          \"url\": \"cite.0@schmidhuber1992learning\",\n",
      "          \"start_index\": 443\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2005\",\n",
      "          \"url\": \"cite.0@hebb2005organization\",\n",
      "          \"start_index\": 490\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"1989\",\n",
      "          \"url\": \"cite.0@prados1989neural\",\n",
      "          \"start_index\": 522\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@irie2021going\",\n",
      "          \"start_index\": 668\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.0@munkhdalai2019metalearned\",\n",
      "          \"start_index\": 702\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2017\",\n",
      "          \"url\": \"cite.0@munkhdalai2017neural\",\n",
      "          \"start_index\": 729\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@schlag2021linear\",\n",
      "          \"start_index\": 772\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"1992\",\n",
      "          \"url\": \"cite.0@schmidhuber1992learning\",\n",
      "          \"start_index\": 793\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024gated\",\n",
      "          \"start_index\": 831\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024parallelizing\",\n",
      "          \"start_index\": 872\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Section 3 . 1\",\n",
      "          \"url\": \"subsection.3.1\",\n",
      "          \"start_index\": 983\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"5ac1ba3a3c677ffbd2ba1f2763643f1d\",\n",
      "    \"text\": \"We further discuss the connection of our architectures with recent models in Appendix C. Additional related work are discussed in Appendix A.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9139958024024963,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.67222222222222,\n",
      "            1941.5122222222221\n",
      "          ],\n",
      "          [\n",
      "            198.67222222222222,\n",
      "            2004.591552734375\n",
      "          ],\n",
      "          [\n",
      "            1564.6026611328125,\n",
      "            2004.591552734375\n",
      "          ],\n",
      "          [\n",
      "            1564.6026611328125,\n",
      "            1941.5122222222221\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Appendix C\",\n",
      "          \"url\": \"appendix.C\",\n",
      "          \"start_index\": 77\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"a59947b4982cb13fb3ca46d876ca0db3\",\n",
      "    \"text\": \"4\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            873.5666666666667,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            873.5666666666667,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350250000001,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350250000001,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"f2d5eee84f47a83a977e1345c55eb217\",\n",
      "    \"text\": \"3 Learning to Memorize at Test Time\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8613103628158569,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            196.84376525878906,\n",
      "            198.8762664794922\n",
      "          ],\n",
      "          [\n",
      "            196.84376525878906,\n",
      "            239.42201232910156\n",
      "          ],\n",
      "          [\n",
      "            893.6334838867188,\n",
      "            239.42201232910156\n",
      "          ],\n",
      "          [\n",
      "            893.6334838867188,\n",
      "            198.8762664794922\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b967e3da6fc83dd88880877381ed0e1c\",\n",
      "    \"text\": \"To overcome the lack of long-term memory and to enable the model to learn, forget, and retrieve information, in this section, we present a neural long-term memory module, which is a meta models that learns to memorize at test time. In Section 3.1, we first discuss the motivation and the design of the neural memory. In Section 3.2, we discuss how our architecture design can benefit from a fast and parallelizable training. Finally, in Section 3.3, we augment our architecture using persistent memory module, in which we use learnable but data-independent parameters to learn meta information about the task.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9515153169631958,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.7576446533203,\n",
      "            254.4083333333333\n",
      "          ],\n",
      "          [\n",
      "            198.7576446533203,\n",
      "            461.75396728515625\n",
      "          ],\n",
      "          [\n",
      "            1564.4705810546875,\n",
      "            461.75396728515625\n",
      "          ],\n",
      "          [\n",
      "            1564.4705810546875,\n",
      "            254.4083333333333\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Section 3 . 1\",\n",
      "          \"url\": \"subsection.3.1\",\n",
      "          \"start_index\": 123\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Section 3 . 2\",\n",
      "          \"url\": \"subsection.3.2\",\n",
      "          \"start_index\": 207\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Section 3 . 3\",\n",
      "          \"url\": \"subsection.3.3\",\n",
      "          \"start_index\": 323\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"f2d5eee84f47a83a977e1345c55eb217\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"f8fa76e0936c899cf39ec01e9b595adc\",\n",
      "    \"text\": \"3.1 Long-term Memory\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8635743856430054,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            196.80340576171875,\n",
      "            507.6734755555555\n",
      "          ],\n",
      "          [\n",
      "            196.80340576171875,\n",
      "            540.8823644444443\n",
      "          ],\n",
      "          [\n",
      "            573.3630981445312,\n",
      "            540.8823644444443\n",
      "          ],\n",
      "          [\n",
      "            573.3630981445312,\n",
      "            507.6734755555555\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0006445ff1e8f2f86b810dba8bd712fd\",\n",
      "    \"text\": \"To design a neural long-term memory module, we need a model that can encode the abstraction of the past history into its parameters. An example of this can be LLMs that are shown to be memorizing their training data (Leybzon and Kervadec 2024; Schwarzschild et al. 2024; Staab et al. 2024). Therefore, a simple idea is to train a neural network and expect it to memorize its training data. Memorization, however, has almost always been known as an undesirable phenomena in neural networks as it limits the model generalization (Bayat et al. 2024), causes privacy concerns (Staab et al. 2024), and so results in poor performance at test time. Moreover, the memorization of the training data might not be helpful at test time, in which the data might be out-of-distribution. We argue that, we need an online meta-model that learns how to memorize/forget the data at test time. In this setup, the model is learning a function that is capable of memorization, but it is not overfitting to the training data, resulting in a better generalization at test time.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9566864967346191,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            556.5566666666667\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            854.2660522460938\n",
      "          ],\n",
      "          [\n",
      "            1570.3927001953125,\n",
      "            854.2660522460938\n",
      "          ],\n",
      "          [\n",
      "            1570.3927001953125,\n",
      "            556.5566666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@leybzon2024learning\",\n",
      "          \"start_index\": 259\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@schwarzschild2024rethinking\",\n",
      "          \"start_index\": 286\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@staab2024beyond\",\n",
      "          \"start_index\": 305\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@bayat2024pitfalls\",\n",
      "          \"start_index\": 562\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@staab2024beyond\",\n",
      "          \"start_index\": 607\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"f8fa76e0936c899cf39ec01e9b595adc\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"7b63495029c283f428ffdadd9ea7a849\",\n",
      "    \"text\": \"Learning Process and Surprise Metric. The key idea to train a long-term memory is to treat its training as an online learning problem, in which we aim to compress the past information \\ud835\\udc651, . . . , \\ud835\\udc65\\ud835\\udc61 \\u22121 into the parameters of our long-term neural memory module M\\ud835\\udc61 . As discussed earlier, an event that violates the expectations (i.e., is surprising) is more memorable for humans (Mandler 2014). Inspired by this, a simple definition of surprise for a model can be its gradient with respect to the input. The larger the gradient is, the more different the input data is from the past data. Accordingly, using this surprise score, we can update the memory as:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9523562788963318,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            885.426111111111\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1085.81298828125\n",
      "          ],\n",
      "          [\n",
      "            1563.9140625,\n",
      "            1085.81298828125\n",
      "          ],\n",
      "          [\n",
      "            1563.9140625,\n",
      "            885.426111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2014\",\n",
      "          \"url\": \"cite.0@mandler2014structure\",\n",
      "          \"start_index\": 387\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"f8fa76e0936c899cf39ec01e9b595adc\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"7f0ddf714ace4c867c7a3a501e1b2228\",\n",
      "    \"text\": \"M\\ud835\\udc61 = M\\ud835\\udc61 \\u22121 \\u2212 \\ud835\\udf03\\ud835\\udc61 \\u2207\\u2113 (M\\ud835\\udc61 \\u22121; \\ud835\\udc65\\ud835\\udc61 ) . (8)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.6321243643760681,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            701.0697631835938,\n",
      "            1108.0261111111108\n",
      "          ],\n",
      "          [\n",
      "            701.0697631835938,\n",
      "            1148.56884765625\n",
      "          ],\n",
      "          [\n",
      "            1561.6619961111114,\n",
      "            1148.56884765625\n",
      "          ],\n",
      "          [\n",
      "            1561.6619961111114,\n",
      "            1108.0261111111108\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"45a1c2f2572d12b3131bb9670b88e092\",\n",
      "    \"text\": \"SS\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            898.0,\n",
      "            1150.0\n",
      "          ],\n",
      "          [\n",
      "            898.0,\n",
      "            1162.0\n",
      "          ],\n",
      "          [\n",
      "            1049.0,\n",
      "            1162.0\n",
      "          ],\n",
      "          [\n",
      "            1049.0,\n",
      "            1150.0\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"09a7ed3ae5b1489ea7a108ed78920681\",\n",
      "    \"text\": \"Surprise\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            939.888888888889,\n",
      "            1166.503611111111\n",
      "          ],\n",
      "          [\n",
      "            939.888888888889,\n",
      "            1186.7055555555553\n",
      "          ],\n",
      "          [\n",
      "            1008.3128747222223,\n",
      "            1186.7055555555553\n",
      "          ],\n",
      "          [\n",
      "            1008.3128747222223,\n",
      "            1166.503611111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9e12d5abb2020b5b20bc8b25be98e18e\",\n",
      "    \"text\": \"This surprise metric, however, can result in missing important information that comes after a big surprising moment.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1211.6927777777778\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1239.3666666666668\n",
      "          ],\n",
      "          [\n",
      "            1564.2731238111116,\n",
      "            1239.3666666666668\n",
      "          ],\n",
      "          [\n",
      "            1564.2731238111116,\n",
      "            1211.6927777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"09a7ed3ae5b1489ea7a108ed78920681\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e2467f79f69f5b7014fbcce9b6d6eefe\",\n",
      "    \"text\": \"That is, the gradient can become extremely small after several surprising steps, leading to stocking in a flat area (i.e., local minima), and missing information about some parts of the sequence. From the human memory perspective, an event might not consistently surprise us through a long-period of time although it is memorable. The reason is that the initial moment is surprising enough to get our attention through a long time frame, leading to memorizing the entire time frame. To improve the above surprise metric (Equation 8), we break the surprise metric into (1) past surprise, which measures the surprise amount of a very recent past; and (2) momentary surprise, which measures the surprise of incoming data:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9550566673278809,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            197.88540649414062,\n",
      "            1218.8453369140625\n",
      "          ],\n",
      "          [\n",
      "            197.88540649414062,\n",
      "            1445.0951344444445\n",
      "          ],\n",
      "          [\n",
      "            1572.213623046875,\n",
      "            1445.0951344444445\n",
      "          ],\n",
      "          [\n",
      "            1572.213623046875,\n",
      "            1218.8453369140625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Equation 8\",\n",
      "          \"url\": \"equation.3.8\",\n",
      "          \"start_index\": 637\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"09a7ed3ae5b1489ea7a108ed78920681\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"721377ac16aff4dd450e3e88c8ec8f18\",\n",
      "    \"text\": \"M\\ud835\\udc61 = M\\ud835\\udc61 \\u22121 + \\ud835\\udc46\\ud835\\udc61, (9)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.3135146498680115,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            669.1361111111111,\n",
      "            1467.503888888889\n",
      "          ],\n",
      "          [\n",
      "            669.1361111111111,\n",
      "            1511.6492919921875\n",
      "          ],\n",
      "          [\n",
      "            1564.837158203125,\n",
      "            1511.6492919921875\n",
      "          ],\n",
      "          [\n",
      "            1564.837158203125,\n",
      "            1467.503888888889\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"7710c0ce3ede508022f3c73edcbb4b04\",\n",
      "    \"text\": \"Se=me Sra \\u2014 Of VO (Mr-15 x2) \\u00ab (10) ee SS\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5409674048423767,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            665.923828125,\n",
      "            1504.1549072265625\n",
      "          ],\n",
      "          [\n",
      "            665.923828125,\n",
      "            1558.1833333333334\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            1558.1833333333334\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            1504.1549072265625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"2735a0a9882f4c8d2e8a634d2d2fa514\",\n",
      "    \"text\": \"Past Surprise\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            746.7916666666667,\n",
      "            1566.3174999999999\n",
      "          ],\n",
      "          [\n",
      "            746.7916666666667,\n",
      "            1586.5194444444446\n",
      "          ],\n",
      "          [\n",
      "            854.6902519444445,\n",
      "            1586.5194444444446\n",
      "          ],\n",
      "          [\n",
      "            854.6902519444445,\n",
      "            1566.3174999999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"e8d3be1427d34dfefc47198134dfd664\",\n",
      "    \"text\": \"Momentary Surprise\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            913.4805555555554,\n",
      "            1567.4508333333335\n",
      "          ],\n",
      "          [\n",
      "            913.4805555555554,\n",
      "            1587.6527777777778\n",
      "          ],\n",
      "          [\n",
      "            1083.8637549999999,\n",
      "            1587.6527777777778\n",
      "          ],\n",
      "          [\n",
      "            1083.8637549999999,\n",
      "            1567.4508333333335\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"6e6ed601d223acbaa1822b97c22b2e7e\",\n",
      "    \"text\": \"Interestingly, this formulation is similar to gradient descent with momentum, where \\ud835\\udc46\\ud835\\udc61 is the momentum element. Therefore, the momentum here act as a memory of surprise across time (sequence length). In this formulation, the term \\ud835\\udf02\\ud835\\udc61 is a data-dependent surprise decay (a function of \\ud835\\udc65\\ud835\\udc61 ), controlling how surprise decays over time, and the term \\ud835\\udf03\\ud835\\udc61 is controlling how much of momentary surprise should be incorporated into the final surprise metric in a data-dependent manner. This data-dependency is particularly important in this design: While surprise of previous tokens might be needed to affect the surprise of the next token, it is mostly valid if all tokens are relevant and are in the same context. Accordingly, a data-dependent \\ud835\\udf02 can control if memory needs to: (1) ignore the last surprise by setting \\ud835\\udf02\\ud835\\udc61 \\u2192 0 (possibly due to the change of context), or (2) fully incorporate the last surprise by setting \\ud835\\udf02\\ud835\\udc61 \\u2192 1 (possibly as the token is highly relevant to its recent past tokens).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9540640711784363,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1612.6427777777778\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1910.580322265625\n",
      "          ],\n",
      "          [\n",
      "            1566.091064453125,\n",
      "            1910.580322265625\n",
      "          ],\n",
      "          [\n",
      "            1566.091064453125,\n",
      "            1612.6427777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"e8d3be1427d34dfefc47198134dfd664\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"221928f9f396e6c6e7fb706b43f4285b\",\n",
      "    \"text\": \"Objective. Our above surprise metric is based on a loss function \\u2113 (.; .), which is the objective that our memory is learning\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1941.5122222222221\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1975.5787794444443\n",
      "          ],\n",
      "          [\n",
      "            1559.991181371111,\n",
      "            1975.5787794444443\n",
      "          ],\n",
      "          [\n",
      "            1559.991181371111,\n",
      "            1941.5122222222221\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"e8d3be1427d34dfefc47198134dfd664\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f0b20f52f3bdd8310182721f098c1159\",\n",
      "    \"text\": \"to act as it at test time. That is, our memory module is a meta model that learns a function based on the loss function \\u2113 (.; .).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9256730079650879,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1950.04833984375\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            2006.8046875\n",
      "          ],\n",
      "          [\n",
      "            1564.2637126666664,\n",
      "            2006.8046875\n",
      "          ],\n",
      "          [\n",
      "            1564.2637126666664,\n",
      "            1950.04833984375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"e8d3be1427d34dfefc47198134dfd664\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"aa24309e71e21ba20240ca1fd2e21703\",\n",
      "    \"text\": \"5\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            873.5666666666666,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            873.5666666666666,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350249999999,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350249999999,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"e8d3be1427d34dfefc47198134dfd664\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"906e238358f3aa5c1933e93c37254f5c\",\n",
      "    \"text\": \"In this work, we focus on associative memory, in which we aim to store the past data as the pairs of keys and values. Given\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            202.39277777777778\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            236.54235666666668\n",
      "          ],\n",
      "          [\n",
      "            1560.0059411777775,\n",
      "            236.54235666666668\n",
      "          ],\n",
      "          [\n",
      "            1560.0059411777775,\n",
      "            202.39277777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"e8d3be1427d34dfefc47198134dfd664\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"12a3bbf674b3fd40c20554c824f7b5a1\",\n",
      "    \"text\": \"\\ud835\\udc65\\ud835\\udc61 , similar to Transformers (Vaswani et al. 2017), we use two linear layers to project \\ud835\\udc65\\ud835\\udc61 into a key and value:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9224147200584412,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            212.03903198242188\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            268.8795471191406\n",
      "          ],\n",
      "          [\n",
      "            1562.93359375,\n",
      "            268.8795471191406\n",
      "          ],\n",
      "          [\n",
      "            1562.93359375,\n",
      "            212.03903198242188\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"e8d3be1427d34dfefc47198134dfd664\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"3603a13d47947893ce11ab1fc5277997\",\n",
      "    \"text\": \"k\\ud835\\udc61 = \\ud835\\udc65\\ud835\\udc61\\ud835\\udc4a\\ud835\\udc3e, v\\ud835\\udc61 = \\ud835\\udc65\\ud835\\udc61\\ud835\\udc4a\\ud835\\udc49 , (11)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.634596586227417,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            694.9714965820312,\n",
      "            296.4844444444446\n",
      "          ],\n",
      "          [\n",
      "            694.9714965820312,\n",
      "            332.3160705566406\n",
      "          ],\n",
      "          [\n",
      "            1561.6609099999996,\n",
      "            332.3160705566406\n",
      "          ],\n",
      "          [\n",
      "            1561.6609099999996,\n",
      "            296.4844444444446\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"64b121b3d8d99539c0ec401765c9b7b0\",\n",
      "    \"text\": \"where \\ud835\\udc4a\\ud835\\udc3e and \\ud835\\udc4a\\ud835\\udc49 \\u2208 R\\ud835\\udc51in \\u00d7\\ud835\\udc51in. Next, we expect our memory module to learn the associations between keys and values. To\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            358.8258325000001\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            393.22499916666675\n",
      "          ],\n",
      "          [\n",
      "            1560.0052324333335,\n",
      "            393.22499916666675\n",
      "          ],\n",
      "          [\n",
      "            1560.0052324333335,\n",
      "            358.8258325000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e64466181939b3445c23bbae8dbbc30b\",\n",
      "    \"text\": \"this end, we define the loss as follows:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9202572107315063,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            369.45849609375\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            426.76611328125\n",
      "          ],\n",
      "          [\n",
      "            1566.947509765625,\n",
      "            426.76611328125\n",
      "          ],\n",
      "          [\n",
      "            1566.947509765625,\n",
      "            369.45849609375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"5ebdda765218a446054046c080a5cd82\",\n",
      "    \"text\": \"\\u2113 (M\\ud835\\udc61 \\u22121; \\ud835\\udc65\\ud835\\udc61 ) = \\u2225M\\ud835\\udc61 \\u22121 (k\\ud835\\udc61 ) \\u2212 v\\ud835\\udc61 \\u22252\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            693.6027777777778,\n",
      "            450.9175000000002\n",
      "          ],\n",
      "          [\n",
      "            693.6027777777778,\n",
      "            490.16514000000006\n",
      "          ],\n",
      "          [\n",
      "            1064.9022375,\n",
      "            490.16514000000006\n",
      "          ],\n",
      "          [\n",
      "            1064.9022375,\n",
      "            450.9175000000002\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"7e26ef6d719c5c128d04c053fce2a29b\",\n",
      "    \"text\": \"2\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.6151119470596313,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            697.6447143554688,\n",
      "            461.0958251953125\n",
      "          ],\n",
      "          [\n",
      "            697.6447143554688,\n",
      "            491.9449768066406\n",
      "          ],\n",
      "          [\n",
      "            1548.2830810546875,\n",
      "            491.9449768066406\n",
      "          ],\n",
      "          [\n",
      "            1548.2830810546875,\n",
      "            461.0958251953125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"29ecb6d6fa6b5fd7c16def14ae543698\",\n",
      "    \"text\": \"By optimizing the above loss function in the inner-loop of our meta model (memory), the model learns how to memorize the mapping between keys and values at test time. Note that, similar to meta-learning models (Nichol 2018; Zintgraf et al. 2019), training of the memory is in the inner-loop, and so parameters \\ud835\\udc4a\\ud835\\udc3e and \\ud835\\udc4a\\ud835\\udc49 are hyperparameters in the above loss function. Accordingly, in the inner loop, we optimize M\\u2019s weights, while in the outer-loop, we optimize other parameters of the entire architecture.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9486731290817261,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            516.1511111111114\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            683.2410278320312\n",
      "          ],\n",
      "          [\n",
      "            1566.0045166015625,\n",
      "            683.2410278320312\n",
      "          ],\n",
      "          [\n",
      "            1566.0045166015625,\n",
      "            516.1511111111114\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2018\",\n",
      "          \"url\": \"cite.0@nichol2018first\",\n",
      "          \"start_index\": 218\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.0@zintgraf2019fast\",\n",
      "          \"start_index\": 240\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"d610f981f8ca84bf37800a4a9799e766\",\n",
      "    \"text\": \"Forgetting Mechanism. When dealing with very large sequences (e.g., millions of tokens), it is crucial to manage which past information should be forgotten\\u2013even with a deep or a very large matrix-valued memory. To this end, we use an adaptive forgetting mechanism that allows the memory to forget the information that is not needed anymore, resulting in better managing the memory\\u2019s limited capacity. That is, given the next token \\ud835\\udc65\\ud835\\udc61 , we modify the update rule as:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9406565427780151,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            712.1872222222224\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            845.2297973632812\n",
      "          ],\n",
      "          [\n",
      "            1566.1424560546875,\n",
      "            845.2297973632812\n",
      "          ],\n",
      "          [\n",
      "            1566.1424560546875,\n",
      "            712.1872222222224\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"e34f32de40fe59c025dfcbc3662bfbe7\",\n",
      "    \"text\": \"M\\ud835\\udc61 = (1 \\u2212 \\ud835\\udefc\\ud835\\udc61 )M\\ud835\\udc61 \\u22121 + \\ud835\\udc46\\ud835\\udc61, (13)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5927087664604187,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            711.9166666666665,\n",
      "            872.6955555555554\n",
      "          ],\n",
      "          [\n",
      "            711.9166666666665,\n",
      "            909.36181640625\n",
      "          ],\n",
      "          [\n",
      "            1561.6609099999998,\n",
      "            909.36181640625\n",
      "          ],\n",
      "          [\n",
      "            1561.6609099999998,\n",
      "            872.6955555555554\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"f0560b0479c22a952ebfcdba5c7ef400\",\n",
      "    \"text\": \"\\ud835\\udc46\\ud835\\udc61 = \\ud835\\udf02\\ud835\\udc61\\ud835\\udc46\\ud835\\udc61 \\u22121 \\u2212 \\ud835\\udf03\\ud835\\udc61 \\u2207\\u2113 (\\ud835\\udc40\\ud835\\udc61 \\u22121; \\ud835\\udc65\\ud835\\udc61 ),\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            711.0861111111108,\n",
      "            914.2066666666666\n",
      "          ],\n",
      "          [\n",
      "            711.0861111111108,\n",
      "            949.1012511111111\n",
      "          ],\n",
      "          [\n",
      "            1047.8076999999994,\n",
      "            949.1012511111111\n",
      "          ],\n",
      "          [\n",
      "            1047.8076999999994,\n",
      "            914.2066666666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"69f057e015044467f6bda8f5354e0f78\",\n",
      "    \"text\": \"= MeSe-1 \\u2014 8 VE (My-13 1); (14)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5550870895385742,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            723.9215087890625,\n",
      "            922.0646362304688\n",
      "          ],\n",
      "          [\n",
      "            723.9215087890625,\n",
      "            948.4002685546875\n",
      "          ],\n",
      "          [\n",
      "            1555.6673583984375,\n",
      "            948.4002685546875\n",
      "          ],\n",
      "          [\n",
      "            1555.6673583984375,\n",
      "            922.0646362304688\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3d9abd72ef022cd941f94e738c6d13cc\",\n",
      "    \"text\": \"where \\ud835\\udefc\\ud835\\udc61 \\u2208 [0, 1] is the gating mechanism that flexibly controls the memory; i.e., decides how much information should be forgotten. For example, it can update the memory without affecting the past abstraction by letting \\ud835\\udefc\\ud835\\udc61 \\u2192 0, and can clear the entire memory by letting \\ud835\\udefc\\ud835\\udc61 \\u2192 1. Later in this section, we show that this weight decay mechanism is closely related to the gating mechanism in modern RNNs (Dao and Gu 2024; Orvieto et al. 2023).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9416041374206543,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            975.0899999999999\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            1107.2740478515625\n",
      "          ],\n",
      "          [\n",
      "            1564.720458984375,\n",
      "            1107.2740478515625\n",
      "          ],\n",
      "          [\n",
      "            1564.720458984375,\n",
      "            975.0899999999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0e6be9a7aa550ac1fc6c6521d3c1aa13\",\n",
      "    \"text\": \"Memory Architecture. In this paper, we focus on simple MLPs with \\ud835\\udc3fM \\u2265 1 layers as the architecture of our long-term memory. The main reason behind this choice is that we want to focus on better motivating the design of the long-term memory and ways that it can be incorporated into an architecture. However, our formulation and architectural design opens a new research direction to design neural architectures that are more effective and efficient in memorization of data. Recently, there has been a promising line of work to design such architectures (Berges et al. 2024; Cetin et al. 2024; J. Zhang et al. 2024), which incorporating them into our framework (i.e., replacing simple MLPs with such architectures) can be an interesting future work.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9546708464622498,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1137.915\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1369.467041015625\n",
      "          ],\n",
      "          [\n",
      "            1568.6455078125,\n",
      "            1369.467041015625\n",
      "          ],\n",
      "          [\n",
      "            1568.6455078125,\n",
      "            1137.915\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@berges2024memory\",\n",
      "          \"start_index\": 565\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@cetin2024evolved\",\n",
      "          \"start_index\": 584\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@zhang2024memory\",\n",
      "          \"start_index\": 606\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"64980f1cf18196777425072dead57c33\",\n",
      "    \"text\": \"When using vector-valued or matrix-valued memory (De et al. 2024; Orvieto et al. 2023; S. Yang, B. Wang, Shen, et al. 2024), the memory module is compressing the past data and fit it into a line. That is, from the meta learning or online learning perspective (Yu Sun et al. 2024), using a matrix-valued memory M = \\ud835\\udc4a \\u2208 R\\ud835\\udc51in \\u00d7\\ud835\\udc51in is equivalent to optimize \\u2113 (\\ud835\\udc4a\\ud835\\udc61 \\u22121; \\ud835\\udc65\\ud835\\udc61 ) = \\u2225\\ud835\\udc4a\\ud835\\udc61 \\u22121k\\ud835\\udc61 \\u2212 v\\ud835\\udc61 \\u22252 2, which is an online linear regression objective and so the optimal solution assumes the underlying dependency of historical data is linear. On the other hand, we argue that deep memory modules (i.e., \\ud835\\udc3fM \\u2265 2) . Aligning with the theoretical results that MLPs with at least two layers are strictly more expressive than linear models (Hornik, Stinchcombe, and White 1989), in Section 5.5, we show that deep memory modules are more effective in practice.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9549524188041687,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.67222222222222,\n",
      "            1386.9816666666666\n",
      "          ],\n",
      "          [\n",
      "            198.67222222222222,\n",
      "            1653.0419921875\n",
      "          ],\n",
      "          [\n",
      "            1568.328857421875,\n",
      "            1653.0419921875\n",
      "          ],\n",
      "          [\n",
      "            1568.328857421875,\n",
      "            1386.9816666666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@de2024griffin\",\n",
      "          \"start_index\": 60\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@orvieto2023resurrecting\",\n",
      "          \"start_index\": 81\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024gatedattn\",\n",
      "          \"start_index\": 118\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@sun2024learning\",\n",
      "          \"start_index\": 273\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"1989\",\n",
      "          \"url\": \"cite.0@hornik1989multilayer\",\n",
      "          \"start_index\": 752\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Section 5 . 5\",\n",
      "          \"url\": \"subsection.5.5\",\n",
      "          \"start_index\": 762\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"fe6a3a3f6841a8526307b09c22f77413\",\n",
      "    \"text\": \"Retrieving a Memory. In the above, we discuss how one can design and train a long-term memory module that learns to memorize at test time. A key remaining question is: How one can retrieve information from the memory? We simply use the forward pass without weight update (i.e., inference) to retrieve a memory correspond to a query. Formally, given an input \\ud835\\udc65\\ud835\\udc61 , we use a linear layer \\ud835\\udc4a\\ud835\\udc44 to project the input, i.e., q\\ud835\\udc61 = \\ud835\\udc65\\ud835\\udc61\\ud835\\udc4a\\ud835\\udc44 and retrieve the corresponding (or useful) information from the memory \\ud835\\udc66\\ud835\\udc61 by:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9449653029441833,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            197.80874633789062,\n",
      "            1682.6399999999999\n",
      "          ],\n",
      "          [\n",
      "            197.80874633789062,\n",
      "            1848.4163818359375\n",
      "          ],\n",
      "          [\n",
      "            1566.35986328125,\n",
      "            1848.4163818359375\n",
      "          ],\n",
      "          [\n",
      "            1566.35986328125,\n",
      "            1682.6399999999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"d32317f62d05aab4849291f7c1fc3579\",\n",
      "    \"text\": \"\\ud835\\udc66\\ud835\\udc61 = M\\u2217 (q\\ud835\\udc61 ). (15)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5819500088691711,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            795.5859985351562,\n",
      "            1875.4715288888888\n",
      "          ],\n",
      "          [\n",
      "            795.5859985351562,\n",
      "            1924.876708984375\n",
      "          ],\n",
      "          [\n",
      "            1565.6160888671875,\n",
      "            1924.876708984375\n",
      "          ],\n",
      "          [\n",
      "            1565.6160888671875,\n",
      "            1875.4715288888888\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"8598fa8798930e07ace21b520c3f6ce9\",\n",
      "    \"text\": \"6\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            873.5666666666671,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            873.5666666666671,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350250000005,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350250000005,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"e1b54ab4c90134ed9f53185f7eba79cc\",\n",
      "    \"text\": \"(12)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1519.4305555555554,\n",
      "            455.27055555555603\n",
      "          ],\n",
      "          [\n",
      "            1519.4305555555554,\n",
      "            482.9444444444448\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            482.9444444444448\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            455.27055555555603\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"21240d78a98f95e3a80fece5c337b14b\",\n",
      "    \"text\": \"(14)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1519.430555555555,\n",
      "            914.2066666666666\n",
      "          ],\n",
      "          [\n",
      "            1519.430555555555,\n",
      "            941.8805555555555\n",
      "          ],\n",
      "          [\n",
      "            1561.6609099999996,\n",
      "            941.8805555555555\n",
      "          ],\n",
      "          [\n",
      "            1561.6609099999996,\n",
      "            914.2066666666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Image\",\n",
      "    \"element_id\": \"21e8d8c670b9ca2937cc5871dc580515\",\n",
      "    \"text\": \"Linear Non-Linear Momentum Calculation Within-Chunk Cross-Chunk Weight Decay All gradients are pre-computed W/o Decay J Sum oeeea PeewrE oooss, (WeX \\u2014X)XT | \\u00b0 rire W/ Decay ) Parallel Associati * 7 \\u00a9,By(WoX \\u2014 X)XT viacumsum | _via Gradient aceleeeooeae aaa) Global Kernel via Matmul\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            335.9972222222222,\n",
      "            202.39610592222226\n",
      "          ],\n",
      "          [\n",
      "            335.9972222222222,\n",
      "            447.5833333333333\n",
      "          ],\n",
      "          [\n",
      "            1423.9914222027778,\n",
      "            447.5833333333333\n",
      "          ],\n",
      "          [\n",
      "            1423.9914222027778,\n",
      "            202.39610592222226\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"fb62de0f02d310605c1f661f093f2970\",\n",
      "    \"text\": \"Figure 1: The illustration of how the training of neural memory can be done in parallel and using matmuls.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            277.66666666666663,\n",
      "            470.83166666666676\n",
      "          ],\n",
      "          [\n",
      "            277.66666666666663,\n",
      "            503.3208122222223\n",
      "          ],\n",
      "          [\n",
      "            1482.3338499999998,\n",
      "            503.3208122222223\n",
      "          ],\n",
      "          [\n",
      "            1482.3338499999998,\n",
      "            470.83166666666676\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"6fd8e085dfe8d6cce56de02318f8e35d\",\n",
      "    \"text\": \"3.2 How to Parallelize the Long-term Memory Training\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8506954312324524,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.6814727783203,\n",
      "            565.8325805664062\n",
      "          ],\n",
      "          [\n",
      "            198.6814727783203,\n",
      "            599.1601422222221\n",
      "          ],\n",
      "          [\n",
      "            1052.7046400000004,\n",
      "            599.1601422222221\n",
      "          ],\n",
      "          [\n",
      "            1052.7046400000004,\n",
      "            565.8325805664062\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c22f0eeef81576c8ca8e9f4624d517ac\",\n",
      "    \"text\": \"As discussed above, the design of our long-term memory module is equivalent to training a meta model by optimizing associative memory loss function \\u2113 (M\\ud835\\udc61 \\u22121; \\ud835\\udc65\\ud835\\udc61 ) = \\u2225M\\ud835\\udc61 \\u22121 (k\\ud835\\udc61 ) \\u2212 v\\ud835\\udc61 \\u22252 2 using gradient descent with momentum and weight decay. Therefore, in theory, the training of long-term memory module requires O (\\ud835\\udc41 ) FLOPs, where \\ud835\\udc41 is the sequence length. However, in practice, we need to parallelize the training process and to fully take advantage of hardware accelerators (e.g., TPUs, GPUs), we need to tensorize the process and use more matmuls.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9443891644477844,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.03055555555554,\n",
      "            614.8316666666668\n",
      "          ],\n",
      "          [\n",
      "            199.03055555555554,\n",
      "            780.7759399414062\n",
      "          ],\n",
      "          [\n",
      "            1565.4493408203125,\n",
      "            780.7759399414062\n",
      "          ],\n",
      "          [\n",
      "            1565.4493408203125,\n",
      "            614.8316666666668\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"6fd8e085dfe8d6cce56de02318f8e35d\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"5057f2388d58a9e33ee3c0656067a525\",\n",
      "    \"text\": \"Next, we show that calculating the weights in the inner loop with mini-batch gradient descent, data-dependent learning\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            797.4816666666666\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            825.1555555555555\n",
      "          ],\n",
      "          [\n",
      "            1559.9998393866665,\n",
      "            825.1555555555555\n",
      "          ],\n",
      "          [\n",
      "            1559.9998393866665,\n",
      "            797.4816666666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"6fd8e085dfe8d6cce56de02318f8e35d\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"af5aea9607d08f137520a90fbf271f59\",\n",
      "    \"text\": \"rate, and weight decay can be reformulated so that it uses only matmuls and sum. We build upon the work of Yu Sun et al. (2024) that shows forward pass of a model optimizing with the mini-batch gradient descent (with constant learning rate) can be calculated using matmuls. We can split the sequence into chunks of size \\ud835\\udc4f \\u2265 1, and write the mini-batch gradient descent as:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9428063631057739,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            805.2402954101562\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            964.6571655273438\n",
      "          ],\n",
      "          [\n",
      "            1565.5462646484375,\n",
      "            964.6571655273438\n",
      "          ],\n",
      "          [\n",
      "            1565.5462646484375,\n",
      "            805.2402954101562\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@sun2024learning\",\n",
      "          \"start_index\": 241\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"6fd8e085dfe8d6cce56de02318f8e35d\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"15a546393a24308c49cd39905052c60a\",\n",
      "    \"text\": \"\\ud835\\udc61\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1056.4250000000002,\n",
      "            982.7591658333332\n",
      "          ],\n",
      "          [\n",
      "            1056.4250000000002,\n",
      "            1002.9611102777776\n",
      "          ],\n",
      "          [\n",
      "            1063.5158825,\n",
      "            1002.9611102777776\n",
      "          ],\n",
      "          [\n",
      "            1063.5158825,\n",
      "            982.7591658333332\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"39c8c34ff30bb9f8bddc11a5a0c02468\",\n",
      "    \"text\": \"M\\ud835\\udc61 = (1 \\u2212 \\ud835\\udefc\\ud835\\udc61 )M\\ud835\\udc61 \\u22121 \\u2212 \\ud835\\udf03\\ud835\\udc61 \\u2207\\u2113 (M\\ud835\\udc61 \\u22121; \\ud835\\udc65\\ud835\\udc61 ) = \\ud835\\udefd\\ud835\\udc61 M0 \\u2212 \\u2211\\ufe01 \\ud835\\udc56=1 \\ud835\\udf03\\ud835\\udc56 \\ud835\\udefd\\ud835\\udc61 \\ud835\\udefd\\ud835\\udc56 \\u2207\\u2113 (M\\ud835\\udc61 \\u2032 ; \\ud835\\udc65\\ud835\\udc56 ), (16)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8292020559310913,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            485.43611111111113,\n",
      "            988.0106811523438\n",
      "          ],\n",
      "          [\n",
      "            485.43611111111113,\n",
      "            1073.273681640625\n",
      "          ],\n",
      "          [\n",
      "            1561.6609100000005,\n",
      "            1073.273681640625\n",
      "          ],\n",
      "          [\n",
      "            1561.6609100000005,\n",
      "            988.0106811523438\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"b80b9fc27c3452f8040aec2d41b086ff\",\n",
      "    \"text\": \"where t\\u2019 = t \\u2014 mod(t, b), and f; =\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            1093.4647213888888\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            1129.9149449999998\n",
      "          ],\n",
      "          [\n",
      "            614.9269969444445,\n",
      "            1129.9149449999998\n",
      "          ],\n",
      "          [\n",
      "            614.9269969444445,\n",
      "            1093.4647213888888\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0272091ba7da0eb2522957c9cfea4aac\",\n",
      "    \"text\": \"\\ud835\\udc57=1(1 \\u2212 \\ud835\\udefc \\ud835\\udc57 ). For the sake of simplicity, we focus on the first chunk, i.e., \\ud835\\udc61 = \\ud835\\udc4f and so \\ud835\\udc61 \\u2032 = 0. Also, we explain the process for the case that M\\ud835\\udc61 = \\ud835\\udc4a\\ud835\\udc61 is linear. The process for MLPs with \\ud835\\udc41\\ud835\\udc5d \\u2265 2 is similar. Using our loss function, we have:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9308575391769409,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.03055555555554,\n",
      "            1097.3427777777777\n",
      "          ],\n",
      "          [\n",
      "            199.03055555555554,\n",
      "            1198.4581298828125\n",
      "          ],\n",
      "          [\n",
      "            1562.772705078125,\n",
      "            1198.4581298828125\n",
      "          ],\n",
      "          [\n",
      "            1562.772705078125,\n",
      "            1097.3427777777777\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"b80b9fc27c3452f8040aec2d41b086ff\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"8959576ee7da5e1e6587975c97528bb8\",\n",
      "    \"text\": \"\\u2207\\u2113 (\\ud835\\udc4a0; \\ud835\\udc65\\ud835\\udc61 ) = (\\ud835\\udc4a0\\ud835\\udc65\\ud835\\udc61 \\u2212 \\ud835\\udc65\\ud835\\udc61 )\\ud835\\udc65 \\u22a4 \\ud835\\udc61 \\u21d2 \\ud835\\udc4f \\u2211\\ufe01 \\ud835\\udc56=1 \\ud835\\udf03\\ud835\\udc56 \\ud835\\udefd\\ud835\\udc4f \\ud835\\udefd\\ud835\\udc56 \\u2207\\u2113 (\\ud835\\udc4a0; \\ud835\\udc65\\ud835\\udc56 ) = \\u0398\\ud835\\udc4fB\\ud835\\udc4f (\\ud835\\udc4a0\\ud835\\udc4b \\u2212 \\ud835\\udc4b )\\ud835\\udc4b \\u22a4, (17)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8069216012954712,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            463.4621887207031,\n",
      "            1222.6008324999998\n",
      "          ],\n",
      "          [\n",
      "            463.4621887207031,\n",
      "            1311.850830078125\n",
      "          ],\n",
      "          [\n",
      "            1571.355712890625,\n",
      "            1311.850830078125\n",
      "          ],\n",
      "          [\n",
      "            1571.355712890625,\n",
      "            1222.6008324999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f854f2f1354928bb0c390a04ce5128c4\",\n",
      "    \"text\": \"94]) and By is defined analogously on\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            580.1190377777776,\n",
      "            1335.1647213888887\n",
      "          ],\n",
      "          [\n",
      "            580.1190377777776,\n",
      "            1375.6622166666666\n",
      "          ],\n",
      "          [\n",
      "            1027.3602777777776,\n",
      "            1375.6622166666666\n",
      "          ],\n",
      "          [\n",
      "            1027.3602777777776,\n",
      "            1335.1647213888887\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"9cc07247182dadbc361299717d73ca07\",\n",
      "    \"text\": \"where \\u00a9, = diag ((%\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            1336.2819755555556\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            1374.1955005555553\n",
      "          ],\n",
      "          [\n",
      "            442.8994597222222,\n",
      "            1374.1955005555553\n",
      "          ],\n",
      "          [\n",
      "            442.8994597222222,\n",
      "            1336.2819755555556\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"efeb2e094e1e5405c0027cd6b3d6e667\",\n",
      "    \"text\": \"\\ud835\\udf032 . . . s. Note that, we do not need to store all \\u0398\\ud835\\udc58\\ud835\\udc4f and \\ud835\\udefd\\ud835\\udc56 B\\ud835\\udc58\\ud835\\udc4f for \\ud835\\udc58 = 1, . . . , \\ud835\\udc41 /\\ud835\\udc4f, instead, we store these matrices for each chunk, resulting in using less memory. Next, we extend this representation so we can also incorporate the momentum term. In a chunk wise gradient descent with momentum, if we look at the momentum term, we have:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9403248429298401,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            1341.4583016666666\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            1477.52880859375\n",
      "          ],\n",
      "          [\n",
      "            1563.0775146484375,\n",
      "            1477.52880859375\n",
      "          ],\n",
      "          [\n",
      "            1563.0775146484375,\n",
      "            1341.4583016666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"9cc07247182dadbc361299717d73ca07\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"ae2368e01cedf3ce88940e4691dddce9\",\n",
      "    \"text\": \"\\ud835\\udc46\\ud835\\udc61 = \\ud835\\udf02\\ud835\\udc61\\ud835\\udc46\\ud835\\udc61 \\u22121 \\u2212 \\ud835\\udf03\\ud835\\udc61 \\ud835\\udc62\\ud835\\udc61, (18)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.6020569801330566,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            773.1472222222221,\n",
      "            1505.5372222222225\n",
      "          ],\n",
      "          [\n",
      "            773.1472222222221,\n",
      "            1548.5462646484375\n",
      "          ],\n",
      "          [\n",
      "            1561.6609099999998,\n",
      "            1548.5462646484375\n",
      "          ],\n",
      "          [\n",
      "            1561.6609099999998,\n",
      "            1505.5372222222225\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"78bbac69d50c456e1af45aecc0ff37bb\",\n",
      "    \"text\": \"where \\ud835\\udc62\\ud835\\udc61 = \\u2207\\u2113 (\\ud835\\udc40\\ud835\\udc61 \\u2032 ; \\ud835\\udc65\\ud835\\udc61 ). Note that, we can compute all \\ud835\\udc62\\ud835\\udc61 at the same time, and so Equation 18 is a linear recurrence with \\ud835\\udc62\\ud835\\udc61 as an input, \\ud835\\udc46\\ud835\\udc61 as the hidden state, and \\ud835\\udf02\\ud835\\udc61 as input-dependent transition value. Accordingly, we can use parallel associative scan (J. T. Smith, Warrington, and Linderman 2023) to calculate \\ud835\\udc46\\ud835\\udc61 s in this chunk.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9316344857215881,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            1566.4177777777777\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            1664.8833324999998\n",
      "          ],\n",
      "          [\n",
      "            1565.34765625,\n",
      "            1664.8833324999998\n",
      "          ],\n",
      "          [\n",
      "            1565.34765625,\n",
      "            1566.4177777777777\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Equation 18\",\n",
      "          \"url\": \"equation.3.18\",\n",
      "          \"start_index\": 86\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c7d8864058502eab0f94e7e6d29cf9d7\",\n",
      "    \"text\": \"Parameters as the Function of Chunks. Instead of making parameters like \\ud835\\udefc\\ud835\\udc61, \\ud835\\udf03\\ud835\\udc61 , and \\ud835\\udf02\\ud835\\udc61 input-dependent (i.e., a function of token \\ud835\\udc65\\ud835\\udc61 ), we can make them functions of their chunk. Despite losing expressive power, this formulation can help to make the training even faster. In this case, we are using the same value for each of \\ud835\\udefc, \\ud835\\udf03 , and \\ud835\\udf02 in each chunk. Accordingly, in Equation 17, we can store \\u0398 using a single scaler. Similarly we can make Equation 18 faster. That is, when \\ud835\\udf02 and \\ud835\\udf03 are learnable but time-invariant inside each chunk, this equation becomes a linear time-invariant system (LTI), which can be computed by a global convolution (Gu, Goel, and Re 2022). In our experiments, we make these parameters as the functions of tokens. However, such simplifications (i.e., as the function of chunks) can be the interest of future work to training larger models in more efficient manner.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9561675190925598,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1696.0344444444445\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1961.6810302734375\n",
      "          ],\n",
      "          [\n",
      "            1565.9637451171875,\n",
      "            1961.6810302734375\n",
      "          ],\n",
      "          [\n",
      "            1565.9637451171875,\n",
      "            1696.0344444444445\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Equation 17\",\n",
      "          \"url\": \"equation.3.17\",\n",
      "          \"start_index\": 371\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Equation 18\",\n",
      "          \"url\": \"equation.3.18\",\n",
      "          \"start_index\": 444\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.0@gu2022efficiently\",\n",
      "          \"start_index\": 662\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"899cc9c4ab8aab7124fdb1ad196ee5c8\",\n",
      "    \"text\": \"7\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            873.5666666666667,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            873.5666666666667,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350250000001,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350250000001,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Image\",\n",
      "    \"element_id\": \"3acaef674b2068bdb8e9557dc8d101c0\",\n",
      "    \"text\": \"Test Time Neural Memory a i) Bi le | a | aa g Ee 4 is) 3 Be 4 3 \\u2014 4 \\u2014 | 8 \\u00ae 8 8 1) 3 2 oO Sequence = | Sl 2 Eo de 3 aa Learnable Data-Independent Weights # Ss re Aa\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            268.00555555555553,\n",
      "            202.39253938333346\n",
      "          ],\n",
      "          [\n",
      "            268.00555555555553,\n",
      "            588.8083333333333\n",
      "          ],\n",
      "          [\n",
      "            1491.9470262555556,\n",
      "            588.8083333333333\n",
      "          ],\n",
      "          [\n",
      "            1491.9470262555556,\n",
      "            202.39253938333346\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 8,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"74d8723728ccefea4bbe9767127807a8\",\n",
      "    \"text\": \"Figure 2: Memory as a Context (MAC) Architecture. This architecture includes three branches of (1) core, (2) contextual (long-term) memory, and (3) persistent memory. The core branch concatenates the corresponding long-term and persistent memories with the input sequence. Next, attention performs on the sequence and decides what part of the information should store in the long-term memory. At the test time, parameters corresponds to contextual memory are still learning, parameters corresponds to the core branch are responsible for in-context learning, and parameters of persistent memory are responsible to store the knowledge about tasks and so are fixed.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8252611756324768,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            612.0538888888891\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            810.6336669921875\n",
      "          ],\n",
      "          [\n",
      "            1563.0308497411106,\n",
      "            810.6336669921875\n",
      "          ],\n",
      "          [\n",
      "            1563.0308497411106,\n",
      "            612.0538888888891\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 8,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"28479d8c9cec7c6aa6e79e080865b97c\",\n",
      "    \"text\": \"3.3 Persistent Memory\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8538755178451538,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.134033203125,\n",
      "            873.2179199999999\n",
      "          ],\n",
      "          [\n",
      "            198.134033203125,\n",
      "            906.4268088888888\n",
      "          ],\n",
      "          [\n",
      "            562.6845703125,\n",
      "            906.4268088888888\n",
      "          ],\n",
      "          [\n",
      "            562.6845703125,\n",
      "            873.2179199999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 8,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"effb7e6f8a9ffa6504b0867ccb940103\",\n",
      "    \"text\": \"Our long-term memory can also be seen as a contextual memory, meaning that the output is fully depend on the context. Therefore, in addition to our long-term memory, we also use a set of learnable but input-independent parameters to act as task-related memory. This type of memory has been referred to as persistent or meta-memory in the literature (X. Dong et al. 2024; Sukhbaatar, Grave, et al. 2019). Given Ny = 1, we use learnable parameters P = [pi po \\u00ab-- PN, | and append it to the start of our sequence: i.e., given a context window size of N, we modify the input as:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9452491998672485,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.63307189941406,\n",
      "            922.0983333333332\n",
      "          ],\n",
      "          [\n",
      "            198.63307189941406,\n",
      "            1088.384521484375\n",
      "          ],\n",
      "          [\n",
      "            1574.4747314453125,\n",
      "            1088.384521484375\n",
      "          ],\n",
      "          [\n",
      "            1574.4747314453125,\n",
      "            922.0983333333332\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@dong2024hymba\",\n",
      "          \"start_index\": 387\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.0@sukhbaatar2019augmenting\",\n",
      "          \"start_index\": 419\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 8,\n",
      "      \"parent_id\": \"28479d8c9cec7c6aa6e79e080865b97c\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"2e6e3c08562e473c45bc7cb4e71f4fb6\",\n",
      "    \"text\": \"Xnew =[Pr P2 +.\\u00bb PNp| ll x (19)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.7079141736030579,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            690.4307250976562,\n",
      "            1110.47642\n",
      "          ],\n",
      "          [\n",
      "            690.4307250976562,\n",
      "            1162.608642578125\n",
      "          ],\n",
      "          [\n",
      "            1564.868408203125,\n",
      "            1162.608642578125\n",
      "          ],\n",
      "          [\n",
      "            1564.868408203125,\n",
      "            1110.47642\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 8,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"872a90aa4708623e659ba34d1f5f755a\",\n",
      "    \"text\": \"where || is concatenation. Next, we discuss the motivation of persistent memory from three perspective:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8493790626525879,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.97500000000008,\n",
      "            1176.701111111111\n",
      "          ],\n",
      "          [\n",
      "            198.97500000000008,\n",
      "            1209.441162109375\n",
      "          ],\n",
      "          [\n",
      "            1376.7501266666663,\n",
      "            1209.441162109375\n",
      "          ],\n",
      "          [\n",
      "            1376.7501266666663,\n",
      "            1176.701111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 8,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f10f6254f5013c0192660b8d960d5540\",\n",
      "    \"text\": \"Memory Perspective. As discussed earlier, our neural long-term memory is a contextual memory, in which all parameters are input-dependent. An effective memory system, however, also needs input-independent parameters to store the abstraction of the task knowledge. That is, mastering a task requires the memorization of the knowledge that how the task can be done, and these parameters are responsible for storing such knowledge.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9422780871391296,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1239.8983333333333\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1372.7950439453125\n",
      "          ],\n",
      "          [\n",
      "            1566.8309326171875,\n",
      "            1372.7950439453125\n",
      "          ],\n",
      "          [\n",
      "            1566.8309326171875,\n",
      "            1239.8983333333333\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 8,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"30ebd242d27cb9d8545d856f5dc9918e\",\n",
      "    \"text\": \"Feedforward Network Perspective. In the Transformer architectures, there are fully connected layers after the attention module, which are shown to be similar to attention weights but with data-independent parameters. That is, Sukhbaatar, Grave, et al. (2019) showed that replacing the ReLU in fully connected layers with Softmax can results in an attention-like weights, in which weights are data-independent:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9413570761680603,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            1402.726111111111\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            1534.774658203125\n",
      "          ],\n",
      "          [\n",
      "            1566.135009765625,\n",
      "            1534.774658203125\n",
      "          ],\n",
      "          [\n",
      "            1566.135009765625,\n",
      "            1402.726111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.0@sukhbaatar2019augmenting\",\n",
      "          \"start_index\": 253\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 8,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"4bbeb6aecece253c9b9e1f673b79c430\",\n",
      "    \"text\": \"\\ud835\\udc39 \\ud835\\udc39 \\ud835\\udc41 (\\ud835\\udc65) = \\ud835\\udc4a\\ud835\\udc49 Softmax (\\ud835\\udc4a\\ud835\\udc3e\\ud835\\udc65) . (20)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.6367090344429016,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            700.2078247070312,\n",
      "            1563.2344444444445\n",
      "          ],\n",
      "          [\n",
      "            700.2078247070312,\n",
      "            1596.345947265625\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            1596.345947265625\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            1563.2344444444445\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 8,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"70e29c842b35ef8803f365b27550c064\",\n",
      "    \"text\": \"In fact, \\ud835\\udc4a\\ud835\\udc3e and \\ud835\\udc4a\\ud835\\udc49 are acting similar to \\ud835\\udc3e and \\ud835\\udc49 matrices in attention module when they are input-independent. The persistent memory weights are expected to have the same functionality, meaning that using them in the first part of the sequence leads to having input-independent attention weights (Sukhbaatar, Grave, et al. 2019).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9349142909049988,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1624.1177777777777\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1723.389892578125\n",
      "          ],\n",
      "          [\n",
      "            1568.7908935546875,\n",
      "            1723.389892578125\n",
      "          ],\n",
      "          [\n",
      "            1568.7908935546875,\n",
      "            1624.1177777777777\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 8,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a038ad1176c9b94d3b97944b43be2b88\",\n",
      "    \"text\": \"Technical Perspective. Attention with causal mask has implicit bias toward initial tokens in the sequence, and so attention weights are almost always highly active for initial tokens, resulting in performance damage. From the technical perspective, these learnable parameters at the start of the sequence can mitigate such effect by redistributing the attention weights more effectively (Han et al. 2024; Xiao et al. 2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9426199197769165,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            1753.7344444444443\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            1885.52197265625\n",
      "          ],\n",
      "          [\n",
      "            1565.6124267578125,\n",
      "            1885.52197265625\n",
      "          ],\n",
      "          [\n",
      "            1565.6124267578125,\n",
      "            1753.7344444444443\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 8,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"ad14006689940d2d90c6756c8e59483b\",\n",
      "    \"text\": \"8\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            873.5666666666667,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            873.5666666666667,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350250000001,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350250000001,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 8,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Image\",\n",
      "    \"element_id\": \"06298160d888dd91485e488cff26182f\",\n",
      "    \"text\": \"Segment Window + Long-term Memory HEH EEE iseuszataszesnsse femory @ Long-term Memory @ Persistent Memory\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            202.39645824722206\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            477.2472222222221\n",
      "          ],\n",
      "          [\n",
      "            852.7414673,\n",
      "            477.2472222222221\n",
      "          ],\n",
      "          [\n",
      "            852.7414673,\n",
      "            202.39645824722206\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Image\",\n",
      "    \"element_id\": \"b152eddac4496f6a1c0d2a599bb7502b\",\n",
      "    \"text\": \"Sliding Window Long-term Memor (sutton Memory) (Short. and Long-term Memory) de eteeecaite PaeenOny : : : He +H +H HH +4} if | \\u2014 Z T @ Short-term Memory @ Long-term Memory @ Persistent Memory\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            907.2055555555555,\n",
      "            232.8381249138889\n",
      "          ],\n",
      "          [\n",
      "            907.2055555555555,\n",
      "            507.6888888888889\n",
      "          ],\n",
      "          [\n",
      "            1559.9470228555554,\n",
      "            507.6888888888889\n",
      "          ],\n",
      "          [\n",
      "            1559.9470228555554,\n",
      "            232.8381249138889\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"FigureCaption\",\n",
      "    \"element_id\": \"eb55fc3e45d8c83aea332766018d2178\",\n",
      "    \"text\": \"(a) Memory as a Context (MAC). We segment the sequence and use full causal attention in each window. Again, the first \\ud835\\udc41\\ud835\\udc5d tokens are persistent memory and the next \\ud835\\udc41\\ud835\\udc59 are long-term memory tokens\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8840398192405701,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.25277777777777,\n",
      "            490.2544444444443\n",
      "          ],\n",
      "          [\n",
      "            199.25277777777777,\n",
      "            609.941162109375\n",
      "          ],\n",
      "          [\n",
      "            854.7462768554688,\n",
      "            609.941162109375\n",
      "          ],\n",
      "          [\n",
      "            854.7462768554688,\n",
      "            490.2544444444443\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"FigureCaption\",\n",
      "    \"element_id\": \"7949821e04993b1ce668bc8bd7626efb\",\n",
      "    \"text\": \"(b) Memory as Gating (MAG). We use sliding window attention (SWA) as a short-term memory and our neural memory module as a long-term memory, combining by a gating.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.7996006608009338,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            906.4583333333333,\n",
      "            520.6961111111111\n",
      "          ],\n",
      "          [\n",
      "            906.4583333333333,\n",
      "            611.1847534179688\n",
      "          ],\n",
      "          [\n",
      "            1562.9820556640625,\n",
      "            611.1847534179688\n",
      "          ],\n",
      "          [\n",
      "            1562.9820556640625,\n",
      "            520.6961111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b6a1e724ab3d050542173328ad6e3e8c\",\n",
      "    \"text\": \"Figure 3: Attention masks for different variants of Titans.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.6857901811599731,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            550.7899780273438,\n",
      "            638.8622222222223\n",
      "          ],\n",
      "          [\n",
      "            550.7899780273438,\n",
      "            672.5655517578125\n",
      "          ],\n",
      "          [\n",
      "            1203.774659444444,\n",
      "            672.5655517578125\n",
      "          ],\n",
      "          [\n",
      "            1203.774659444444,\n",
      "            638.8622222222223\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"402945b3218d7f8699b00c438c111f65\",\n",
      "    \"text\": \"4 How to Incorporate Memory?\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8510892391204834,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            197.81092834472656,\n",
      "            728.3688116666667\n",
      "          ],\n",
      "          [\n",
      "            197.81092834472656,\n",
      "            768.2193672222221\n",
      "          ],\n",
      "          [\n",
      "            800.3629760742188,\n",
      "            768.2193672222221\n",
      "          ],\n",
      "          [\n",
      "            800.3629760742188,\n",
      "            728.3688116666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"57509458dff4d13c3b74d3ae9720aeb6\",\n",
      "    \"text\": \"An important question that remained unanswered is: How one can effectively and efficiently incorporate the designed neural memory into a deep learning architecture? As discussed earlier, from a memory perspective, the pair of K and V matrices in transformers can be interpreted as an associative memory block. Due to their accurate modeling of dependencies and so their limited context window, we interpret them as short-term memory modules, attending to the current context window size. On the other hand, our neural memory with the ability to continuously learn from data and store it in its weights can play the role of a a long-term memory. In this section, we aim to answer the above question by proposing three different variants of Titans. Later in our experiments, we show that each of these variants has its own advantages/disadvantages and also can show a trade-off between the efficiency and effectiveness in very long-contexts.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9557410478591919,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            193.403076171875,\n",
      "            783.3555555555556\n",
      "          ],\n",
      "          [\n",
      "            193.403076171875,\n",
      "            1090.0882568359375\n",
      "          ],\n",
      "          [\n",
      "            1566.1307373046875,\n",
      "            1090.0882568359375\n",
      "          ],\n",
      "          [\n",
      "            1566.1307373046875,\n",
      "            783.3555555555556\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"402945b3218d7f8699b00c438c111f65\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"655e547071615c3d79d703ec00480eb0\",\n",
      "    \"text\": \"4.1 Memory as a Context\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8554794192314148,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.8147735595703,\n",
      "            1135.246826171875\n",
      "          ],\n",
      "          [\n",
      "            198.8147735595703,\n",
      "            1170.0879200000002\n",
      "          ],\n",
      "          [\n",
      "            599.763916015625,\n",
      "            1170.0879200000002\n",
      "          ],\n",
      "          [\n",
      "            599.763916015625,\n",
      "            1135.246826171875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c9ef607219c7d2940784788581f6a978\",\n",
      "    \"text\": \"In the first architecture design (see Figure 2), we treat the memory as a context to the current information. That is, given a long sequence \\ud835\\udc65 \\u2208 R\\ud835\\udc41 \\u00d7\\ud835\\udc51in, we first chunk the sequence into fixed-size segments S(\\ud835\\udc56 ) for \\ud835\\udc56 = 1, . . . , \\ud835\\udc41 /\\ud835\\udc36. Given the incoming segment S(\\ud835\\udc61 ) , we consider it as the current context and its past segment as the historical information. Therefore, let M\\ud835\\udc61 \\u22121 be the state of long-term memory before segment S(\\ud835\\udc61 ) , we use the input context as the query to the memory M\\ud835\\udc61 \\u22121 to retrieve the corresponding information from the long-term memory. That is, we retrieve the past information that corresponds to S(\\ud835\\udc61 ) as:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9499762654304504,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1185.7622222222221\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1384.2930344444444\n",
      "          ],\n",
      "          [\n",
      "            1564.783203125,\n",
      "            1384.2930344444444\n",
      "          ],\n",
      "          [\n",
      "            1564.783203125,\n",
      "            1185.7622222222221\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Figure 2\",\n",
      "          \"url\": \"figure.caption.4\",\n",
      "          \"start_index\": 61\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"655e547071615c3d79d703ec00480eb0\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"4f6f2ae5f0514b557c9086396ccdf188\",\n",
      "    \"text\": \"\\u210e\\ud835\\udc61 = M\\u2217\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            792.8000000000001,\n",
      "            1411.1659733333333\n",
      "          ],\n",
      "          [\n",
      "            792.8000000000001,\n",
      "            1444.626056111111\n",
      "          ],\n",
      "          [\n",
      "            890.7706713888889,\n",
      "            1444.626056111111\n",
      "          ],\n",
      "          [\n",
      "            890.7706713888889,\n",
      "            1411.1659733333333\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"b95107ab0f6455a43eba647c6bd613f2\",\n",
      "    \"text\": \"\\ud835\\udc61 \\u22121(q\\ud835\\udc61 ),\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            879.5777777777778,\n",
      "            1412.3583016666666\n",
      "          ],\n",
      "          [\n",
      "            879.5777777777778,\n",
      "            1450.0012511111113\n",
      "          ],\n",
      "          [\n",
      "            965.6799222222221,\n",
      "            1450.0012511111113\n",
      "          ],\n",
      "          [\n",
      "            965.6799222222221,\n",
      "            1412.3583016666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"4f6f2ae5f0514b557c9086396ccdf188\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"11144424ed1c7cf1755ffb8d5b665681\",\n",
      "    \"text\": \"hy = M;_1(40)s (21)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5805140733718872,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            788.71826171875,\n",
      "            1420.4012451171875\n",
      "          ],\n",
      "          [\n",
      "            788.71826171875,\n",
      "            1445.533447265625\n",
      "          ],\n",
      "          [\n",
      "            1551.6427001953125,\n",
      "            1445.533447265625\n",
      "          ],\n",
      "          [\n",
      "            1551.6427001953125,\n",
      "            1420.4012451171875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"37650981324017e9b72c5ba22b38d557\",\n",
      "    \"text\": \"where q\\ud835\\udc61 = S(\\ud835\\udc61 )\\ud835\\udc4a\\ud835\\udc44 . Next, we use this historical information along with our persistent memory parameters as the input\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            1473.8091658333335\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            1510.1983277777776\n",
      "          ],\n",
      "          [\n",
      "            1560.009836702222,\n",
      "            1510.1983277777776\n",
      "          ],\n",
      "          [\n",
      "            1560.009836702222,\n",
      "            1473.8091658333335\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4856e7d99480d8bb3854318afb214774\",\n",
      "    \"text\": \"sequence to the attention module:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9169612526893616,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1483.263916015625\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1540.245849609375\n",
      "          ],\n",
      "          [\n",
      "            1557.861572265625,\n",
      "            1540.245849609375\n",
      "          ],\n",
      "          [\n",
      "            1557.861572265625,\n",
      "            1483.263916015625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"9d66b5c6bc3d54d0f1c0041d0127ea8f\",\n",
      "    \"text\": \"a(t) (t) Shs [pr pe + Pvp] Il he IS\\\", (22)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.6494177579879761,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            645.5292358398438,\n",
      "            1567.6952769444445\n",
      "          ],\n",
      "          [\n",
      "            645.5292358398438,\n",
      "            1617.4375\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            1617.4375\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            1567.6952769444445\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"14b37f33f01bda8e490d35e4a773abe5\",\n",
      "    \"text\": \"yp = Attn (\\u00b0\\u00b0) . (23)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.603111207485199,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            648.0194444444444,\n",
      "            1616.1153088888889\n",
      "          ],\n",
      "          [\n",
      "            648.0194444444444,\n",
      "            1669.728271484375\n",
      "          ],\n",
      "          [\n",
      "            1561.6609099999998,\n",
      "            1669.728271484375\n",
      "          ],\n",
      "          [\n",
      "            1561.6609099999998,\n",
      "            1616.1153088888889\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b50a4544f524051f552b1e71ad1cecdf\",\n",
      "    \"text\": \"The structure of the attention map over the entire sequence is shown in Figure 3a. We then use \\ud835\\udc66\\ud835\\udc61 to update the long-term\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1696.4816666666666\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1728.530554722222\n",
      "          ],\n",
      "          [\n",
      "            1560.0053053550002,\n",
      "            1728.530554722222\n",
      "          ],\n",
      "          [\n",
      "            1560.0053053550002,\n",
      "            1696.4816666666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Figure 3a\",\n",
      "          \"url\": \"figure.caption.5\",\n",
      "          \"start_index\": 72\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"092b5469ed6d40bcc0276ae7f5c4acb9\",\n",
      "    \"text\": \"memory module for the next segment and the final output:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9298713207244873,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1705.248046875\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1761.6248779296875\n",
      "          ],\n",
      "          [\n",
      "            1563.021484375,\n",
      "            1761.6248779296875\n",
      "          ],\n",
      "          [\n",
      "            1563.021484375,\n",
      "            1705.248046875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Figure 3a\",\n",
      "          \"url\": \"figure.caption.5\",\n",
      "          \"start_index\": 72\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"01de1bf785cbc66a80e1ee05cf2a7409\",\n",
      "    \"text\": \"M\\ud835\\udc61 = M\\ud835\\udc61 \\u22121 (\\ud835\\udc66\\ud835\\udc61 ) , (24)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.44562700390815735,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            773.6277777777776,\n",
      "            1789.94\n",
      "          ],\n",
      "          [\n",
      "            773.6277777777776,\n",
      "            1831.8385009765625\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            1831.8385009765625\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            1789.94\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"aedda55d63dc37c58424b884d1ccfe30\",\n",
      "    \"text\": \"\\ud835\\udc5c\\ud835\\udc61 = \\ud835\\udc66\\ud835\\udc61 \\u2297 M\\u2217\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            772.3833333333333,\n",
      "            1830.5631955555555\n",
      "          ],\n",
      "          [\n",
      "            772.3833333333333,\n",
      "            1864.0232783333333\n",
      "          ],\n",
      "          [\n",
      "            923.4651158333334,\n",
      "            1864.0232783333333\n",
      "          ],\n",
      "          [\n",
      "            923.4651158333334,\n",
      "            1830.5631955555555\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"1d7fe364c821672a05f7d8be095518f6\",\n",
      "    \"text\": \"\\ud835\\udc61 (\\ud835\\udc66\\ud835\\udc61 ) . (25)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.46637457609176636,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            777.696044921875,\n",
      "            1831.451111111111\n",
      "          ],\n",
      "          [\n",
      "            777.696044921875,\n",
      "            1866.95263671875\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            1866.95263671875\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            1831.451111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"cb6e779e01c51671a06ca53afe6337d3\",\n",
      "    \"text\": \"Note that, in the above, we are updating the weight of M\\ud835\\udc61 \\u22121 through forward pass.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1891.6983333333333\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1926.5929177777775\n",
      "          ],\n",
      "          [\n",
      "            1138.780081111111,\n",
      "            1926.5929177777775\n",
      "          ],\n",
      "          [\n",
      "            1138.780081111111,\n",
      "            1891.6983333333333\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"fcc6acc990babf4055d5e1362def4cbc\",\n",
      "    \"text\": \"This architecture has two key advantages: (1) Attention by having both historical and current context, has the ability to\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1941.5122222222221\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1969.1861111111111\n",
      "          ],\n",
      "          [\n",
      "            1560.0127839644447,\n",
      "            1969.1861111111111\n",
      "          ],\n",
      "          [\n",
      "            1560.0127839644447,\n",
      "            1941.5122222222221\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0c19e19cb91a88c212853b914cbb695f\",\n",
      "    \"text\": \"decides whether given the current data, the long-term memory information is needed. (2) The attention module helps\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9255869388580322,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1949.7606201171875\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            2006.645751953125\n",
      "          ],\n",
      "          [\n",
      "            1560.9832763671875,\n",
      "            2006.645751953125\n",
      "          ],\n",
      "          [\n",
      "            1560.9832763671875,\n",
      "            1949.7606201171875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"42fc86b1a20e40638ebcd97b4b70d6c9\",\n",
      "    \"text\": \"9\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            873.5666666666666,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            873.5666666666666,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350249999999,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            886.4350249999999,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"b74ca1b3eca21aac9401a6be23956824\",\n",
      "    \"text\": \"(21)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1519.4305555555554,\n",
      "            1412.0538888888889\n",
      "          ],\n",
      "          [\n",
      "            1519.4305555555554,\n",
      "            1439.7277777777779\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            1439.7277777777779\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            1412.0538888888889\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Image\",\n",
      "    \"element_id\": \"e0973ff38426a3e41d0899266a4a8796\",\n",
      "    \"text\": \"Test Time Neural Memory s Sp EI \\u00a3\\u00a2 \\u2018d oq 3 gs 3 oO = 8 32 g \\u2014 2 \\u00a34 8 = -\\u2014- i ( ap 2 | \\u2014\\u2014\\u2014\\u2014\\u2014\\u2014 o\\u2014 8a 2 \\u00ae Sequence = | Sl gE z\\u00b0 29 i @ aq ARR Learnable Data-Independent Weights g os a a,\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            268.00555555555553,\n",
      "            202.39253938333346\n",
      "          ],\n",
      "          [\n",
      "            268.00555555555553,\n",
      "            588.8083333333333\n",
      "          ],\n",
      "          [\n",
      "            1491.9470262555556,\n",
      "            588.8083333333333\n",
      "          ],\n",
      "          [\n",
      "            1491.9470262555556,\n",
      "            202.39253938333346\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"eec6923f1cadf4624777ad881a214c1b\",\n",
      "    \"text\": \"Figure 4: Memory as a Gate (MAG) Architecture. This architecture, similarly, has the three branches of (1) core, (2) contextual memory, and (3) persistent memory. It, however, incorporates only persistent memory into the context and combine memory with the core branch using a gating mechanism. At test time, the behavior is the same as Figure 2.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.919221818447113,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            612.0538888888891\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            711.9276123046875\n",
      "          ],\n",
      "          [\n",
      "            1565.5220947265625,\n",
      "            711.9276123046875\n",
      "          ],\n",
      "          [\n",
      "            1565.5220947265625,\n",
      "            612.0538888888891\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a8bc8542349c135a7bbe0cca45b2bf10\",\n",
      "    \"text\": \"the long-term memory to store only useful information from the current context. That is, not all tokens in each segment are useful and memorizing all of them can result in memory overflow. Therefore, attention is helping the memory to understand which information is useful, better managing the memory capacity. (3) At test time: (i) persistent memory parameters are fixed as they encodes the knowledge about the task, which should not be changed; (ii) the attention module weights are in-context learner; and (iii) the long-term memory module is still learning (memorizing) the information at test time. That is, we update the weights of the neural memory even at test time as weights are encoding the abstraction of long past.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9510798454284668,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            771.4566666666668\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            1003.6691284179688\n",
      "          ],\n",
      "          [\n",
      "            1564.644287109375,\n",
      "            1003.6691284179688\n",
      "          ],\n",
      "          [\n",
      "            1564.644287109375,\n",
      "            771.4566666666668\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"2fabe7a7578807294a1126b897f45818\",\n",
      "    \"text\": \"4.2 Gated Memory\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8532147407531738,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            197.83827209472656,\n",
      "            1049.2222900390625\n",
      "          ],\n",
      "          [\n",
      "            197.83827209472656,\n",
      "            1083.3823644444444\n",
      "          ],\n",
      "          [\n",
      "            501.66375732421875,\n",
      "            1083.3823644444444\n",
      "          ],\n",
      "          [\n",
      "            501.66375732421875,\n",
      "            1049.2222900390625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"867bf1458f070ccb73da1e9d329aa085\",\n",
      "    \"text\": \"In the next variant (see Figure 4), in one branch, we directly use the input data to update the long-term memory, and in the\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1099.0538888888889\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1126.7277777777779\n",
      "          ],\n",
      "          [\n",
      "            1560.007255988889,\n",
      "            1126.7277777777779\n",
      "          ],\n",
      "          [\n",
      "            1560.007255988889,\n",
      "            1099.0538888888889\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Figure 4\",\n",
      "          \"url\": \"figure.caption.6\",\n",
      "          \"start_index\": 42\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"parent_id\": \"2fabe7a7578807294a1126b897f45818\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"18fdfc9524244f90c442b37a064dbc97\",\n",
      "    \"text\": \"second branch, we use a sliding window attention (SWA):\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9280877709388733,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1107.58740234375\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1163.7940673828125\n",
      "          ],\n",
      "          [\n",
      "            1563.8814697265625,\n",
      "            1163.7940673828125\n",
      "          ],\n",
      "          [\n",
      "            1563.8814697265625,\n",
      "            1107.58740234375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Figure 4\",\n",
      "          \"url\": \"figure.caption.6\",\n",
      "          \"start_index\": 42\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"parent_id\": \"2fabe7a7578807294a1126b897f45818\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"a1db21deeeee535fdefb2ab43f160b02\",\n",
      "    \"text\": \"F=[pi po -- pnp] ll x (26)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.626982569694519,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            704.7227172851562,\n",
      "            1237.6180866666666\n",
      "          ],\n",
      "          [\n",
      "            704.7227172851562,\n",
      "            1290.974365234375\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            1290.974365234375\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            1237.6180866666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"20ecc75c7b029fb11d2ea43284655e51\",\n",
      "    \"text\": \"\\ud835\\udc66 = SW-Attn\\u2217 ( \\u02dc\\ud835\\udc65) ,\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            707.5916666666667,\n",
      "            1283.58264\n",
      "          ],\n",
      "          [\n",
      "            707.5916666666667,\n",
      "            1317.0427227777777\n",
      "          ],\n",
      "          [\n",
      "            914.224366666667,\n",
      "            1317.0427227777777\n",
      "          ],\n",
      "          [\n",
      "            914.224366666667,\n",
      "            1283.58264\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"a4f07765dbe01d04b7c6ae9d59887c2f\",\n",
      "    \"text\": \"\\ud835\\udc5c = \\ud835\\udc66 \\u2297 M ( \\u02dc\\ud835\\udc65), (28)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.6603898406028748,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            703.380859375,\n",
      "            1297.9105224609375\n",
      "          ],\n",
      "          [\n",
      "            703.380859375,\n",
      "            1370.5799560546875\n",
      "          ],\n",
      "          [\n",
      "            1566.054931640625,\n",
      "            1370.5799560546875\n",
      "          ],\n",
      "          [\n",
      "            1566.054931640625,\n",
      "            1297.9105224609375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"fbdb160c4360253238d89092b72280c9\",\n",
      "    \"text\": \"where SW-Attn\\u2217 is sliding window attention with prefix (see Figure 3b). Note that, contrary to the previous design, we are not segmenting the input data. Also, we abuse the notation and use M (\\ud835\\udc65) to refer to the final output of the memory after all recursion over the tokens of the sequence. In the above equation, \\u2297 can be any non-linear gating. In our experiments, we normalize the outputs \\ud835\\udc66 and M ( \\u02dc\\ud835\\udc65) using learnable vector-valued weights, followed by a non-linearity \\ud835\\udf0e (.).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.93864506483078,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            1386.8649999999998\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            1518.37032\n",
      "          ],\n",
      "          [\n",
      "            1568.2042236328125,\n",
      "            1518.37032\n",
      "          ],\n",
      "          [\n",
      "            1568.2042236328125,\n",
      "            1386.8649999999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Figure 3b\",\n",
      "          \"url\": \"figure.caption.5\",\n",
      "          \"start_index\": 59\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a7d5f0ded0b4d030b617bfbd1a5e6adc\",\n",
      "    \"text\": \"The overall attention mask of this design is shown in Figure 3b. In this design, sliding window attention is act as a precise\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1536.3038888888887\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1563.9777777777779\n",
      "          ],\n",
      "          [\n",
      "            1559.986632139445,\n",
      "            1563.9777777777779\n",
      "          ],\n",
      "          [\n",
      "            1559.986632139445,\n",
      "            1536.3038888888887\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Figure 3b\",\n",
      "          \"url\": \"figure.caption.5\",\n",
      "          \"start_index\": 54\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a3066f9e6c038d0a442d9dbb2636dbc7\",\n",
      "    \"text\": \"short-term memory, while the neural memory module is acting as a fading memory for the model. This architecture design can also be seen as a multi-head architecture where the structure of heads are different (X. Dong et al. 2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9376937747001648,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1543.43115234375\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1634.78271484375\n",
      "          ],\n",
      "          [\n",
      "            1565.6680908203125,\n",
      "            1634.78271484375\n",
      "          ],\n",
      "          [\n",
      "            1565.6680908203125,\n",
      "            1543.43115234375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Figure 3b\",\n",
      "          \"url\": \"figure.caption.5\",\n",
      "          \"start_index\": 54\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"4732612417b4960385ebde44cc0871e2\",\n",
      "    \"text\": \"4.3 Memory as a Layer\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8616694211959839,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            197.0912322998047,\n",
      "            1681.0794677734375\n",
      "          ],\n",
      "          [\n",
      "            197.0912322998047,\n",
      "            1715.3934755555554\n",
      "          ],\n",
      "          [\n",
      "            563.0821533203125,\n",
      "            1715.3934755555554\n",
      "          ],\n",
      "          [\n",
      "            563.0821533203125,\n",
      "            1681.0794677734375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3e1e2c8add9592980386e1aef1177b6d\",\n",
      "    \"text\": \"The last variant uses the neural Memory As a Layer (MAL) of a deep neural network (see Figure 5). This architecture\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1731.065\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1758.7388888888888\n",
      "          ],\n",
      "          [\n",
      "            1560.0107914444445,\n",
      "            1758.7388888888888\n",
      "          ],\n",
      "          [\n",
      "            1560.0107914444445,\n",
      "            1731.065\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Figure 5\",\n",
      "          \"url\": \"figure.caption.7\",\n",
      "          \"start_index\": 109\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"parent_id\": \"4732612417b4960385ebde44cc0871e2\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9d9515ed38123932327c87e65f79ec1f\",\n",
      "    \"text\": \"design is more common in the literature, where the hybrid models stack recurrent models with full or sliding window attentions. Given input \\ud835\\udc65, we have:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9348325133323669,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1737.94482421875\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1828.5050048828125\n",
      "          ],\n",
      "          [\n",
      "            1562.677734375,\n",
      "            1828.5050048828125\n",
      "          ],\n",
      "          [\n",
      "            1562.677734375,\n",
      "            1737.94482421875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Figure 5\",\n",
      "          \"url\": \"figure.caption.7\",\n",
      "          \"start_index\": 109\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"parent_id\": \"4732612417b4960385ebde44cc0871e2\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"d3934a7c915ba9336773d617799869d5\",\n",
      "    \"text\": \"k= [pr po... pnp] lls (29) M(x),\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.6469423770904541,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            705.3078002929688,\n",
      "            1853.0264199999997\n",
      "          ],\n",
      "          [\n",
      "            705.3078002929688,\n",
      "            1919.01220703125\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            1919.01220703125\n",
      "          ],\n",
      "          [\n",
      "            1561.66091,\n",
      "            1853.0264199999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"f57bd132df94d3e640be978dbd20e9b4\",\n",
      "    \"text\": \"\\ud835\\udc66 = M ( \\u02dc\\ud835\\udc65),\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            707.5916666666667,\n",
      "            1899.7122222222222\n",
      "          ],\n",
      "          [\n",
      "            707.5916666666667,\n",
      "            1932.4482783333333\n",
      "          ],\n",
      "          [\n",
      "            828.7910333333335,\n",
      "            1932.4482783333333\n",
      "          ],\n",
      "          [\n",
      "            828.7910333333335,\n",
      "            1899.7122222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"2a92427521a3eb2830c3fb16d9593fe4\",\n",
      "    \"text\": \"\\ud835\\udc5c = SW-Attn (\\ud835\\udc66) , (31)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.4830491840839386,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            708.0055555555558,\n",
      "            1941.3872222222221\n",
      "          ],\n",
      "          [\n",
      "            708.0055555555558,\n",
      "            1977.03564453125\n",
      "          ],\n",
      "          [\n",
      "            1561.6609100000005,\n",
      "            1977.03564453125\n",
      "          ],\n",
      "          [\n",
      "            1561.6609100000005,\n",
      "            1941.3872222222221\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"a1995646a55c5e9fc50882c26eca4456\",\n",
      "    \"text\": \"10\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1305555555559,\n",
      "            2057.7427777777775\n",
      "          ],\n",
      "          [\n",
      "            867.1305555555559,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222226,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222226,\n",
      "            2057.7427777777775\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"e4321467d09e8b91c8449d189ab6e02f\",\n",
      "    \"text\": \"(27)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1519.4305555555559,\n",
      "            1284.4705555555556\n",
      "          ],\n",
      "          [\n",
      "            1519.4305555555559,\n",
      "            1312.1444444444444\n",
      "          ],\n",
      "          [\n",
      "            1561.6609100000005,\n",
      "            1312.1444444444444\n",
      "          ],\n",
      "          [\n",
      "            1561.6609100000005,\n",
      "            1284.4705555555556\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"99c98b9a716ab051c272db7335ea7d6b\",\n",
      "    \"text\": \"(30)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1519.4305555555559,\n",
      "            1899.8761111111112\n",
      "          ],\n",
      "          [\n",
      "            1519.4305555555559,\n",
      "            1927.55\n",
      "          ],\n",
      "          [\n",
      "            1561.6609100000005,\n",
      "            1927.55\n",
      "          ],\n",
      "          [\n",
      "            1561.6609100000005,\n",
      "            1899.8761111111112\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 10,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Image\",\n",
      "    \"element_id\": \"a6d9d7eebfdfcde428032ec0d5f05e4f\",\n",
      "    \"text\": \"Test Time Neural Memory Contextual Memory Learning Core all Sequence Attention In-Context Learning & Learnable Data-Independent Weights Persistent Memory Fixed\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            268.00555555555553,\n",
      "            202.39222831111096\n",
      "          ],\n",
      "          [\n",
      "            268.00555555555553,\n",
      "            599.736111111111\n",
      "          ],\n",
      "          [\n",
      "            1491.9470262555556,\n",
      "            599.736111111111\n",
      "          ],\n",
      "          [\n",
      "            1491.9470262555556,\n",
      "            202.39222831111096\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"d8ff4760d5f162a20630acd7932263db\",\n",
      "    \"text\": \"Figure 5: Memory as a Layer (MAL) Architecture. In this architecture, the memory layer is responsible to compress the past and current context before the attention module.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8282893300056458,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            622.9816666666668\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            687.8258056640625\n",
      "          ],\n",
      "          [\n",
      "            1560.009486144444,\n",
      "            687.8258056640625\n",
      "          ],\n",
      "          [\n",
      "            1560.009486144444,\n",
      "            622.9816666666668\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f997e2b2b322b16e6ebf91c1178041c4\",\n",
      "    \"text\": \"where SW-Attn is sliding window attention. The main drawback of this design is that the power of the model is limited by each of the layers and so it cannot take advantage of the complementary data processing of attention and neural memory module. In our experiments, for evaluating memory in this design, we use a similar architecture as H3 (D. Y. Fu et al. 2023), where we replace the the sequence model with our neural memory module (LMM).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.940243661403656,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            748.4455555555558\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            880.9974975585938\n",
      "          ],\n",
      "          [\n",
      "            1566.228515625,\n",
      "            880.9974975585938\n",
      "          ],\n",
      "          [\n",
      "            1566.228515625,\n",
      "            748.4455555555558\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@fu2023hungry\",\n",
      "          \"start_index\": 359\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e86ed883bde531e5209e33c823e4be81\",\n",
      "    \"text\": \"Memory Without Attention. Although in the above, we discussed MAL as the combination of LMMs and attention in a sequential manner, one simple variant of MAL is to treat LMM as a sequence model without any attention. From the memory perspective, as discussed in Section 1, we expect each part of the memory system to work independently, even if other components are disturbed. Therefore, a long-term memory module should still be a powerful model even without short-term memory (i.e., attention). We refer to this variant as LMM or Titans (LMM) in our experiments. We provide additional discussions on the connection of Titans and other modern recurrent models in Appendix C.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9539770483970642,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            911.2705555555555\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1109.2110595703125\n",
      "          ],\n",
      "          [\n",
      "            1567.0167236328125,\n",
      "            1109.2110595703125\n",
      "          ],\n",
      "          [\n",
      "            1567.0167236328125,\n",
      "            911.2705555555555\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Section 1\",\n",
      "          \"url\": \"section.1\",\n",
      "          \"start_index\": 261\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"7d1090c61156ad97d688eafcfd49b940\",\n",
      "    \"text\": \"4.4 Architectural Details\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8619310855865479,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.8319549560547,\n",
      "            1155.1644287109375\n",
      "          ],\n",
      "          [\n",
      "            199.8319549560547,\n",
      "            1189.8295866666667\n",
      "          ],\n",
      "          [\n",
      "            593.7836303710938,\n",
      "            1189.8295866666667\n",
      "          ],\n",
      "          [\n",
      "            593.7836303710938,\n",
      "            1155.1644287109375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"cfbdb91dc0a6bc477a0bf573a865bb20\",\n",
      "    \"text\": \"For the sake of simplicity and presentation, we avoid discussing the implementation details like using residual connection,\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1205.503888888889\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1233.1777777777777\n",
      "          ],\n",
      "          [\n",
      "            1563.0480628999996,\n",
      "            1233.1777777777777\n",
      "          ],\n",
      "          [\n",
      "            1563.0480628999996,\n",
      "            1205.503888888889\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"7d1090c61156ad97d688eafcfd49b940\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0e9122ed2981e6d402c32553c79199ae\",\n",
      "    \"text\": \"gating with linear layer, and normalization. In all blocks, we use residual connections. In our implementation, we use SiLU(.) activation (Elfwing, Uchibe, and Doya 2018) as the non-linear activation for computing query, key, and values and normalize queries and keys using \\u21132-norm.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9444149732589722,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1212.363037109375\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1336.9527777777778\n",
      "          ],\n",
      "          [\n",
      "            1566.6048583984375,\n",
      "            1336.9527777777778\n",
      "          ],\n",
      "          [\n",
      "            1566.6048583984375,\n",
      "            1212.363037109375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2018\",\n",
      "          \"url\": \"cite.0@elfwing2018sigmoid\",\n",
      "          \"start_index\": 315\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"7d1090c61156ad97d688eafcfd49b940\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"625973629c63ffbd8e835895e56a4a72\",\n",
      "    \"text\": \"Convolution. Following the recent modern linear recurrent models (Gu and Dao 2024; S. Yang, Kautz, and Hatamizadeh 2024), we incorporate a 1D depthwise-separable convolution layer after each of the query, key, and value projections. While not significantly affect the performance, these 1D convolutions have shown performance improvement and are also computationally efficient.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9431231021881104,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.67222222222222,\n",
      "            1368.3288888888887\n",
      "          ],\n",
      "          [\n",
      "            198.67222222222222,\n",
      "            1498.2186279296875\n",
      "          ],\n",
      "          [\n",
      "            1569.9544677734375,\n",
      "            1498.2186279296875\n",
      "          ],\n",
      "          [\n",
      "            1569.9544677734375,\n",
      "            1368.3288888888887\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@gu2024mamba\",\n",
      "          \"start_index\": 77\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024gated\",\n",
      "          \"start_index\": 115\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"7d1090c61156ad97d688eafcfd49b940\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b5fb3dda78183bc2066a25b2d1c99169\",\n",
      "    \"text\": \"Gating. We also follow the recent architectures that use normalization and gating with a linear layer before the final output projection (Mehta et al. 2023).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9205619096755981,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1531.153888888889\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1592.0361111111113\n",
      "          ],\n",
      "          [\n",
      "            1566.552490234375,\n",
      "            1592.0361111111113\n",
      "          ],\n",
      "          [\n",
      "            1566.552490234375,\n",
      "            1531.153888888889\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"7d1090c61156ad97d688eafcfd49b940\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"40de9074be1b31a699ef7773aa6d2ad8\",\n",
      "    \"text\": \"Theorem 4.1. Contrary to Transformers, diagonal linear recurrent models, and DeltaNet, all of which are limited to TC0 (Merrill,\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.0861111111111,\n",
      "            1611.6008333333334\n",
      "          ],\n",
      "          [\n",
      "            199.0861111111111,\n",
      "            1648.32569\n",
      "          ],\n",
      "          [\n",
      "            1563.0177991555554,\n",
      "            1648.32569\n",
      "          ],\n",
      "          [\n",
      "            1563.0177991555554,\n",
      "            1611.6008333333334\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"7d1090c61156ad97d688eafcfd49b940\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"5f25004b7417db9f699a57fa44ecfd6c\",\n",
      "    \"text\": \"Petty, and Sabharwal 2024), Titans are capable of solving problems beyond TC 0, meaning that Titans are theoretically more expressive than Transformers and most modern linear recurrent models in state tracking tasks.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9426270127296448,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1622.9024658203125\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1714.7423566666664\n",
      "          ],\n",
      "          [\n",
      "            1565.390869140625,\n",
      "            1714.7423566666664\n",
      "          ],\n",
      "          [\n",
      "            1565.390869140625,\n",
      "            1622.9024658203125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@merrill2024the\",\n",
      "          \"start_index\": 150\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"7d1090c61156ad97d688eafcfd49b940\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"cfa3a575fd3817cf4e4fda1b3228636b\",\n",
      "    \"text\": \"5 Experiments\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8551798462867737,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.04727172851562,\n",
      "            1767.907958984375\n",
      "          ],\n",
      "          [\n",
      "            198.04727172851562,\n",
      "            1808.6804783333332\n",
      "          ],\n",
      "          [\n",
      "            495.02960205078125,\n",
      "            1808.6804783333332\n",
      "          ],\n",
      "          [\n",
      "            495.02960205078125,\n",
      "            1767.907958984375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e3cb3e3df256cf71b36abdfcb57a8c59\",\n",
      "    \"text\": \"Next, we evaluate the performance of Titans and its variants in language modeling, commonsense reasoning, needle\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9443007111549377,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.08029174804688,\n",
      "            1823.8166666666668\n",
      "          ],\n",
      "          [\n",
      "            198.08029174804688,\n",
      "            1928.6317138671875\n",
      "          ],\n",
      "          [\n",
      "            1564.968017578125,\n",
      "            1928.6317138671875\n",
      "          ],\n",
      "          [\n",
      "            1564.968017578125,\n",
      "            1823.8166666666668\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"Hfootnote.1\",\n",
      "          \"start_index\": 61\n",
      "        },\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"Hfootnote.1\",\n",
      "          \"start_index\": 61\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"cfa3a575fd3817cf4e4fda1b3228636b\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0757247660c446e70f6b54aa7360638c\",\n",
      "    \"text\": \"1In the first version of the work, we aim to provide insights/evidences about why the learning paradigms of Titans are effective. We are working on\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            230.48888888888888,\n",
      "            1950.9088888888887\n",
      "          ],\n",
      "          [\n",
      "            230.48888888888888,\n",
      "            1976.1027777777779\n",
      "          ],\n",
      "          [\n",
      "            1559.9979700899994,\n",
      "            1976.1027777777779\n",
      "          ],\n",
      "          [\n",
      "            1559.9979700899994,\n",
      "            1950.9088888888887\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"cfa3a575fd3817cf4e4fda1b3228636b\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2e49a10ea482dee884d9ca170c7fe001\",\n",
      "    \"text\": \"finalizing the results of larger models and will report them in the next version.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9321843385696411,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1959.3563232421875\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            2006.4149169921875\n",
      "          ],\n",
      "          [\n",
      "            1560.4755859375,\n",
      "            2006.4149169921875\n",
      "          ],\n",
      "          [\n",
      "            1560.4755859375,\n",
      "            1959.3563232421875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"cfa3a575fd3817cf4e4fda1b3228636b\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"8c0e876fbcc34b3f2c4505fcd2c95403\",\n",
      "    \"text\": \"11\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1305555555556,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            867.1305555555556,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222223,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222223,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"cfa3a575fd3817cf4e4fda1b3228636b\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0098411969ee1e6028f605d4bcddab8e\",\n",
      "    \"text\": \"\\u00a75.6, and \\u00a75.7); (2) What is the actual context length of Titans? (see \\u00a75.3 and \\u00a75.4); (3) How do Titans scale with respect to context length? (see \\u00a75.8); (4) How the depth of memory can affect both performance and efficiency? (see \\u00a75.5); and (5) What is the contribution of each Titans\\u2019 component in its performance? (see \\u00a75.9).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.933875560760498,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.67222222222222,\n",
      "            202.39277777777778\n",
      "          ],\n",
      "          [\n",
      "            198.67222222222222,\n",
      "            303.04248046875\n",
      "          ],\n",
      "          [\n",
      "            1566.6962890625,\n",
      "            303.04248046875\n",
      "          ],\n",
      "          [\n",
      "            1566.6962890625,\n",
      "            202.39277777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"5 . 6\",\n",
      "          \"url\": \"subsection.5.6\",\n",
      "          \"start_index\": 1\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"5 . 7\",\n",
      "          \"url\": \"subsection.5.7\",\n",
      "          \"start_index\": 11\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"5 . 3\",\n",
      "          \"url\": \"subsection.5.3\",\n",
      "          \"start_index\": 72\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"5 . 4\",\n",
      "          \"url\": \"subsection.5.4\",\n",
      "          \"start_index\": 81\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"5 . 8\",\n",
      "          \"url\": \"subsection.5.8\",\n",
      "          \"start_index\": 149\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"5 . 5\",\n",
      "          \"url\": \"subsection.5.5\",\n",
      "          \"start_index\": 230\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"cfa3a575fd3817cf4e4fda1b3228636b\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"767636bcfe635f847f80a633df9c9861\",\n",
      "    \"text\": \"5.1 Experimental Setup\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8617863059043884,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.5486602783203,\n",
      "            348.1585388183594\n",
      "          ],\n",
      "          [\n",
      "            198.5486602783203,\n",
      "            381.48514222222207\n",
      "          ],\n",
      "          [\n",
      "            575.4789428710938,\n",
      "            381.48514222222207\n",
      "          ],\n",
      "          [\n",
      "            575.4789428710938,\n",
      "            348.1585388183594\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 12,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"993a4c5d969cb202b84d112e1c04f884\",\n",
      "    \"text\": \"Models. In our experiments, we focus on the three variants of Titans, which we refer to as: Titans with (1) Memory as a Context (MAC), (2) Memory as a Gate (MAG), and (3) Memory as a Layer (MAL) as well as (4) neural memory module alone. The reason behind using our long-term memory as a separate module is based on our definition of learning. As discussed in Section 1, we define learning a process for acquiring effective and useful memory. Accordingly, we expect our long-term memory to effectively learn from data, even without attention. For each of these models, we consider four scales with: (i) 170M, (ii) 340M, (iii) 400M, and (iv) 760M parameters. While the first three are trained on 15B tokens sampled from FineWeb-Edu dataset (Penedo et al. 2024), the last one is trained on 30B tokens from the same dataset.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9535374045372009,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            410.5427777777777\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            643.736083984375\n",
      "          ],\n",
      "          [\n",
      "            1571.53955078125,\n",
      "            643.736083984375\n",
      "          ],\n",
      "          [\n",
      "            1571.53955078125,\n",
      "            410.5427777777777\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Section 1\",\n",
      "          \"url\": \"section.1\",\n",
      "          \"start_index\": 359\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"767636bcfe635f847f80a633df9c9861\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"febb6cae14b8f768549a0faa0467bfc9\",\n",
      "    \"text\": \"Baselines. We compare our models with the state-of-the-art linear recurrent models, Transformers, and hybrid models (recurrent + attention). More specifically in language tasks, we compare with Transformer++ (Touvron et al. 2023), RetNet (Yutao Sun et al. 2023), Gated Linear Attention (GLA) (S. Yang, B. Wang, Shen, et al. 2024), Mamba (Gu and Dao 2024), Mamba2 (Dao and Gu 2024), DeltaNet (S. Yang, B. Wang, Yu Zhang, et al. 2024), TTT (Yu Sun et al. 2024), and Gated DeltaNet (S. Yang, Kautz, and Hatamizadeh 2024). In needle in haystack tasks, we also compare with GPT4 (Achiam et al. 2023), Llama3 with RAG (Touvron et al. 2023), RecurrentGemma2-9B (Botev et al. 2024), and Mistral (Jiang et al. 2023) models, all of which are provided in the benchmark (Yuri Kuratov et al. 2024). In time series tasks, we compare with Mamba-based (Behrouz, Santacatterina, and Zabih 2024), Transformer-based (Y. Liu et al. 2023; Nie et al. 2022; Yunhao Zhang and Yan 2023), and linear models (Das et al. 2023; Z. Li et al. 2023; H. Wu et al. 2023; Zeng et al. 2023).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.953460156917572,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            672.9927777777779\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            971.8728637695312\n",
      "          ],\n",
      "          [\n",
      "            1566.31396484375,\n",
      "            971.8728637695312\n",
      "          ],\n",
      "          [\n",
      "            1566.31396484375,\n",
      "            672.9927777777779\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@touvron2023llama\",\n",
      "          \"start_index\": 223\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@sun2023retentive\",\n",
      "          \"start_index\": 255\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024gatedattn\",\n",
      "          \"start_index\": 323\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@gu2024mamba\",\n",
      "          \"start_index\": 348\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@dao2024transformers\",\n",
      "          \"start_index\": 374\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024parallelizing\",\n",
      "          \"start_index\": 426\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@sun2024learning\",\n",
      "          \"start_index\": 452\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024gated\",\n",
      "          \"start_index\": 511\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@achiam2023gpt\",\n",
      "          \"start_index\": 588\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@touvron2023llama\",\n",
      "          \"start_index\": 627\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@botev2024recurrentgemma\",\n",
      "          \"start_index\": 667\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@jiang2023mistral\",\n",
      "          \"start_index\": 700\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@kuratov2024babilong\",\n",
      "          \"start_index\": 778\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@behrouz2024mambamixer\",\n",
      "          \"start_index\": 871\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@liu2023itransformer\",\n",
      "          \"start_index\": 911\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.0@nie2022time\",\n",
      "          \"start_index\": 928\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"767636bcfe635f847f80a633df9c9861\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2f1d0f392effad35785493f3e9dbe77b\",\n",
      "    \"text\": \"Training. In the training, we follow the training procedure of S. Yang, Kautz, and Hatamizadeh (2024), and use LLama 2 tokenizer with a vocabulary size of 32K and use training length of 4K tokens. We employ AdamW optimizer with learning rate of 4\\ud835\\udc52-4 with cosine annealing schedule with batch size of 0.5M tokens, and weight decay of 0.1.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.93450528383255,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.0861111111111,\n",
      "            1001.8622222222222\n",
      "          ],\n",
      "          [\n",
      "            199.0861111111111,\n",
      "            1100.464111328125\n",
      "          ],\n",
      "          [\n",
      "            1565.51513671875,\n",
      "            1100.464111328125\n",
      "          ],\n",
      "          [\n",
      "            1565.51513671875,\n",
      "            1001.8622222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024gated\",\n",
      "          \"start_index\": 96\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"767636bcfe635f847f80a633df9c9861\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"39cb78456cdcc2ce4c4fe062816ccc92\",\n",
      "    \"text\": \"5.2 Language Modeling\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8633062839508057,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            197.72181701660156,\n",
      "            1145.8643798828125\n",
      "          ],\n",
      "          [\n",
      "            197.72181701660156,\n",
      "            1180.9545866666667\n",
      "          ],\n",
      "          [\n",
      "            572.2686767578125,\n",
      "            1180.9545866666667\n",
      "          ],\n",
      "          [\n",
      "            572.2686767578125,\n",
      "            1145.8643798828125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 12,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e775e217658dde3282ad00ce4a9a3097\",\n",
      "    \"text\": \"We first focus on the perplexity in language modeling and also commonsense reasoning tasks. The results for Titans\\u2019 variants and also baselines with three different sizes of 340M, 400M, and 760M are reported in Table 1. Among non-hybrid models, including Transformer++, our neural memory module achieves the best performance in both perplexity and accuracy measures. Comparing our neural memory module and TTT, which is also a gradient-based recurrent model can show us the importance of our weight decay as well as the momentum. As discussed earlier, the weight decay can be interpreted as a gating mechanism to forget the past data, when it is needed. Also, momentum can help us better manage the memory by providing additional memory for the surprise metric. While some baselines also take advantage of gating mechanism, e.g., Mamba, Mamba2, and Gated DeltaNet, the superior performance of our neural memory module shows the importance of both our surprise mechanism and having deep and non-linear memory. We further discuss the later in Section 5.5.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9554047584533691,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.67222222222222,\n",
      "            1196.626111111111\n",
      "          ],\n",
      "          [\n",
      "            198.67222222222222,\n",
      "            1525.4429931640625\n",
      "          ],\n",
      "          [\n",
      "            1567.996826171875,\n",
      "            1525.4429931640625\n",
      "          ],\n",
      "          [\n",
      "            1567.996826171875,\n",
      "            1196.626111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Table 1\",\n",
      "          \"url\": \"table.caption.8\",\n",
      "          \"start_index\": 231\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"39cb78456cdcc2ce4c4fe062816ccc92\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0d3b1ec75c73d1cdee06d2073bf9d998\",\n",
      "    \"text\": \"Comparing the hybrid models, we found that all three variants of Titans (MAC, MAG, and MAL) outperform both Samba (Mamba + attention) and Gated DeltaNet-H2 (Gated DeltaNet + atttention). We attribute the superior performance of Titans (MAL) to the power of neural memory module as the architecture design and used attention are all the same. Comparing Titans (MAG) and (MAC), we find that while their performance are close, MAC performs better when dealing with longer dependencies in the data. Interestingly, both MAG and MAC outperform MAL variant, which due to using the same modules, we attribute this to the architecture design of these models. This finding is particularly important as the current hybrid models (except Hymba (X. Dong et al. 2024)) in the literature are using MAL-style combination of recurrent models and attention.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9574702978134155,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1545.3177777777776\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1809.2642822265625\n",
      "          ],\n",
      "          [\n",
      "            1566.637451171875,\n",
      "            1809.2642822265625\n",
      "          ],\n",
      "          [\n",
      "            1566.637451171875,\n",
      "            1545.3177777777776\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@dong2024hymba\",\n",
      "          \"start_index\": 746\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"39cb78456cdcc2ce4c4fe062816ccc92\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"ee5e23d702741ae81942bad2cd360674\",\n",
      "    \"text\": \"5.3 Needle in a Haystack\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8665764331817627,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            196.60450744628906,\n",
      "            1853.6009521484375\n",
      "          ],\n",
      "          [\n",
      "            196.60450744628906,\n",
      "            1890.4518088888888\n",
      "          ],\n",
      "          [\n",
      "            596.41845703125,\n",
      "            1890.4518088888888\n",
      "          ],\n",
      "          [\n",
      "            596.41845703125,\n",
      "            1853.6009521484375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 12,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"17ecbfba394dc6af481adcc7890c5fe8\",\n",
      "    \"text\": \"Scaling a model to longer context window is not always equivalent to being effective for very long sequences (Hsieh et al. 2024). The needle-in-a-haystack (NIAH) task is designed to measure the actual effective context length of models. In this task, we evaluate the model on retrieving a piece of information (i.e., the \\u201cneedle\\u201d) from long distractor texts (i.e.,\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9367905259132385,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1906.1261111111112\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            2004.8243408203125\n",
      "          ],\n",
      "          [\n",
      "            1564.3790283203125,\n",
      "            2004.8243408203125\n",
      "          ],\n",
      "          [\n",
      "            1564.3790283203125,\n",
      "            1906.1261111111112\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@hsieh2024ruler\",\n",
      "          \"start_index\": 147\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"ee5e23d702741ae81942bad2cd360674\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"04c1c33e52bc71528878346400dea054\",\n",
      "    \"text\": \"12\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1305555555555,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            867.1305555555555,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222221,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222221,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"ee5e23d702741ae81942bad2cd360674\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"3258a588b3fff4fb2efa8056bfa139cc\",\n",
      "    \"text\": \"Table 1: Performance of Titans and recurrent- and Transformer-based baselines on language modeling and common-sense\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            197.96500000000017\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            225.63888888888894\n",
      "          ],\n",
      "          [\n",
      "            1560.0095461194444,\n",
      "            225.63888888888894\n",
      "          ],\n",
      "          [\n",
      "            1560.0095461194444,\n",
      "            197.96500000000017\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"ee5e23d702741ae81942bad2cd360674\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"FigureCaption\",\n",
      "    \"element_id\": \"9e76e442a42d0ef79390227fe5a4d912\",\n",
      "    \"text\": \"reasoning tasks. Hybrid models are marked with \\u2217. The best results among simple and hybrid models are highlighted.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9193933010101318,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            207.19430541992188\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            267.585693359375\n",
      "          ],\n",
      "          [\n",
      "            1559.9769387244442,\n",
      "            267.585693359375\n",
      "          ],\n",
      "          [\n",
      "            1559.9769387244442,\n",
      "            207.19430541992188\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"ee5e23d702741ae81942bad2cd360674\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Table\",\n",
      "    \"element_id\": \"f326c8f48f3c77fa751d5c7ff95f9f6b\",\n",
      "    \"text\": \"Model Wiki. LMB. LMB. PIQA Hella. Wino. ARC-e ARC-c SIQA BoolQ Avg. ppl \\u2193 ppl \\u2193 acc \\u2191 acc \\u2191 acc_n \\u2191 acc \\u2191 acc \\u2191 acc_n \\u2191 acc \\u2191 acc \\u2191 \\u2191 340M params / 15B tokens Transformer++ 31.52 41.08 30.76 62.98 34.76 50.53 45.21 24.05 36.81 58.24 42.92 RetNet 32.50 49.73 28.24 62.61 34.15 50.91 44.27 23.62 36.79 59.72 42.54 GLA 28.51 43.02 28.73 64.05 35.96 50.00 54.19 24.29 37.13 58.39 44.09 Mamba 30.83 40.21 29.94 63.79 35.88 49.82 49.24 24.56 35.41 60.07 43.59 DeltaNet 28.65 47.30 28.43 63.52 35.95 49.63 52.68 25.37 37.96 58.79 44.04 TTT 27.44 34.19 30.06 63.97 35.71 50.08 53.01 26.11 37.32 59.83 44.51 Gated DeltaNet 27.01 30.94 34.11 63.08 38.12 51.60 55.28 26.77 34.89 59.54 45.42 Titans (LMM) 26.18 29.97 34.98 64.73 39.61 51.85 55.60 28.14 34.52 59.99 46.17 Titans (MAC)\\u2217 25.43 28.13 36.00 65.32 40.35 51.21 58.17 29.00 38.63 60.18 47.36 Titans (MAG)\\u2217 25.07 28.72 36.71 64.88 40.56 52.49 57.72 28.16 39.75 60.01 47.54 Titans (MAL)\\u2217 24.69 28.80 35.74 64.97 39.44 51.97 56.58 28.21 38.14 57.32 46.55 400M params / 15B tokens Transformer++ 30.63 37.37 29.64 64.27 37.72 51.53 54.95 27.36 38.07 61.59 45.64 RetNet 29.92 46.83 29.16 65.23 36.97 51.85 56.01 27.55 37.30 59.66 45.47 HGRN2 32.33 47.14 26.12 64.52 35.45 52.24 55.97 25.51 37.35 59.02 44.52 GLA 27.96 36.66 27.86 65.94 37.41 49.56 56.01 26.36 38.94 59.84 45.24 Mamba 29.22 39.88 29.82 65.72 37.93 50.11 58.37 26.70 37.76 61.13 45.94 Mamba2 26.34 33.19 32.03 65.77 39.73 52.48 59.00 27.64 37.92 60.72 46.91 DeltaNet 27.69 44.04 29.96 64.52 37.03 50.82 56.77 27.13 38.22 60.09 45.57 TTT 26.11 31.52 33.25 65.70 39.11 51.68 58.04 28.99 38.26 59.87 46.86 Gated DeltaNet 25.47 29.24 34.40 65.94 40.46 51.46 59.80 28.58 37.43 60.03 47.26 Samba\\u2217 25.32 29.47 36.86 66.09 39.24 51.45 60.12 27.20 38.68 58.22 47.23 Gated DeltaNet-H2\\u2217 24.19 28.09 36.77 66.43 40.79 52.17 59.55 29.09 39.04 58.56 47.69 Titans (LMM) 25.03 28.99 35.21 65.85 40.91 52.19 59.97 29.20 38.74 60.85 47.83 Titans (MAC)\\u2217 25.61 27.73 36.92 66.39 41.18 52.80 60.24 29.69 40.07 61.93 48.65 Titans (MAG)\\u2217 23.59 27.81 37.24 66.80 40.92 53.21 60.01 29.45 39.91 61.28 48.60 Titans (MAL)\\u2217 23.93 27.89 36.84 66.29 40.74 52.26 59.85 29.71 38.92 58.40 47.87 760M params / 30B tokens Transformer++ 25.21 27.64 35.78 66.92 42.19 51.95 60.38 32.46 39.51 60.37 48.69 RetNet 26.08 24.45 34.51 67.19 41.63 52.09 63.17 32.78 38.36 57.92 48.46 Mamba 28.12 23.96 32.80 66.04 39.15 52.38 61.49 30.34 37.96 57.62 47.22 Mamba2 22.94 28.37 33.54 67.90 42.71 49.77 63.48 31.09 40.06 58.15 48.34 DeltaNet 24.37 24.60 37.06 66.93 41.98 50.65 64.87 31.39 39.88 59.02 48.97 TTT 24.17 23.51 34.74 67.25 43.92 50.99 64.53 33.81 40.16 59.58 47.32 Gated DeltaNet 21.18 22.09 35.54 68.01 44.95 50.73 66.87 33.09 39.21 59.14 49.69 Samba\\u2217 20.63 22.71 39.72 69.19 47.35 52.01 66.92 33.20 38.98 61.24 51.08 Gated DeltaNet-H2\\u2217 19.88 20.83 39.18 68.95 48.22 52.57 67.01 35.49 39.39 61.11 51.49 Titans (LMM) 20.04 21.96 37.40 69.28 48.46 52.27 66.31 35.84 40.13 62.76 51.56 Titans (MAC) 19.93 20.12 39.62 70.46 49.01 53.18 67.86 36.01 41.87 62.05 52.51 Titans (MAG) 18.61 19.86 40.98 70.25 48.94 52.89 68.23 36.19 40.38 62.11 52.50 Titans (MAL) 19.07 20.33 40.05 69.99 48.82 53.02 67.54 35.65 30.98 61.72 50.97\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9166533946990967,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            280.84796142578125,\n",
      "            270.0185852050781\n",
      "          ],\n",
      "          [\n",
      "            280.84796142578125,\n",
      "            1669.321044921875\n",
      "          ],\n",
      "          [\n",
      "            1482.90869140625,\n",
      "            1669.321044921875\n",
      "          ],\n",
      "          [\n",
      "            1482.90869140625,\n",
      "            270.0185852050781\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"ee5e23d702741ae81942bad2cd360674\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"5c51bae9e7b87b2c27ceaad6adb8992a\",\n",
      "    \"text\": \"the \\u201chaystack\\u201d). In this part, we use Single NIAH (S-NIAH) task from RULER benchmark (Hsieh et al. 2024) and evaluate\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1723.24\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1750.9138888888888\n",
      "          ],\n",
      "          [\n",
      "            1560.0055955555554,\n",
      "            1750.9138888888888\n",
      "          ],\n",
      "          [\n",
      "            1560.0055955555554,\n",
      "            1723.24\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@hsieh2024ruler\",\n",
      "          \"start_index\": 99\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"ee5e23d702741ae81942bad2cd360674\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"FigureCaption\",\n",
      "    \"element_id\": \"38849a19de1196bebcdda36360e934d6\",\n",
      "    \"text\": \"Titans and baselines on sequences with length 2K, 4K, 8K, and 16K. The results are reported in Table 2. Neural Memory module achieves the best results compare to baselines in all three tasks. We attribute this superior performance to three key differences of Titans with existing sequence models: (1) Compared to TTT, our Neural Memory can better handle the memory capacity by using momentum and also the forgetting mechanism (i.e., weight decay). Therefore, with increasing the sequence length, the performance of Neural Memory does not drop and show a consistent trend; (2) Compared to Mamba2, which has the gating (forgetting) mechanism, Titans have deep non-linear memory, resulting in better memory management. Also, contrary to our neural memory and DeltaNet, Mamba2 is not capable of removing a memory and so\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.6737350225448608,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.4200897216797,\n",
      "            1730.409912109375\n",
      "          ],\n",
      "          [\n",
      "            198.4200897216797,\n",
      "            1986.7840576171875\n",
      "          ],\n",
      "          [\n",
      "            1561.7860107421875,\n",
      "            1986.7840576171875\n",
      "          ],\n",
      "          [\n",
      "            1561.7860107421875,\n",
      "            1730.409912109375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@hsieh2024ruler\",\n",
      "          \"start_index\": 99\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Table 2\",\n",
      "          \"url\": \"table.caption.9\",\n",
      "          \"start_index\": 213\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"ee5e23d702741ae81942bad2cd360674\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"7e8d49e59562858dc30123b725dabef6\",\n",
      "    \"text\": \"13\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1305555555555,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            867.1305555555555,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222221,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222221,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"ee5e23d702741ae81942bad2cd360674\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"be81182e888fd2f84ca92ced2ac20a6c\",\n",
      "    \"text\": \"Table 2: Performance of Titans and baselines on S-NIAH task from RULER benchmark. The best results among simple\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            202.03444444444472\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            229.70833333333346\n",
      "          ],\n",
      "          [\n",
      "            1551.6992516666667,\n",
      "            229.70833333333346\n",
      "          ],\n",
      "          [\n",
      "            1551.6992516666667,\n",
      "            202.03444444444472\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"ee5e23d702741ae81942bad2cd360674\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"FigureCaption\",\n",
      "    \"element_id\": \"821fda1f2372016c494cb8d57abcdae3\",\n",
      "    \"text\": \"and hybrid models are highlighted.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9149815440177917,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.00000000000014,\n",
      "            210.7920379638672\n",
      "          ],\n",
      "          [\n",
      "            200.00000000000014,\n",
      "            280.1686706542969\n",
      "          ],\n",
      "          [\n",
      "            1550.5684814453125,\n",
      "            280.1686706542969\n",
      "          ],\n",
      "          [\n",
      "            1550.5684814453125,\n",
      "            210.7920379638672\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"ee5e23d702741ae81942bad2cd360674\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Image\",\n",
      "    \"element_id\": \"42a87d2fbce36a12043c0574713a246a\",\n",
      "    \"text\": \"Model  S-NIAH-PK  S-NIAH-N  S-NIAH-W  2K  4K  8K  16K  2K  4K  8K  16K  2K  4K  8K  16K  TTT  98.4  98.8  98.0  88.4  60.2  36.6  10.2  4.4  78.8  28.0  4.4  0.0  Mamba2  98.6  61.4  31.0  5.4  98.4  55.8  14.2  0.0  42.2  4.2  0.0  0.0  DeltaNet  96.8  98.8  98.6  71.4  47.2  15.4  12.8  5.4  46.2  20.0  1.6  0.0  Titans (LMM)  99.8  98.4  98.2  96.2  100.0  99.8  93.4  80.2  90.4  89.4  85.8  80.6  Titans (MAC)  99.2  98.8  99.0  98.4  99.6  98.2  97.6  97.4  98.2  98.2  95.6  95.2  Titans (MAG)  99.4  98.0  97.4  97.4  99.2  98.8  97.2  98.6  98.0  98.0  90.2  88.2  Titans (MAL)  98.8  98.6  98.8  97.8  99.8  98.1  96.8  96.4  98.0  97.4  92.0  90.4  (a) Few-shot Setup  (b) Fine-Tuning Setup \",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8545629382133484,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            395.8653869628906,\n",
      "            316.42633056640625\n",
      "          ],\n",
      "          [\n",
      "            395.8653869628906,\n",
      "            1042.736572265625\n",
      "          ],\n",
      "          [\n",
      "            1352.8878173828125,\n",
      "            1042.736572265625\n",
      "          ],\n",
      "          [\n",
      "            1352.8878173828125,\n",
      "            316.42633056640625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 14,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Image\",\n",
      "    \"element_id\": \"5680d96ce15b94a68ce2dd02093b867e\",\n",
      "    \"text\": \"@- Llama3.1-70B + GPr4 = RMEFT \\u00a9 Qwen2.5-72B a GPT4o-mini \\u2014#~ Titans (MAC)-FT + Llama3.1-8B + RAG \\u00a9 \\u2014@- Mamba-FT 100) -iaiaiiieliben = 90 sis ~ re NS i S 80 EOS > 70h4\\u2014 g NL s Ut B 60 8 < sol, hie. = 40 ay 7 10\\u00b0 \\u201810* 10\\u00b0 10% 10 Sequence Length\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            917.5805555555555,\n",
      "            653.2239466666668\n",
      "          ],\n",
      "          [\n",
      "            917.5805555555555,\n",
      "            994.1416666666669\n",
      "          ],\n",
      "          [\n",
      "            1366.3760855555556,\n",
      "            994.1416666666669\n",
      "          ],\n",
      "          [\n",
      "            1366.3760855555556,\n",
      "            653.2239466666668\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 14,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"fa105d80cb73fc7dd6285cbfaeced69e\",\n",
      "    \"text\": \"Figure 6: Performance of Titans and baselines on BABILong benchmark. Titans (MAC) outperforms all baselines, including\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1064.4316666666668\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1092.1055555555556\n",
      "          ],\n",
      "          [\n",
      "            1560.0072559888893,\n",
      "            1092.1055555555556\n",
      "          ],\n",
      "          [\n",
      "            1560.0072559888893,\n",
      "            1064.4316666666668\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 14,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"FigureCaption\",\n",
      "    \"element_id\": \"8c32e47abcb229be1c387a2de56c00b7\",\n",
      "    \"text\": \"extremely large models, e.g., GPT4.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9033907651901245,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1073.912841796875\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1127.3084716796875\n",
      "          ],\n",
      "          [\n",
      "            1561.974609375,\n",
      "            1127.3084716796875\n",
      "          ],\n",
      "          [\n",
      "            1561.974609375,\n",
      "            1073.912841796875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 14,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e246e1de1bf32616da30e78b32998e23\",\n",
      "    \"text\": \"we can see a significant drop in performance when increasing the sequence length; (3) Compared to DeltaNet, although it\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            1165.8233333333335\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            1193.4972222222223\n",
      "          ],\n",
      "          [\n",
      "            1560.0106176999996,\n",
      "            1193.4972222222223\n",
      "          ],\n",
      "          [\n",
      "            1560.0106176999996,\n",
      "            1165.8233333333335\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 14,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"fe2bb1ccdb8b2859aaf2637bdce55e75\",\n",
      "    \"text\": \"is capable of removing memory using delta rule, it cannot erase the memory, lacking forgetting mechanism. Finally, As expected we can see on par or better results when using Titans variants, where the best results correspond to MAC.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9368510842323303,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1174.1148681640625\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1263.5576171875\n",
      "          ],\n",
      "          [\n",
      "            1565.7198486328125,\n",
      "            1263.5576171875\n",
      "          ],\n",
      "          [\n",
      "            1565.7198486328125,\n",
      "            1174.1148681640625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 14,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"db5f6808d6ddb8066174c9b3c25b2dea\",\n",
      "    \"text\": \"5.4 BABILong Benchmark\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8660844564437866,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.65325927734375,\n",
      "            1311.01416015625\n",
      "          ],\n",
      "          [\n",
      "            198.65325927734375,\n",
      "            1344.6851422222223\n",
      "          ],\n",
      "          [\n",
      "            618.3074340820312,\n",
      "            1344.6851422222223\n",
      "          ],\n",
      "          [\n",
      "            618.3074340820312,\n",
      "            1311.01416015625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 14,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"5a045e9e7ef6d5583ed32428ed49e224\",\n",
      "    \"text\": \"In the previous section we discussed the results on a simple NIAH tasks where a single needle needs to be retrieved. Although Titans showed better performance compared to baselines, their true advantage over very long sequences is still hidden. To this end, in this section, we use a harder task from BABILong benchmark (Yuri Kuratov et al. 2024), in which the model needs to reason across facts distributed in extremely long documents. We follow the original experimental setup and training process in the benchmark. There are two settings: (1) Few-shot setting, in which we use large pre-trained models, and (2) fine-tuning setting, where we fine-tune the MAC variant of Titans to compare it with other fine-tuned baselines. The results for few-shot setting are reported in Figure 6a. In this setup, we can see Titans outperform all baselines\\u2013i.e., Mamba2.8B (Gu and Dao 2024), RWKV-6-7B (Peng, Goldstein, et al. 2024), RecurrentGemma-9B (Botev et al. 2024), Gemma-9B (Team et al. 2024), Llama3.1-8B (Touvron et al. 2023), GPT-4, and GPT4o-mini (Achiam et al. 2023). These results are achieved while Titans (MAC) is having much less number of parameters than baselines.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9541263580322266,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.03055555555554,\n",
      "            1360.3566666666666\n",
      "          ],\n",
      "          [\n",
      "            199.03055555555554,\n",
      "            1691.16650390625\n",
      "          ],\n",
      "          [\n",
      "            1564.258767865,\n",
      "            1691.16650390625\n",
      "          ],\n",
      "          [\n",
      "            1564.258767865,\n",
      "            1360.3566666666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@kuratov2024babilong\",\n",
      "          \"start_index\": 364\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Figure 6a\",\n",
      "          \"url\": \"figure.caption.10\",\n",
      "          \"start_index\": 796\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@gu2024mamba\",\n",
      "          \"start_index\": 893\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@peng2024eagle\",\n",
      "          \"start_index\": 935\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@botev2024recurrentgemma\",\n",
      "          \"start_index\": 974\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@team2024gemma\",\n",
      "          \"start_index\": 1003\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@touvron2023llama\",\n",
      "          \"start_index\": 1038\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@achiam2023gpt\",\n",
      "          \"start_index\": 1082\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"db5f6808d6ddb8066174c9b3c25b2dea\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4b9242a2128397895bca6b5e58173ce4\",\n",
      "    \"text\": \"In the fine-tuning setup, we compare the small fine-tuned version of Titans (MAC) with: (i) the fine-tuned version of small models (almost the same number of parameters as Titans) such as Mamba (Gu and Dao 2024), RMT (Bulatov, Yury Kuratov, and Burtsev 2022), (ii) large models with Retrieval-Augmented Generation (RAG) (P. Lewis et al. 2020) such as Llama3.1- 8B (Touvron et al. 2023), and (iii) extremely large models such as GPT-4 (Achiam et al. 2023), GPT4o-mini, Qwen2.5-72B (A. Yang et al. 2024), and Llama3.1-70B (Touvron et al. 2023). Baseline results are reported by (Yuri Kuratov et al. 2024). The results of Titans and baselines are reported in Figure 6b. Titans outperform all models even extremely large models like GPT4. Also, compared to Transformer-based with memory models like RMT, Titans show better performance mainly due to their powerful memory. That is, RMT compress the historical data into 16 size vector-valued memory, while Titans with in-context online memory learner are capable of encoding the past into the parameters of the model. Interestingly, even\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9518201947212219,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.19722222222222,\n",
      "            1709.0483333333334\n",
      "          ],\n",
      "          [\n",
      "            199.19722222222222,\n",
      "            2006.9635009765625\n",
      "          ],\n",
      "          [\n",
      "            1565.4959716796875,\n",
      "            2006.9635009765625\n",
      "          ],\n",
      "          [\n",
      "            1565.4959716796875,\n",
      "            1709.0483333333334\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@gu2024mamba\",\n",
      "          \"start_index\": 203\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.0@bulatov2022recurrent\",\n",
      "          \"start_index\": 250\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2020\",\n",
      "          \"url\": \"cite.0@lewis2020retrieval\",\n",
      "          \"start_index\": 334\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@touvron2023llama\",\n",
      "          \"start_index\": 377\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@achiam2023gpt\",\n",
      "          \"start_index\": 446\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024qwen2\",\n",
      "          \"start_index\": 493\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@touvron2023llama\",\n",
      "          \"start_index\": 533\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@kuratov2024babilong\",\n",
      "          \"start_index\": 594\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Figure 6b\",\n",
      "          \"url\": \"figure.caption.10\",\n",
      "          \"start_index\": 653\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"db5f6808d6ddb8066174c9b3c25b2dea\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"7e395ad161d6e47970de5a813477ce0e\",\n",
      "    \"text\": \"14\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1305555555555,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            867.1305555555555,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222221,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222221,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"db5f6808d6ddb8066174c9b3c25b2dea\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Image\",\n",
      "    \"element_id\": \"6ec25947a652ad98829719d0459223d1\",\n",
      "    \"text\": \"_| -\\u2014 Mamba +\\u2014 LMM (Ly, =3) 17.5) \\u2014e\\u2014 LMM (L. + LMM (Ly =4) 2 FI Ey = fo i \\u2014 \\u2014+ 2000 4000 8000 16000 32000 Sequence Length\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            202.39695555555573\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            473.23055555555567\n",
      "          ],\n",
      "          [\n",
      "            652.84296,\n",
      "            473.23055555555567\n",
      "          ],\n",
      "          [\n",
      "            652.84296,\n",
      "            202.39695555555573\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Image\",\n",
      "    \"element_id\": \"e9511a8b88ad5ae9d78ecf5bfcab173f\",\n",
      "    \"text\": \"13.4 13.2) 213.0 FI Ey #128 fo 12.6 12.4 \\u2014_ 2000 4000 8000 76000 32000 Sequence Length\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            662.0972222222222,\n",
      "            202.39695555555573\n",
      "          ],\n",
      "          [\n",
      "            662.0972222222222,\n",
      "            473.23055555555567\n",
      "          ],\n",
      "          [\n",
      "            1114.9401822222223,\n",
      "            473.23055555555567\n",
      "          ],\n",
      "          [\n",
      "            1114.9401822222223,\n",
      "            202.39695555555573\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Image\",\n",
      "    \"element_id\": \"bc768cc27ac8b79442611b5f1a8210d3\",\n",
      "    \"text\": \"2000 4000 3000 16000 32000 Sequence Length\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1124.1944444444443,\n",
      "            202.62647555555557\n",
      "          ],\n",
      "          [\n",
      "            1124.1944444444443,\n",
      "            473.23055555555567\n",
      "          ],\n",
      "          [\n",
      "            1577.0374044444445,\n",
      "            473.23055555555567\n",
      "          ],\n",
      "          [\n",
      "            1577.0374044444445,\n",
      "            202.62647555555557\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Image\",\n",
      "    \"element_id\": \"41a39c6bd83eece2e90eff16250da4c6\",\n",
      "    \"text\": \"(a) 170M Parameters  (b) 360M Parameters  (c) 760M Parameters \",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9234110116958618,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            217.23411560058594,\n",
      "            206.51914978027344\n",
      "          ],\n",
      "          [\n",
      "            217.23411560058594,\n",
      "            519.6882934570312\n",
      "          ],\n",
      "          [\n",
      "            1553.3426513671875,\n",
      "            519.6882934570312\n",
      "          ],\n",
      "          [\n",
      "            1553.3426513671875,\n",
      "            206.51914978027344\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c965e9a8aada8d7e7caff73f9df657af\",\n",
      "    \"text\": \"Figure 7: The effect of memory depth on the perplexity. Deeper long-term memory results in better scaling in longer\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            543.5205555555557\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            571.1944444444445\n",
      "          ],\n",
      "          [\n",
      "            1560.5308459666664,\n",
      "            571.1944444444445\n",
      "          ],\n",
      "          [\n",
      "            1560.5308459666664,\n",
      "            543.5205555555557\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"FigureCaption\",\n",
      "    \"element_id\": \"53686cbf28b59b250989f07826fe4fc9\",\n",
      "    \"text\": \"sequences.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8924880623817444,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            553.0755004882812\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            607.6875610351562\n",
      "          ],\n",
      "          [\n",
      "            1557.4742431640625,\n",
      "            607.6875610351562\n",
      "          ],\n",
      "          [\n",
      "            1557.4742431640625,\n",
      "            553.0755004882812\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1b13085c26c029f9b8ea1189ef2421a2\",\n",
      "    \"text\": \"Table 3: Performance on long-term forecasting. The best results are highlighted .\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            458.9083333333333,\n",
      "            645.3150000000003\n",
      "          ],\n",
      "          [\n",
      "            458.9083333333333,\n",
      "            672.988888888889\n",
      "          ],\n",
      "          [\n",
      "            1300.2565644444444,\n",
      "            672.988888888889\n",
      "          ],\n",
      "          [\n",
      "            1300.2565644444444,\n",
      "            645.3150000000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Table\",\n",
      "    \"element_id\": \"fe80ecb57d19e6a9bc501d12653c54c2\",\n",
      "    \"text\": \"Neural Memory Simba iTransformer RLinear PatchTST Crossformer TiDE TimesNet DLinear MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE ETTm1 0.358 0.387 0.383 0.396 0.407 0.410 0.414 0.407 0.387 0.400 0.513 0.496 0.419 0.419 0.400 0.406 0.403 0.407 ETTm2 0.261 0.309 0.271 0.327 0.288 0.332 0.286 0.327 0.281 0.326 0.757 0.610 0.358 0.404 0.291 0.333 0.350 0.401 ETTh1 0.420 0.421 0.441 0.432 0.454 0.447 0.446 0.434 0.469 0.454 0.529 0.522 0.541 0.507 0.458 0.450 0.456 0.452 ETTh2 0.336 0.382 0.361 0.391 0.383 0.407 0.374 0.398 0.387 0.407 0.942 0.684 0.611 0.550 0.414 0.427 0.559 0.515 ECL 0.162 0.261 0.169 0.274 0.178 0.270 0.219 0.298 0.205 0.290 0.244 0.334 0.251 0.344 0.192 0.295 0.212 0.300 Traffic 0.415 0.289 0.493 0.291 0.428 0.282 0.626 0.378 0.481 0.304 0.550 0.304 0.760 0.473 0.620 0.336 0.625 0.383 Weather 0.231 0.265 0.255 0.280 0.258 0.278 0.272 0.291 0.259 0.281 0.259 0.315 0.271 0.320 0.259 0.287 0.265 0.317\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9363962411880493,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            254.84336853027344,\n",
      "            713.1383056640625\n",
      "          ],\n",
      "          [\n",
      "            254.84336853027344,\n",
      "            980.8899536132812\n",
      "          ],\n",
      "          [\n",
      "            1501.0079345703125,\n",
      "            980.8899536132812\n",
      "          ],\n",
      "          [\n",
      "            1501.0079345703125,\n",
      "            713.1383056640625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"434d9873e308875724f7bf356d1c12b4\",\n",
      "    \"text\": \"augmenting Llama3.1-8B model with RAG performs worse than Titans with about \\u00d770 less parameters.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1037.4622222222222\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1069.3425422222222\n",
      "          ],\n",
      "          [\n",
      "            1365.6825577777777,\n",
      "            1069.3425422222222\n",
      "          ],\n",
      "          [\n",
      "            1365.6825577777777,\n",
      "            1037.4622222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"9b2c6b5deabe6b6517d1812ff9118cde\",\n",
      "    \"text\": \"5.5 The Effect of Deep Memory\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8681725859642029,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            197.95777893066406,\n",
      "            1116.9262533333335\n",
      "          ],\n",
      "          [\n",
      "            197.95777893066406,\n",
      "            1150.1351422222224\n",
      "          ],\n",
      "          [\n",
      "            692.5165405273438,\n",
      "            1150.1351422222224\n",
      "          ],\n",
      "          [\n",
      "            692.5165405273438,\n",
      "            1116.9262533333335\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"11d174183be9fbe23cebc304d203809b\",\n",
      "    \"text\": \"In this section, we evaluate the effect of deep memory in both wall-clock training time and model performance2. To this\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1163.2341666666666\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1193.4805555555556\n",
      "          ],\n",
      "          [\n",
      "            1560.0003107111108,\n",
      "            1193.4805555555556\n",
      "          ],\n",
      "          [\n",
      "            1560.0003107111108,\n",
      "            1163.2341666666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"Hfootnote.2\",\n",
      "          \"start_index\": 138\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"parent_id\": \"9b2c6b5deabe6b6517d1812ff9118cde\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1734a4e78f32d022f39bdb269f4f793f\",\n",
      "    \"text\": \"end, we focus on different variants of our neural memory module, where \\ud835\\udc3fM = 1, 2, 3, 4. We also use Mamba as a baseline for the model performance. For a fair comparison, we use the same training process for all models and train them on a subset of the Pile dataset (L. Gao et al. 2020).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9466488361358643,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1174.880615234375\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1296.033935546875\n",
      "          ],\n",
      "          [\n",
      "            1560.0112442133334,\n",
      "            1296.033935546875\n",
      "          ],\n",
      "          [\n",
      "            1560.0112442133334,\n",
      "            1174.880615234375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"Hfootnote.2\",\n",
      "          \"start_index\": 138\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"parent_id\": \"9b2c6b5deabe6b6517d1812ff9118cde\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c5302c285f312832979a25c0bfdbdda4\",\n",
      "    \"text\": \"We report the perplexity of our models and baselines as the function of the sequence length in Figure 7. Interestingly, with\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.67222222222222,\n",
      "            1315.2483333333332\n",
      "          ],\n",
      "          [\n",
      "            198.67222222222222,\n",
      "            1342.9222222222222\n",
      "          ],\n",
      "          [\n",
      "            1560.008378355555,\n",
      "            1342.9222222222222\n",
      "          ],\n",
      "          [\n",
      "            1560.008378355555,\n",
      "            1315.2483333333332\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Figure 7\",\n",
      "          \"url\": \"figure.caption.11\",\n",
      "          \"start_index\": 95\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"parent_id\": \"9b2c6b5deabe6b6517d1812ff9118cde\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"22caa86808cb446522414a69b4faa1de\",\n",
      "    \"text\": \"the increase of memory depth, \\ud835\\udc3fM, the model can achieve better perplexity over all sequence length. Also, deeper memory modules are more robust to the sequence length when the model has less number of parameters. With the increase of the number of parameters, all models show better performance on longer sequences.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9428799748420715,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1323.0491943359375\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1446.423583984375\n",
      "          ],\n",
      "          [\n",
      "            1563.3824462890625,\n",
      "            1446.423583984375\n",
      "          ],\n",
      "          [\n",
      "            1563.3824462890625,\n",
      "            1323.0491943359375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Figure 7\",\n",
      "          \"url\": \"figure.caption.11\",\n",
      "          \"start_index\": 95\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"parent_id\": \"9b2c6b5deabe6b6517d1812ff9118cde\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"510311511a08ebeb7e1a46c62f03200c\",\n",
      "    \"text\": \"We also evaluate the effect of memory depth (\\ud835\\udc3fM = 1, 2, 3, 4) on the training throughput. We report the training throughput (the number of tokens per second) as the function of sequence length in Figure 8. All models scale linearly with respect to the context length (i.e., constant trend in the number of tokens per second with respect to sequence length). Also, by increasing the memory depth, as expected, we can see a linear trend that a deeper memory results in a slower training. Therefore, it is not always efficient to use deeper memory modules, showing a trade-off between effectiveness and efficiency.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9418091177940369,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            1464.687222222222\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            1728.46728515625\n",
      "          ],\n",
      "          [\n",
      "            1084.2504882,\n",
      "            1728.46728515625\n",
      "          ],\n",
      "          [\n",
      "            1084.2504882,\n",
      "            1464.687222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Figure 8\",\n",
      "          \"url\": \"figure.caption.12\",\n",
      "          \"start_index\": 195\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"parent_id\": \"9b2c6b5deabe6b6517d1812ff9118cde\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Image\",\n",
      "    \"element_id\": \"d1436dceb56024791b6a8770d169a69c\",\n",
      "    \"text\": \"45 - . = = LMM (Ly =1) + LMM (Ly =3) #40 \\u2014\\u2014 LMM (Ly=2) + LMM (Ly =4) e |. . \\u2014\\u2014 B 3 35) 2 4 3 = 30 + + & =] 25 + oe . + { 2000 4000 8000 16000 32000 Sequence Length\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1111.1972222222223,\n",
      "            1461.4617355555556\n",
      "          ],\n",
      "          [\n",
      "            1111.1972222222223,\n",
      "            1729.6805555555554\n",
      "          ],\n",
      "          [\n",
      "            1559.9742122222221,\n",
      "            1729.6805555555554\n",
      "          ],\n",
      "          [\n",
      "            1559.9742122222221,\n",
      "            1461.4617355555556\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"fa9d60deec6cd075a7ecfca7f26e475c\",\n",
      "    \"text\": \"5.6 Time Series Forecasting\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8799609541893005,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1800.3568088888887\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1833.5656977777776\n",
      "          ],\n",
      "          [\n",
      "            632.2801066666667,\n",
      "            1833.5656977777776\n",
      "          ],\n",
      "          [\n",
      "            632.2801066666667,\n",
      "            1800.3568088888887\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"5e7a61bfce587d76acace66b4ebf09c8\",\n",
      "    \"text\": \"Figure 8: The effect of memory depth on\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1111.1972222222223,\n",
      "            1752.9261111111111\n",
      "          ],\n",
      "          [\n",
      "            1111.1972222222223,\n",
      "            1780.6\n",
      "          ],\n",
      "          [\n",
      "            1560.0129056999997,\n",
      "            1780.6\n",
      "          ],\n",
      "          [\n",
      "            1560.0129056999997,\n",
      "            1752.9261111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"FigureCaption\",\n",
      "    \"element_id\": \"a9befff25d43bcbfbafb81d152ee73d9\",\n",
      "    \"text\": \"training throughput\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5338314771652222,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1104.86572265625,\n",
      "            1761.0892333984375\n",
      "          ],\n",
      "          [\n",
      "            1104.86572265625,\n",
      "            1816.961669921875\n",
      "          ],\n",
      "          [\n",
      "            1565.711181640625,\n",
      "            1816.961669921875\n",
      "          ],\n",
      "          [\n",
      "            1565.711181640625,\n",
      "            1761.0892333984375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"parent_id\": \"5e7a61bfce587d76acace66b4ebf09c8\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"7ff588c5aa0e966db8d145ce7d11cb3e\",\n",
      "    \"text\": \"To show the effectiveness of our memory module in a broader tasks, we also evaluate its performance in time series\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1849.2372222222223\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1876.911111111111\n",
      "          ],\n",
      "          [\n",
      "            1560.0107914444447,\n",
      "            1876.911111111111\n",
      "          ],\n",
      "          [\n",
      "            1560.0107914444447,\n",
      "            1849.2372222222223\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"parent_id\": \"5e7a61bfce587d76acace66b4ebf09c8\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b9f273370467ebdb07c025043ce05de3\",\n",
      "    \"text\": \"forecasting tasks. To this end, we use Simba framework (Patro and Agneeswaran 2024) for time series forecasting, and\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9361444115638733,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1857.79833984375\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1913.3341064453125\n",
      "          ],\n",
      "          [\n",
      "            1559.9945260000004,\n",
      "            1913.3341064453125\n",
      "          ],\n",
      "          [\n",
      "            1559.9945260000004,\n",
      "            1857.79833984375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"parent_id\": \"5e7a61bfce587d76acace66b4ebf09c8\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9723de2be1d489ae21369a74e4453181\",\n",
      "    \"text\": \"2Note that, in this experiment, we only focus on the neural memory module to evaluate the effect of memory depth in the memorization process.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            230.48888888888888,\n",
      "            1934.9866666666665\n",
      "          ],\n",
      "          [\n",
      "            230.48888888888888,\n",
      "            1960.1805555555554\n",
      "          ],\n",
      "          [\n",
      "            1563.4115417808332,\n",
      "            1960.1805555555554\n",
      "          ],\n",
      "          [\n",
      "            1563.4115417808332,\n",
      "            1934.9866666666665\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"parent_id\": \"5e7a61bfce587d76acace66b4ebf09c8\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"988737679076a9eee3cfa5e20cfef1db\",\n",
      "    \"text\": \"Combining neural memory with attention as we do in Titans variants, can additionally enhance the performance of the model over long sequences.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8751121163368225,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1943.901611328125\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1989.947265625\n",
      "          ],\n",
      "          [\n",
      "            1562.83984375,\n",
      "            1989.947265625\n",
      "          ],\n",
      "          [\n",
      "            1562.83984375,\n",
      "            1943.901611328125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"parent_id\": \"5e7a61bfce587d76acace66b4ebf09c8\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"755a3db5f6fcbe95c20f0152d8555547\",\n",
      "    \"text\": \"15\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1305555555556,\n",
      "            2057.7427777777775\n",
      "          ],\n",
      "          [\n",
      "            867.1305555555556,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222223,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222223,\n",
      "            2057.7427777777775\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"parent_id\": \"5e7a61bfce587d76acace66b4ebf09c8\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"8676945b07ccfd0b87e5db9e6dd3b8c5\",\n",
      "    \"text\": \"Table 4: Downstream evaluation of pre-trained DNA models on GenomicsBenchmarks (Gre\\u0161ov\\u00e1 et al. 2023). We report\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            197.96500000000017\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            225.63888888888894\n",
      "          ],\n",
      "          [\n",
      "            1560.0048138844438,\n",
      "            225.63888888888894\n",
      "          ],\n",
      "          [\n",
      "            1560.0048138844438,\n",
      "            197.96500000000017\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@grevsova2023genomic\",\n",
      "          \"start_index\": 95\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"parent_id\": \"5e7a61bfce587d76acace66b4ebf09c8\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"FigureCaption\",\n",
      "    \"element_id\": \"3e65e6f56a682fb0b87d890470dda2a9\",\n",
      "    \"text\": \"top-1 classification accuracy (%).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8962758779525757,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            207.50033569335938\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            262.038330078125\n",
      "          ],\n",
      "          [\n",
      "            1556.0098876953125,\n",
      "            262.038330078125\n",
      "          ],\n",
      "          [\n",
      "            1556.0098876953125,\n",
      "            207.50033569335938\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@grevsova2023genomic\",\n",
      "          \"start_index\": 95\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"parent_id\": \"5e7a61bfce587d76acace66b4ebf09c8\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Table\",\n",
      "    \"element_id\": \"020b306f4cbd17fd4fdb07308c03cecc\",\n",
      "    \"text\": \"Model Enhancer Cohn CNN 69.5 68.9 93.3 84.6 68.0 DNABERT 74.0 85.7 88.1 85.6 75.1 GPT 70.5 83.5 91.5 87.7 73.0 HyenaDNA 74.2 89.2 93.8 96.6 80.9 Transformer++ 73.4 89.5 89.9 94.4 79.5 Mamba 73.0 - - 96.6 - Based 74.6 89.5 89.5 96.8 79.0 Neural Memory Module 75.2 89.6 89.3 96.6 79.9\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9018147587776184,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            364.7044677734375,\n",
      "            292.1773376464844\n",
      "          ],\n",
      "          [\n",
      "            364.7044677734375,\n",
      "            561.2373046875\n",
      "          ],\n",
      "          [\n",
      "            1361.913330078125,\n",
      "            561.2373046875\n",
      "          ],\n",
      "          [\n",
      "            1361.913330078125,\n",
      "            292.1773376464844\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"parent_id\": \"5e7a61bfce587d76acace66b4ebf09c8\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f1930162ce8fb055daf0455ca3bfecad\",\n",
      "    \"text\": \"Enhancer Ens Human Reg. Non-TATA Promoters Human OCR Ens.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            758.5441105917499,\n",
      "            300.60162344444416\n",
      "          ],\n",
      "          [\n",
      "            758.5441105917499,\n",
      "            321.2006826388887\n",
      "          ],\n",
      "          [\n",
      "            1384.8585053988334,\n",
      "            321.2006826388887\n",
      "          ],\n",
      "          [\n",
      "            1384.8585053988334,\n",
      "            300.60162344444416\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"parent_id\": \"5e7a61bfce587d76acace66b4ebf09c8\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"32396d879ec1435a8bc2e957672e84df\",\n",
      "    \"text\": \"replace its Mamba module with our neural memory. We report the results on common time series forecasting benchmark\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            617.9316666666668\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            645.6055555555555\n",
      "          ],\n",
      "          [\n",
      "            1560.7081802466673,\n",
      "            645.6055555555555\n",
      "          ],\n",
      "          [\n",
      "            1560.7081802466673,\n",
      "            617.9316666666668\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"parent_id\": \"5e7a61bfce587d76acace66b4ebf09c8\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2f3a6bc6f66768a2a59e5129dbc1401b\",\n",
      "    \"text\": \"datasets\\u2013ETT, ECL, Traffic, and Weather (H. Zhou et al. 2021). The results are reported in Table 3. Our neural memory module is outperforming all baselines, including Mamba-based, linear-based, and Transformer-based architectures.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8954199552536011,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            626.2957763671875\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            717.1416625976562\n",
      "          ],\n",
      "          [\n",
      "            1565.2095947265625,\n",
      "            717.1416625976562\n",
      "          ],\n",
      "          [\n",
      "            1565.2095947265625,\n",
      "            626.2957763671875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@zhou2021informer\",\n",
      "          \"start_index\": 169\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Table 3\",\n",
      "          \"url\": \"table.caption.13\",\n",
      "          \"start_index\": 204\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"parent_id\": \"5e7a61bfce587d76acace66b4ebf09c8\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"c354c5e7d5b49658ec1a6000ab7e87b7\",\n",
      "    \"text\": \"5.7 DNA Modeling\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.851783812046051,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.2525177001953,\n",
      "            763.3439331054688\n",
      "          ],\n",
      "          [\n",
      "            198.2525177001953,\n",
      "            797.0212533333333\n",
      "          ],\n",
      "          [\n",
      "            502.4660949707031,\n",
      "            797.0212533333333\n",
      "          ],\n",
      "          [\n",
      "            502.4660949707031,\n",
      "            763.3439331054688\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"10de833b7d8378dd8e8964794af0ec0b\",\n",
      "    \"text\": \"In order to understand the capability of Titans beyond natural language, we further evaluate the performance of our\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            812.6927777777777\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            840.3666666666666\n",
      "          ],\n",
      "          [\n",
      "            1560.5308459666658,\n",
      "            840.3666666666666\n",
      "          ],\n",
      "          [\n",
      "            1560.5308459666658,\n",
      "            812.6927777777777\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"parent_id\": \"c354c5e7d5b49658ec1a6000ab7e87b7\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9d6324f083700645380b6cb85e13637b\",\n",
      "    \"text\": \"neural memory module on DNA modeling tasks. To this end, we evaluate pre-trained models on the downstream tasks in GenomicsBenchmarks (Gre\\u0161ov\\u00e1 et al. 2023). We follow the same experimental setups from Nguyen et al. (2024), and re-use the reported results of baselines by Arora et al. (2024). The performance of Titans (LMM) and baselines are reported in Table 4. We find that LMM is competitive with state-of-the-art architectures across different downstream genomics tasks.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.946012556552887,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            820.7929077148438\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1012.0374145507812\n",
      "          ],\n",
      "          [\n",
      "            1562.5748291015625,\n",
      "            1012.0374145507812\n",
      "          ],\n",
      "          [\n",
      "            1562.5748291015625,\n",
      "            820.7929077148438\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@grevsova2023genomic\",\n",
      "          \"start_index\": 283\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@nguyen2024hyenadna\",\n",
      "          \"start_index\": 349\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@arora2024simple\",\n",
      "          \"start_index\": 418\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Table 4\",\n",
      "          \"url\": \"table.caption.14\",\n",
      "          \"start_index\": 487\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"parent_id\": \"c354c5e7d5b49658ec1a6000ab7e87b7\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"0277bbcf74858a081bab5b133f4a909a\",\n",
      "    \"text\": \"5.8 Efficiency\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8462503552436829,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            196.75523376464844,\n",
      "            1055.302734375\n",
      "          ],\n",
      "          [\n",
      "            196.75523376464844,\n",
      "            1091.4101422222222\n",
      "          ],\n",
      "          [\n",
      "            426.0948486328125,\n",
      "            1091.4101422222222\n",
      "          ],\n",
      "          [\n",
      "            426.0948486328125,\n",
      "            1055.302734375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"696157b3dfc7c7fe6dd3b2ddd5637071\",\n",
      "    \"text\": \"In this part, we compare the efficiency of our neural memory as well as Titans with state-of-the-art sequence models. The training throughput of models for different sequence length \\u00d7 batch size are reported in Figure 9. Comparing recurrent models, including our neural memory module, we can see our memory module is slightly slower than Mamba2 and Gated DeltaNet, mainly due to: (1) having deep memory and more expressive transition process (memory update), and (2) highly optimized kernel in the implementation of Mamba2. Interestingly, Titans (MAL) are faster than baselines as well as the memory module. The main reason for this better throughput is the highly optimized kernel of Flash- Attention (Dao 2024), which is used for implementing SWA and full attention module in Titans.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9486216306686401,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.00833333333333,\n",
      "            1107.0816666666667\n",
      "          ],\n",
      "          [\n",
      "            198.00833333333333,\n",
      "            1471.76171875\n",
      "          ],\n",
      "          [\n",
      "            1089.8770751953125,\n",
      "            1471.76171875\n",
      "          ],\n",
      "          [\n",
      "            1089.8770751953125,\n",
      "            1107.0816666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Figure 9\",\n",
      "          \"url\": \"figure.caption.15\",\n",
      "          \"start_index\": 221\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@dao2024flashattention\",\n",
      "          \"start_index\": 717\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"parent_id\": \"0277bbcf74858a081bab5b133f4a909a\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Image\",\n",
      "    \"element_id\": \"3cdd5939d13177913e45136ba788e3a2\",\n",
      "    \"text\": \"\\u2014,,_, \\u201c\\u00a9 Gated DeltaNet_ + Titans (MAL) ~ ba2 ~@ Titans (MAG) ae Mamba 4- Titans (MAC) 45, ~\\\\- Transformer++ \\u2014 \\u2014#- LMM 10? Tokens/Second 25| NY 2K en TK\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1111.1972222222223,\n",
      "            1115.7336266666666\n",
      "          ],\n",
      "          [\n",
      "            1111.1972222222223,\n",
      "            1414.9166666666667\n",
      "          ],\n",
      "          [\n",
      "            1559.9717822222221,\n",
      "            1414.9166666666667\n",
      "          ],\n",
      "          [\n",
      "            1559.9717822222221,\n",
      "            1115.7336266666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"6bd3a433494572b1a337396d888c9d90\",\n",
      "    \"text\": \"Figure 9: Training throughput compari-\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1111.1972222222223,\n",
      "            1438.162222222222\n",
      "          ],\n",
      "          [\n",
      "            1111.1972222222223,\n",
      "            1465.8361111111112\n",
      "          ],\n",
      "          [\n",
      "            1564.6699784177779,\n",
      "            1465.8361111111112\n",
      "          ],\n",
      "          [\n",
      "            1564.6699784177779,\n",
      "            1438.162222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"FigureCaption\",\n",
      "    \"element_id\": \"572d1394a44faac426dc4bfc700db6e6\",\n",
      "    \"text\": \"son of Titans and baselines.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.802072286605835,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            1103.30322265625,\n",
      "            1446.6357421875\n",
      "          ],\n",
      "          [\n",
      "            1103.30322265625,\n",
      "            1503.1563720703125\n",
      "          ],\n",
      "          [\n",
      "            1573.0343017578125,\n",
      "            1503.1563720703125\n",
      "          ],\n",
      "          [\n",
      "            1573.0343017578125,\n",
      "            1446.6357421875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"parent_id\": \"6bd3a433494572b1a337396d888c9d90\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"e11fd238b71573de34e50de961d78951\",\n",
      "    \"text\": \"5.9 Ablation Study\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8695608377456665,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.21348571777344,\n",
      "            1515.399658203125\n",
      "          ],\n",
      "          [\n",
      "            199.21348571777344,\n",
      "            1551.8434755555554\n",
      "          ],\n",
      "          [\n",
      "            500.90574222222233,\n",
      "            1551.8434755555554\n",
      "          ],\n",
      "          [\n",
      "            500.90574222222233,\n",
      "            1515.399658203125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"336ffce7c0006f19400a1a804cd84bc1\",\n",
      "    \"text\": \"Finally, we perform ablation studies on the different architectural choices in Titans. We consider our neural memory module as a base model and then changing one component at a time: (1) replacing deep memory with linear memory, removing (2) convolution, (3) momentum in the surprise measure, (4) weight decay (or forgot mechanism), and (5) persistent memory. The results are reported in Table 5. All components of neural memory design are positively contributing to its performance, where the greatest contribution comes from weight decay, momentum, convolution, and persistent memory, respectively.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9450936913490295,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1567.5149999999999\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1767.3814697265625\n",
      "          ],\n",
      "          [\n",
      "            1570.572998046875,\n",
      "            1767.3814697265625\n",
      "          ],\n",
      "          [\n",
      "            1570.572998046875,\n",
      "            1567.5149999999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Table 5\",\n",
      "          \"url\": \"table.caption.16\",\n",
      "          \"start_index\": 406\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"parent_id\": \"e11fd238b71573de34e50de961d78951\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"06ca8c647727425d18f335e2d8cc54bd\",\n",
      "    \"text\": \"The Effect of Architectural Design. To evaluate the effect of architecture design, we compare the performance of three represented variants of Titans in three aspects of (i) language modeling, (ii) commen-sense reasoning, and (iii) long context NIAH (BABILong) tasks. The results are reported in Table 5. We find that MAC and MAG have close performance in language modeling and common-sense reasoning tasks, while MAC achieve significantly better performance in long-context NIAH. Both of these models achieve better performance than MAL. These results along with Figure 9, show a trade-off between fast training and more expressive design.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9524518847465515,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.0861111111111,\n",
      "            1796.7594444444444\n",
      "          ],\n",
      "          [\n",
      "            199.0861111111111,\n",
      "            1995.7353515625\n",
      "          ],\n",
      "          [\n",
      "            1566.4866943359375,\n",
      "            1995.7353515625\n",
      "          ],\n",
      "          [\n",
      "            1566.4866943359375,\n",
      "            1796.7594444444444\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Table 5\",\n",
      "          \"url\": \"table.caption.16\",\n",
      "          \"start_index\": 294\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Figure 9\",\n",
      "          \"url\": \"figure.caption.15\",\n",
      "          \"start_index\": 560\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"parent_id\": \"e11fd238b71573de34e50de961d78951\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"99cd1dda52623ec9526f77eb2126591a\",\n",
      "    \"text\": \"16\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1305555555556,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            867.1305555555556,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222223,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222223,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"parent_id\": \"e11fd238b71573de34e50de961d78951\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"369eed2987c7c1916eeeba1d48c226e3\",\n",
      "    \"text\": \"Table 5: Ablation Study on Titans. All components of Titans are positively contributing to its performance.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            275.94166666666666,\n",
      "            197.96500000000017\n",
      "          ],\n",
      "          [\n",
      "            275.94166666666666,\n",
      "            225.63888888888894\n",
      "          ],\n",
      "          [\n",
      "            1483.215069444445,\n",
      "            225.63888888888894\n",
      "          ],\n",
      "          [\n",
      "            1483.215069444445,\n",
      "            197.96500000000017\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 17,\n",
      "      \"parent_id\": \"e11fd238b71573de34e50de961d78951\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Table\",\n",
      "    \"element_id\": \"27762e6e16f02471a71feb3f67e7e47d\",\n",
      "    \"text\": \"Model Language Modeling ppl \\u2193 Reasoning acc \\u2191 Long Context acc \\u2191 LMM 27.01 47.83 92.68 +Attn (MAC) 26.67 48.65 97.95 +Attn (MAG) 25.70 48.60 96.70 +Attn (MAL) 25.91 47.87 96.91 Linear Memory 28.49 46.97 85.34 w/o Convolution 28.73 45.82 90.28 w/o Momentum 28.98 45.49 87.12 w/o Weight Decay 29.04 45.11 85.60 w/o Persistent Memory 27.63 46.35 92.49\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9273986220359802,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            512.8308715820312,\n",
      "            265.9290771484375\n",
      "          ],\n",
      "          [\n",
      "            512.8308715820312,\n",
      "            616.736083984375\n",
      "          ],\n",
      "          [\n",
      "            1247.7249755859375,\n",
      "            616.736083984375\n",
      "          ],\n",
      "          [\n",
      "            1247.7249755859375,\n",
      "            265.9290771484375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 17,\n",
      "      \"parent_id\": \"e11fd238b71573de34e50de961d78951\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"a367729757636a56e8163f1377462bce\",\n",
      "    \"text\": \"6 Conclusion\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8624047040939331,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            196.0810089111328,\n",
      "            673.929922777778\n",
      "          ],\n",
      "          [\n",
      "            196.0810089111328,\n",
      "            713.7804783333333\n",
      "          ],\n",
      "          [\n",
      "            466.7868957519531,\n",
      "            713.7804783333333\n",
      "          ],\n",
      "          [\n",
      "            466.7868957519531,\n",
      "            673.929922777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 17,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"5840be1376efbc7893bc3c3f47df169d\",\n",
      "    \"text\": \"In this paper, we present a neural long-term memory that, as a meta in-context learner, learns to memorize at test time.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            737.4150000000002\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            765.088888888889\n",
      "          ],\n",
      "          [\n",
      "            1564.2545060861103,\n",
      "            765.088888888889\n",
      "          ],\n",
      "          [\n",
      "            1564.2545060861103,\n",
      "            737.4150000000002\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 17,\n",
      "      \"parent_id\": \"a367729757636a56e8163f1377462bce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"8d99444edffc7b53b42f9796ccc4891b\",\n",
      "    \"text\": \"The neural memory module is a recurrent model in nature, and is adaptively memorizing tokens that are more surprising or are close to surprising tokens. Comparing to modern recurrent models, it has more expressive memory update and storing mechanism. Using this memory, we present Titans architectures, and its three variants, in which we suggest to incorporate the memory module as (1) a context, (2) gating, and (3) a layer. Our experimental evaluation on diverse tasks tasks validate that Titans are more effective than Transformers and recent modern linear recurrent models, specifically for long context. That is, Titans can scale to larger than 2M context window size with better accuracy than baselines.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9448438882827759,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            745.9639892578125\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            968.3486328125\n",
      "          ],\n",
      "          [\n",
      "            1570.300048828125,\n",
      "            968.3486328125\n",
      "          ],\n",
      "          [\n",
      "            1570.300048828125,\n",
      "            745.9639892578125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 17,\n",
      "      \"parent_id\": \"a367729757636a56e8163f1377462bce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"144b8aead5700f0f9add8c5f1d9f0c69\",\n",
      "    \"text\": \"Titans are implemented in Pytorch and JAX and we intend to make the code we used to train and evaluate our models\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            986.4816666666666\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1014.1555555555556\n",
      "          ],\n",
      "          [\n",
      "            1560.0107914444445,\n",
      "            1014.1555555555556\n",
      "          ],\n",
      "          [\n",
      "            1560.0107914444445,\n",
      "            986.4816666666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 17,\n",
      "      \"parent_id\": \"a367729757636a56e8163f1377462bce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a7578ddd82f0c9679f5796bc5a2498a0\",\n",
      "    \"text\": \"available soon.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9105446934700012,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.4379119873047,\n",
      "            993.5421142578125\n",
      "          ],\n",
      "          [\n",
      "            198.4379119873047,\n",
      "            1050.5699462890625\n",
      "          ],\n",
      "          [\n",
      "            1569.28564453125,\n",
      "            1050.5699462890625\n",
      "          ],\n",
      "          [\n",
      "            1569.28564453125,\n",
      "            993.5421142578125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 17,\n",
      "      \"parent_id\": \"a367729757636a56e8163f1377462bce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"fb419e81a6dd7e1d6a2c38921b86fd25\",\n",
      "    \"text\": \"17\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1305555555556,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            867.1305555555556,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222223,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222223,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 17,\n",
      "      \"parent_id\": \"a367729757636a56e8163f1377462bce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "    \"text\": \"References\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8416945338249207,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            195.32904052734375,\n",
      "            196.8306121826172\n",
      "          ],\n",
      "          [\n",
      "            195.32904052734375,\n",
      "            240.04158944444433\n",
      "          ],\n",
      "          [\n",
      "            401.1822204589844,\n",
      "            240.04158944444433\n",
      "          ],\n",
      "          [\n",
      "            401.1822204589844,\n",
      "            196.8306121826172\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"3e2f8fccd81b6c814f92a2a4f595b687\",\n",
      "    \"text\": \"[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. \\u201cGpt-4 technical report\\u201d. In: arXiv preprint arXiv:2303.08774 (2023).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9282832145690918,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            225.73611111111111,\n",
      "            252.9761111111112\n",
      "          ],\n",
      "          [\n",
      "            225.73611111111111,\n",
      "            353.5423566666667\n",
      "          ],\n",
      "          [\n",
      "            1562.872314453125,\n",
      "            353.5423566666667\n",
      "          ],\n",
      "          [\n",
      "            1562.872314453125,\n",
      "            252.9761111111112\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"2738f2035ce6078195e26956bd9164a6\",\n",
      "    \"text\": \"[2] Yaroslav Aksenov, Nikita Balagansky, Sofia Maria Lo Cicero Vaina, Boris Shaposhnikov, Alexey Gorbatovski, and Daniil Gavrilov. \\u201cLinear Transformers with Learnable Kernel Functions are Better In-Context Models\\u201d. In: arXiv preprint arXiv:2402.10644 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9298158884048462,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            225.03121948242188,\n",
      "            352.60388888888895\n",
      "          ],\n",
      "          [\n",
      "            225.03121948242188,\n",
      "            453.1701344444444\n",
      "          ],\n",
      "          [\n",
      "            1568.842529296875,\n",
      "            453.1701344444444\n",
      "          ],\n",
      "          [\n",
      "            1568.842529296875,\n",
      "            352.60388888888895\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"a805a7e69239f84b50ce09ff7eb4caef\",\n",
      "    \"text\": \"[3] Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul, Brendan Shillingford, and Nando De Freitas. \\u201cLearning to learn by gradient descent by gradient descent\\u201d. In: Advances in neural information processing systems 29 (2016).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9288116693496704,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            223.5616912841797,\n",
      "            452.22888888888895\n",
      "          ],\n",
      "          [\n",
      "            223.5616912841797,\n",
      "            552.7951344444444\n",
      "          ],\n",
      "          [\n",
      "            1570.71240234375,\n",
      "            552.7951344444444\n",
      "          ],\n",
      "          [\n",
      "            1570.71240234375,\n",
      "            452.22888888888895\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"aa6b9ba4aec4d373959831b02f3010fa\",\n",
      "    \"text\": \"[4] Cem Anil, Yuhuai Wu, Anders Andreassen, Aitor Lewkowycz, Vedant Misra, Vinay Ramasesh, Ambrose Slone, Guy Gur-Ari, Ethan Dyer, and Behnam Neyshabur. \\u201cExploring length generalization in large language models\\u201d. In: Advances in Neural Information Processing Systems 35 (2022), pp. 38546\\u201338556.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9269450306892395,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            222.81700134277344,\n",
      "            551.8566666666667\n",
      "          ],\n",
      "          [\n",
      "            222.81700134277344,\n",
      "            652.4229122222225\n",
      "          ],\n",
      "          [\n",
      "            1571.403564453125,\n",
      "            652.4229122222225\n",
      "          ],\n",
      "          [\n",
      "            1571.403564453125,\n",
      "            551.8566666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"fedf4fde6ef19b666400925c127fa11a\",\n",
      "    \"text\": \"[5] Simran Arora, Sabri Eyuboglu, Michael Zhang, Aman Timalsina, Silas Alberti, James Zou, Atri Rudra, and Christo- pher Re. \\u201cSimple linear attention language models balance the recall-throughput tradeoff\\u201d. In: Forty-first International Conference on Machine Learning. 2024. url: https://openreview.net/forum?id=e93ffDcpH3.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9245644807815552,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            223.0419464111328,\n",
      "            651.4816666666667\n",
      "          ],\n",
      "          [\n",
      "            223.0419464111328,\n",
      "            752.0479122222222\n",
      "          ],\n",
      "          [\n",
      "            1575.37646484375,\n",
      "            752.0479122222222\n",
      "          ],\n",
      "          [\n",
      "            1575.37646484375,\n",
      "            651.4816666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ? id = e93ffDcpH3\",\n",
      "          \"url\": \"https://openreview.net/forum?id=e93ffDcpH3\",\n",
      "          \"start_index\": 569\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"3c797362696502a0e3c03d6e903d13bd\",\n",
      "    \"text\": \"[6] Dzmitry Bahdanau. \\u201cNeural machine translation by jointly learning to align and translate\\u201d. In: arXiv preprint arXiv:1409.0473 (2014).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8986682891845703,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            225.73611111111106,\n",
      "            751.1094444444444\n",
      "          ],\n",
      "          [\n",
      "            225.73611111111106,\n",
      "            818.4673566666667\n",
      "          ],\n",
      "          [\n",
      "            1565.320068359375,\n",
      "            818.4673566666667\n",
      "          ],\n",
      "          [\n",
      "            1565.320068359375,\n",
      "            751.1094444444444\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"a0055f59c637913b94df2d1bc83c2b33\",\n",
      "    \"text\": \"[7] Reza Bayat, Mohammad Pezeshki, Elvis Dohmatob, David Lopez-Paz, and Pascal Vincent. \\u201cThe Pitfalls of Memo- rization: When Memorization Hurts Generalization\\u201d. In: arXiv preprint arXiv:2412.07684 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8623228073120117,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            225.73611111111106,\n",
      "            817.526111111111\n",
      "          ],\n",
      "          [\n",
      "            225.73611111111106,\n",
      "            884.8840233333332\n",
      "          ],\n",
      "          [\n",
      "            1570.2103271484375,\n",
      "            884.8840233333332\n",
      "          ],\n",
      "          [\n",
      "            1570.2103271484375,\n",
      "            817.526111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"9cd5a4f706779be82ac96763f1ad3180\",\n",
      "    \"text\": \"[8] Maximilian Beck, Korbinian P\\u00f6ppel, Markus Spanring, Andreas Auer, Oleksandra Prudnikova, Michael Kopp, G\\u00fcnter Klambauer, Johannes Brandstetter, and Sepp Hochreiter. \\u201cxLSTM: Extended Long Short-Term Memory\\u201d. In: arXiv preprint arXiv:2405.04517 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9255558848381042,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            225.73611111111106,\n",
      "            883.9427777777776\n",
      "          ],\n",
      "          [\n",
      "            225.73611111111106,\n",
      "            984.5118011111111\n",
      "          ],\n",
      "          [\n",
      "            1568.4385986328125,\n",
      "            984.5118011111111\n",
      "          ],\n",
      "          [\n",
      "            1568.4385986328125,\n",
      "            883.9427777777776\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"939ce46a8eef44b55ebe587198dd5ee6\",\n",
      "    \"text\": \"[9] Ali Behrouz, Michele Santacatterina, and Ramin Zabih. \\u201cMambamixer: Efficient selective state space models with dual token and channel selection\\u201d. In: arXiv preprint arXiv:2403.19888 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9102137088775635,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            225.73611111111106,\n",
      "            983.5705555555555\n",
      "          ],\n",
      "          [\n",
      "            225.73611111111106,\n",
      "            1050.9284677777778\n",
      "          ],\n",
      "          [\n",
      "            1562.3333740234375,\n",
      "            1050.9284677777778\n",
      "          ],\n",
      "          [\n",
      "            1562.3333740234375,\n",
      "            983.5705555555555\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"70742a31d29e54710858d678d0f3cda5\",\n",
      "    \"text\": \"[10] Vincent-Pierre Berges, Barlas O\\u011fuz, Daniel Haziza, Wen-tau Yih, Luke Zettlemoyer, and Gargi Gosh. \\u201cMemory Layers at Scale\\u201d. In: arXiv preprint arXiv:2412.09764 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9108033180236816,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444424,\n",
      "            1049.987222222222\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444424,\n",
      "            1117.3451344444445\n",
      "          ],\n",
      "          [\n",
      "            1565.0843505859375,\n",
      "            1117.3451344444445\n",
      "          ],\n",
      "          [\n",
      "            1565.0843505859375,\n",
      "            1049.987222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"267318c96080a80db740f69cb4acdd5f\",\n",
      "    \"text\": \"[11] Alberto Bietti, Vivien Cabannes, Diane Bouchacourt, Herve Jegou, and Leon Bottou. \\u201cBirth of a transformer: A memory viewpoint\\u201d. In: Advances in Neural Information Processing Systems 36 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8379277586936951,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1116.4038888888888\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1183.7645788888888\n",
      "          ],\n",
      "          [\n",
      "            1566.1783447265625,\n",
      "            1183.7645788888888\n",
      "          ],\n",
      "          [\n",
      "            1566.1783447265625,\n",
      "            1116.4038888888888\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"eef9f0ee0403fee1344de617a7e1efa4\",\n",
      "    \"text\": \"[12] Yonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, et al. \\u201cPiqa: Reasoning about physical commonsense in natural language\\u201d. In: Proceedings of the AAAI conference on artificial intelligence. Vol. 34. 05. 2020, pp. 7432\\u20137439.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8776463270187378,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1182.8233333333333\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1250.1812455555555\n",
      "          ],\n",
      "          [\n",
      "            1567.5328369140625,\n",
      "            1250.1812455555555\n",
      "          ],\n",
      "          [\n",
      "            1567.5328369140625,\n",
      "            1182.8233333333333\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"64d5e4395794b48785bc0c1517fae4bc\",\n",
      "    \"text\": \"[13] Aleksandar Botev, Soham De, Samuel L Smith, Anushan Fernando, George-Cristian Muraru, Ruba Haroun, Leonard Berrada, Razvan Pascanu, Pier Giuseppe Sessa, Robert Dadashi, et al. \\u201cRecurrentGemma: Moving Past Transformers for Efficient Open Language Models\\u201d. In: arXiv preprint arXiv:2404.07839 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9177321791648865,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1249.2399999999998\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1349.8062455555555\n",
      "          ],\n",
      "          [\n",
      "            1569.1826171875,\n",
      "            1349.8062455555555\n",
      "          ],\n",
      "          [\n",
      "            1569.1826171875,\n",
      "            1249.2399999999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"f4ff3067dbecf1feb72db2eab1b36323\",\n",
      "    \"text\": \"[14] L\\u00e9on Bottou and Vladimir Vapnik. \\u201cLocal learning algorithms\\u201d. In: Neural computation 4.6 (1992), pp. 888\\u2013900.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8178014159202576,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444424,\n",
      "            1348.8677777777777\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444424,\n",
      "            1383.0173566666667\n",
      "          ],\n",
      "          [\n",
      "            1535.019287109375,\n",
      "            1383.0173566666667\n",
      "          ],\n",
      "          [\n",
      "            1535.019287109375,\n",
      "            1348.8677777777777\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"9717100ca7820abdbf9b6cc56b816f65\",\n",
      "    \"text\": \"[15] Aydar Bulatov, Yuri Kuratov, Yermek Kapushev, and Mikhail S Burtsev. \\u201cScaling transformer to 1m tokens and beyond with rmt\\u201d. In: arXiv preprint arXiv:2304.11062 (2023).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8804656267166138,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1382.076111111111\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1449.4340233333332\n",
      "          ],\n",
      "          [\n",
      "            1559.997300466667,\n",
      "            1449.4340233333332\n",
      "          ],\n",
      "          [\n",
      "            1559.997300466667,\n",
      "            1382.076111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"cf3ff24b33d832cf62cad7402a688f60\",\n",
      "    \"text\": \"[16] Aydar Bulatov, Yury Kuratov, and Mikhail Burtsev. \\u201cRecurrent memory transformer\\u201d. In: Advances in Neural Information Processing Systems 35 (2022), pp. 11079\\u201311091.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.911705493927002,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1448.4927777777777\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1515.85069\n",
      "          ],\n",
      "          [\n",
      "            1568.8035888671875,\n",
      "            1515.85069\n",
      "          ],\n",
      "          [\n",
      "            1568.8035888671875,\n",
      "            1448.4927777777777\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"e1a9ea52f5025115f65a617d07301582\",\n",
      "    \"text\": \"[17] Edoardo Cetin, Qi Sun, Tianyu Zhao, and Yujin Tang. \\u201cAn Evolved Universal Transformer Memory\\u201d. In: arXiv preprint arXiv:2410.13166 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9065442085266113,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1514.912222222222\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1582.2701344444445\n",
      "          ],\n",
      "          [\n",
      "            1565.142333984375,\n",
      "            1582.2701344444445\n",
      "          ],\n",
      "          [\n",
      "            1565.142333984375,\n",
      "            1514.912222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"c82bc2127c83e6e1d5b7592fedb458de\",\n",
      "    \"text\": \"[18] Beidi Chen, Tri Dao, Eric Winsor, Zhao Song, Atri Rudra, and Christopher R\\u00e9. \\u201cScatterbrain: Unifying sparse and low-rank attention\\u201d. In: Advances in Neural Information Processing Systems 34 (2021), pp. 17413\\u201317426.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9051321148872375,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1581.328888888889\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1648.686801111111\n",
      "          ],\n",
      "          [\n",
      "            1570.8846435546875,\n",
      "            1648.686801111111\n",
      "          ],\n",
      "          [\n",
      "            1570.8846435546875,\n",
      "            1581.328888888889\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"accd409576762cd4b7d296ff6cc6fc17\",\n",
      "    \"text\": \"[19] Krzysztof Marcin Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song, Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Quincy Davis, Afroz Mohiuddin, Lukasz Kaiser, David Benjamin Belanger, Lucy J Colwell, and Adrian Weller. \\u201cRethinking Attention with Performers\\u201d. In: International Conference on Learning Representations. 2021. url: https://openreview.net/forum?id=Ua6zuk0WRH.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.929196834564209,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1647.7455555555555\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1779.8624788888887\n",
      "          ],\n",
      "          [\n",
      "            1574.648193359375,\n",
      "            1779.8624788888887\n",
      "          ],\n",
      "          [\n",
      "            1574.648193359375,\n",
      "            1647.7455555555555\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ? id = Ua6zuk0WRH\",\n",
      "          \"url\": \"https://openreview.net/forum?id=Ua6zuk0WRH\",\n",
      "          \"start_index\": 349\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"cf70d9df16e5d63880426e159394ef8b\",\n",
      "    \"text\": \"[20] Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina Toutanova. \\u201cBoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions\\u201d. In: Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Ed. by Jill Burstein, Christy Doran, and Thamar Solorio. Minneapolis, Minnesota: Association for Computational Linguistics, June 2019, pp. 2924\\u20132936. doi: 10.18653/v1/N19-1300. url: https: //aclanthology.org/N19-1300/.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9478564858436584,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1780.5816666666667\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1979.1152566666665\n",
      "          ],\n",
      "          [\n",
      "            1564.2596328333334,\n",
      "            1979.1152566666665\n",
      "          ],\n",
      "          [\n",
      "            1564.2596328333334,\n",
      "            1780.5816666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"10 . 18653 / v1 / N19 - 1300\",\n",
      "          \"url\": \"https://doi.org/10.18653/v1/N19-1300\",\n",
      "          \"start_index\": 519\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"https :\",\n",
      "          \"url\": \"https://aclanthology.org/N19-1300/\",\n",
      "          \"start_index\": 546\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"// aclanthology . org / N19 - 1300 /.\",\n",
      "          \"url\": \"https://aclanthology.org/N19-1300/\",\n",
      "          \"start_index\": 553\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"8bd77ab3d238f5d2889649ea39e62100\",\n",
      "    \"text\": \"18\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1333333333333,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            867.1333333333333,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.87005,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.87005,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"c2fb800a7f864c1e81fd875ea9bfaec6\",\n",
      "    \"text\": \"[21] Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. \\u201cThink you have solved question answering? try arc, the ai2 reasoning challenge\\u201d. In: arXiv preprint arXiv:1803.05457 (2018).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9293677806854248,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            202.39277777777778\n",
      "          ],\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            300.06475830078125\n",
      "          ],\n",
      "          [\n",
      "            1564.2729163000004,\n",
      "            300.06475830078125\n",
      "          ],\n",
      "          [\n",
      "            1564.2729163000004,\n",
      "            202.39277777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"82dd37c327fd20d57e0173dec94f9c20\",\n",
      "    \"text\": \"[22] Nelson Cowan. \\u201cWhat are the differences between long-term, short-term, and working memory?\\u201d In: Progress in brain research 169 (2008), pp. 323\\u2013338.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9089279770851135,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            302.0205555555558\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            369.37846777777787\n",
      "          ],\n",
      "          [\n",
      "            1564.532958984375,\n",
      "            369.37846777777787\n",
      "          ],\n",
      "          [\n",
      "            1564.532958984375,\n",
      "            302.0205555555558\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"7123205c7bc238f114e5af151b10b750\",\n",
      "    \"text\": \"[23] Zihang Dai, Zhilin Yang, Yiming Yang, Jaime G. Carbonell, Quoc Viet Le, and Ruslan Salakhutdinov. \\u201cTransformer- XL: Attentive Language Models beyond a Fixed-Length Context\\u201d. In: ACL (1). Ed. by Anna Korhonen, David R. Traum, and Llu\\u00eds M\\u00e0rquez. Association for Computational Linguistics, 2019, pp. 2978\\u20132988. isbn: 978-1-950737-48-2.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9225428104400635,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            368.43722222222243\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            467.312255859375\n",
      "          ],\n",
      "          [\n",
      "            1567.12548828125,\n",
      "            467.312255859375\n",
      "          ],\n",
      "          [\n",
      "            1567.12548828125,\n",
      "            368.43722222222243\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"1d609fbc6e3728f4a3947470bbe56d25\",\n",
      "    \"text\": \"[24] Tri Dao. \\u201cFlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning\\u201d. In: The Twelfth Inter- national Conference on Learning Representations. 2024. url: https://openreview.net/forum?id=mZn2Xyh9Ec.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8119913935661316,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            468.0650000000001\n",
      "          ],\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            535.4229122222225\n",
      "          ],\n",
      "          [\n",
      "            1568.7291259765625,\n",
      "            535.4229122222225\n",
      "          ],\n",
      "          [\n",
      "            1568.7291259765625,\n",
      "            468.0650000000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ? id = mZn2Xyh9Ec\",\n",
      "          \"url\": \"https://openreview.net/forum?id=mZn2Xyh9Ec\",\n",
      "          \"start_index\": 60\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1412890c8e3d5feeb161580088dab77b\",\n",
      "    \"text\": \"[25] Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher R\\u00e9. \\u201cFlashAttention: Fast and Memory-Efficient\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            534.4816666666667\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            562.1555555555558\n",
      "          ],\n",
      "          [\n",
      "            1559.9973004666667,\n",
      "            562.1555555555558\n",
      "          ],\n",
      "          [\n",
      "            1559.9973004666667,\n",
      "            534.4816666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"e52528854f16431cde9712adc4ee1214\",\n",
      "    \"text\": \"Exact Attention with IO-Awareness\\u201d. In: Advances in Neural Information Processing Systems. Ed. by S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh. Vol. 35. Curran Associates, Inc., 2022, pp. 16344\\u201316359. url: https://proceedings.neurips.cc/paper_files/paper/2022/file/67d57c32e20fd0a7a302cb81d36e40d5- Paper-Conference.pdf.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9345605373382568,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            219.263916015625,\n",
      "            542.2435302734375\n",
      "          ],\n",
      "          [\n",
      "            219.263916015625,\n",
      "            699.8069233333334\n",
      "          ],\n",
      "          [\n",
      "            1576.0330810546875,\n",
      "            699.8069233333334\n",
      "          ],\n",
      "          [\n",
      "            1576.0330810546875,\n",
      "            542.2435302734375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// proceedings . neurips . cc / paper _ files / paper / 2022 / file / 67d57c32e20fd0a7a302cb81d36e40d5 -\",\n",
      "          \"url\": \"https://proceedings.neurips.cc/paper_files/paper/2022/file/67d57c32e20fd0a7a302cb81d36e40d5-Paper-Conference.pdf\",\n",
      "          \"start_index\": 337\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Paper - Conference . pdf\",\n",
      "          \"url\": \"https://proceedings.neurips.cc/paper_files/paper/2022/file/67d57c32e20fd0a7a302cb81d36e40d5-Paper-Conference.pdf\",\n",
      "          \"start_index\": 430\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"661fa5b533b3978e85f0b3d8ab06d816\",\n",
      "    \"text\": \"[26] Tri Dao and Albert Gu. \\u201cTransformers are SSMs: Generalized models and efficient algorithms through structured state space duality\\u201d. In: arXiv preprint arXiv:2405.21060 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9015275835990906,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            700.5261111111114\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            767.8840233333334\n",
      "          ],\n",
      "          [\n",
      "            1562.8834228515625,\n",
      "            767.8840233333334\n",
      "          ],\n",
      "          [\n",
      "            1562.8834228515625,\n",
      "            700.5261111111114\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"38c2dc53aa2b5c64a7170ce043adc63d\",\n",
      "    \"text\": \"[27] Abhimanyu Das, Weihao Kong, Andrew Leach, Shaan K Mathur, Rajat Sen, and Rose Yu. \\u201cLong-term Forecasting with TiDE: Time-series Dense Encoder\\u201d. In: Transactions on Machine Learning Research (2023). issn: 2835-8856. url: https://openreview.net/forum?id=pCbC3aQB5W.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9265975952148438,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.8694444444443,\n",
      "            766.9427777777776\n",
      "          ],\n",
      "          [\n",
      "            212.8694444444443,\n",
      "            865.8513677777778\n",
      "          ],\n",
      "          [\n",
      "            1571.010009765625,\n",
      "            865.8513677777778\n",
      "          ],\n",
      "          [\n",
      "            1571.010009765625,\n",
      "            766.9427777777776\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ? id = pCbC3aQB5W\",\n",
      "          \"url\": \"https://openreview.net/forum?id=pCbC3aQB5W\",\n",
      "          \"start_index\": 225\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"180d382ef81ebf3bdac7f49a2288affe\",\n",
      "    \"text\": \"[28] Soham De, Samuel L Smith, Anushan Fernando, Aleksandar Botev, George Cristian-Muraru, Albert Gu, Ruba Haroun, Leonard Berrada, Yutian Chen, Srivatsan Srinivasan, et al. \\u201cGriffin: Mixing gated linear recurrences with local attention for efficient language models\\u201d. In: arXiv preprint arXiv:2402.19427 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9309122562408447,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            866.5705555555555\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            967.1368011111111\n",
      "          ],\n",
      "          [\n",
      "            1571.615966796875,\n",
      "            967.1368011111111\n",
      "          ],\n",
      "          [\n",
      "            1571.615966796875,\n",
      "            866.5705555555555\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"b2f3400a328b769869a25132ca339baa\",\n",
      "    \"text\": \"[29] Juechu Dong, Boyuan Feng, Driss Guessous, Yanbo Liang, and Horace He. \\u201cFlex Attention: A Programming Model for Generating Optimized Attention Kernels\\u201d. In: arXiv preprint arXiv:2412.05496 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8994935750961304,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            966.1955555555555\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1033.5534677777778\n",
      "          ],\n",
      "          [\n",
      "            1570.4847412109375,\n",
      "            1033.5534677777778\n",
      "          ],\n",
      "          [\n",
      "            1570.4847412109375,\n",
      "            966.1955555555555\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"8c555af3f66d16bab2b169a24302af6d\",\n",
      "    \"text\": \"[30] Xin Dong, Yonggan Fu, Shizhe Diao, Wonmin Byeon, Zijia Chen, Ameya Sunil Mahabaleshwarkar, Shih-Yang Liu, Matthijs Van Keirsbilck, Min-Hung Chen, Yoshi Suhara, et al. \\u201cHymba: A Hybrid-head Architecture for Small Language Models\\u201d. In: arXiv preprint arXiv:2411.13676 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9272312521934509,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            1032.615\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            1133.1812455555555\n",
      "          ],\n",
      "          [\n",
      "            1569.2747802734375,\n",
      "            1133.1812455555555\n",
      "          ],\n",
      "          [\n",
      "            1569.2747802734375,\n",
      "            1032.615\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"926518ca9ed7388cd045a37d239a5b17\",\n",
      "    \"text\": \"[31] Stefan Elfwing, Eiji Uchibe, and Kenji Doya. \\u201cSigmoid-weighted linear units for neural network function approxi- mation in reinforcement learning\\u201d. In: Neural networks 107 (2018), pp. 3\\u201311.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9024097919464111,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            208.5481414794922,\n",
      "            1132.2399999999998\n",
      "          ],\n",
      "          [\n",
      "            208.5481414794922,\n",
      "            1199.5979122222222\n",
      "          ],\n",
      "          [\n",
      "            1567.8973388671875,\n",
      "            1199.5979122222222\n",
      "          ],\n",
      "          [\n",
      "            1567.8973388671875,\n",
      "            1132.2399999999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"a96735968891a796e1093d5420ea2311\",\n",
      "    \"text\": \"[32] Yukun Feng, Feng Li, Ziang Song, Boyuan Zheng, and Philipp Koehn. \\u201cLearn to remember: Transformer with recurrent memory for document-level machine translation\\u201d. In: arXiv preprint arXiv:2205.01546 (2022).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8318759799003601,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1198.6566666666665\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1266.0173566666665\n",
      "          ],\n",
      "          [\n",
      "            1566.1385498046875,\n",
      "            1266.0173566666665\n",
      "          ],\n",
      "          [\n",
      "            1566.1385498046875,\n",
      "            1198.6566666666665\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"7ca89c868863d6b10f5dae3bd2d496f3\",\n",
      "    \"text\": \"[33] Daniel Y Fu, Tri Dao, Khaled Kamal Saab, Armin W Thomas, Atri Rudra, and Christopher Re. \\u201cHungry Hungry Hippos: Towards Language Modeling with State Space Models\\u201d. In: The Eleventh International Conference on Learning Representations. 2023. url: https://openreview.net/forum?id=COZDy0WYGg.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9171264171600342,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            1265.076111111111\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            1365.6423566666667\n",
      "          ],\n",
      "          [\n",
      "            1565.7921142578125,\n",
      "            1365.6423566666667\n",
      "          ],\n",
      "          [\n",
      "            1565.7921142578125,\n",
      "            1265.076111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ? id = COZDy0WYGg\",\n",
      "          \"url\": \"https://openreview.net/forum?id=COZDy0WYGg\",\n",
      "          \"start_index\": 251\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"c8c0c3b0ac7921a93fbc6ec87c372e24\",\n",
      "    \"text\": \"[34] Yossi Gandelsman, Yu Sun, Xinlei Chen, and Alexei Efros. \\u201cTest-time training with masked autoencoders\\u201d. In: Advances in Neural Information Processing Systems 35 (2022), pp. 29374\\u201329385.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9040347933769226,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            1364.701111111111\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            1432.0590233333332\n",
      "          ],\n",
      "          [\n",
      "            1563.2716749999997,\n",
      "            1432.0590233333332\n",
      "          ],\n",
      "          [\n",
      "            1563.2716749999997,\n",
      "            1364.701111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"2556a1f33e24e6a7b0f2f9f6bb5f3304\",\n",
      "    \"text\": \"[35] Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, et al. \\u201cThe pile: An 800gb dataset of diverse text for language modeling\\u201d. In: arXiv preprint arXiv:2101.00027 (2020).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9284109473228455,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1431.1205555555555\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1531.686801111111\n",
      "          ],\n",
      "          [\n",
      "            1570.7281494140625,\n",
      "            1531.686801111111\n",
      "          ],\n",
      "          [\n",
      "            1570.7281494140625,\n",
      "            1431.1205555555555\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"c33ff1872f68e0ccdc722ad716b80fd6\",\n",
      "    \"text\": \"[36] Felix A Gers, J\\u00fcrgen Schmidhuber, and Fred Cummins. \\u201cLearning to forget: Continual prediction with LSTM\\u201d. In: Neural computation 12.10 (2000), pp. 2451\\u20132471.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9097015261650085,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1530.7455555555555\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1598.1034677777775\n",
      "          ],\n",
      "          [\n",
      "            1568.39697265625,\n",
      "            1598.1034677777775\n",
      "          ],\n",
      "          [\n",
      "            1568.39697265625,\n",
      "            1530.7455555555555\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"91a4e32a282922597094660a5622c8b2\",\n",
      "    \"text\": \"[37] Alex Graves, Greg Wayne, and Ivo Danihelka. Neural Turing Machines. 2014. arXiv: 1410.5401 [cs.NE]. url: https://arxiv.org/abs/1410.5401.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9143458604812622,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            1597.162222222222\n",
      "          ],\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            1662.8624788888887\n",
      "          ],\n",
      "          [\n",
      "            1566.314697265625,\n",
      "            1662.8624788888887\n",
      "          ],\n",
      "          [\n",
      "            1566.314697265625,\n",
      "            1597.162222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"1410 . 5401 [ cs . NE ].\",\n",
      "          \"url\": \"https://arxiv.org/abs/1410.5401\",\n",
      "          \"start_index\": 86\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"dc0f06bade97691fb0cf5e46931a72b2\",\n",
      "    \"text\": \"[38] Klaus Greff, Rupesh K Srivastava, Jan Koutn\\u00edk, Bas R Steunebrink, and J\\u00fcrgen Schmidhuber. \\u201cLSTM: A search space\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1663.5816666666667\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1691.2555555555555\n",
      "          ],\n",
      "          [\n",
      "            1559.9917656888888,\n",
      "            1691.2555555555555\n",
      "          ],\n",
      "          [\n",
      "            1559.9917656888888,\n",
      "            1663.5816666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"211ecb333349675e6821ce19618eea79\",\n",
      "    \"text\": \"odyssey\\u201d. In: IEEE transactions on neural networks and learning systems 28.10 (2016), pp. 2222\\u20132232.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8899675607681274,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            225.14430236816406,\n",
      "            1671.33154296875\n",
      "          ],\n",
      "          [\n",
      "            225.14430236816406,\n",
      "            1730.9395788888887\n",
      "          ],\n",
      "          [\n",
      "            1565.5889892578125,\n",
      "            1730.9395788888887\n",
      "          ],\n",
      "          [\n",
      "            1565.5889892578125,\n",
      "            1671.33154296875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"fc7ce83dbe0ff9429f693b0ae9ede054\",\n",
      "    \"text\": \"[39] Katar\\u00edna Gre\\u0161ov\\u00e1, Vlastimil Martinek, David \\u010cech\\u00e1k, Petr \\u0160ime\\u010dek, and Panagiotis Alexiou. \\u201cGenomic benchmarks: a collection of datasets for genomic sequence classification\\u201d. In: BMC Genomic Data 24.1 (2023), p. 25.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.7562036514282227,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1729.9983333333332\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1797.3562455555557\n",
      "          ],\n",
      "          [\n",
      "            1584.2481689453125,\n",
      "            1797.3562455555557\n",
      "          ],\n",
      "          [\n",
      "            1584.2481689453125,\n",
      "            1729.9983333333332\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"0bc598aed32cce872cd8364a61f96751\",\n",
      "    \"text\": \"[40] Albert Gu and Tri Dao. \\u201cMamba: Linear-Time Sequence Modeling with Selective State Spaces\\u201d. In: First Conference on Language Modeling. 2024. url: https://openreview.net/forum?id=tEYskw1VY2.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8621627688407898,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1796.4149999999997\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1863.77569\n",
      "          ],\n",
      "          [\n",
      "            1569.128662109375,\n",
      "            1863.77569\n",
      "          ],\n",
      "          [\n",
      "            1569.128662109375,\n",
      "            1796.4149999999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ? id = tEYskw1VY2\",\n",
      "          \"url\": \"https://openreview.net/forum?id=tEYskw1VY2\",\n",
      "          \"start_index\": 33\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"51e684a92bb7b02d4388d94c086eb674\",\n",
      "    \"text\": \"[41] Albert Gu, Karan Goel, and Christopher Re. \\u201cEfficiently Modeling Long Sequences with Structured State Spaces\\u201d. In: International Conference on Learning Representations. 2022. url: https : / / openreview . net / forum ? id = uYLFoz1vlAC.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9330478310585022,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            1862.8344444444444\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            1961.7402566666665\n",
      "          ],\n",
      "          [\n",
      "            1568.7193603515625,\n",
      "            1961.7402566666665\n",
      "          ],\n",
      "          [\n",
      "            1568.7193603515625,\n",
      "            1862.8344444444444\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https : / / openreview . net / forum ? id =\",\n",
      "          \"url\": \"https://openreview.net/forum?id=uYLFoz1vlAC\",\n",
      "          \"start_index\": 183\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"uYLFoz1vlAC\",\n",
      "          \"url\": \"https://openreview.net/forum?id=uYLFoz1vlAC\",\n",
      "          \"start_index\": 227\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"fd50ffa9ed7ba8535df4f01aded5be00\",\n",
      "    \"text\": \"19\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1305555555552,\n",
      "            2057.7427777777775\n",
      "          ],\n",
      "          [\n",
      "            867.1305555555552,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222219,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222219,\n",
      "            2057.7427777777775\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"1fbbea9dcec6954a5050b821c4b27c1b\",\n",
      "    \"text\": \"[42] Chi Han, Qifan Wang, Hao Peng, Wenhan Xiong, Yu Chen, Heng Ji, and Sinong Wang. \\u201cLM-Infinite: Zero-Shot\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            202.39277777777778\n",
      "          ],\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            230.06666666666652\n",
      "          ],\n",
      "          [\n",
      "            1559.9973004666663,\n",
      "            230.06666666666652\n",
      "          ],\n",
      "          [\n",
      "            1559.9973004666663,\n",
      "            202.39277777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"21fc05a3d82fb88f73c69fff9a6b4958\",\n",
      "    \"text\": \"Extreme Length Generalization for Large Language Models\\u201d. In: Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). Ed. by Kevin Duh, Helena Gomez, and Steven Bethard. Mexico City, Mexico: Association for Computational Linguistics, June 2024, pp. 3991\\u20134008. doi: 10.18653/v1/2024.naacl-long.222. url: https://aclanthology. org/2024.naacl-long.222.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9473839402198792,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            216.13760375976562,\n",
      "            209.43060302734375\n",
      "          ],\n",
      "          [\n",
      "            216.13760375976562,\n",
      "            400.92636777777795\n",
      "          ],\n",
      "          [\n",
      "            1566.906388888889,\n",
      "            400.92636777777795\n",
      "          ],\n",
      "          [\n",
      "            1566.906388888889,\n",
      "            209.43060302734375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"10 . 18653 / v1 / 2024 . naacl - long . 222\",\n",
      "          \"url\": \"https://doi.org/10.18653/v1/2024.naacl-long.222\",\n",
      "          \"start_index\": 485\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"https :// aclanthology .\",\n",
      "          \"url\": \"https://aclanthology.org/2024.naacl-long.222\",\n",
      "          \"start_index\": 523\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"org / 2024 . naacl - long . 222\",\n",
      "          \"url\": \"https://aclanthology.org/2024.naacl-long.222\",\n",
      "          \"start_index\": 545\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"58853991ba3795ef150f4a7fe2ab6c53\",\n",
      "    \"text\": \"[43] Ramin Hasani, Mathias Lechner, Tsun-Hsuan Wang, Makram Chahine, Alexander Amini, and Daniela Rus. \\u201cLiquid Structural State-Space Models\\u201d. In: The Eleventh International Conference on Learning Representations. 2023. url: https://openreview.net/forum?id=g4OTKRKfS7R.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9291703701019287,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            401.6455555555555\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            500.5541455555557\n",
      "          ],\n",
      "          [\n",
      "            1565.3060302734375,\n",
      "            500.5541455555557\n",
      "          ],\n",
      "          [\n",
      "            1565.3060302734375,\n",
      "            401.6455555555555\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ? id = g4OTKRKfS7R\",\n",
      "          \"url\": \"https://openreview.net/forum?id=g4OTKRKfS7R\",\n",
      "          \"start_index\": 225\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"f9f579d7702c842a5e9bbaf3fe2a02fc\",\n",
      "    \"text\": \"[44] Zexue He, Leonid Karlinsky, Donghyun Kim, Julian McAuley, Dmitry Krotov, and Rogerio Feris. \\u201cCAMELoT: Towards Large Language Models with Training-Free Consolidated Associative Memory\\u201d. In: arXiv preprint arXiv:2402.13449 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9310929775238037,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            501.2733333333336\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            601.839578888889\n",
      "          ],\n",
      "          [\n",
      "            1568.3333740234375,\n",
      "            601.839578888889\n",
      "          ],\n",
      "          [\n",
      "            1568.3333740234375,\n",
      "            501.2733333333336\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"37604c2aeb8a0a665bb543f80ea4654a\",\n",
      "    \"text\": \"[45] Donald Olding Hebb. The organization of behavior: A neuropsychological theory. Psychology press, 2005.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.846422016620636,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            600.8983333333337\n",
      "          ],\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            635.0479122222225\n",
      "          ],\n",
      "          [\n",
      "            1462.09912109375,\n",
      "            635.0479122222225\n",
      "          ],\n",
      "          [\n",
      "            1462.09912109375,\n",
      "            600.8983333333337\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"85ff9dfbde5feb627636523ec23e6f5d\",\n",
      "    \"text\": \"[46]\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            634.1094444444448\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            661.7833333333335\n",
      "          ],\n",
      "          [\n",
      "            258.3099700000001,\n",
      "            661.7833333333335\n",
      "          ],\n",
      "          [\n",
      "            258.3099700000001,\n",
      "            634.1094444444448\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"ba42cbe1ba2010e7b9abb03703c585f3\",\n",
      "    \"text\": \"John J Hopfield. \\u201cNeural networks and physical systems with emergent collective computational abilities.\\u201d In: Proceedings of the national academy of sciences 79.8 (1982), pp. 2554\\u20132558.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.908971905708313,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            220.43829345703125,\n",
      "            634.1094444444444\n",
      "          ],\n",
      "          [\n",
      "            220.43829345703125,\n",
      "            701.4673566666668\n",
      "          ],\n",
      "          [\n",
      "            1573.6435546875,\n",
      "            701.4673566666668\n",
      "          ],\n",
      "          [\n",
      "            1573.6435546875,\n",
      "            634.1094444444444\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"6a32d18d00b4d2f3dac1639184a4ddc8\",\n",
      "    \"text\": \"[47] Kurt Hornik, Maxwell Stinchcombe, and Halbert White. \\u201cMultilayer feedforward networks are universal approxi- mators\\u201d. In: Neural networks 2.5 (1989), pp. 359\\u2013366.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9008928537368774,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            700.5261111111114\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            767.8840233333334\n",
      "          ],\n",
      "          [\n",
      "            1564.7615966796875,\n",
      "            767.8840233333334\n",
      "          ],\n",
      "          [\n",
      "            1564.7615966796875,\n",
      "            700.5261111111114\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"c1b78343ee89abb9b93281b79f014a09\",\n",
      "    \"text\": \"[48] Cheng-Ping Hsieh, Simeng Sun, Samuel Kriman, Shantanu Acharya, Dima Rekesh, Fei Jia, and Boris Ginsburg. \\u201cRULER: What\\u2019s the Real Context Size of Your Long-Context Language Models?\\u201d In: First Conference on Language Modeling. 2024. url: https://openreview.net/forum?id=kIoBbc76Sy.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9126501679420471,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            766.9427777777776\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            867.5118011111111\n",
      "          ],\n",
      "          [\n",
      "            1571.36328125,\n",
      "            867.5118011111111\n",
      "          ],\n",
      "          [\n",
      "            1571.36328125,\n",
      "            766.9427777777776\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ? id = kIoBbc76Sy\",\n",
      "          \"url\": \"https://openreview.net/forum?id=kIoBbc76Sy\",\n",
      "          \"start_index\": 240\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"5b32ec41867cb404db75092b5d17a036\",\n",
      "    \"text\": \"[49] DeLesley Hutchins, Imanol Schlag, Yuhuai Wu, Ethan Dyer, and Behnam Neyshabur. \\u201cBlock-recurrent transformers\\u201d. In: Advances in neural information processing systems 35 (2022), pp. 33248\\u201333261.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9002556204795837,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            866.5705555555555\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            933.9284677777777\n",
      "          ],\n",
      "          [\n",
      "            1567.771728515625,\n",
      "            933.9284677777777\n",
      "          ],\n",
      "          [\n",
      "            1567.771728515625,\n",
      "            866.5705555555555\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"0fc19dc898ec2ff4cc691cfbec83c9e1\",\n",
      "    \"text\": \"[50] Kazuki Irie, R\\u00f3bert Csord\\u00e1s, and J\\u00fcrgen Schmidhuber. \\u201cThe dual form of neural networks revisited: Connecting test time predictions to training patterns via spotlights of attention\\u201d. In: International Conference on Machine Learning. PMLR. 2022, pp. 9639\\u20139659.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9240564107894897,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            932.987222222222\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1030.9283447265625\n",
      "          ],\n",
      "          [\n",
      "            1569.8016357421875,\n",
      "            1030.9283447265625\n",
      "          ],\n",
      "          [\n",
      "            1569.8016357421875,\n",
      "            932.987222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"84e80600d4096ead1e4ab3e4156fb662\",\n",
      "    \"text\": \"[51] Kazuki Irie, Imanol Schlag, R\\u00f3bert Csord\\u00e1s, and J\\u00fcrgen Schmidhuber. \\u201cGoing beyond linear transformers with recurrent fast weight programmers\\u201d. In: Advances in neural information processing systems 34 (2021), pp. 7703\\u20137717.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8279474377632141,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            1032.615\n",
      "          ],\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            1099.9729122222222\n",
      "          ],\n",
      "          [\n",
      "            1566.0423583984375,\n",
      "            1099.9729122222222\n",
      "          ],\n",
      "          [\n",
      "            1566.0423583984375,\n",
      "            1032.615\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"b2f7f0d256df8e2d3de8f369565a9c7a\",\n",
      "    \"text\": \"[52] Vidit Jain and Erik Learned-Miller. \\u201cOnline domain adaptation of a pre-trained cascade of classifiers\\u201d. In: CVPR 2011. IEEE. 2011, pp. 577\\u2013584.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8178349733352661,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            1099.0316666666665\n",
      "          ],\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            1166.3895788888888\n",
      "          ],\n",
      "          [\n",
      "            1564.4793701171875,\n",
      "            1166.3895788888888\n",
      "          ],\n",
      "          [\n",
      "            1564.4793701171875,\n",
      "            1099.0316666666665\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"197365196eed4c06c8eb35e13e9b0138\",\n",
      "    \"text\": \"[53] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. \\u201cMistral 7B\\u201d. In: arXiv preprint arXiv:2310.06825 (2023).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9288909435272217,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            1165.4483333333333\n",
      "          ],\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            1266.0173566666665\n",
      "          ],\n",
      "          [\n",
      "            1569.4532470703125,\n",
      "            1266.0173566666665\n",
      "          ],\n",
      "          [\n",
      "            1569.4532470703125,\n",
      "            1165.4483333333333\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"612f6adb2f1aeca8d724baeef0998fbf\",\n",
      "    \"text\": \"[54] Praneeth Kacham, Vahab Mirrokni, and Peilin Zhong. \\u201cPolySketchFormer: Fast Transformers via Sketching Polyno- mial Kernels\\u201d. In: Forty-first International Conference on Machine Learning. 2024. url: https://openreview.net/ forum?id=ghYrfdJfjK.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9269412159919739,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            1265.076111111111\n",
      "          ],\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            1363.9819233333333\n",
      "          ],\n",
      "          [\n",
      "            1570.786376953125,\n",
      "            1363.9819233333333\n",
      "          ],\n",
      "          [\n",
      "            1570.786376953125,\n",
      "            1265.076111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net /\",\n",
      "          \"url\": \"https://openreview.net/forum?id=ghYrfdJfjK\",\n",
      "          \"start_index\": 202\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"forum ? id = ghYrfdJfjK\",\n",
      "          \"url\": \"https://openreview.net/forum?id=ghYrfdJfjK\",\n",
      "          \"start_index\": 226\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"396bdfb6cf8251c192df8980b3af55c5\",\n",
      "    \"text\": \"[55] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. \\u201cScaling laws for neural language models\\u201d. In: arXiv preprint arXiv:2001.08361 (2020).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9312649965286255,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.568359375,\n",
      "            1364.701111111111\n",
      "          ],\n",
      "          [\n",
      "            212.568359375,\n",
      "            1460.0240478515625\n",
      "          ],\n",
      "          [\n",
      "            1569.978271484375,\n",
      "            1460.0240478515625\n",
      "          ],\n",
      "          [\n",
      "            1569.978271484375,\n",
      "            1364.701111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"b9f730a1e3d937774d12c8a670084be0\",\n",
      "    \"text\": \"[56] Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and Fran\\u00e7ois Fleuret. \\u201cTransformers are rnns: Fast au- toregressive transformers with linear attention\\u201d. In: International conference on machine learning. PMLR. 2020, pp. 5156\\u20135165.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.926834762096405,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1464.328888888889\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1560.1353759765625\n",
      "          ],\n",
      "          [\n",
      "            1570.65185546875,\n",
      "            1560.1353759765625\n",
      "          ],\n",
      "          [\n",
      "            1570.65185546875,\n",
      "            1464.328888888889\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"4994340a1ffc957694e674123a82c354\",\n",
      "    \"text\": \"[57] Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis. \\u201cGeneralization through Memorization: Nearest Neighbor Language Models\\u201d. In: International Conference on Learning Representations. 2020. url: https://openreview.net/forum?id=HklBjCEKvH.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9287479519844055,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            210.14068603515625,\n",
      "            1563.953888888889\n",
      "          ],\n",
      "          [\n",
      "            210.14068603515625,\n",
      "            1662.8624788888887\n",
      "          ],\n",
      "          [\n",
      "            1572.1239013671875,\n",
      "            1662.8624788888887\n",
      "          ],\n",
      "          [\n",
      "            1572.1239013671875,\n",
      "            1563.953888888889\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ? id = HklBjCEKvH\",\n",
      "          \"url\": \"https://openreview.net/forum?id=HklBjCEKvH\",\n",
      "          \"start_index\": 226\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"bc91f95a8fccc831b6f54d0627b3c658\",\n",
      "    \"text\": \"[58] Yuri Kuratov, Aydar Bulatov, Petr Anokhin, Ivan Rodkin, Dmitry Igorevich Sorokin, Artyom Sorokin, and Mikhail Burtsev. \\u201cBABILong: Testing the Limits of LLMs with Long Context Reasoning-in-a-Haystack\\u201d. In: The Thirty- eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 2024. url: https : //openreview.net/forum?id=u7m2CG84BQ.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9385219812393188,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1663.5816666666667\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1795.6958122222222\n",
      "          ],\n",
      "          [\n",
      "            1570.595458984375,\n",
      "            1795.6958122222222\n",
      "          ],\n",
      "          [\n",
      "            1570.595458984375,\n",
      "            1663.5816666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :\",\n",
      "          \"url\": \"https://openreview.net/forum?id=u7m2CG84BQ\",\n",
      "          \"start_index\": 322\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"// openreview . net / forum ? id = u7m2CG84BQ\",\n",
      "          \"url\": \"https://openreview.net/forum?id=u7m2CG84BQ\",\n",
      "          \"start_index\": 330\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"d83a5185b07fbb3cb05081c4e83b2fe4\",\n",
      "    \"text\": \"[59] Hung Le, Truyen Tran, and Svetha Venkatesh. \\u201cSelf-attentive associative memory\\u201d. In: International conference on machine learning. PMLR. 2020, pp. 5682\\u20135691.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9187585115432739,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1796.4149999999997\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1863.77569\n",
      "          ],\n",
      "          [\n",
      "            1563.44189453125,\n",
      "            1863.77569\n",
      "          ],\n",
      "          [\n",
      "            1563.44189453125,\n",
      "            1796.4149999999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"dcdd71942adf816502b95c5a957a2942\",\n",
      "    \"text\": \"[60] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K\\u00fcttler, Mike Lewis, Wen-tau Yih, Tim Rockt\\u00e4schel, et al. \\u201cRetrieval-augmented generation for knowledge-intensive nlp tasks\\u201d. In: Advances in Neural Information Processing Systems 33 (2020), pp. 9459\\u20139474.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9357931017875671,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444435,\n",
      "            1862.8344444444444\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444435,\n",
      "            1963.40069\n",
      "          ],\n",
      "          [\n",
      "            1567.6470947265625,\n",
      "            1963.40069\n",
      "          ],\n",
      "          [\n",
      "            1567.6470947265625,\n",
      "            1862.8344444444444\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"7cfb434be67b849528ca568db856274b\",\n",
      "    \"text\": \"20\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1305555555556,\n",
      "            2057.7427777777775\n",
      "          ],\n",
      "          [\n",
      "            867.1305555555556,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222223,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222223,\n",
      "            2057.7427777777775\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"9245e1318eaaa8209a6706973c595ac4\",\n",
      "    \"text\": \"[61] Danny Leybzon and Corentin Kervadec. \\u201cLearning, Forgetting, Remembering: Insights From Tracking LLM Mem- orization During Training\\u201d. In: Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP. 2024, pp. 43\\u201357.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9275368452072144,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            202.39277777777778\n",
      "          ],\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            302.9618011111113\n",
      "          ],\n",
      "          [\n",
      "            1565.2808837890625,\n",
      "            302.9618011111113\n",
      "          ],\n",
      "          [\n",
      "            1565.2808837890625,\n",
      "            202.39277777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"bda042f7810e9c0fd28e6df7e40ad32d\",\n",
      "    \"text\": \"[62] Zhe Li, Shiyi Qi, Yiduo Li, and Zenglin Xu. \\u201cRevisiting long-term time series forecasting: An investigation on linear mapping\\u201d. In: arXiv preprint arXiv:2305.10721 (2023).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9175124764442444,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            302.0205555555558\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            369.37846777777787\n",
      "          ],\n",
      "          [\n",
      "            1569.8525390625,\n",
      "            369.37846777777787\n",
      "          ],\n",
      "          [\n",
      "            1569.8525390625,\n",
      "            302.0205555555558\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"cd565e0c696037462b8d68d5cfcfb84a\",\n",
      "    \"text\": \"[63] Bo Liu, Rui Wang, Lemeng Wu, Yihao Feng, Peter Stone, and Qiang Liu. \\u201cLonghorn: State space models are amortized online learners\\u201d. In: arXiv preprint arXiv:2407.14207 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9080849885940552,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            368.43722222222243\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            435.79513444444444\n",
      "          ],\n",
      "          [\n",
      "            1572.627685546875,\n",
      "            435.79513444444444\n",
      "          ],\n",
      "          [\n",
      "            1572.627685546875,\n",
      "            368.43722222222243\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"ec540ae1e9d6beba7e82614554b3673e\",\n",
      "    \"text\": \"[64] Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. \\u201cLost in the middle: How language models use long contexts\\u201d. In: Transactions of the Association for Computational Linguistics 12 (2024), pp. 157\\u2013173.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9220607280731201,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            434.8566666666667\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            535.4229122222225\n",
      "          ],\n",
      "          [\n",
      "            1569.8511962890625,\n",
      "            535.4229122222225\n",
      "          ],\n",
      "          [\n",
      "            1569.8511962890625,\n",
      "            434.8566666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"a92d15aa40541d96f74aa2112fa6f079\",\n",
      "    \"text\": \"[65] Yong Liu, Tengge Hu, Haoran Zhang, Haixu Wu, Shiyu Wang, Lintao Ma, and Mingsheng Long. \\u201citransformer: Inverted transformers are effective for time series forecasting\\u201d. In: arXiv preprint arXiv:2310.06625 (2023).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.89239501953125,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            534.4816666666667\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            602.0623168945312\n",
      "          ],\n",
      "          [\n",
      "            1568.9495849609375,\n",
      "            602.0623168945312\n",
      "          ],\n",
      "          [\n",
      "            1568.9495849609375,\n",
      "            534.4816666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"363cb3b0271dc02b2cb6044c7bc3d44d\",\n",
      "    \"text\": \"[66] George Mandler. \\u201cThe structure of value: Accounting for taste\\u201d. In: Affect and cognition. Psychology Press, 2014, pp. 3\\u201336.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8881871700286865,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            600.8983333333333\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            665.1192626953125\n",
      "          ],\n",
      "          [\n",
      "            1565.2939453125,\n",
      "            665.1192626953125\n",
      "          ],\n",
      "          [\n",
      "            1565.2939453125,\n",
      "            600.8983333333333\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"5aeaa0497b64bfaf2a87445a715a298f\",\n",
      "    \"text\": \"[67] Harsh Mehta, Ankit Gupta, Ashok Cutkosky, and Behnam Neyshabur. \\u201cLong Range Language Modeling via Gated State Spaces\\u201d. In: The Eleventh International Conference on Learning Representations. 2023. url: https : //openreview.net/forum?id=5MkYIYCbva.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9304193258285522,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            667.3177777777779\n",
      "          ],\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            766.2235900000003\n",
      "          ],\n",
      "          [\n",
      "            1566.8189697265625,\n",
      "            766.2235900000003\n",
      "          ],\n",
      "          [\n",
      "            1566.8189697265625,\n",
      "            667.3177777777779\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :\",\n",
      "          \"url\": \"https://openreview.net/forum?id=5MkYIYCbva\",\n",
      "          \"start_index\": 206\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"// openreview . net / forum ? id = 5MkYIYCbva\",\n",
      "          \"url\": \"https://openreview.net/forum?id=5MkYIYCbva\",\n",
      "          \"start_index\": 214\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"563f8a71a3db37e1995b36bda311bab1\",\n",
      "    \"text\": \"[68]\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.8694444444443,\n",
      "            766.9427777777779\n",
      "          ],\n",
      "          [\n",
      "            212.8694444444443,\n",
      "            794.6166666666668\n",
      "          ],\n",
      "          [\n",
      "            258.30996999999985,\n",
      "            794.6166666666668\n",
      "          ],\n",
      "          [\n",
      "            258.30996999999985,\n",
      "            766.9427777777779\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"334dc07ef6234466b8619075c20b1e15\",\n",
      "    \"text\": \"Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. \\u201cPointer Sentinel Mixture Models\\u201d. In: International Conference on Learning Representations. 2017. url: https://openreview.net/forum?id=Byj72udxe.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.72942715883255,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            216.45787048339844,\n",
      "            766.9427777777779\n",
      "          ],\n",
      "          [\n",
      "            216.45787048339844,\n",
      "            846.8300170898438\n",
      "          ],\n",
      "          [\n",
      "            1567.5665283203125,\n",
      "            846.8300170898438\n",
      "          ],\n",
      "          [\n",
      "            1567.5665283203125,\n",
      "            766.9427777777779\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ? id = Byj72udxe\",\n",
      "          \"url\": \"https://openreview.net/forum?id=Byj72udxe\",\n",
      "          \"start_index\": 423\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"57b672c19d2975c6aa2a2b89bfb99df4\",\n",
      "    \"text\": \"[69] William Merrill, Jackson Petty, and Ashish Sabharwal. \\u201cThe Illusion of State in State-Space Models\\u201d. In: Forty-first\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5419095754623413,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            833.3622222222222\n",
      "          ],\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            867.5118011111111\n",
      "          ],\n",
      "          [\n",
      "            1560.0009814222224,\n",
      "            867.5118011111111\n",
      "          ],\n",
      "          [\n",
      "            1560.0009814222224,\n",
      "            833.3622222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"9b14f2201376ab190f3d9c9d391412d7\",\n",
      "    \"text\": \"International Conference on Machine Learning. 2024. url: https://openreview.net/forum?id=QZgo9JZpLq.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5192927718162537,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            216.8472442626953,\n",
      "            866.5705555555555\n",
      "          ],\n",
      "          [\n",
      "            216.8472442626953,\n",
      "            900.7201344444444\n",
      "          ],\n",
      "          [\n",
      "            1531.2598876953125,\n",
      "            900.7201344444444\n",
      "          ],\n",
      "          [\n",
      "            1531.2598876953125,\n",
      "            866.5705555555555\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ? id = QZgo9JZpLq\",\n",
      "          \"url\": \"https://openreview.net/forum?id=QZgo9JZpLq\",\n",
      "          \"start_index\": 644\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"a149b43ea2e99cf62f6f5bf35b1c458e\",\n",
      "    \"text\": \"[70] Ravi Teja Mullapudi, Steven Chen, Keyi Zhang, Deva Ramanan, and Kayvon Fatahalian. \\u201cOnline model distillation for efficient video inference\\u201d. In: Proceedings of the IEEE/CVF International conference on computer vision. 2019, pp. 3573\\u20133582.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9187974333763123,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.8694444444447,\n",
      "            899.7788888888888\n",
      "          ],\n",
      "          [\n",
      "            212.8694444444447,\n",
      "            995.8250122070312\n",
      "          ],\n",
      "          [\n",
      "            1567.339599609375,\n",
      "            995.8250122070312\n",
      "          ],\n",
      "          [\n",
      "            1567.339599609375,\n",
      "            899.7788888888888\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"087a67c6e64dfbd73532687915c575fa\",\n",
      "    \"text\": \"[71] Tsendsuren Munkhdalai, Manaal Faruqui, and Siddharth Gopal. \\u201cLeave no context behind: Efficient infinite context transformers with infini-attention\\u201d. In: arXiv preprint arXiv:2404.07143 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8968675136566162,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            999.4038888888888\n",
      "          ],\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            1066.7645788888888\n",
      "          ],\n",
      "          [\n",
      "            1562.6968994140625,\n",
      "            1066.7645788888888\n",
      "          ],\n",
      "          [\n",
      "            1562.6968994140625,\n",
      "            999.4038888888888\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"fe7058cfdb37ae7abf8a34fb70542843\",\n",
      "    \"text\": \"[72] Tsendsuren Munkhdalai, Alessandro Sordoni, Tong Wang, and Adam Trischler. \\u201cMetalearned neural memory\\u201d. In: Advances in Neural Information Processing Systems 32 (2019).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9015272259712219,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1065.8233333333333\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1133.1812455555555\n",
      "          ],\n",
      "          [\n",
      "            1564.3822021484375,\n",
      "            1133.1812455555555\n",
      "          ],\n",
      "          [\n",
      "            1564.3822021484375,\n",
      "            1065.8233333333333\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"bed1173f766596693d33fa9150b6c97c\",\n",
      "    \"text\": \"[73] Tsendsuren Munkhdalai and Hong Yu. \\u201cNeural semantic encoders\\u201d. In: Proceedings of the conference. Association for Computational Linguistics. Meeting. Vol. 1. NIH Public Access. 2017, p. 397.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8919792771339417,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1132.2399999999998\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1199.5979122222222\n",
      "          ],\n",
      "          [\n",
      "            1564.0413818359375,\n",
      "            1199.5979122222222\n",
      "          ],\n",
      "          [\n",
      "            1564.0413818359375,\n",
      "            1132.2399999999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"2d6e01e1eb797f2862de3ee763602bab\",\n",
      "    \"text\": \"[74] Eric Nguyen, Michael Poli, Marjan Faizi, Armin Thomas, Michael Wornow, Callum Birch-Sykes, Stefano Massaroli, Aman Patel, Clayton Rabideau, Yoshua Bengio, et al. \\u201cHyenadna: Long-range genomic sequence modeling at single nucleotide resolution\\u201d. In: Advances in neural information processing systems 36 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9300422668457031,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            210.95529174804688,\n",
      "            1198.6566666666665\n",
      "          ],\n",
      "          [\n",
      "            210.95529174804688,\n",
      "            1299.22569\n",
      "          ],\n",
      "          [\n",
      "            1572.59814453125,\n",
      "            1299.22569\n",
      "          ],\n",
      "          [\n",
      "            1572.59814453125,\n",
      "            1198.6566666666665\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"7e82e4f33f5b5eaa85f008f8e6e7020e\",\n",
      "    \"text\": \"[75] A Nichol. \\u201cOn first-order meta-learning algorithms\\u201d. In: arXiv preprint arXiv:1803.02999 (2018).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8335362076759338,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1298.2844444444443\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1332.4340233333332\n",
      "          ],\n",
      "          [\n",
      "            1351.6136599999998,\n",
      "            1332.4340233333332\n",
      "          ],\n",
      "          [\n",
      "            1351.6136599999998,\n",
      "            1298.2844444444443\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"38bc1e365e0946ca62103e06ed7d2e38\",\n",
      "    \"text\": \"[76] Yuqi Nie, Nam H Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. \\u201cA time series is worth 64 words: Long-term forecasting with transformers\\u201d. In: arXiv preprint arXiv:2211.14730 (2022).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9055324792861938,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444424,\n",
      "            1331.4927777777775\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444424,\n",
      "            1398.85069\n",
      "          ],\n",
      "          [\n",
      "            1566.486328125,\n",
      "            1398.85069\n",
      "          ],\n",
      "          [\n",
      "            1566.486328125,\n",
      "            1331.4927777777775\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"69eb859e881f15a901b8504f7a6936ae\",\n",
      "    \"text\": \"[77] Hideyuki Okano, Tomoo Hirano, and Evan Balaban. \\u201cLearning and memory\\u201d. In: Proceedings of the National Academy of Sciences 97.23 (2000), pp. 12403\\u201312404.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9112675786018372,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1397.9094444444443\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1465.2701344444445\n",
      "          ],\n",
      "          [\n",
      "            1563.8050537109375,\n",
      "            1465.2701344444445\n",
      "          ],\n",
      "          [\n",
      "            1563.8050537109375,\n",
      "            1397.9094444444443\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"a78fca6f1cf17692cdcaad22450fab1b\",\n",
      "    \"text\": \"[78] Antonio Orvieto, Samuel L Smith, Albert Gu, Anushan Fernando, Caglar Gulcehre, Razvan Pascanu, and Soham De. \\u201cResurrecting recurrent neural networks for long sequences\\u201d. In: International Conference on Machine Learning. PMLR. 2023, pp. 26670\\u201326698.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9280918836593628,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1464.328888888889\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1561.4949951171875\n",
      "          ],\n",
      "          [\n",
      "            1566.6651611328125,\n",
      "            1561.4949951171875\n",
      "          ],\n",
      "          [\n",
      "            1566.6651611328125,\n",
      "            1464.328888888889\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"d0c47b3640992ab136840035d4c8125d\",\n",
      "    \"text\": \"[79] Denis Paperno, Germ\\u00e1n Kruszewski, Angeliki Lazaridou, Ngoc Quan Pham, Raffaella Bernardi, Sandro Pezzelle, Marco Baroni, Gemma Boleda, and Raquel Fern\\u00e1ndez. \\u201cThe LAMBADA dataset: Word prediction requiring a broad discourse context\\u201d. In: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Ed. by Katrin Erk and Noah A. Smith. Berlin, Germany: Association for Computational Linguistics, Aug. 2016, pp. 1525\\u20131534. doi: 10.18653/v1/P16-1144. url: https://aclanthology.org/P16-1144/.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9328086972236633,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            1563.953888888889\n",
      "          ],\n",
      "          [\n",
      "            212.8694444444444,\n",
      "            1729.2791455555553\n",
      "          ],\n",
      "          [\n",
      "            1575.8616943359375,\n",
      "            1729.2791455555553\n",
      "          ],\n",
      "          [\n",
      "            1575.8616943359375,\n",
      "            1563.953888888889\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"10 . 18653 / v1 / P16 - 1144\",\n",
      "          \"url\": \"https://doi.org/10.18653/v1/P16-1144\",\n",
      "          \"start_index\": 482\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"https :// aclanthology . org / P16 - 1144 /.\",\n",
      "          \"url\": \"https://aclanthology.org/P16-1144/\",\n",
      "          \"start_index\": 509\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"0d269f2317422295d3875d1b283b96d4\",\n",
      "    \"text\": \"[80] Badri N. Patro and Vijay S. Agneeswaran. SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time series. 2024. arXiv: 2403.15360 [cs.CV].\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9093729853630066,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            1729.9983333333332\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            1797.3562455555557\n",
      "          ],\n",
      "          [\n",
      "            1565.7232666015625,\n",
      "            1797.3562455555557\n",
      "          ],\n",
      "          [\n",
      "            1565.7232666015625,\n",
      "            1729.9983333333332\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2403 . 15360 [ cs . CV ].\",\n",
      "          \"url\": \"https://arxiv.org/abs/2403.15360\",\n",
      "          \"start_index\": 26\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"39742196086308c336f4fb6964e23484\",\n",
      "    \"text\": \"[81] Guilherme Penedo, Hynek Kydl\\u00ed\\u010dek, Loubna Ben allal, Anton Lozhkov, Margaret Mitchell, Colin Raffel, Leandro\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            1796.4149999999997\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444455,\n",
      "            1824.088888888889\n",
      "          ],\n",
      "          [\n",
      "            1559.9960274677776,\n",
      "            1824.088888888889\n",
      "          ],\n",
      "          [\n",
      "            1559.9960274677776,\n",
      "            1796.4149999999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"f883825b0a76d377561ba1ff7e94fe21\",\n",
      "    \"text\": \"Von Werra, and Thomas Wolf. \\u201cThe FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale\\u201d. In: The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 2024. url: https://openreview.net/forum?id=n6SCkn2QaG.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9344808459281921,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            215.3038787841797,\n",
      "            1803.9774169921875\n",
      "          ],\n",
      "          [\n",
      "            215.3038787841797,\n",
      "            1928.531923333333\n",
      "          ],\n",
      "          [\n",
      "            1571.5167236328125,\n",
      "            1928.531923333333\n",
      "          ],\n",
      "          [\n",
      "            1571.5167236328125,\n",
      "            1803.9774169921875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ? id = n6SCkn2QaG\",\n",
      "          \"url\": \"https://openreview.net/forum?id=n6SCkn2QaG\",\n",
      "          \"start_index\": 332\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"6fd27be0c7b9039f381ec8abc62b4b5b\",\n",
      "    \"text\": \"[82] Bo Peng. RWKV-LM. Version 1.0.0. Aug. 2021. doi: 10.5281/ zenodo.5196577. url: https://github.com/ BlinkDL/RWKV-LM.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.916765034198761,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            211.0111541748047,\n",
      "            1929.251111111111\n",
      "          ],\n",
      "          [\n",
      "            211.0111541748047,\n",
      "            1994.94859\n",
      "          ],\n",
      "          [\n",
      "            1571.77978515625,\n",
      "            1994.94859\n",
      "          ],\n",
      "          [\n",
      "            1571.77978515625,\n",
      "            1929.251111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"10 . 5281 / zenodo . 5196577\",\n",
      "          \"url\": \"https://doi.org/10.5281/zenodo.5196577\",\n",
      "          \"start_index\": 54\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"https :// github . com /\",\n",
      "          \"url\": \"https://github.com/BlinkDL/RWKV-LM\",\n",
      "          \"start_index\": 84\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"BlinkDL / RWKV - LM\",\n",
      "          \"url\": \"https://github.com/BlinkDL/RWKV-LM\",\n",
      "          \"start_index\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"a2a065d6f522e40381d78bc56a08e2d4\",\n",
      "    \"text\": \"21\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1333333333333,\n",
      "            2057.7427777777775\n",
      "          ],\n",
      "          [\n",
      "            867.1333333333333,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.87005,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.87005,\n",
      "            2057.7427777777775\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"a85d9a4675e2942f5c8737972329f958\",\n",
      "    \"text\": \"[83] Bo Peng, Eric Alcaide, Quentin Gregory Anthony, Alon Albalak, Samuel Arcadinho, Stella Biderman, Huanqi Cao, Xin Cheng, Michael Nguyen Chung, Leon Derczynski, Xingjian Du, Matteo Grella, Kranthi Kiran GV, Xuzheng He, Haowen Hou, Przemyslaw Kazienko, Jan Kocon, Jiaming Kong, Bart\\u0142omiej Koptyra, Hayden Lau, Jiaju Lin, Krishna Sri Ipsit Mantri, Ferdinand Mom, Atsushi Saito, Guangyu Song, Xiangru Tang, Johan S. Wind, Stanis\\u0142aw Wo\\u017aniak, Zhenyuan Zhang, Qinghua Zhou, Jian Zhu, and Rui-Jie Zhu. \\u201cRWKV: Reinventing RNNs for the Transformer Era\\u201d. In: The 2023 Conference on Empirical Methods in Natural Language Processing. 2023. url: https://openreview. net/forum?id=7SaXczaBpG.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9509968757629395,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.64462280273438,\n",
      "            202.39277777777778\n",
      "          ],\n",
      "          [\n",
      "            212.64462280273438,\n",
      "            434.1347011111114\n",
      "          ],\n",
      "          [\n",
      "            1577.00439453125,\n",
      "            434.1347011111114\n",
      "          ],\n",
      "          [\n",
      "            1577.00439453125,\n",
      "            202.39277777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview .\",\n",
      "          \"url\": \"https://openreview.net/forum?id=7SaXczaBpG\",\n",
      "          \"start_index\": 636\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"net / forum ? id = 7SaXczaBpG\",\n",
      "          \"url\": \"https://openreview.net/forum?id=7SaXczaBpG\",\n",
      "          \"start_index\": 656\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"b1b0b96ad903c1d353bff7607c32f197\",\n",
      "    \"text\": \"[84] Bo Peng, Daniel Goldstein, Quentin Anthony, Alon Albalak, Eric Alcaide, Stella Biderman, Eugene Cheah, Xingjian Du, Teddy Ferdinan, Haowen Hou, et al. \\u201cEagle and finch: Rwkv with matrix-valued states and dynamic recurrence\\u201d. In: arXiv preprint arXiv:2404.05892 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9296343922615051,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.4974365234375,\n",
      "            434.8566666666667\n",
      "          ],\n",
      "          [\n",
      "            212.4974365234375,\n",
      "            535.4229122222225\n",
      "          ],\n",
      "          [\n",
      "            1570.9840087890625,\n",
      "            535.4229122222225\n",
      "          ],\n",
      "          [\n",
      "            1570.9840087890625,\n",
      "            434.8566666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"d8d31cfcfb768b8c8debc8325c6a144d\",\n",
      "    \"text\": \"[85] DL Prados and SC Kak. \\u201cNeural network capacity using delta rule\\u201d. In: Electronics Letters 25.3 (1989), pp. 197\\u2013199. [86] Zhen Qin, Yiran Zhong, and Hui Deng. \\u201cExploring Transformer Extrapolation\\u201d. In: Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 38. 17. 2024, pp. 18897\\u201318905.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8864221572875977,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444424,\n",
      "            534.481666666667\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444424,\n",
      "            635.8010864257812\n",
      "          ],\n",
      "          [\n",
      "            1569.8192138671875,\n",
      "            635.8010864257812\n",
      "          ],\n",
      "          [\n",
      "            1569.8192138671875,\n",
      "            534.481666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"e5d1eec20425a2b2418d6f0cd5aa0075\",\n",
      "    \"text\": \"[87] Liliang Ren, Yang Liu, Yadong Lu, Yelong Shen, Chen Liang, and Weizhu Chen. \\u201cSamba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling\\u201d. In: arXiv preprint arXiv:2406.07522 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9055854082107544,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            634.1094444444444\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            701.4673566666668\n",
      "          ],\n",
      "          [\n",
      "            1572.44091796875,\n",
      "            701.4673566666668\n",
      "          ],\n",
      "          [\n",
      "            1572.44091796875,\n",
      "            634.1094444444444\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"4f36e8ffdb2f6163a45874abcc7a6e39\",\n",
      "    \"text\": \"[88] Ivan Rodkin, Yuri Kuratov, Aydar Bulatov, and Mikhail Burtsev. \\u201cAssociative recurrent memory transformer\\u201d. In: arXiv preprint arXiv:2407.04841 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8901927471160889,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            211.77732849121094,\n",
      "            700.5261111111114\n",
      "          ],\n",
      "          [\n",
      "            211.77732849121094,\n",
      "            767.8840233333334\n",
      "          ],\n",
      "          [\n",
      "            1567.2939453125,\n",
      "            767.8840233333334\n",
      "          ],\n",
      "          [\n",
      "            1567.2939453125,\n",
      "            700.5261111111114\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"ce064b579d0ec61590c5bb8cabad0296\",\n",
      "    \"text\": \"[89] Aurko Roy, Mohammad Saffar, Ashish Vaswani, and David Grangier. \\u201cEfficient content-based sparse attention with routing transformers\\u201d. In: Transactions of the Association for Computational Linguistics 9 (2021), pp. 53\\u201368.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8964818716049194,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            766.9427777777776\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            834.3006899999999\n",
      "          ],\n",
      "          [\n",
      "            1566.4276123046875,\n",
      "            834.3006899999999\n",
      "          ],\n",
      "          [\n",
      "            1566.4276123046875,\n",
      "            766.9427777777776\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"2f962983fd2e4ca6472eb97cbaa1db3e\",\n",
      "    \"text\": \"[90] Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. \\u201cWinogrande: An adversarial winograd schema challenge at scale\\u201d. In: Communications of the ACM 64.9 (2021), pp. 99\\u2013106.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8856917023658752,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            209.63363647460938,\n",
      "            833.3622222222222\n",
      "          ],\n",
      "          [\n",
      "            209.63363647460938,\n",
      "            900.7201344444444\n",
      "          ],\n",
      "          [\n",
      "            1574.8765869140625,\n",
      "            900.7201344444444\n",
      "          ],\n",
      "          [\n",
      "            1574.8765869140625,\n",
      "            833.3622222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"798c9210fedecb2ff12b9b7a3c72ada7\",\n",
      "    \"text\": \"[91] Maarten Sap, Hannah Rashkin, Derek Chen, Ronan Le Bras, and Yejin Choi. \\u201cSocial IQa: Commonsense Reasoning\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            899.7788888888888\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            927.4527777777777\n",
      "          ],\n",
      "          [\n",
      "            1559.9962211849997,\n",
      "            927.4527777777777\n",
      "          ],\n",
      "          [\n",
      "            1559.9962211849997,\n",
      "            899.7788888888888\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"29e0c908135ce0b2623b6aee4123e6bd\",\n",
      "    \"text\": \"about Social Interactions\\u201d. In: Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). Ed. by Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan. Hong Kong, China: Association for Computational Linguistics, Nov. 2019, pp. 4463\\u20134473. doi: 10.18653/v1/D19-1454. url: https://aclanthology.org/D19-1454/.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9288128614425659,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.25694274902344,\n",
      "            906.700927734375\n",
      "          ],\n",
      "          [\n",
      "            212.25694274902344,\n",
      "            1065.1041455555555\n",
      "          ],\n",
      "          [\n",
      "            1571.5223388671875,\n",
      "            1065.1041455555555\n",
      "          ],\n",
      "          [\n",
      "            1571.5223388671875,\n",
      "            906.700927734375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"10 . 18653 / v1 / D19 - 1454\",\n",
      "          \"url\": \"https://doi.org/10.18653/v1/D19-1454\",\n",
      "          \"start_index\": 475\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"https :// aclanthology . org / D19 - 1454 /.\",\n",
      "          \"url\": \"https://aclanthology.org/D19-1454/\",\n",
      "          \"start_index\": 502\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"d6bab19846123e03c60c32b1fdc31d06\",\n",
      "    \"text\": \"[92] Imanol Schlag, Kazuki Irie, and J\\u00fcrgen Schmidhuber. \\u201cLinear transformers are secretly fast weight programmers\\u201d. In: International Conference on Machine Learning. PMLR. 2021, pp. 9355\\u20139366.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9075857996940613,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1065.8233333333333\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1133.1812455555555\n",
      "          ],\n",
      "          [\n",
      "            1567.985107421875,\n",
      "            1133.1812455555555\n",
      "          ],\n",
      "          [\n",
      "            1567.985107421875,\n",
      "            1065.8233333333333\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"b45303afad08f315effc80be93d8c19a\",\n",
      "    \"text\": \"[93] JH Schmidhuber. \\u201cLearning to control fast-weight memories: An alternative to recurrent nets. Accepted for publication in\\u201d. In: Neural Computation (1992).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9082035422325134,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            209.47036743164062,\n",
      "            1132.2399999999998\n",
      "          ],\n",
      "          [\n",
      "            209.47036743164062,\n",
      "            1199.5979122222222\n",
      "          ],\n",
      "          [\n",
      "            1560.9659423828125,\n",
      "            1199.5979122222222\n",
      "          ],\n",
      "          [\n",
      "            1560.9659423828125,\n",
      "            1132.2399999999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"5d74c0db54c6df7bc4be69ade9f64cf9\",\n",
      "    \"text\": \"[94] J\\u00fcrgen Schmidhuber. \\u201cReducing the ratio between learning complexity and number of time varying variables in fully recurrent nets\\u201d. In: ICANN\\u201993: Proceedings of the International Conference on Artificial Neural Networks Amsterdam, The Netherlands 13\\u201316 September 1993 3. Springer. 1993, pp. 460\\u2013463.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9287434816360474,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1198.6566666666665\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1299.22569\n",
      "          ],\n",
      "          [\n",
      "            1569.2467041015625,\n",
      "            1299.22569\n",
      "          ],\n",
      "          [\n",
      "            1569.2467041015625,\n",
      "            1198.6566666666665\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"9b150dd69e0b9256760b2a978d9901c7\",\n",
      "    \"text\": \"[95] J\\u00fcrgen Schmidhuber and Sepp Hochreiter. \\u201cLong Short-term Memory\\u201d. In: Neural Computation MIT-Press (1997). [96] Avi Schwarzschild, Zhili Feng, Pratyush Maini, Zachary C Lipton, and J Zico Kolter. \\u201cRethinking llm memorization through the lens of adversarial compression\\u201d. In: arXiv preprint arXiv:2404.15146 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8829230070114136,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444424,\n",
      "            1298.2844444444443\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444424,\n",
      "            1398.85069\n",
      "          ],\n",
      "          [\n",
      "            1564.9110107421875,\n",
      "            1398.85069\n",
      "          ],\n",
      "          [\n",
      "            1564.9110107421875,\n",
      "            1298.2844444444443\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"32c2faa27e5bd76521e44a3f8d6eca73\",\n",
      "    \"text\": \"[97] Jimmy T.H. Smith, Andrew Warrington, and Scott Linderman. \\u201cSimplified State Space Layers for Sequence Modeling\\u201d. In: The Eleventh International Conference on Learning Representations. 2023. url: https://openreview.net/forum? id=Ai8Hw3AXqks.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.928068995475769,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1397.9094444444443\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444438,\n",
      "            1496.8180344444445\n",
      "          ],\n",
      "          [\n",
      "            1572.157470703125,\n",
      "            1496.8180344444445\n",
      "          ],\n",
      "          [\n",
      "            1572.157470703125,\n",
      "            1397.9094444444443\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ?\",\n",
      "          \"url\": \"https://openreview.net/forum?id=Ai8Hw3AXqks\",\n",
      "          \"start_index\": 284\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"3fbe6725c37acd19c95b5ac50e586f25\",\n",
      "    \"text\": \"[98] Robin Staab, Mark Vero, Mislav Balunovic, and Martin Vechev. \\u201cBeyond Memorization: Violating Privacy via Inference with Large Language Models\\u201d. In: The Twelfth International Conference on Learning Representations. 2024. url: https://openreview.net/forum?id=kmn0BhQk7p.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9269329905509949,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1497.537222222222\n",
      "          ],\n",
      "          [\n",
      "            212.86944444444447,\n",
      "            1596.4430344444445\n",
      "          ],\n",
      "          [\n",
      "            1567.3453369140625,\n",
      "            1596.4430344444445\n",
      "          ],\n",
      "          [\n",
      "            1567.3453369140625,\n",
      "            1497.537222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ? id = kmn0BhQk7p\",\n",
      "          \"url\": \"https://openreview.net/forum?id=kmn0BhQk7p\",\n",
      "          \"start_index\": 230\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"c38aa92580f5f9102fbc3d25dcd263e9\",\n",
      "    \"text\": \"[99] Sainbayar Sukhbaatar, Edouard Grave, Guillaume Lample, Herve Jegou, and Armand Joulin. \\u201cAugmenting self- attention with persistent memory\\u201d. In: arXiv preprint arXiv:1907.01470 (2019).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8968758583068848,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            209.27264404296875,\n",
      "            1597.162222222222\n",
      "          ],\n",
      "          [\n",
      "            209.27264404296875,\n",
      "            1664.5229122222222\n",
      "          ],\n",
      "          [\n",
      "            1564.683043333333,\n",
      "            1664.5229122222222\n",
      "          ],\n",
      "          [\n",
      "            1564.683043333333,\n",
      "            1597.162222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"9932bad0035bb92345502f3476137c42\",\n",
      "    \"text\": \"[100]\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.99999999999983,\n",
      "            1663.5816666666667\n",
      "          ],\n",
      "          [\n",
      "            199.99999999999983,\n",
      "            1691.2555555555555\n",
      "          ],\n",
      "          [\n",
      "            258.3088838888887,\n",
      "            1691.2555555555555\n",
      "          ],\n",
      "          [\n",
      "            258.3088838888887,\n",
      "            1663.5816666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"ed5b21bb0d1c8e6b116bb5b2111d9a45\",\n",
      "    \"text\": \"Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et al. \\u201cEnd-to-end memory networks\\u201d. In: Advances in neural information processing systems 28 (2015).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9013057351112366,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.10508728027344,\n",
      "            1663.5816666666667\n",
      "          ],\n",
      "          [\n",
      "            212.10508728027344,\n",
      "            1730.9395788888887\n",
      "          ],\n",
      "          [\n",
      "            1560.354248046875,\n",
      "            1730.9395788888887\n",
      "          ],\n",
      "          [\n",
      "            1560.354248046875,\n",
      "            1663.5816666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"b6327f97da8b1e7002bb4fe27fc06302\",\n",
      "    \"text\": \"[101] Yu Sun, Xinhao Li, Karan Dalal, Jiarui Xu, Arjun Vikram, Genghan Zhang, Yann Dubois, Xinlei Chen, Xiaolong Wang, Sanmi Koyejo, et al. \\u201cLearning to (learn at test time): Rnns with expressive hidden states\\u201d. In: arXiv preprint arXiv:2407.04620 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9278379678726196,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1729.9983333333332\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1830.5645788888887\n",
      "          ],\n",
      "          [\n",
      "            1569.6258544921875,\n",
      "            1830.5645788888887\n",
      "          ],\n",
      "          [\n",
      "            1569.6258544921875,\n",
      "            1729.9983333333332\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"c7bfca5d43bfaed9f6162d9988fbfd74\",\n",
      "    \"text\": \"[102] Yutao Sun, Li Dong, Shaohan Huang, Shuming Ma, Yuqing Xia, Jilong Xue, Jianyong Wang, and Furu Wei. \\u201cRetentive network: A successor to transformer for large language models\\u201d. In: arXiv preprint arXiv:2307.08621 (2023).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8898824453353882,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1829.626111111111\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1896.9840233333334\n",
      "          ],\n",
      "          [\n",
      "            1566.685791015625,\n",
      "            1896.9840233333334\n",
      "          ],\n",
      "          [\n",
      "            1566.685791015625,\n",
      "            1829.626111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"54de770b6fdd03363f17df8c63551577\",\n",
      "    \"text\": \"[103] Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivi\\u00e8re, Mihir Sanjay Kale, Juliette Love, et al. \\u201cGemma: Open models based on gemini research and technology\\u201d. In: arXiv preprint arXiv:2403.08295 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9135253429412842,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.00000000000014,\n",
      "            1896.0427777777775\n",
      "          ],\n",
      "          [\n",
      "            200.00000000000014,\n",
      "            1996.6090233333334\n",
      "          ],\n",
      "          [\n",
      "            1571.2227783203125,\n",
      "            1996.6090233333334\n",
      "          ],\n",
      "          [\n",
      "            1571.2227783203125,\n",
      "            1896.0427777777775\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"9990396932fc985e8bfd0961788a4c61\",\n",
      "    \"text\": \"22\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1305555555555,\n",
      "            2057.7427777777775\n",
      "          ],\n",
      "          [\n",
      "            867.1305555555555,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222221,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222221,\n",
      "            2057.7427777777775\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 22,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"2a12848ae887876ddbb9728e8ef3b986\",\n",
      "    \"text\": \"[104] W Scott Terry. Learning and memory: Basic principles, processes, and procedures. Routledge, 2017.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8305689096450806,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            202.39277777777778\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            236.54235666666668\n",
      "          ],\n",
      "          [\n",
      "            1370.9954872222222,\n",
      "            236.54235666666668\n",
      "          ],\n",
      "          [\n",
      "            1370.9954872222222,\n",
      "            202.39277777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"542de7f35b46be731e3e0bc8fa34b907\",\n",
      "    \"text\": \"[105] Matteo Tiezzi, Michele Casoni, Alessandro Betti, Tommaso Guidi, Marco Gori, and Stefano Melacci. \\u201cOn the\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            235.60388888888895\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            263.2777777777777\n",
      "          ],\n",
      "          [\n",
      "            1559.9973004666667,\n",
      "            263.2777777777777\n",
      "          ],\n",
      "          [\n",
      "            1559.9973004666667,\n",
      "            235.60388888888895\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"3eaad4f57819f23ac118137caea76a9e\",\n",
      "    \"text\": \"resurgence of recurrent models for long sequences: Survey and research opportunities in the transformer era\\u201d. In: arXiv preprint arXiv:2402.08132 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9219294786453247,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            215.618408203125,\n",
      "            243.19244384765625\n",
      "          ],\n",
      "          [\n",
      "            215.618408203125,\n",
      "            336.1701344444447\n",
      "          ],\n",
      "          [\n",
      "            1563.2734738027777,\n",
      "            336.1701344444447\n",
      "          ],\n",
      "          [\n",
      "            1563.2734738027777,\n",
      "            243.19244384765625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"9113cafcfc6cd9cb4028cba9df989b82\",\n",
      "    \"text\": \"[106] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\\u00e9e Lacroix, Baptiste Rozi\\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, et al. \\u201cLlama: Open and efficient foundation language models\\u201d. In: arXiv preprint arXiv:2302.13971 (2023).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9289218783378601,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            335.22888888888895\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            435.79513444444444\n",
      "          ],\n",
      "          [\n",
      "            1570.6680908203125,\n",
      "            435.79513444444444\n",
      "          ],\n",
      "          [\n",
      "            1570.6680908203125,\n",
      "            335.22888888888895\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"a4c5fdaa98cd41b684ba0d6f7275102f\",\n",
      "    \"text\": \"[107] Jos Van Der Westhuizen and Joan Lasenby. \\u201cThe unreasonable effectiveness of the forget gate\\u201d. In: arXiv preprint arXiv:1804.04849 (2018).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9036277532577515,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            434.8566666666667\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            502.21457888888904\n",
      "          ],\n",
      "          [\n",
      "            1563.489501953125,\n",
      "            502.21457888888904\n",
      "          ],\n",
      "          [\n",
      "            1563.489501953125,\n",
      "            434.8566666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"83255dde299d2e12f351dab4197612e8\",\n",
      "    \"text\": \"[108] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \\u0141ukasz Kaiser, and Illia Polosukhin. \\u201cAttention is All you Need\\u201d. In: Advances in Neural Information Processing Systems. Ed. by I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett. Vol. 30. Cur- ran Associates, Inc., 2017. url: https : / / proceedings . neurips . cc / paper _ files / paper / 2017 / file / 3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9346182346343994,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.99999999999994,\n",
      "            501.2733333333336\n",
      "          ],\n",
      "          [\n",
      "            199.99999999999994,\n",
      "            666.59859\n",
      "          ],\n",
      "          [\n",
      "            1580.15185546875,\n",
      "            666.59859\n",
      "          ],\n",
      "          [\n",
      "            1580.15185546875,\n",
      "            501.2733333333336\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https : / / proceedings . neurips . cc / paper _ files / paper / 2017 / file /\",\n",
      "          \"url\": \"https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\",\n",
      "          \"start_index\": 362\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"3f5ee243547dee91fbd053c1c4a845aa - Paper . pdf\",\n",
      "          \"url\": \"https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\",\n",
      "          \"start_index\": 441\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"030a885bf11aa5edffdc5ac9610e9e92\",\n",
      "    \"text\": \"[109]\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.00000000000009,\n",
      "            667.3177777777779\n",
      "          ],\n",
      "          [\n",
      "            200.00000000000009,\n",
      "            694.9916666666667\n",
      "          ],\n",
      "          [\n",
      "            258.30888388888894,\n",
      "            694.9916666666667\n",
      "          ],\n",
      "          [\n",
      "            258.30888388888894,\n",
      "            667.3177777777779\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"ca5967123754a143982b583f8623ca8f\",\n",
      "    \"text\": \"Shida Wang. \\u201cLongSSM: On the Length Extension of State-space Models in Language Modelling\\u201d. In: arXiv preprint arXiv:2406.02080 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.900538444519043,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            205.34962463378906,\n",
      "            667.3177777777779\n",
      "          ],\n",
      "          [\n",
      "            205.34962463378906,\n",
      "            734.6756900000003\n",
      "          ],\n",
      "          [\n",
      "            1560.0118323222223,\n",
      "            734.6756900000003\n",
      "          ],\n",
      "          [\n",
      "            1560.0118323222223,\n",
      "            667.3177777777779\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"b1526505e19514cef5b845584322c3c0\",\n",
      "    \"text\": \"[110] Yu Wang, Yifan Gao, Xiusi Chen, Haoming Jiang, Shiyang Li, Jingfeng Yang, Qingyu Yin, Zheng Li, Xian Li, Bing Yin, Jingbo Shang, and Julian McAuley. \\u201cMEMORYLLM: Towards Self-Updatable Large Language Models\\u201d. In: Forty-first International Conference on Machine Learning. 2024. url: https://openreview.net/forum?id=p0lKWzdikQ.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9253214597702026,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            733.7344444444444\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            834.3006899999999\n",
      "          ],\n",
      "          [\n",
      "            1576.404052734375,\n",
      "            834.3006899999999\n",
      "          ],\n",
      "          [\n",
      "            1576.404052734375,\n",
      "            733.7344444444444\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ? id = p0lKWzdikQ\",\n",
      "          \"url\": \"https://openreview.net/forum?id=p0lKWzdikQ\",\n",
      "          \"start_index\": 286\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"b6fc9d7894a7f133a7b549a1f4e7019d\",\n",
      "    \"text\": \"[111] Yu Wang, Chi Han, Tongtong Wu, Xiaoxin He, Wangchunshu Zhou, Nafis Sadeq, Xiusi Chen, Zexue He, Wei Wang, Gholamreza Haffari, et al. \\u201cTowards LifeSpan Cognitive Systems\\u201d. In: arXiv preprint arXiv:2409.13265 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.6857630610466003,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.00000000000014,\n",
      "            833.3622222222222\n",
      "          ],\n",
      "          [\n",
      "            200.00000000000014,\n",
      "            901.1973266601562\n",
      "          ],\n",
      "          [\n",
      "            1575.837646484375,\n",
      "            901.1973266601562\n",
      "          ],\n",
      "          [\n",
      "            1575.837646484375,\n",
      "            833.3622222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"20bac5ec7d70e92faac644dbf993cf07\",\n",
      "    \"text\": \"[112] Zhiwei Wang, Yao Ma, Zitao Liu, and Jiliang Tang. \\u201cR-transformer: Recurrent neural network enhanced transformer\\u201d. In: arXiv preprint arXiv:1907.05572 (2019).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8642727732658386,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.99999999999983,\n",
      "            899.7788888888888\n",
      "          ],\n",
      "          [\n",
      "            199.99999999999983,\n",
      "            967.1368011111111\n",
      "          ],\n",
      "          [\n",
      "            1580.4820556640625,\n",
      "            967.1368011111111\n",
      "          ],\n",
      "          [\n",
      "            1580.4820556640625,\n",
      "            899.7788888888888\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"d360435dcee0f2ed244fd0b384576257\",\n",
      "    \"text\": \"Jason Weston, Sumit Chopra, and Antoine Bordes. \\u201cMemory networks\\u201d. In: arXiv preprint arXiv:1410.3916 (2014).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8178769946098328,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.99999999999991,\n",
      "            966.1955555555555\n",
      "          ],\n",
      "          [\n",
      "            199.99999999999991,\n",
      "            1000.3451344444444\n",
      "          ],\n",
      "          [\n",
      "            1568.9691162109375,\n",
      "            1000.3451344444444\n",
      "          ],\n",
      "          [\n",
      "            1568.9691162109375,\n",
      "            966.1955555555555\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"7ea39358812acd303e70e395973f1972\",\n",
      "    \"text\": \"[114] Bernard Widrow and Marcian E Hoff. \\u201cAdaptive switching circuits\\u201d. In: Neurocomputing: foundations of research. 1988, pp. 123\\u2013134.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8637577891349792,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            999.4038888888888\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1062.786865234375\n",
      "          ],\n",
      "          [\n",
      "            1564.2630270000002,\n",
      "            1062.786865234375\n",
      "          ],\n",
      "          [\n",
      "            1564.2630270000002,\n",
      "            999.4038888888888\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"a02a85702ac4d9d21c0c8852f3e53756\",\n",
      "    \"text\": \"[115] Ronald J Williams and David Zipser. \\u201cA learning algorithm for continually running fully recurrent neural networks\\u201d. In: Neural computation 1.2 (1989), pp. 270\\u2013280.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.915719211101532,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1065.8233333333333\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1133.1812455555555\n",
      "          ],\n",
      "          [\n",
      "            1569.8358154296875,\n",
      "            1133.1812455555555\n",
      "          ],\n",
      "          [\n",
      "            1569.8358154296875,\n",
      "            1065.8233333333333\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"f1bb7df1d5a9337c615306be150b0e3f\",\n",
      "    \"text\": \"[116] Daniel B Willingham. \\u201cSystems of memory in the human brain\\u201d. In: Neuron 18.1 (1997), pp. 5\\u20138.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8550569415092468,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.771728515625,\n",
      "            1132.2399999999998\n",
      "          ],\n",
      "          [\n",
      "            199.771728515625,\n",
      "            1166.3895788888888\n",
      "          ],\n",
      "          [\n",
      "            1376.1343994140625,\n",
      "            1166.3895788888888\n",
      "          ],\n",
      "          [\n",
      "            1376.1343994140625,\n",
      "            1132.2399999999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"5c73cda04129382fc27f135bc6044443\",\n",
      "    \"text\": \"[117] Chao-Yuan Wu, Christoph Feichtenhofer, Haoqi Fan, Kaiming He, Philipp Krahenbuhl, and Ross Girshick. \\u201cLong- term feature banks for detailed video understanding\\u201d. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019, pp. 284\\u2013293.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9293369650840759,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1165.448333333333\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1266.0173566666665\n",
      "          ],\n",
      "          [\n",
      "            1571.5032958984375,\n",
      "            1266.0173566666665\n",
      "          ],\n",
      "          [\n",
      "            1571.5032958984375,\n",
      "            1165.448333333333\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"72e11671b4c0e1ed7e26003db857ddc4\",\n",
      "    \"text\": \"[118] Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang, and Mingsheng Long. \\u201cTimesNet: Temporal 2D- Variation Modeling for General Time Series Analysis\\u201d. In: The Eleventh International Conference on Learning Representations. 2023. url: https://openreview.net/forum?id=ju_Uqw384Oq.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9247042536735535,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.99999999999994,\n",
      "            1265.076111111111\n",
      "          ],\n",
      "          [\n",
      "            199.99999999999994,\n",
      "            1365.6423566666667\n",
      "          ],\n",
      "          [\n",
      "            1573.9576416015625,\n",
      "            1365.6423566666667\n",
      "          ],\n",
      "          [\n",
      "            1573.9576416015625,\n",
      "            1265.076111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ? id = ju _ Uqw384Oq\",\n",
      "          \"url\": \"https://openreview.net/forum?id=ju_Uqw384Oq\",\n",
      "          \"start_index\": 242\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"c1e1f2abc0753030facbd22d05f7e50b\",\n",
      "    \"text\": \"[119] Qingyang Wu, Zhenzhong Lan, Kun Qian, Jing Gu, Alborz Geramifard, and Zhou Yu. \\u201cMemformer: A memory- augmented transformer for sequence modeling\\u201d. In: arXiv preprint arXiv:2010.06891 (2020).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8952859044075012,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1364.701111111111\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1432.0590233333332\n",
      "          ],\n",
      "          [\n",
      "            1575.46044921875,\n",
      "            1432.0590233333332\n",
      "          ],\n",
      "          [\n",
      "            1575.46044921875,\n",
      "            1364.701111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"577727594d33fb3750f8b78b421927be\",\n",
      "    \"text\": \"[120] Guangxuan Xiao, Yuandong Tian, Beidi Chen, Song Han, and Mike Lewis. \\u201cEfficient Streaming Language Models with Attention Sinks\\u201d. In: The Twelfth International Conference on Learning Representations. 2024. url: https: //openreview.net/forum?id=NG7sS51zVF.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9219179749488831,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1431.1205555555555\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1530.0263677777775\n",
      "          ],\n",
      "          [\n",
      "            1579.558349609375,\n",
      "            1530.0263677777775\n",
      "          ],\n",
      "          [\n",
      "            1579.558349609375,\n",
      "            1431.1205555555555\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :\",\n",
      "          \"url\": \"https://openreview.net/forum?id=NG7sS51zVF\",\n",
      "          \"start_index\": 214\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"// openreview . net / forum ? id = NG7sS51zVF\",\n",
      "          \"url\": \"https://openreview.net/forum?id=NG7sS51zVF\",\n",
      "          \"start_index\": 221\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"0fde5bf676a2235ea8f3907bbafb7b2c\",\n",
      "    \"text\": \"[121] An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, et al. \\u201cQwen2. 5 Technical Report\\u201d. In: arXiv preprint arXiv:2412.15115 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8988270163536072,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.99999999999991,\n",
      "            1530.7455555555555\n",
      "          ],\n",
      "          [\n",
      "            199.99999999999991,\n",
      "            1598.1034677777775\n",
      "          ],\n",
      "          [\n",
      "            1574.86767578125,\n",
      "            1598.1034677777775\n",
      "          ],\n",
      "          [\n",
      "            1574.86767578125,\n",
      "            1530.7455555555555\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"9b45bf4d73c5463626493f3e1ffc8719\",\n",
      "    \"text\": \"[122]\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.99999999999983,\n",
      "            1597.162222222222\n",
      "          ],\n",
      "          [\n",
      "            199.99999999999983,\n",
      "            1624.8361111111112\n",
      "          ],\n",
      "          [\n",
      "            258.3088838888887,\n",
      "            1624.8361111111112\n",
      "          ],\n",
      "          [\n",
      "            258.3088838888887,\n",
      "            1597.162222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"a74fd3684dca06cc2c2180d77967892c\",\n",
      "    \"text\": \"Songlin Yang, Jan Kautz, and Ali Hatamizadeh. \\u201cGated Delta Networks: Improving Mamba2 with Delta Rule\\u201d. In: arXiv preprint arXiv:2412.06464 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8875871896743774,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            213.52435302734375,\n",
      "            1597.162222222222\n",
      "          ],\n",
      "          [\n",
      "            213.52435302734375,\n",
      "            1664.5229122222222\n",
      "          ],\n",
      "          [\n",
      "            1573.7567138671875,\n",
      "            1664.5229122222222\n",
      "          ],\n",
      "          [\n",
      "            1573.7567138671875,\n",
      "            1597.162222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"e89c293baa2b79a65558c34a007ab85e\",\n",
      "    \"text\": \"[123]\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1663.5816666666667\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1691.2555555555555\n",
      "          ],\n",
      "          [\n",
      "            258.3088838888889,\n",
      "            1691.2555555555555\n",
      "          ],\n",
      "          [\n",
      "            258.3088838888889,\n",
      "            1663.5816666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"db87bc8d07170452ea71ec9455c38d10\",\n",
      "    \"text\": \"Songlin Yang, Bailin Wang, Yikang Shen, Rameswar Panda, and Yoon Kim. \\u201cGated Linear Attention Transformers with Hardware-Efficient Training\\u201d. In: Forty-first International Conference on Machine Learning. 2024. url: https: //openreview.net/forum?id=ia5XvxFUJT.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9332243800163269,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            209.1600341796875,\n",
      "            1663.5816666666667\n",
      "          ],\n",
      "          [\n",
      "            209.1600341796875,\n",
      "            1762.4874788888887\n",
      "          ],\n",
      "          [\n",
      "            1574.3201904296875,\n",
      "            1762.4874788888887\n",
      "          ],\n",
      "          [\n",
      "            1574.3201904296875,\n",
      "            1663.5816666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :\",\n",
      "          \"url\": \"https://openreview.net/forum?id=ia5XvxFUJT\",\n",
      "          \"start_index\": 459\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"// openreview . net / forum ? id = ia5XvxFUJT\",\n",
      "          \"url\": \"https://openreview.net/forum?id=ia5XvxFUJT\",\n",
      "          \"start_index\": 466\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"7e1b1ea188905d119dd3ebbce22f422a\",\n",
      "    \"text\": \"[124]\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.00000000000009,\n",
      "            1763.2066666666667\n",
      "          ],\n",
      "          [\n",
      "            200.00000000000009,\n",
      "            1790.8805555555555\n",
      "          ],\n",
      "          [\n",
      "            258.30888388888894,\n",
      "            1790.8805555555555\n",
      "          ],\n",
      "          [\n",
      "            258.30888388888894,\n",
      "            1763.2066666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"6431f5aae0a485d128848a448c6faf98\",\n",
      "    \"text\": \"Songlin Yang, Bailin Wang, Yu Zhang, Yikang Shen, and Yoon Kim. \\u201cParallelizing Linear Transformers with the Delta Rule over Sequence Length\\u201d. In: The Thirty-eighth Annual Conference on Neural Information Processing Systems. 2024. url: https://openreview.net/forum?id=y8Rm4VNRPH.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9306691884994507,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            212.37603759765625,\n",
      "            1763.2066666666667\n",
      "          ],\n",
      "          [\n",
      "            212.37603759765625,\n",
      "            1862.1152566666665\n",
      "          ],\n",
      "          [\n",
      "            1569.53076171875,\n",
      "            1862.1152566666665\n",
      "          ],\n",
      "          [\n",
      "            1569.53076171875,\n",
      "            1763.2066666666667\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ? id = y8Rm4VNRPH\",\n",
      "          \"url\": \"https://openreview.net/forum?id=y8Rm4VNRPH\",\n",
      "          \"start_index\": 739\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"74385ec1817dc35c2f395b5be5423d4c\",\n",
      "    \"text\": \"[125] Luca Zancato, Arjun Seshadri, Yonatan Dukler, Aditya Golatkar, Yantao Shen, Benjamin Bowman, Matthew Trager, Alessandro Achille, and Stefano Soatto. \\u201cB\\u2019MOJO: Hybrid State Space Realizations of Foundation Models with Eidetic and Fading Memory\\u201d. In: The Thirty-eighth Annual Conference on Neural Information Processing Systems. 2024. url: https://openreview.net/forum?id=RnQdRY1h5v.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9307580590248108,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1862.8344444444444\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1994.94859\n",
      "          ],\n",
      "          [\n",
      "            1570.2584228515625,\n",
      "            1994.94859\n",
      "          ],\n",
      "          [\n",
      "            1570.2584228515625,\n",
      "            1862.8344444444444\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"https :// openreview . net / forum ? id = RnQdRY1h5v\",\n",
      "          \"url\": \"https://openreview.net/forum?id=RnQdRY1h5v\",\n",
      "          \"start_index\": 343\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"58c83ce7b8d1322d7f51ef040470ba63\",\n",
      "    \"text\": \"23\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1305555555555,\n",
      "            2057.7427777777775\n",
      "          ],\n",
      "          [\n",
      "            867.1305555555555,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222221,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222221,\n",
      "            2057.7427777777775\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"0a021b55ca01d40b0d032fd83f6aebff\",\n",
      "    \"text\": \"[126] Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. \\u201cHellaSwag: Can a Machine Really Finish Your Sentence?\\u201d In: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Ed. by Anna Korhonen, David Traum, and Llu\\u00eds M\\u00e0rquez. Florence, Italy: Association for Computational Linguistics, July 2019, pp. 4791\\u20134800. doi: 10.18653/v1/P19-1472. url: https://aclanthology.org/P19-1472/.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.919060468673706,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            202.39277777777778\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            334.5097011111114\n",
      "          ],\n",
      "          [\n",
      "            1563.8358154296875,\n",
      "            334.5097011111114\n",
      "          ],\n",
      "          [\n",
      "            1563.8358154296875,\n",
      "            202.39277777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 24,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"f2b54fa93578f9ecbc9a243916b83cf6\",\n",
      "    \"text\": \"[127] Ailing Zeng, Muxi Chen, Lei Zhang, and Qiang Xu. \\u201cAre transformers effective for time series forecasting?\\u201d In: Proceedings of the AAAI conference on artificial intelligence. Vol. 37. 2023, pp. 11121\\u201311128.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8880152106285095,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.99999999999983,\n",
      "            335.22888888888895\n",
      "          ],\n",
      "          [\n",
      "            199.99999999999983,\n",
      "            403.1347961425781\n",
      "          ],\n",
      "          [\n",
      "            1568.7403564453125,\n",
      "            403.1347961425781\n",
      "          ],\n",
      "          [\n",
      "            1568.7403564453125,\n",
      "            335.22888888888895\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 24,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"781cf590e4c360c35f53f161d17bc0b6\",\n",
      "    \"text\": \"[128] Hao Zhang, Alexander C Berg, Michael Maire, and Jitendra Malik. \\u201cSVM-KNN: Discriminative nearest neighbor classification for visual category recognition\\u201d. In: 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR\\u201906). Vol. 2. IEEE. 2006, pp. 2126\\u20132136.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9237822890281677,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            401.6455555555555\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            502.21457888888904\n",
      "          ],\n",
      "          [\n",
      "            1570.148193359375,\n",
      "            502.21457888888904\n",
      "          ],\n",
      "          [\n",
      "            1570.148193359375,\n",
      "            401.6455555555555\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 24,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"7d83a2ccdcf6fc41a9353242cd58a2ad\",\n",
      "    \"text\": \"[129] Jianyu Zhang, Niklas Nolte, Ranajoy Sadhukhan, Beidi Chen, and L\\u00e9on Bottou. \\u201cMemory Mosaics\\u201d. In: arXiv preprint arXiv:2405.06394 (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8927627205848694,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            501.2733333333336\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            568.6312455555556\n",
      "          ],\n",
      "          [\n",
      "            1563.6253662109375,\n",
      "            568.6312455555556\n",
      "          ],\n",
      "          [\n",
      "            1563.6253662109375,\n",
      "            501.2733333333336\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 24,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"e97b974d36429ad957fe79dcb32e376f\",\n",
      "    \"text\": \"[130] Yunhao Zhang and Junchi Yan. \\u201cCrossformer: Transformer utilizing cross-dimension dependency for multivariate time series forecasting\\u201d. In: The eleventh international conference on learning representations. 2023.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.800880491733551,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            567.6900000000002\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            635.0479122222222\n",
      "          ],\n",
      "          [\n",
      "            1567.3720703125,\n",
      "            635.0479122222222\n",
      "          ],\n",
      "          [\n",
      "            1567.3720703125,\n",
      "            567.6900000000002\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 24,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"48521c4d4a240b4caec9abcf9bd2723e\",\n",
      "    \"text\": \"[131] Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang. \\u201cInformer: Beyond efficient transformer for long sequence time-series forecasting\\u201d. In: Proceedings of the AAAI conference on artificial intelligence. Vol. 35. 12. 2021, pp. 11106\\u201311115.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.921810507774353,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            634.1094444444444\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            734.6756900000003\n",
      "          ],\n",
      "          [\n",
      "            1575.0091552734375,\n",
      "            734.6756900000003\n",
      "          ],\n",
      "          [\n",
      "            1575.0091552734375,\n",
      "            634.1094444444444\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 24,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"31b3abcc69f4eed2943e61908a2eb766\",\n",
      "    \"text\": \"[132] Luisa Zintgraf, Kyriacos Shiarli, Vitaly Kurin, Katja Hofmann, and Shimon Whiteson. \\u201cFast context adaptation via meta-learning\\u201d. In: International Conference on Machine Learning. PMLR. 2019, pp. 7693\\u20137702.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9019168615341187,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.49061584472656,\n",
      "            733.7344444444444\n",
      "          ],\n",
      "          [\n",
      "            198.49061584472656,\n",
      "            801.0923566666667\n",
      "          ],\n",
      "          [\n",
      "            1561.7681884765625,\n",
      "            801.0923566666667\n",
      "          ],\n",
      "          [\n",
      "            1561.7681884765625,\n",
      "            733.7344444444444\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 24,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"f38df2c3daecdcadc18337bc2c908bf2\",\n",
      "    \"text\": \"24\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1305555555555,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            867.1305555555555,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222221,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222221,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 24,\n",
      "      \"parent_id\": \"867642d9def453fac13e17c0debc3ad1\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"a23c743a726a422fba0de2e7e95fb90a\",\n",
      "    \"text\": \"A Related Work\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8510819673538208,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            197.47247314453125\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            240.04158944444433\n",
      "          ],\n",
      "          [\n",
      "            519.9432373046875,\n",
      "            240.04158944444433\n",
      "          ],\n",
      "          [\n",
      "            519.9432373046875,\n",
      "            197.47247314453125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 25,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"968bb32d2db2548a4cf8d400e6289e9e\",\n",
      "    \"text\": \"There are diverse perspectives that can independently lead to the design of Titans or its components. Accordingly, to further situate our work in a broader context, we review three categories of studies:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9304509162902832,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            263.6788888888889\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            329.7239685058594\n",
      "          ],\n",
      "          [\n",
      "            1561.053955078125,\n",
      "            329.7239685058594\n",
      "          ],\n",
      "          [\n",
      "            1561.053955078125,\n",
      "            263.6788888888889\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 25,\n",
      "      \"parent_id\": \"a23c743a726a422fba0de2e7e95fb90a\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"bf7b60f80dca3dfad259e622ba633f23\",\n",
      "    \"text\": \"A.1 Linear Recurrent Models\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8645645380020142,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            376.1134033203125\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            409.56014222222194\n",
      "          ],\n",
      "          [\n",
      "            660.622802734375,\n",
      "            409.56014222222194\n",
      "          ],\n",
      "          [\n",
      "            660.622802734375,\n",
      "            376.1134033203125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 25,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"7249416ce2a4e7e59b72ba9701d8636a\",\n",
      "    \"text\": \"Recently, to address the computational cost of Transformers in both training and inference, linear recurrent models have attracted much attention (Tiezzi et al. 2024), mainly due to their fast inference and training. The first generation of models\\u2013such as RetNet (Yutao Sun et al. 2023), LRU (Orvieto et al. 2023), RWKV (Peng, Alcaide, et al. 2023), S5 (J. T. Smith, Warrington, and Linderman 2023), and S4 (Gu, Goel, and Re 2022)\\u2013uses data-independent transition matrix/decay mechanism. The second generation of such models started to incorporate gating mechanism, a widely used techniques in traditional RNNs (Gers, J\\u00fcrgen Schmidhuber, and Cummins 2000; Greff et al. 2016; Van Der Westhuizen and Lasenby 2018), into such linear architectures\\u2013e.g., Griffin (De et al. 2024), SSMs (Behrouz, Santacatterina, and Zabih 2024; Dao and Gu 2024; Gu and Dao 2024; Hasani et al. 2023), RWKV6 (Peng, Goldstein, et al. 2024). The third generation of linear recurrent models are based on more complex memory updating rule based on meta-learning, online learning, and/or delta-rule, resulting in more expressive and effective models such as: Longhorn (B. Liu et al. 2024), Gated DeltaNet (S. Yang, Kautz, and Hatamizadeh 2024), TTT (Yu Sun et al. 2024), and DeltaNet (S. Yang, B. Wang, Yu Zhang, et al. 2024). Our LMM model can be seen as the next generation of such models, in which we incorporate the token flow into the memory updating mechanism, having more powerful memory updating process. See Appendix C for a detailed discussion of different recurrent models and Titans.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9524243474006653,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            425.2316666666669\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            887.6248779296875\n",
      "          ],\n",
      "          [\n",
      "            1564.256858366666,\n",
      "            887.6248779296875\n",
      "          ],\n",
      "          [\n",
      "            1564.256858366666,\n",
      "            425.2316666666669\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@tiezzi2024resurgence\",\n",
      "          \"start_index\": 189\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@sun2023retentive\",\n",
      "          \"start_index\": 308\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@orvieto2023resurrecting\",\n",
      "          \"start_index\": 335\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@peng2023rwkv\",\n",
      "          \"start_index\": 370\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@smith2023simplified\",\n",
      "          \"start_index\": 420\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.0@gu2022efficiently\",\n",
      "          \"start_index\": 452\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2000\",\n",
      "          \"url\": \"cite.0@gers2000learning\",\n",
      "          \"start_index\": 677\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2016\",\n",
      "          \"url\": \"cite.0@greff2016lstm\",\n",
      "          \"start_index\": 695\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2018\",\n",
      "          \"url\": \"cite.0@van2018unreasonable\",\n",
      "          \"start_index\": 732\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@de2024griffin\",\n",
      "          \"start_index\": 793\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@behrouz2024mambamixer\",\n",
      "          \"start_index\": 841\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@dao2024transformers\",\n",
      "          \"start_index\": 858\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@gu2024mamba\",\n",
      "          \"start_index\": 875\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@hasani2023liquid\",\n",
      "          \"start_index\": 895\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@peng2024eagle\",\n",
      "          \"start_index\": 933\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@liu2024longhorn\",\n",
      "          \"start_index\": 1177\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024gated\",\n",
      "          \"start_index\": 1232\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@sun2024learning\",\n",
      "          \"start_index\": 1258\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024parallelizing\",\n",
      "          \"start_index\": 1314\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Appendix C\",\n",
      "          \"url\": \"appendix.C\",\n",
      "          \"start_index\": 1510\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 25,\n",
      "      \"parent_id\": \"bf7b60f80dca3dfad259e622ba633f23\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"18e700de39e52656c3412939258d07fc\",\n",
      "    \"text\": \"A.2 Transformer-based Architectures\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8608254790306091,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            196.95957946777344,\n",
      "            933.9984130859375\n",
      "          ],\n",
      "          [\n",
      "            196.95957946777344,\n",
      "            969.6184755555557\n",
      "          ],\n",
      "          [\n",
      "            789.4044189453125,\n",
      "            969.6184755555557\n",
      "          ],\n",
      "          [\n",
      "            789.4044189453125,\n",
      "            933.9984130859375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 25,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9bbaf1b7078c6de81070943bfc7c1dca\",\n",
      "    \"text\": \"Transformers. Transformers (Vaswani et al. 2017) as the de facto backbone for many deep learning models are based on attention mechanism (Bahdanau 2014). They, however, suffer from quadratic computational cost, limiting their ability to scale to long context window. To improve the memory consumption and throughput of softmax attention for longer sequences, various studies focused on I/O aware implementations of attention (Dao 2024; Dao, D. Fu, et al. 2022), designing more efficient attention mechanisms by sparsifying the attention matrix (B. Chen et al. 2021; Choromanski et al. 2021; Dai et al. 2019; J. Dong et al. 2024; Roy et al. 2021), approximating the softmax (Arora et al. 2024), or developing kernel-based (linear) attentions (Aksenov et al. 2024; Kacham, Mirrokni, and P. Zhong 2024; Schlag, Irie, and J\\u00fcrgen Schmidhuber 2021; S. Yang, B. Wang, Shen, et al. 2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9554130434989929,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.0861111111111,\n",
      "            998.676111111111\n",
      "          ],\n",
      "          [\n",
      "            199.0861111111111,\n",
      "            1263.0526123046875\n",
      "          ],\n",
      "          [\n",
      "            1569.68017578125,\n",
      "            1263.0526123046875\n",
      "          ],\n",
      "          [\n",
      "            1569.68017578125,\n",
      "            998.676111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2017\",\n",
      "          \"url\": \"cite.0@transformers\",\n",
      "          \"start_index\": 43\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2014\",\n",
      "          \"url\": \"cite.0@bahdanau2014neural\",\n",
      "          \"start_index\": 147\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@dao2024flashattention\",\n",
      "          \"start_index\": 429\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.0@flashattention-1\",\n",
      "          \"start_index\": 454\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@chen2021scatterbrain\",\n",
      "          \"start_index\": 557\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@choromanski2021rethinking\",\n",
      "          \"start_index\": 582\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.0@dai2019transformerxl\",\n",
      "          \"start_index\": 599\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@dong2024flex\",\n",
      "          \"start_index\": 620\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@roy2021efficient\",\n",
      "          \"start_index\": 637\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@arora2024simple\",\n",
      "          \"start_index\": 684\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@aksenov2024linear\",\n",
      "          \"start_index\": 754\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@kacham2024polysketchformer\",\n",
      "          \"start_index\": 791\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@schlag2021linear\",\n",
      "          \"start_index\": 834\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 25,\n",
      "      \"parent_id\": \"18e700de39e52656c3412939258d07fc\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"32605ca2e3191eb119f920d2c0620054\",\n",
      "    \"text\": \"Segment-based Transformers. Another line of research to improve the efficiency of Transformers is segment-based or Chunk Transformers (Dai et al. 2019). The main drawback of chunk Transformers is that segments are fully separated and so the context window is limited to the length of the chunks. To address this issue, various studies discuss the importance of a memory so it can help the model to transfer information across chunks (Bulatov, Yuri Kuratov, et al. 2023; Bulatov, Yury Kuratov, and Burtsev 2022; Feng et al. 2022; Hutchins et al. 2022; Rodkin et al. 2024; Z. Wang et al. 2019; Q. Wu et al. 2020; Zancato et al. 2024). The key differences of Titans with these models are: (1) The memory in such models are simple small size vectors, lacking expressive power to compress complex information; (2) The memory module lacks forget mechanism, leading to a fast memory overflow; (3) only focus on momentary surprise, missing the information flow. More specifically, recalling Recurrent Memory Transformers (RMT) (Bulatov, Yuri Kuratov, et al. 2023; Bulatov, Yury Kuratov, and Burtsev 2022; Rodkin et al. 2024), one can treat Titans (MAC) as the generalization of RMT, where we use a neural memory module instead of a vector-valued small size memory.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9546858072280884,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.19722222222222,\n",
      "            1294.3372222222222\n",
      "          ],\n",
      "          [\n",
      "            199.19722222222222,\n",
      "            1660.6866455078125\n",
      "          ],\n",
      "          [\n",
      "            1563.750732421875,\n",
      "            1660.6866455078125\n",
      "          ],\n",
      "          [\n",
      "            1563.750732421875,\n",
      "            1294.3372222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.0@dai2019transformerxl\",\n",
      "          \"start_index\": 144\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@bulatov2023scaling\",\n",
      "          \"start_index\": 462\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.0@bulatov2022recurrent\",\n",
      "          \"start_index\": 503\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.0@feng2022learn\",\n",
      "          \"start_index\": 521\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.0@hutchins2022block\",\n",
      "          \"start_index\": 543\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@rodkin2024associative\",\n",
      "          \"start_index\": 563\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.0@wang2019r\",\n",
      "          \"start_index\": 584\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2020\",\n",
      "          \"url\": \"cite.0@wu2020memformer\",\n",
      "          \"start_index\": 603\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@zancato2024bmojo\",\n",
      "          \"start_index\": 624\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@bulatov2023scaling\",\n",
      "          \"start_index\": 1044\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.0@bulatov2022recurrent\",\n",
      "          \"start_index\": 1085\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@rodkin2024associative\",\n",
      "          \"start_index\": 1105\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 25,\n",
      "      \"parent_id\": \"18e700de39e52656c3412939258d07fc\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"41905710e4b87601e969518d3d416c72\",\n",
      "    \"text\": \"Memory for Large Language Models. Another interesting research direction has been to incorporate external memory modules to LLMs after training (Z. He et al. 2024; Khandelwal et al. 2020; Y. Wang, Y. Gao, et al. 2024). Such models are different from our approach as we incorporate the memory as a part of initial architecture and so we train it in an end-to-end manner. Also, most of these explicit memory modules suffer from the same limitations as chunk-based Transformers (mentioned above). For a detailed discussion of such models, we refer to the recent study of Y. Wang, Han, et al. (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9520406126976013,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1689.6233333333334\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1887.388916015625\n",
      "          ],\n",
      "          [\n",
      "            1564.5279541015625,\n",
      "            1887.388916015625\n",
      "          ],\n",
      "          [\n",
      "            1564.5279541015625,\n",
      "            1689.6233333333334\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@he2024camelot\",\n",
      "          \"start_index\": 158\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2020\",\n",
      "          \"url\": \"cite.0@Khandelwal2020Generalization\",\n",
      "          \"start_index\": 182\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@wang2024memoryllm\",\n",
      "          \"start_index\": 212\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 25,\n",
      "      \"parent_id\": \"18e700de39e52656c3412939258d07fc\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"6f201ce7215051f26bd1649cd4cc2f13\",\n",
      "    \"text\": \"25\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1305555555556,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            867.1305555555556,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222223,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222223,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 25,\n",
      "      \"parent_id\": \"18e700de39e52656c3412939258d07fc\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"ec73933ac8248ef90145a62a83535713\",\n",
      "    \"text\": \"A.3 Test Time Training and Fast Weight Programs\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8472745418548584,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.34396362304688,\n",
      "            204.5290311111109\n",
      "          ],\n",
      "          [\n",
      "            199.34396362304688,\n",
      "            237.7632598876953\n",
      "          ],\n",
      "          [\n",
      "            981.28759765625,\n",
      "            237.7632598876953\n",
      "          ],\n",
      "          [\n",
      "            981.28759765625,\n",
      "            204.5290311111109\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 26,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"bfa8a390148606502d4a07bb2816ec46\",\n",
      "    \"text\": \"Memory Design and Augmentation with Memory. In the literature, a substantial research effort have been toward designing memory modules that are capable of either memorizing the knowledge abstraction (e.g., persistent mem- ory) (Sukhbaatar, Grave, et al. 2019), or memorizing the data-dependent information (also known as contextual memory), through recurrence (Bulatov, Yury Kuratov, and Burtsev 2022; Rodkin et al. 2024; Zancato et al. 2024), Transformers (Berges et al. 2024; Cetin et al. 2024; Feng et al. 2022; Le, Tran, and Venkatesh 2020; Munkhdalai, Faruqui, and Gopal 2024; J. Zhang et al. 2024), gradient (Irie, Csord\\u00e1s, and J\\u00fcrgen Schmidhuber 2022; Munkhdalai, Sordoni, et al. 2019), or other learning paradigms (Sukhbaatar, Weston, Fergus, et al. 2015; Weston, Chopra, and Bordes 2014). These memory models, however, either (1) are based on momentary surprise, missing the data flow and events, (2) lack forget mechanisms to remove the memory, leading to a fast memory overflow (3) are fixed-size shallow (matrix valued) memory, resulting in poor performance in long context, and (4) are based on fixed parameters at test time, lacking test time adaption.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9551926255226135,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            266.7955555555557\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            600.5435180664062\n",
      "          ],\n",
      "          [\n",
      "            1570.71240234375,\n",
      "            600.5435180664062\n",
      "          ],\n",
      "          [\n",
      "            1570.71240234375,\n",
      "            266.7955555555557\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.0@sukhbaatar2019augmenting\",\n",
      "          \"start_index\": 253\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.0@bulatov2022recurrent\",\n",
      "          \"start_index\": 395\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@rodkin2024associative\",\n",
      "          \"start_index\": 415\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@zancato2024bmojo\",\n",
      "          \"start_index\": 436\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@berges2024memory\",\n",
      "          \"start_index\": 471\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@cetin2024evolved\",\n",
      "          \"start_index\": 490\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.0@feng2022learn\",\n",
      "          \"start_index\": 508\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2020\",\n",
      "          \"url\": \"cite.0@le2020self\",\n",
      "          \"start_index\": 538\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@munkhdalai2024leave\",\n",
      "          \"start_index\": 575\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@zhang2024memory\",\n",
      "          \"start_index\": 597\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.0@irie2022dual\",\n",
      "          \"start_index\": 652\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.0@munkhdalai2019metalearned\",\n",
      "          \"start_index\": 686\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2015\",\n",
      "          \"url\": \"cite.0@sukhbaatar2015end\",\n",
      "          \"start_index\": 757\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2014\",\n",
      "          \"url\": \"cite.0@weston2014memory\",\n",
      "          \"start_index\": 790\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 26,\n",
      "      \"parent_id\": \"ec73933ac8248ef90145a62a83535713\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"d2059827adc00ad43ae783f7089239c4\",\n",
      "    \"text\": \"Fast Weight Programs. The idea of seeing linear layers as the key-value (associative) memory system backs to fast weight programs, in which dynamic fast programs are incorporated into recurrent neural networks to serve as writable memory (Schlag, Irie, and J\\u00fcrgen Schmidhuber 2021; JH Schmidhuber 1992; J\\u00fcrgen Schmidhuber 1993). The two learning rules of Hebbian (Hebb 2005) and delta (Prados and Kak 1989) are the most popular learning rules for fast weight programs, which have been extensively explored in various studies (Irie, Schlag, et al. 2021; Munkhdalai, Sordoni, et al. 2019; Munkhdalai and H. Yu 2017; Schlag, Irie, and J\\u00fcrgen Schmidhuber 2021; JH Schmidhuber 1992; S. Yang, Kautz, and Hatamizadeh 2024; S. Yang, B. Wang, Yu Zhang, et al. 2024). All these models, however, are based on momentary surprise, missing the token flow in the sequences (see Section 3.1), and most of them lacks a forgetting gate, resulting in a poor memory management.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9537719488143921,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            628.8761111111111\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            926.1392822265625\n",
      "          ],\n",
      "          [\n",
      "            1566.78955078125,\n",
      "            926.1392822265625\n",
      "          ],\n",
      "          [\n",
      "            1566.78955078125,\n",
      "            628.8761111111111\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@schlag2021linear\",\n",
      "          \"start_index\": 276\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"1992\",\n",
      "          \"url\": \"cite.0@schmidhuber1992learning\",\n",
      "          \"start_index\": 297\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"1993\",\n",
      "          \"url\": \"cite.0@schmidhuber1993reducing\",\n",
      "          \"start_index\": 322\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2005\",\n",
      "          \"url\": \"cite.0@hebb2005organization\",\n",
      "          \"start_index\": 369\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"1989\",\n",
      "          \"url\": \"cite.0@prados1989neural\",\n",
      "          \"start_index\": 401\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@irie2021going\",\n",
      "          \"start_index\": 547\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.0@munkhdalai2019metalearned\",\n",
      "          \"start_index\": 581\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2017\",\n",
      "          \"url\": \"cite.0@munkhdalai2017neural\",\n",
      "          \"start_index\": 608\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@schlag2021linear\",\n",
      "          \"start_index\": 651\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"1992\",\n",
      "          \"url\": \"cite.0@schmidhuber1992learning\",\n",
      "          \"start_index\": 672\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024gated\",\n",
      "          \"start_index\": 710\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024parallelizing\",\n",
      "          \"start_index\": 751\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Section 3 . 1\",\n",
      "          \"url\": \"subsection.3.1\",\n",
      "          \"start_index\": 862\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 26,\n",
      "      \"parent_id\": \"ec73933ac8248ef90145a62a83535713\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4e0465ef94883879fa17c61398678e1e\",\n",
      "    \"text\": \"Test Time Training. The key ideas of learning at test time or learning to learn (i.e., (Andrychowicz et al. 2016)) backs to very early studies on local learning Bottou and Vapnik 1992, in which each test data sample is trained on its neighbors before making a prediction (Gandelsman et al. 2022; H. Zhang et al. 2006). This approach further has shown promising performance in vision tasks (Jain and Learned-Miller 2011; Mullapudi et al. 2019), mostly due to their ability to mitigate out-of-distribution samples. The most similar studies to ours in this direction are MNM (Munkhdalai, Sordoni, et al. 2019) and TTT-layer (Yu Sun et al. 2024), which we discussed the key differences in Appendix C.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9524902701377869,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.0861111111111,\n",
      "            957.7455555555555\n",
      "          ],\n",
      "          [\n",
      "            199.0861111111111,\n",
      "            1157.6739501953125\n",
      "          ],\n",
      "          [\n",
      "            1566.9964599609375,\n",
      "            1157.6739501953125\n",
      "          ],\n",
      "          [\n",
      "            1566.9964599609375,\n",
      "            957.7455555555555\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2016\",\n",
      "          \"url\": \"cite.0@andrychowicz2016learning\",\n",
      "          \"start_index\": 108\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"1992\",\n",
      "          \"url\": \"cite.0@bottou1992local\",\n",
      "          \"start_index\": 179\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.0@gandelsman2022test\",\n",
      "          \"start_index\": 290\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2006\",\n",
      "          \"url\": \"cite.0@zhang2006svm\",\n",
      "          \"start_index\": 312\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2011\",\n",
      "          \"url\": \"cite.0@jain2011online\",\n",
      "          \"start_index\": 414\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.0@mullapudi2019online\",\n",
      "          \"start_index\": 437\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.0@munkhdalai2019metalearned\",\n",
      "          \"start_index\": 601\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 26,\n",
      "      \"parent_id\": \"ec73933ac8248ef90145a62a83535713\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"6baac9157846f5af0f64d63c9b2f1507\",\n",
      "    \"text\": \"B Language Modeling and Common-sense Reasoning Datasets\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.853956401348114,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            197.41592407226562,\n",
      "            1210.8538818359375\n",
      "          ],\n",
      "          [\n",
      "            197.41592407226562,\n",
      "            1251.2221450000002\n",
      "          ],\n",
      "          [\n",
      "            1348.5328616666666,\n",
      "            1251.2221450000002\n",
      "          ],\n",
      "          [\n",
      "            1348.5328616666666,\n",
      "            1210.8538818359375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 26,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f6c113293be5734cca3b2c24402b779e\",\n",
      "    \"text\": \"Following recent studies on linear recurrent models (Dao and Gu 2024; S. Yang, Kautz, and Hatamizadeh 2024; S. Yang, B. Wang, Yu Zhang, et al. 2024), we use Wikitext (Merity et al. 2017), LMB (Paperno et al. 2016), PIQA (Bisk et al. 2020), HellaSwag (Zellers et al. 2019), WinoGrande (Sakaguchi et al. 2021), ARC-easy (ARC-e) and ARC-challenge (ARC-c) (P. Clark et al. 2018), SIQA (Sap et al. 2019), and BoolQ (C. Clark et al. 2019). Also, the baselines results for 400M models are from the reported results by S. Yang, Kautz, and Hatamizadeh (2024).\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9474785923957825,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1274.8566666666666\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1441.7156982421875\n",
      "          ],\n",
      "          [\n",
      "            1572.387939453125,\n",
      "            1441.7156982421875\n",
      "          ],\n",
      "          [\n",
      "            1572.387939453125,\n",
      "            1274.8566666666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@dao2024transformers\",\n",
      "          \"start_index\": 64\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024gated\",\n",
      "          \"start_index\": 102\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024parallelizing\",\n",
      "          \"start_index\": 143\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2017\",\n",
      "          \"url\": \"cite.0@merity2017pointer\",\n",
      "          \"start_index\": 181\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2016\",\n",
      "          \"url\": \"cite.0@paperno-etal-2016-lambada\",\n",
      "          \"start_index\": 208\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2020\",\n",
      "          \"url\": \"cite.0@bisk2020piqa\",\n",
      "          \"start_index\": 233\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.0@zellers-etal-2019-hellaswag\",\n",
      "          \"start_index\": 266\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@sakaguchi2021winogrande\",\n",
      "          \"start_index\": 302\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2018\",\n",
      "          \"url\": \"cite.0@clark2018think\",\n",
      "          \"start_index\": 369\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.0@sap-etal-2019-social\",\n",
      "          \"start_index\": 393\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.0@clark-etal-2019-boolq\",\n",
      "          \"start_index\": 427\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 26,\n",
      "      \"parent_id\": \"6baac9157846f5af0f64d63c9b2f1507\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"32ac3d76b7ae279024a642d3b256783a\",\n",
      "    \"text\": \"C Long-term Memory Module (LMM) as a Sequence Model\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.8558773398399353,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            196.16053771972656,\n",
      "            1492.846923828125\n",
      "          ],\n",
      "          [\n",
      "            196.16053771972656,\n",
      "            1535.1249227777778\n",
      "          ],\n",
      "          [\n",
      "            1277.3179931640625,\n",
      "            1535.1249227777778\n",
      "          ],\n",
      "          [\n",
      "            1277.3179931640625,\n",
      "            1492.846923828125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 26,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"09feebb366635492ba65a549f2b9514e\",\n",
      "    \"text\": \"In this section, we discuss how LMM as a sequence model is connected to modern linear recurrent models. For the sake of simplicity, we start with a linear memory, where M\\ud835\\udc61 = \\ud835\\udc4a\\ud835\\udc61 \\u2208 R\\ud835\\udc51in \\u00d7\\ud835\\udc51in. In this case, our objective function becomes 2 \\u2225M\\ud835\\udc61 k\\ud835\\udc61 \\u2212 v\\ud835\\udc61 \\u22252 \\u2113 (M; \\ud835\\udc65\\ud835\\udc61 ) = 1 2, in which we use gradient descent with momentum and weight decay for the optimization. Accordingly, revisiting the recurrent formula in Equation 13:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9411402344703674,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.03055555555554,\n",
      "            1558.7594444444444\n",
      "          ],\n",
      "          [\n",
      "            199.03055555555554,\n",
      "            1690.577880859375\n",
      "          ],\n",
      "          [\n",
      "            1565.9735107421875,\n",
      "            1690.577880859375\n",
      "          ],\n",
      "          [\n",
      "            1565.9735107421875,\n",
      "            1558.7594444444444\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 26,\n",
      "      \"parent_id\": \"32ac3d76b7ae279024a642d3b256783a\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"a95f6335e637528682c8dba5a90464a2\",\n",
      "    \"text\": \"M; = diag (1 - a7) Mr + St (32) S; = diag (y;) S;-1 \\u2014 diag (@;) (Mi-1k; ke - v; k;) : (33)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.5204486846923828,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            572.2598266601562,\n",
      "            1714.537222222222\n",
      "          ],\n",
      "          [\n",
      "            572.2598266601562,\n",
      "            1795.898193359375\n",
      "          ],\n",
      "          [\n",
      "            1575.0819091796875,\n",
      "            1795.898193359375\n",
      "          ],\n",
      "          [\n",
      "            1575.0819091796875,\n",
      "            1714.537222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 26,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"6582d45cf6262e5a5d94c3d8f3526d44\",\n",
      "    \"text\": \"LMM is Generalized Gated DeltaNet. As discussed by S. Yang, Kautz, and Hatamizadeh (2024), DeltaNet (S. Yang, B. Wang, Yu Zhang, et al. 2024) can alternatively be interpreted as an online learning problem that optimizes the L = 1 2 \\u2225S\\ud835\\udc61 k\\ud835\\udc61 \\u2212 v\\ud835\\udc61 \\u22252 resulting in: 2,\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9331384897232056,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.19722222222222,\n",
      "            1842.1899999999998\n",
      "          ],\n",
      "          [\n",
      "            199.19722222222222,\n",
      "            1940.8453369140625\n",
      "          ],\n",
      "          [\n",
      "            1565.67138671875,\n",
      "            1940.8453369140625\n",
      "          ],\n",
      "          [\n",
      "            1565.67138671875,\n",
      "            1842.1899999999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024gated\",\n",
      "          \"start_index\": 84\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024parallelizing\",\n",
      "          \"start_index\": 153\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 26,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"24efa924e2b1dd73f671bc9d5039b668\",\n",
      "    \"text\": \"Set = Sr \\u2014 VL = 8, (I= Okyk7) + Orvik? (34)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.6225360631942749,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            624.261474609375,\n",
      "            1960.5986422222222\n",
      "          ],\n",
      "          [\n",
      "            624.261474609375,\n",
      "            1999.6540288888887\n",
      "          ],\n",
      "          [\n",
      "            1565.1314697265625,\n",
      "            1999.6540288888887\n",
      "          ],\n",
      "          [\n",
      "            1565.1314697265625,\n",
      "            1960.5986422222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 26,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"bd3dcb116b070fb8a64c1eca73db0c74\",\n",
      "    \"text\": \"26\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1333333333337,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            867.1333333333337,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8700500000003,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8700500000003,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 26,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"78ae709687459196a381cf539188994e\",\n",
      "    \"text\": \"In this formulation, Gated DeltaNet is the same as above but with an additional weight decay term (S. Yang, Kautz, and\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            202.39277777777778\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            230.06666666666652\n",
      "          ],\n",
      "          [\n",
      "            1560.0130675055548,\n",
      "            230.06666666666652\n",
      "          ],\n",
      "          [\n",
      "            1560.0130675055548,\n",
      "            202.39277777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"5cf6298129b1c1ef01ebcc27a4b73c38\",\n",
      "    \"text\": \"Hatamizadeh 2024). Comparing Equation 32 and Equation 34, we can see that setting \\ud835\\udf02\\ud835\\udc61 = 0 results in both formulations to be equivalent. Accordingly, we can say LMM is generalizing the very recent study of Gated DeltaNet (S. Yang, Kautz, and Hatamizadeh 2024) from three aspects:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.941305935382843,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            210.97552490234375\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            333.3111267089844\n",
      "          ],\n",
      "          [\n",
      "            1565.7769775390625,\n",
      "            333.3111267089844\n",
      "          ],\n",
      "          [\n",
      "            1565.7769775390625,\n",
      "            210.97552490234375\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024gated\",\n",
      "          \"start_index\": 131\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Equation 32\",\n",
      "          \"url\": \"equation.C.32\",\n",
      "          \"start_index\": 148\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Equation 34\",\n",
      "          \"url\": \"equation.C.34\",\n",
      "          \"start_index\": 164\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"ed7ca0d9e3715ab208d85958f907811c\",\n",
      "    \"text\": \"Momentum-based Rule: The Delta Rule is based on momentary surprise, meaning that the flow of tokens cannot\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            245.63333333333333,\n",
      "            351.83444444444467\n",
      "          ],\n",
      "          [\n",
      "            245.63333333333333,\n",
      "            379.50833333333344\n",
      "          ],\n",
      "          [\n",
      "            1559.9992361888894,\n",
      "            379.50833333333344\n",
      "          ],\n",
      "          [\n",
      "            1559.9992361888894,\n",
      "            351.83444444444467\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"4da181f7bcfa5dfd708e181d64e19e90\",\n",
      "    \"text\": \"affect the memory update rule. LMM, however, is based on a momentum rule, which consider both past and momentary surprise.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9354394674301147,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            237.36114501953125,\n",
      "            359.3262939453125\n",
      "          ],\n",
      "          [\n",
      "            237.36114501953125,\n",
      "            448.61663818359375\n",
      "          ],\n",
      "          [\n",
      "            1559.9921547444444,\n",
      "            448.61663818359375\n",
      "          ],\n",
      "          [\n",
      "            1559.9921547444444,\n",
      "            359.3262939453125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"220082fa41bf412f549e1494af238c03\",\n",
      "    \"text\": \"Deep Memory: While Gated DeltaNet is limited to a linear (matrix-valued) memory as it requires finding the closed\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            245.63333333333333,\n",
      "            468.0650000000001\n",
      "          ],\n",
      "          [\n",
      "            245.63333333333333,\n",
      "            495.7388888888889\n",
      "          ],\n",
      "          [\n",
      "            1559.9994068711108,\n",
      "            495.7388888888889\n",
      "          ],\n",
      "          [\n",
      "            1559.9994068711108,\n",
      "            468.0650000000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"992fc0b5554dac11aae00bd9dff4e7d3\",\n",
      "    \"text\": \"recurrence form, LMM allows using deep memory module by using a gradient-based formulation, resulting in higher expressive power.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9363850355148315,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            234.09703063964844,\n",
      "            475.3846130371094\n",
      "          ],\n",
      "          [\n",
      "            234.09703063964844,\n",
      "            570.173095703125\n",
      "          ],\n",
      "          [\n",
      "            1561.90869140625,\n",
      "            570.173095703125\n",
      "          ],\n",
      "          [\n",
      "            1561.90869140625,\n",
      "            475.3846130371094\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"0de21ca84516b046828efa2a6cafd824\",\n",
      "    \"text\": \"Non-Linear Recurrence: While DeltaNet and Gated DeltaNet are based on linear recurrence, our LMM is using\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            245.63333333333333,\n",
      "            587.1455555555558\n",
      "          ],\n",
      "          [\n",
      "            245.63333333333333,\n",
      "            614.8194444444446\n",
      "          ],\n",
      "          [\n",
      "            1559.988638422222,\n",
      "            614.8194444444446\n",
      "          ],\n",
      "          [\n",
      "            1559.988638422222,\n",
      "            587.1455555555558\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"5bd4ad88cbb062448ec7d1c0cc2fb49d\",\n",
      "    \"text\": \"inter-chunk non-linear recurrence and intra-chunk linear recurrence. This design allows LMM having a higher expressive power.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9349726438522339,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            235.08010864257812,\n",
      "            595.0479125976562\n",
      "          ],\n",
      "          [\n",
      "            235.08010864257812,\n",
      "            687.198486328125\n",
      "          ],\n",
      "          [\n",
      "            1561.217041015625,\n",
      "            687.198486328125\n",
      "          ],\n",
      "          [\n",
      "            1561.217041015625,\n",
      "            595.0479125976562\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a9f1a3c18051cf2d70c6264765dbc620\",\n",
      "    \"text\": \"Here, we discussed Gated DeltaNet as a sample of recent generation of recurrent models. Similar approaches such\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            703.3761111111112\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            731.05\n",
      "          ],\n",
      "          [\n",
      "            1559.9945260000002,\n",
      "            731.05\n",
      "          ],\n",
      "          [\n",
      "            1559.9945260000002,\n",
      "            703.3761111111112\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"7bd9ee8117ce6c6673a00c7ad482da6d\",\n",
      "    \"text\": \"as RWKV-7 (Peng 2021) are also using the same formulation and loss function, and so LMM is generalizing all such models.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.936514675617218,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            713.5591430664062\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            801.0422973632812\n",
      "          ],\n",
      "          [\n",
      "            1567.1929931640625,\n",
      "            801.0422973632812\n",
      "          ],\n",
      "          [\n",
      "            1567.1929931640625,\n",
      "            713.5591430664062\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.0@rwkv-repo\",\n",
      "          \"start_index\": 128\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"35bf77d30b251d9ab2f255f6d30c1e3d\",\n",
      "    \"text\": \"LMM is Generalized Longhorn. Similar to DeltaNet, Longhorn (B. Liu et al. 2024) uses the same loss function but it\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            832.9927777777776\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            867.0593349999999\n",
      "          ],\n",
      "          [\n",
      "            1559.987369888889,\n",
      "            867.0593349999999\n",
      "          ],\n",
      "          [\n",
      "            1559.987369888889,\n",
      "            832.9927777777776\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@liu2024longhorn\",\n",
      "          \"start_index\": 74\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"658e096dd210ea10fdda172c4066d86a\",\n",
      "    \"text\": \"derives the closed form using implicit online learning:\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9248551726341248,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            841.6473388671875\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            899.4852905273438\n",
      "          ],\n",
      "          [\n",
      "            1563.770751953125,\n",
      "            899.4852905273438\n",
      "          ],\n",
      "          [\n",
      "            1563.770751953125,\n",
      "            841.6473388671875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@liu2024longhorn\",\n",
      "          \"start_index\": 74\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Formula\",\n",
      "    \"element_id\": \"e994aadc3f817e392c781daca9b58aa0\",\n",
      "    \"text\": \"Seat = Sp (I= dykek}) + Syvek7, (35)\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.6339044570922852,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            702.9913940429688,\n",
      "            922.9264200000001\n",
      "          ],\n",
      "          [\n",
      "            702.9913940429688,\n",
      "            961.9790288888889\n",
      "          ],\n",
      "          [\n",
      "            1561.6609099999998,\n",
      "            961.9790288888889\n",
      "          ],\n",
      "          [\n",
      "            1561.6609099999998,\n",
      "            922.9264200000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"fe41073bb92f243b8d5a49535b837b5b\",\n",
      "    \"text\": \"\\ud835\\udf03\\ud835\\udc61\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            363.5694444444444,\n",
      "            989.4258325\n",
      "          ],\n",
      "          [\n",
      "            363.5694444444444,\n",
      "            1012.6035402777778\n",
      "          ],\n",
      "          [\n",
      "            380.32288472222217,\n",
      "            1012.6035402777778\n",
      "          ],\n",
      "          [\n",
      "            380.32288472222217,\n",
      "            989.4258325\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"29e6c92d2c0cf8bae359ed4de31cd9ce\",\n",
      "    \"text\": \"where \\ud835\\udeff\\ud835\\udc61 =\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            198.975,\n",
      "            994.2816666666666\n",
      "          ],\n",
      "          [\n",
      "            198.975,\n",
      "            1026.8538338888889\n",
      "          ],\n",
      "          [\n",
      "            321.97460888888884,\n",
      "            1026.8538338888889\n",
      "          ],\n",
      "          [\n",
      "            321.97460888888884,\n",
      "            994.2816666666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4044a13f88ce78c34eada79de7739236\",\n",
      "    \"text\": \". It, however, lacks a forgetting gate, resulting in a faster memory overflow. Therefore, in addition two\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            418.0777777777778,\n",
      "            994.2816666666666\n",
      "          ],\n",
      "          [\n",
      "            418.0777777777778,\n",
      "            1021.9555555555555\n",
      "          ],\n",
      "          [\n",
      "            1559.9870600855552,\n",
      "            1021.9555555555555\n",
      "          ],\n",
      "          [\n",
      "            1559.9870600855552,\n",
      "            994.2816666666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"parent_id\": \"29e6c92d2c0cf8bae359ed4de31cd9ce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a8177a33e509ff18b41a112a042a8df4\",\n",
      "    \"text\": \"1+\\ud835\\udf03\\ud835\\udc61 k\\ud835\\udc61 k\\u22a4 \\ud835\\udc61 the abovementioned aspects of (1) Momentum-based Rule, (2) Deep Memory, and (3) Non-Linear Recurrence, LMM has the advantage of using an additional (4) Forget Gate, leading to a better memory management.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9326969981193542,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1002.7481689453125\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1102.04638671875\n",
      "          ],\n",
      "          [\n",
      "            1565.3812255859375,\n",
      "            1102.04638671875\n",
      "          ],\n",
      "          [\n",
      "            1565.3812255859375,\n",
      "            1002.7481689453125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"parent_id\": \"29e6c92d2c0cf8bae359ed4de31cd9ce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e8107652f3dbb2f7af129f361f45c68d\",\n",
      "    \"text\": \"LMM is Generalized TTT Layer. To the best of our knowledge, TTT (Yu Sun et al. 2024), is the only modern linear\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1136.4816666666666\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1170.548223888889\n",
      "          ],\n",
      "          [\n",
      "            1560.5247308333335,\n",
      "            1170.548223888889\n",
      "          ],\n",
      "          [\n",
      "            1560.5247308333335,\n",
      "            1136.4816666666666\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@sun2024learning\",\n",
      "          \"start_index\": 79\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"parent_id\": \"29e6c92d2c0cf8bae359ed4de31cd9ce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e3c2732f0197449cd61a02cf742243d8\",\n",
      "    \"text\": \"recurrent models with a gradient-based updating rule. In addition to different architectural designs and also objective functions, our LMM has three key differences with presented TTT layers (Yu Sun et al. 2024):\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9423872232437134,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1146.055908203125\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1234.0982666015625\n",
      "          ],\n",
      "          [\n",
      "            1567.9151611328125,\n",
      "            1234.0982666015625\n",
      "          ],\n",
      "          [\n",
      "            1567.9151611328125,\n",
      "            1146.055908203125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@sun2024learning\",\n",
      "          \"start_index\": 79\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"parent_id\": \"29e6c92d2c0cf8bae359ed4de31cd9ce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"76a820f3eedb82b3eaca556366667dcf\",\n",
      "    \"text\": \"1. Forgetting Mechanism: TTT layers are updating memory at each time, without having the chance to forget the\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            236.39166666666665,\n",
      "            1252.715\n",
      "          ],\n",
      "          [\n",
      "            236.39166666666665,\n",
      "            1280.388888888889\n",
      "          ],\n",
      "          [\n",
      "            1560.0045685999994,\n",
      "            1280.388888888889\n",
      "          ],\n",
      "          [\n",
      "            1560.0045685999994,\n",
      "            1252.715\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"parent_id\": \"29e6c92d2c0cf8bae359ed4de31cd9ce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"f0d66903700f7d080c72d5a9af1fd80e\",\n",
      "    \"text\": \"past data. Accordingly, when fixing the memory size, the model cannot manage the memory for long sequences. A forget mechanism, such as LMM\\u2019s, allows clearing the memory when very past information is not needed anymore. We show that in a general case, this forget mechanism is equivalent to weight decay and provide a fast method to incorporate it into the parallel training.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9225931167602539,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            236.03915405273438,\n",
      "            1260.4791259765625\n",
      "          ],\n",
      "          [\n",
      "            236.03915405273438,\n",
      "            1419.3419189453125\n",
      "          ],\n",
      "          [\n",
      "            1564.2493916111114,\n",
      "            1419.3419189453125\n",
      "          ],\n",
      "          [\n",
      "            1564.2493916111114,\n",
      "            1260.4791259765625\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"parent_id\": \"29e6c92d2c0cf8bae359ed4de31cd9ce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"1fa7bba5e0f672f4f5227eedcd5d8cab\",\n",
      "    \"text\": \"2. Momentum-based Update Rule: TTT layers are based on momentary surprise, meaning that the flow of tokens\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            236.39166666666665,\n",
      "            1438.2122222222222\n",
      "          ],\n",
      "          [\n",
      "            236.39166666666665,\n",
      "            1465.8861111111112\n",
      "          ],\n",
      "          [\n",
      "            1559.9995054888886,\n",
      "            1465.8861111111112\n",
      "          ],\n",
      "          [\n",
      "            1559.9995054888886,\n",
      "            1438.2122222222222\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"parent_id\": \"29e6c92d2c0cf8bae359ed4de31cd9ce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"4085555dd8b7fe895c6c45edcf35e5d6\",\n",
      "    \"text\": \"cannot affect the memory update rule. LMM, however, is based on a momentum rule, which consider both past and momentary surprise. See Section 3.1 for the motivation of this design.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9307817220687866,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            232.07418823242188,\n",
      "            1447.000732421875\n",
      "          ],\n",
      "          [\n",
      "            232.07418823242188,\n",
      "            1538.9959716796875\n",
      "          ],\n",
      "          [\n",
      "            1564.1539306640625,\n",
      "            1538.9959716796875\n",
      "          ],\n",
      "          [\n",
      "            1564.1539306640625,\n",
      "            1447.000732421875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"parent_id\": \"29e6c92d2c0cf8bae359ed4de31cd9ce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"cbaa8c4851d22ec52d7c6f9db2b90b3b\",\n",
      "    \"text\": \"3. Deep Memory: While TTT-layers allows for deeper memory, the advantages/disadvantages of such deeper memory\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            236.39166666666665,\n",
      "            1557.5566666666664\n",
      "          ],\n",
      "          [\n",
      "            236.39166666666665,\n",
      "            1585.2305555555554\n",
      "          ],\n",
      "          [\n",
      "            1560.7095742077775,\n",
      "            1585.2305555555554\n",
      "          ],\n",
      "          [\n",
      "            1560.7095742077775,\n",
      "            1557.5566666666664\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"parent_id\": \"29e6c92d2c0cf8bae359ed4de31cd9ce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"5694b6b22b585cfcb90f599f2fd0e495\",\n",
      "    \"text\": \"modules have not been experimentally evaluated.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9281383156776428,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            229.75120544433594,\n",
      "            1566.2559814453125\n",
      "          ],\n",
      "          [\n",
      "            229.75120544433594,\n",
      "            1624.42822265625\n",
      "          ],\n",
      "          [\n",
      "            1563.8663330078125,\n",
      "            1624.42822265625\n",
      "          ],\n",
      "          [\n",
      "            1563.8663330078125,\n",
      "            1566.2559814453125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"parent_id\": \"29e6c92d2c0cf8bae359ed4de31cd9ce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9c0518738c781b10f2f5f102a297122a\",\n",
      "    \"text\": \"To the best of our knowledge, our neural long-term memory module is the first linear recurrent model with momentum-\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1643.4288888888889\n",
      "          ],\n",
      "          [\n",
      "            199.16944444444442,\n",
      "            1671.1027777777776\n",
      "          ],\n",
      "          [\n",
      "            1564.6706315511115,\n",
      "            1671.1027777777776\n",
      "          ],\n",
      "          [\n",
      "            1564.6706315511115,\n",
      "            1643.4288888888889\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"parent_id\": \"29e6c92d2c0cf8bae359ed4de31cd9ce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"201532de74885ecf159c86b0877944b8\",\n",
      "    \"text\": \"based update rule.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9310884475708008,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1652.7628173828125\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1704.3111111111111\n",
      "          ],\n",
      "          [\n",
      "            1566.9254150390625,\n",
      "            1704.3111111111111\n",
      "          ],\n",
      "          [\n",
      "            1566.9254150390625,\n",
      "            1652.7628173828125\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"parent_id\": \"29e6c92d2c0cf8bae359ed4de31cd9ce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"abeadb8f6cd901e714dfed18267087f0\",\n",
      "    \"text\": \"Finally, as a key difference with all the above and other recent linear recurrent studies, note that the hybrid variants of\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            200.0,\n",
      "            1726.4511111111112\n",
      "          ],\n",
      "          [\n",
      "            200.0,\n",
      "            1754.125\n",
      "          ],\n",
      "          [\n",
      "            1559.9865835938879,\n",
      "            1754.125\n",
      "          ],\n",
      "          [\n",
      "            1559.9865835938879,\n",
      "            1726.4511111111112\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"parent_id\": \"29e6c92d2c0cf8bae359ed4de31cd9ce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f2141e3c24abe309c99088bf712cc58f\",\n",
      "    \"text\": \"modern linear models\\u2013such as Griffin (De et al. 2024), DeltaNet (S. Yang, B. Wang, Yu Zhang, et al. 2024), Gated DeltaNet (S. Yang, Kautz, and Hatamizadeh 2024), H3 (D. Y. Fu et al. 2023), Mamba2 (Dao and Gu 2024), Samba (Ren et al. 2024), etc.\\u2013all are based on sequential layer-wise design. We present Titans to show how effectively one can incorporate such memory modules into an architecture.\",\n",
      "    \"metadata\": {\n",
      "      \"detection_class_prob\": 0.9490077495574951,\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            199.19722222222222,\n",
      "            1734.12841796875\n",
      "          ],\n",
      "          [\n",
      "            199.19722222222222,\n",
      "            1890.4754638671875\n",
      "          ],\n",
      "          [\n",
      "            1569.865478515625,\n",
      "            1890.4754638671875\n",
      "          ],\n",
      "          [\n",
      "            1569.865478515625,\n",
      "            1734.12841796875\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@de2024griffin\",\n",
      "          \"start_index\": 169\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024parallelizing\",\n",
      "          \"start_index\": 221\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@yang2024gated\",\n",
      "          \"start_index\": 276\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.0@fu2023hungry\",\n",
      "          \"start_index\": 303\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@dao2024transformers\",\n",
      "          \"start_index\": 329\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2024\",\n",
      "          \"url\": \"cite.0@ren2024samba\",\n",
      "          \"start_index\": 354\n",
      "        }\n",
      "      ],\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"parent_id\": \"29e6c92d2c0cf8bae359ed4de31cd9ce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"50c421a5c884436b537331311264b66d\",\n",
      "    \"text\": \"27\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            867.1305555555556,\n",
      "            2057.742777777778\n",
      "          ],\n",
      "          [\n",
      "            867.1305555555556,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222223,\n",
      "            2085.4166666666665\n",
      "          ],\n",
      "          [\n",
      "            892.8672722222223,\n",
      "            2057.742777777778\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 1700,\n",
      "        \"layout_height\": 2200\n",
      "      },\n",
      "      \"last_modified\": \"2025-01-25T14:52:27\",\n",
      "      \"filetype\": \"application/pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"page_number\": 27,\n",
      "      \"parent_id\": \"29e6c92d2c0cf8bae359ed4de31cd9ce\",\n",
      "      \"file_directory\": \"PDF STORE\",\n",
      "      \"filename\": \"2501.00663v1.pdf\"\n",
      "    }\n",
      "  }\n",
      "]\n",
      "{'Header', 'FigureCaption', 'ListItem', 'UncategorizedText', 'Image', 'NarrativeText', 'Formula', 'Table', 'Title'}\n"
     ]
    }
   ],
   "source": [
    "element_dict = [el.to_dict() for el in raw_pdf_elements]\n",
    "\n",
    "\n",
    "unique_types = set()\n",
    "\n",
    "for item in element_dict:\n",
    "    unique_types.add(item['type'])\n",
    "\n",
    "print(output)\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'UncategorizedText',\n",
       "  'element_id': 'ae76beb8b6ba3840cf7c218ebd451188',\n",
       "  'text': '4',\n",
       "  'metadata': {'coordinates': {'points': ((45.388888888888886,\n",
       "      583.4999999999998),\n",
       "     (45.388888888888886, 611.2777777777776),\n",
       "     (100.94444444444446, 611.2777777777776),\n",
       "     (100.94444444444446, 583.4999999999998)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '3b3b7b2f2b303144b9b46b127b608af2',\n",
       "  'text': '2024',\n",
       "  'metadata': {'coordinates': {'points': ((51.0, 585.0),\n",
       "     (51.0, 692.0),\n",
       "     (88.0, 692.0),\n",
       "     (88.0, 585.0)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '98444d1a397190296801f0122c0b0fa0',\n",
       "  'text': '2',\n",
       "  'metadata': {'coordinates': {'points': ((45.388888888888886,\n",
       "      611.2777777777776),\n",
       "     (45.388888888888886, 639.0555555555554),\n",
       "     (100.94444444444446, 639.0555555555554),\n",
       "     (100.94444444444446, 611.2777777777776)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'ebc8aef60edf874ef0c26276dbe0bf9e',\n",
       "  'text': '0',\n",
       "  'metadata': {'coordinates': {'points': ((45.388888888888886,\n",
       "      639.0555555555554),\n",
       "     (45.388888888888886, 666.8333333333331),\n",
       "     (100.94444444444446, 666.8333333333331),\n",
       "     (100.94444444444446, 639.0555555555554)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'a61efef3b4d0a1cb062ec015097b08b7',\n",
       "  'text': '2',\n",
       "  'metadata': {'coordinates': {'points': ((45.388888888888886,\n",
       "      666.8333333333331),\n",
       "     (45.388888888888886, 694.611111111111),\n",
       "     (100.94444444444446, 694.611111111111),\n",
       "     (100.94444444444446, 666.8333333333331)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Header',\n",
       "  'element_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "  'text': 'c e D 1 3 ] G L . s c [ 1 v 3 6 6 0 0 . 1 0 5 2',\n",
       "  'metadata': {'detection_class_prob': 0.5007292628288269,\n",
       "   'coordinates': {'points': ((45.388888888888886, 691.5743408203125),\n",
       "     (45.388888888888886, 1413.611111111111),\n",
       "     (100.94444444444446, 1413.611111111111),\n",
       "     (100.94444444444446, 691.5743408203125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '64051a16861382fe6b4ad393d82bae48',\n",
       "  'text': ':',\n",
       "  'metadata': {'coordinates': {'points': ((45.388888888888886,\n",
       "      1413.611111111111),\n",
       "     (45.388888888888886, 1429.0555555555557),\n",
       "     (100.94444444444446, 1429.0555555555557),\n",
       "     (100.94444444444446, 1413.611111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '0434bbf276c234f08789b90f8b6b1d6f',\n",
       "  'text': 'v',\n",
       "  'metadata': {'coordinates': {'points': ((45.388888888888886,\n",
       "      1429.0555555555557),\n",
       "     (45.388888888888886, 1456.8333333333335),\n",
       "     (100.94444444444446, 1456.8333333333335),\n",
       "     (100.94444444444446, 1429.0555555555557)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '9179d8cc861adb2b5257c86d2f5031fd',\n",
       "  'text': 'arXiv',\n",
       "  'metadata': {'coordinates': {'points': ((50.0, 1429.0),\n",
       "     (50.0, 1553.0),\n",
       "     (88.0, 1553.0),\n",
       "     (88.0, 1429.0)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'f80706bc38d55a50473e05f7d0d9f439',\n",
       "  'text': 'i',\n",
       "  'metadata': {'coordinates': {'points': ((45.388888888888886,\n",
       "      1456.8333333333335),\n",
       "     (45.388888888888886, 1472.2777777777776),\n",
       "     (100.94444444444446, 1472.2777777777776),\n",
       "     (100.94444444444446, 1456.8333333333335)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '2805cbe3fd490af78b39effe65221df5',\n",
       "  'text': 'X',\n",
       "  'metadata': {'coordinates': {'points': ((45.388888888888886,\n",
       "      1472.2777777777776),\n",
       "     (45.388888888888886, 1512.388888888889),\n",
       "     (100.94444444444446, 1512.388888888889),\n",
       "     (100.94444444444446, 1472.2777777777776)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'b06ceacb4e1b1372c5e61f3dc87c5564',\n",
       "  'text': 'r',\n",
       "  'metadata': {'coordinates': {'points': ((45.388888888888886,\n",
       "      1512.388888888889),\n",
       "     (45.388888888888886, 1530.888888888889),\n",
       "     (100.94444444444446, 1530.888888888889),\n",
       "     (100.94444444444446, 1512.388888888889)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'ab01bd2ddd49b583abac6f2aa190bbb2',\n",
       "  'text': 'a',\n",
       "  'metadata': {'coordinates': {'points': ((45.388888888888886,\n",
       "      1530.888888888889),\n",
       "     (45.388888888888886, 1555.5555555555554),\n",
       "     (100.94444444444446, 1555.5555555555554),\n",
       "     (100.94444444444446, 1530.888888888889)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'dc616f19f1c3b5c6044b3791dca01fb2',\n",
       "  'text': 'Titans: Learning to Memorize at Test Time',\n",
       "  'metadata': {'coordinates': {'points': ((461.83888888888885,\n",
       "      298.4794444444443),\n",
       "     (461.83888888888885, 346.3),\n",
       "     (1298.1725850000003, 346.3),\n",
       "     (1298.1725850000003, 298.4794444444443)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '7556ea94cf4df7dc9b7d89e0db26dc96',\n",
       "  'text': 'Ali Behrouz†, Peilin Zhong†, and Vahab Mirrokni†',\n",
       "  'metadata': {'coordinates': {'points': ((541.9361111111111,\n",
       "      412.62444444444446),\n",
       "     (541.9361111111111, 448.5944444444445),\n",
       "     (1215.2972222222222, 448.5944444444445),\n",
       "     (1215.2972222222222, 412.62444444444446)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'be258a5f527696ad84c3fdd838869dbc',\n",
       "  'text': '†Google Research',\n",
       "  'metadata': {'coordinates': {'points': ((760.9472222222223,\n",
       "      497.6355555555557),\n",
       "     (760.9472222222223, 533.6055555555557),\n",
       "     (999.0541911111113, 533.6055555555557),\n",
       "     (999.0541911111113, 497.6355555555557)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'fbcc8565ecdc4b03f3ca02d5be2f1660',\n",
       "  'text': '{alibehrouz, peilinz, mirrokni}@google.com',\n",
       "  'metadata': {'detection_class_prob': 0.5302138924598694,\n",
       "   'coordinates': {'points': ((612.71728515625, 551.7770933333335),\n",
       "     (612.71728515625, 577.0736694335938),\n",
       "     (1153.0628662109375, 577.0736694335938),\n",
       "     (1153.0628662109375, 551.7770933333335)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': 'be258a5f527696ad84c3fdd838869dbc',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '2fa0072307b127b5887126f2e385aac8',\n",
       "  'text': 'Abstract',\n",
       "  'metadata': {'detection_class_prob': 0.8325791358947754,\n",
       "   'coordinates': {'points': ((831.1800537109375, 652.8217733333333),\n",
       "     (831.1800537109375, 677.7284400000001),\n",
       "     (931.5001831054688, 677.7284400000001),\n",
       "     (931.5001831054688, 652.8217733333333)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '06457ac1dfb6f5852dcfb21fd70c9360',\n",
       "  'text': 'Over more than a decade there has been an extensive research effort of how effectively utilize recurrent models and',\n",
       "  'metadata': {'coordinates': {'points': ((306.5444444444444,\n",
       "      692.7294444444445),\n",
       "     (306.5444444444444, 717.6361111111112),\n",
       "     (1490.8157967644447, 717.6361111111112),\n",
       "     (1490.8157967644447, 692.7294444444445)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '2fa0072307b127b5887126f2e385aac8',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '3bd58d1d430055d1faea37ff4f843dae',\n",
       "  'text': 'attentions. While recurrent models aim to compress the data into a fixed-size memory (called hidden state), attention allows attending to the entire context window, capturing the direct dependencies of all tokens. This more accurate modeling of dependencies, however, comes with a quadratic cost, limiting the model to a fixed-length context. We present a new neural long-term memory module that learns to memorize historical context and helps an attention to attend to the current context while utilizing long past information. We show that this neural memory has the advantage of a fast parallelizable training while maintaining a fast inference. From a memory perspective, we argue that attention due to its limited context but accurate dependency modeling performs as a short-term memory, while neural memory due to its ability to memorize the data, acts as a long-term, more persistent, memory. Based on these two modules, we introduce a new family of architectures, called Titans, and present three variants to address how one can effectively incorporate memory into this architecture. Our experimental results on language modeling, common-sense reasoning, genomics, and time series tasks show that Titans are more effective than Transformers and recent modern linear recurrent models. They further can effectively scale to larger than 2M context window size with higher accuracy in needle-in-haystack tasks compared to baselines.',\n",
       "  'metadata': {'detection_class_prob': 0.951355516910553,\n",
       "   'coordinates': {'points': ((268.43888888888887, 699.8678588867188),\n",
       "     (268.43888888888887, 1118.1175537109375),\n",
       "     (1498.198974609375, 1118.1175537109375),\n",
       "     (1498.198974609375, 699.8678588867188)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '2fa0072307b127b5887126f2e385aac8',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '9e61532d939b64b4ef05f4fe075cbcc8',\n",
       "  'text': '“The true art of memory is the art of attention!\"',\n",
       "  'metadata': {'coordinates': {'points': ((1013.1944444444445,\n",
       "      1221.0655555555554),\n",
       "     (1013.1944444444445, 1245.9722222222222),\n",
       "     (1499.3974844444444, 1245.9722222222222),\n",
       "     (1499.3974844444444, 1221.0655555555554)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '2fa0072307b127b5887126f2e385aac8',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'cc4877da7b2209d6a9dfb8e4d7cfaefe',\n",
       "  'text': '1 Introduction',\n",
       "  'metadata': {'detection_class_prob': 0.8291983604431152,\n",
       "   'coordinates': {'points': ((200.0, 1244.527145),\n",
       "     (200.0, 1284.3777005555555),\n",
       "     (490.7098027777778, 1284.3777005555555),\n",
       "     (490.7098027777778, 1244.527145)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '0b18fdcaf3c5c667694ea193f6859363',\n",
       "  'text': '— Samuel Johnson, 1787',\n",
       "  'metadata': {'coordinates': {'points': ((1314.2972222222222, 1271.385),\n",
       "     (1314.2972222222222, 1296.2916666666667),\n",
       "     (1560.5743422222224, 1296.2916666666667),\n",
       "     (1560.5743422222224, 1271.385)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '1b4526c12c274aa7bced0ee07a49325d',\n",
       "  'text': 'Transformers, pure attention-based architectures (Vaswani et al. 2017), have been firmly established as state-of- the-art models in sequence modeling, mainly due to their in-context learning and ability to learn at scale (Kaplan et al. 2020). The primary building blocks of Transformers–attention modules—function as associative memory blocks (Bietti et al. 2024), where they learn to store key-value associations and retrieve them by computing pairwise similarity between queries (i.e., search signals) and keys (i.e., contexts). Accordingly, by design, the output of a Transformer is exclusively conditioned on the direct dependencies of tokens in the current context window. This accurate modeling of dependencies, however, comes with quadratic time and memory complexity in terms of the context length. In complex real-world tasks (e.g., language modeling (N. F. Liu et al. 2024), video understanding (C.-Y. Wu et al. 2019), long-term time series forecasting (H. Zhou et al. 2021)), the context window can become extremely large, making the applicability of Transformers challenging in these downstream tasks.',\n",
       "  'metadata': {'detection_class_prob': 0.9560855031013489,\n",
       "   'coordinates': {'points': ((199.16944444444442, 1329.0083333333334),\n",
       "     (199.16944444444442, 1669.036865234375),\n",
       "     (1566.0584716796875, 1669.036865234375),\n",
       "     (1566.0584716796875, 1329.0083333333334)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2017', 'url': 'cite.0@transformers', 'start_index': 65},\n",
       "    {'text': '2020', 'url': 'cite.0@kaplan2020scaling', 'start_index': 122},\n",
       "    {'text': '2024', 'url': 'cite.0@bietti2024birth', 'start_index': 244},\n",
       "    {'text': '2024', 'url': 'cite.0@liu2024lost', 'start_index': 764},\n",
       "    {'text': '2019', 'url': 'cite.0@wu2019long', 'start_index': 808},\n",
       "    {'text': '2021', 'url': 'cite.0@zhou2021informer', 'start_index': 865}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '0b18fdcaf3c5c667694ea193f6859363',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '4ff7bc09f97313a9d922c70e7cf43dbb',\n",
       "  'text': 'To overcome the scalability issue of Transformers, recent studies aim to design different variants of linear Transform-',\n",
       "  'metadata': {'coordinates': {'points': ((199.16944444444442,\n",
       "      1686.1983333333333),\n",
       "     (199.16944444444442, 1713.8722222222223),\n",
       "     (1564.668306944445, 1713.8722222222223),\n",
       "     (1564.668306944445, 1686.1983333333333)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '0b18fdcaf3c5c667694ea193f6859363',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'a40741f6d6f96bee12b6e002a3c03fd9',\n",
       "  'text': 'ers (Kacham, Mirrokni, and P. Zhong 2024; Katharopoulos et al. 2020; S. Yang, B. Wang, Shen, et al. 2024), where softmax is replaced by a kernel function in the attention (see §2.1 for details), resulting in a significant drop in memory consumption. Despite efficiency and the ability to scale to longer context, linear Transformers do not show competitive performance compared to Transformers as the kernel trick makes the model a linear recurrent network, in which the data is compressed into a matrix-valued states (Katharopoulos et al. 2020). This, however, brings a contradictory fact about linear recurrent (or linear Transformers) models: On one hand, we use these linear models to enhance scalability and efficiency (linear vs. quadratic complexity), whose advantages is appeared for very long context; On the other hand, a very long context cannot be properly compressed in a small vector-valued or matrix-valued states (S. Wang 2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9531335234642029,\n",
       "   'coordinates': {'points': ((200.0, 1693.3958740234375),\n",
       "     (200.0, 1982.5596923828125),\n",
       "     (1569.8333740234375, 1982.5596923828125),\n",
       "     (1569.8333740234375, 1693.3958740234375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@kacham2024polysketchformer',\n",
       "     'start_index': 155},\n",
       "    {'text': '2020',\n",
       "     'url': 'cite.0@katharopoulos2020transformers',\n",
       "     'start_index': 182},\n",
       "    {'text': '2024', 'url': 'cite.0@yang2024gatedattn', 'start_index': 219},\n",
       "    {'text': '2 . 1', 'url': 'subsection.2.1', 'start_index': 296},\n",
       "    {'text': '2020',\n",
       "     'url': 'cite.0@katharopoulos2020transformers',\n",
       "     'start_index': 656}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '0b18fdcaf3c5c667694ea193f6859363',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '007a240dc57502b974430836e347dcf8',\n",
       "  'text': '1',\n",
       "  'metadata': {'coordinates': {'points': ((873.5666666666667,\n",
       "      2057.7427777777775),\n",
       "     (873.5666666666667, 2085.4166666666665),\n",
       "     (886.4350250000001, 2085.4166666666665),\n",
       "     (886.4350250000001, 2057.7427777777775)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '0b18fdcaf3c5c667694ea193f6859363',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'bfd6020af4ea5e1297b2a1c971d2d239',\n",
       "  'text': 'Furthermore, beyond efficiency, most existing architectures–ranging from Hopfield Networks (Hopfield 1982) to LSTMs (Jür- gen Schmidhuber and Hochreiter 1997) and Transformers (Vaswani et al. 2017)–face challenges when dealing with general- ization, length extrapolation, and/or reasoning (Anil et al. 2022; Qin, Y. Zhong, and Deng 2024), all of which are inseparable parts of many hard real-world tasks. Although these architectures draw inspiration from the human brain, each of which are missing: (1) a crucial component for learning process—such as short-term memory, long-term memory, meta-memory, attending to current context, etc. (Cowan 2008); (2) how these components are interconnected systems that can operate independently; and/or (3) the ability to actively learn from data and memorize the abstraction of past history. We argue that in an effective learning paradigm, similar to human brain, there are distinct yet interconnected modules, each of which is responsible for a component crucial to the learning process.',\n",
       "  'metadata': {'detection_class_prob': 0.9529550075531006,\n",
       "   'coordinates': {'points': ((200.0, 202.39277777777778),\n",
       "     (200.0, 501.5894470214844),\n",
       "     (1571.102783203125, 501.5894470214844),\n",
       "     (1571.102783203125, 202.39277777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '1982',\n",
       "     'url': 'cite.0@hopfield1982neural',\n",
       "     'start_index': 97},\n",
       "    {'text': '1997', 'url': 'cite.0@LSTM', 'start_index': 149},\n",
       "    {'text': '2017', 'url': 'cite.0@transformers', 'start_index': 188},\n",
       "    {'text': '2022', 'url': 'cite.0@anil2022exploring', 'start_index': 298},\n",
       "    {'text': '2024', 'url': 'cite.0@qin2024exploring', 'start_index': 328},\n",
       "    {'text': '2008',\n",
       "     'url': 'cite.0@cowan2008differences',\n",
       "     'start_index': 641}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'parent_id': '0b18fdcaf3c5c667694ea193f6859363',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '0fbf17e1930416d8476ab4bf94d006ea',\n",
       "  'text': 'Memory Perspective',\n",
       "  'metadata': {'detection_class_prob': 0.8467845916748047,\n",
       "   'coordinates': {'points': ((198.60475158691406, 547.529031111111),\n",
       "     (198.60475158691406, 580.7379199999998),\n",
       "     (512.2913818359375, 580.7379199999998),\n",
       "     (512.2913818359375, 547.529031111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'parent_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'da65c0ed91096c0827b75a3a3ba8fcc4',\n",
       "  'text': 'Memory is a fundamental mental process and is an inseparable component of human learning (Terry 2017). Without a properly functioning memory system, humans and animals would be restricted to basic reflexes and stereotyped behaviors. Accordingly, memory has been the inspiration for many seminal research in machine learning literature; e.g., Hopfield Networks (Hopfield 1982), LSTMs (Jürgen Schmidhuber and Hochreiter 1997), and Transformers (Vaswani et al. 2017).',\n",
       "  'metadata': {'detection_class_prob': 0.9497999548912048,\n",
       "   'coordinates': {'points': ((200.0, 596.4094444444445),\n",
       "     (200.0, 759.14794921875),\n",
       "     (1568.2139892578125, 759.14794921875),\n",
       "     (1568.2139892578125, 596.4094444444445)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2017',\n",
       "     'url': 'cite.0@terry2017learning',\n",
       "     'start_index': 115},\n",
       "    {'text': '1982', 'url': 'cite.0@hopfield1982neural', 'start_index': 386},\n",
       "    {'text': '1997', 'url': 'cite.0@LSTM', 'start_index': 434}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'parent_id': '0fbf17e1930416d8476ab4bf94d006ea',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '031b49a6b702802dd96a79a4a9fcb3b8',\n",
       "  'text': 'Taking inspiration from the common definitions of memory and learning in neuropsychology literature (Okano, Hirano, and Balaban 2000), most existing architectures consider memory as a neural update caused by an input, and define learning as a process for acquiring effective and useful memory, given an objective. In this perspective, Recurrent Neural Networks (RNNs) (Williams and Zipser 1989) can be defined as models with a vector-valued memory module M (also called hidden state) with two main steps: Given a new input 𝑥𝑡 at time 𝑡, the model (1) updates the memory using a function 𝑓 (M𝑡 −1, 𝑥𝑡 ) (with compression); and (2) retrieves the corresponding memory of input using a function 𝑔(M𝑡, 𝑥𝑡 ) (see §2.1 for details). Similarly, Transformers can be seen as architectures with a growing memory and two similar steps. That is, the pair of key and value matrices acts as the model’s memory, and the model: (1) updates the memory by appending the key and value to the memory (without compression), and (2) retrieves query vectors’ corresponding memory by finding the similarity of query and key vectors, which is then used to weight the value vectors for the output.',\n",
       "  'metadata': {'detection_class_prob': 0.9545361399650574,\n",
       "   'coordinates': {'points': ((199.16944444444442, 779.0566666666666),\n",
       "     (199.16944444444442, 1111.074462890625),\n",
       "     (1572.758544921875, 1111.074462890625),\n",
       "     (1572.758544921875, 779.0566666666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2000',\n",
       "     'url': 'cite.0@okano2000learning',\n",
       "     'start_index': 127},\n",
       "    {'text': '1989', 'url': 'cite.0@williams1989learning', 'start_index': 386},\n",
       "    {'text': '2 . 1', 'url': 'subsection.2.1', 'start_index': 704}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'parent_id': '0fbf17e1930416d8476ab4bf94d006ea',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '1788f2c1c7686bab2f3c13a69a9d593f',\n",
       "  'text': 'This perspective, can help us better understand existing paradigms, their critical differences, and design more effective architectures. For example, the main difference between Transformers (Vaswani et al. 2017) and linear Transform- ers (Katharopoulos et al. 2020) is the memory structure as well as the memory updating step, in which linear Transformers compress the historical data into a fixed-size matrix-valued memory while Transformers keep all historical data (within the context length) without any compression. While both linear Transformers and linear RNNs (including state space models) compress the information in memory update step, the critical difference lies in the structure of the memory, where linear RNNs (vs. linear Transformers) use a vector-valued memory (vs. matrix-valued memory). Therefore, this perspective motivates us to ask: (Q1) What constitute a good structure for the memory? (Q2) What is a proper memory update mechanism? and (Q3) What is a good memory retrieval process?',\n",
       "  'metadata': {'detection_class_prob': 0.9561518430709839,\n",
       "   'coordinates': {'points': ((198.975, 1127.751111111111),\n",
       "     (198.975, 1427.4871127777778),\n",
       "     (1572.2919921875, 1427.4871127777778),\n",
       "     (1572.2919921875, 1127.751111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2017',\n",
       "     'url': 'cite.0@transformers',\n",
       "     'start_index': 204},\n",
       "    {'text': '2020',\n",
       "     'url': 'cite.0@katharopoulos2020transformers',\n",
       "     'start_index': 258}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'parent_id': '0fbf17e1930416d8476ab4bf94d006ea',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '8aabbe8092457b66f46195f13ef080f4',\n",
       "  'text': 'Revisiting our understanding of human memory, it is neither a unitary process nor it serves a single function (Cowan 2008). In fact, memory is a confederation of systems–e.g., short-term, working, and long-term memory–each serving a different function with different neural structures, and each capable of operating independently (Willingham 1997). This fact motivates us to ask: (Q4) How to design an efficient architecture that incorporates different interconnected memory modules. Finally, storing a memory is a neural process that requires to encode and store the abstraction of the past. It can be over-simplification to assume a single vector or a matrix, whose parameters are encoding the data in a linear manner, are enough for storing long-term history. (Q5) Is a deep memory module needed to effectively store/remember long past?',\n",
       "  'metadata': {'detection_class_prob': 0.9537711143493652,\n",
       "   'coordinates': {'points': ((200.0, 1443.2344444444443),\n",
       "     (200.0, 1706.5540771484375),\n",
       "     (1571.5101318359375, 1706.5540771484375),\n",
       "     (1571.5101318359375, 1443.2344444444443)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2008',\n",
       "     'url': 'cite.0@cowan2008differences',\n",
       "     'start_index': 1120},\n",
       "    {'text': '1997',\n",
       "     'url': 'cite.0@willingham1997systems',\n",
       "     'start_index': 1343}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'parent_id': '0fbf17e1930416d8476ab4bf94d006ea',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'dafd65efc97d54029818f315014c9303',\n",
       "  'text': 'Contributions and Roadmap',\n",
       "  'metadata': {'detection_class_prob': 0.8583268523216248,\n",
       "   'coordinates': {'points': ((200.0, 1754.059814453125),\n",
       "     (200.0, 1788.3684755555555),\n",
       "     (628.5275022222222, 1788.3684755555555),\n",
       "     (628.5275022222222, 1754.059814453125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'parent_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'd044351a8edb5f7286807da54e5a69c2',\n",
       "  'text': 'In this paper, we aim to answer the above five questions by designing a long-term neural memory module, that can efficiently and effectively learn to memorize at test time. Building upon its design, we discuss how it can be incorporated into an architecture.',\n",
       "  'metadata': {'detection_class_prob': 0.9365269541740417,\n",
       "   'coordinates': {'points': ((200.0, 1804.0399999999997),\n",
       "     (200.0, 1899.3616943359375),\n",
       "     (1565.8660888671875, 1899.3616943359375),\n",
       "     (1565.8660888671875, 1804.0399999999997)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'parent_id': 'dafd65efc97d54029818f315014c9303',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'c06bcb6d47e9e25fbd9feb29b4585b44',\n",
       "  'text': 'Neural Memory (§3). We present a (deep) neural long-term memory that (as a meta in-context model) learns how to memorize/store the data into its parameters at test time. Inspired by human long-term memory system (Mandler 2014),',\n",
       "  'metadata': {'detection_class_prob': 0.9253687858581543,\n",
       "   'coordinates': {'points': ((200.0, 1920.2705555555556),\n",
       "     (200.0, 1984.8072509765625),\n",
       "     (1563.0466792055547, 1984.8072509765625),\n",
       "     (1563.0466792055547, 1920.2705555555556)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '3', 'url': 'section.3', 'start_index': 16}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'parent_id': 'dafd65efc97d54029818f315014c9303',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'eed5f55e0cf28b104b73550a502d0e7b',\n",
       "  'text': '2',\n",
       "  'metadata': {'coordinates': {'points': ((873.5666666666666,\n",
       "      2057.742777777778),\n",
       "     (873.5666666666666, 2085.4166666666665),\n",
       "     (886.4350249999999, 2085.4166666666665),\n",
       "     (886.4350249999999, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'parent_id': 'dafd65efc97d54029818f315014c9303',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'b10095f7042651ad33667419f5261c7a',\n",
       "  'text': 'we design this memory module so an event that violates the expectations (being surprising) is more memorable. To this end, we measure the surprise of an input with the gradient of the neural network with respect to the input in associative memory loss (see §3.1 for details). To better handle the limited memory, we present a decaying mechanism that consider the proportion of memory size and the amount of data surprise, resulting in better memory management. We show that this decay mechanism is in fact the generalization of forgetting mechanism in modern recurrent models (Dao and Gu 2024; Gu and Dao 2024; S. Yang, Kautz, and Hatamizadeh 2024). Interestingly, we find that this mechanism is equivalent to optimizing a meta neural network with mini-batch gradient descent, momentum, and weight decay. Building upon tensorizing mini-batch gradient descent to use more matmul operations (Yu Sun et al. 2024), we present a fast and parallelizable algorithm to train our deep neural long-term memory.',\n",
       "  'metadata': {'detection_class_prob': 0.9539293050765991,\n",
       "   'coordinates': {'points': ((198.975, 202.39277777777778),\n",
       "     (198.975, 500.7691955566406),\n",
       "     (1569.88037109375, 500.7691955566406),\n",
       "     (1569.88037109375, 202.39277777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '3 . 1', 'url': 'subsection.3.1', 'start_index': 258},\n",
       "    {'text': '2024', 'url': 'cite.0@dao2024transformers', 'start_index': 588},\n",
       "    {'text': '2024', 'url': 'cite.0@gu2024mamba', 'start_index': 605},\n",
       "    {'text': '2024', 'url': 'cite.0@yang2024gated', 'start_index': 643},\n",
       "    {'text': '2024', 'url': 'cite.0@sun2024learning', 'start_index': 903}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'parent_id': 'dafd65efc97d54029818f315014c9303',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '20a2f94f10d8f87c8b497d9fc0799517',\n",
       "  'text': 'Titans Architectures (§4). After designing the long-term neural memory, an important remaining question is how to effectively and efficiently incorporate memory into a deep learning architecture. We present Titans, a family of deep models that consists of three hyper-heads: (1) Core: this module consists of the short-term memory, and is responsible for the main flow of processing the data (we use attention with limited window size); (2) Long-term Memory: this branch is our neural long-term memory module that is responsible to store/remember long past; (3) Persistent Memory: this is a set of learnable but date-independent parameters that encodes the knowledge about a task. Finally, as a proof of concept, we present three variants of Titans, in which we incorporate memory as: (i) a context, (ii) a layer, and (iii) a gated branch.',\n",
       "  'metadata': {'detection_class_prob': 0.9561544060707092,\n",
       "   'coordinates': {'points': ((199.0861111111111, 517.878888888889),\n",
       "     (199.0861111111111, 751.0279541015625),\n",
       "     (1572.8656005859375, 751.0279541015625),\n",
       "     (1572.8656005859375, 517.878888888889)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '4', 'url': 'section.4', 'start_index': 23}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'parent_id': 'dafd65efc97d54029818f315014c9303',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0bc9ea02c9460b8e0563e9a001a63eff',\n",
       "  'text': 'Experimental Results (§5). We perform experimental evaluations on language modeling, commonsense reasoning, recall- intensive, needle in haystack, time series forecasting, and DNA modeling tasks. We observe that our Titan architecture outperforms all modern recurrent models as well as their hybrid variants (combining with sliding-window attention) across a comprehensive set of benchmarks. Furthermore, Titans outperforms Transformers with the same context window, and show competitive performance with Transformers that use the entire context. This results are achieved while, contrary to Transformers, Titans scale to larger than 2M context window size.',\n",
       "  'metadata': {'detection_class_prob': 0.9531001448631287,\n",
       "   'coordinates': {'points': ((199.16944444444442, 766.9427777777779),\n",
       "     (199.16944444444442, 965.3643798828125),\n",
       "     (1568.655029296875, 965.3643798828125),\n",
       "     (1568.655029296875, 766.9427777777779)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '5', 'url': 'section.5', 'start_index': 23}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'parent_id': 'dafd65efc97d54029818f315014c9303',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '737bbf88de406398ae1aa6597e489690',\n",
       "  'text': '2 Preliminaries',\n",
       "  'metadata': {'detection_class_prob': 0.8539012670516968,\n",
       "   'coordinates': {'points': ((200.0, 1016.1132202148438),\n",
       "     (200.0, 1058.9138116666668),\n",
       "     (508.08966064453125, 1058.9138116666668),\n",
       "     (508.08966064453125, 1016.1132202148438)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'parent_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '4b22948a2b1bcbd7e5716129d49253a4',\n",
       "  'text': 'In this section, we discuss the notation and some background concepts that we use though the paper. We let 𝑥 ∈ R𝑁 ×𝑑in be the input, M be a neural network (neural memory module), Q, K, V be the query, key and value of the attention mechanism, and M be the attention mask. When segmenting the sequence, we use S(𝑖 ) to refer to the 𝑖-th segment. Through the paper, we abuse the notation and use subscripts to refer to a specific element of a matrix, vector, or segments. For example, we let S(𝑖 ) 𝑗 be the 𝑗-th token in the 𝑖-th segment. The only exception is subscripts with 𝑡, which we reserved to index recurrence over time, or the state of a neural network at time 𝑡. Given a neural network N and a data sample 𝑥, we use N (𝑥) (resp. N ∗ (𝑥)) to refer to the forward pass with (resp. without) weight adjustment. Also, we abuse the notation and use N (𝑘 ) to refer to the 𝑘-th layer of the neural network. In the following, we first, discuss the backgrounds for attention and its efficient variants followed by a review of modern linear RNNs. Finally, we discuss a memory perspective of these architectures that motivates us to design Titans.',\n",
       "  'metadata': {'detection_class_prob': 0.9555183053016663,\n",
       "   'coordinates': {'points': ((197.6663360595703, 1074.0472222222222),\n",
       "     (197.6663360595703, 1419.557373046875),\n",
       "     (1569.7445068359375, 1419.557373046875),\n",
       "     (1569.7445068359375, 1074.0472222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'parent_id': '737bbf88de406398ae1aa6597e489690',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '091a2cbb405d72b4a0b75ca0b2d41adb',\n",
       "  'text': '2.1 Backgrounds',\n",
       "  'metadata': {'detection_class_prob': 0.8662165999412537,\n",
       "   'coordinates': {'points': ((197.19955444335938, 1460.4884033203125),\n",
       "     (197.19955444335938, 1495.896253333333),\n",
       "     (474.5708923339844, 1495.896253333333),\n",
       "     (474.5708923339844, 1460.4884033203125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'parent_id': '3cc0a534c93b72edb6760710ec586c98',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '21d60257a47fb5bd9b6f7d93b265cdb8',\n",
       "  'text': 'Attention. Transformers (Vaswani et al. 2017) as the de facto backbone for many deep learning models are based on attention mechanism. Given input 𝑥 ∈ R𝑁 ×𝑑in, causal attention computes output y ∈ R𝑁 ×𝑑in based on softmax over input dependent key, value, and query matrices:',\n",
       "  'metadata': {'detection_class_prob': 0.9318703413009644,\n",
       "   'coordinates': {'points': ((198.975, 1524.9538888888887),\n",
       "     (198.975, 1625.5074462890625),\n",
       "     (1563.1890869140625, 1625.5074462890625),\n",
       "     (1563.1890869140625, 1524.9538888888887)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2017',\n",
       "     'url': 'cite.0@transformers',\n",
       "     'start_index': 40}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'parent_id': '091a2cbb405d72b4a0b75ca0b2d41adb',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '47db4f5ec96d73e78ba59a4221c628c0',\n",
       "  'text': 'Q = 𝑥WQ, K = 𝑥WK, V = 𝑥WV, (1)',\n",
       "  'metadata': {'detection_class_prob': 0.5782061219215393,\n",
       "   'coordinates': {'points': ((640.1288452148438, 1638.7344444444443),\n",
       "     (640.1288452148438, 1679.1483154296875),\n",
       "     (1565.36767578125, 1679.1483154296875),\n",
       "     (1565.36767578125, 1638.7344444444443)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'a876e96f110f4ad18223db3ba933c162',\n",
       "  'text': '√',\n",
       "  'metadata': {'coordinates': {'points': ((993.2083333333331,\n",
       "      1674.418653333333),\n",
       "     (993.2083333333331, 1702.0925422222217),\n",
       "     (1012.6630772222221, 1702.0925422222217),\n",
       "     (1012.6630772222221, 1674.418653333333)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'b0a476468d8936b39a0c798f7713cc08',\n",
       "  'text': 'exp',\n",
       "  'metadata': {'coordinates': {'points': ((858.1055555555554,\n",
       "      1678.2541977777776),\n",
       "     (858.1055555555554, 1719.5694444444443),\n",
       "     (914.8824599999997, 1719.5694444444443),\n",
       "     (914.8824599999997, 1678.2541977777776)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '0022a45afbe87b763836f5cdb33a9c34',\n",
       "  'text': 'i exp (Q7K;/Van) Vi 2) yi= i 2 F=1 Deas exp (Q7K:/ Van)',\n",
       "  'metadata': {'detection_class_prob': 0.7841492891311646,\n",
       "   'coordinates': {'points': ((732.2149658203125, 1692.1999683333333),\n",
       "     (732.2149658203125, 1795.6583251953125),\n",
       "     (1565.05322265625, 1795.6583251953125),\n",
       "     (1565.05322265625, 1692.1999683333333)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '33031730ba5795853b6a5c7a86c98dd3',\n",
       "  'text': 'where WQ, WK, and WV ∈ R𝑑in ×𝑑in are learnable parameters. Despite the power and effectiveness in recall, transformers need at least 𝑁 × 𝑑 operators to calculate the output, resulting in larger memory consumption and lower-throughput for longer sequences.',\n",
       "  'metadata': {'detection_class_prob': 0.9345545768737793,\n",
       "   'coordinates': {'points': ((198.975, 1809.5424991666666),\n",
       "     (198.975, 1909.30224609375),\n",
       "     (1566.3614501953125, 1909.30224609375),\n",
       "     (1566.3614501953125, 1809.5424991666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'be6359e16c77300785bb6795868935b8',\n",
       "  'text': 'Efficient Attentions. To improve the memory consumption and throughput of softmax attention for longer sequences,',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 1941.5122222222221),\n",
       "     (200.0, 1975.5787794444443),\n",
       "     (1563.0456752305554, 1975.5787794444443),\n",
       "     (1563.0456752305554, 1941.5122222222221)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'd6fa1c186ddac79feec9a12f6ef82464',\n",
       "  'text': 'various studies focused on I/O aware implementations of attention (Dao 2024; Dao, D. Fu, et al. 2022), designing more',\n",
       "  'metadata': {'detection_class_prob': 0.9241685271263123,\n",
       "   'coordinates': {'points': ((199.30833333333334, 1950.0816650390625),\n",
       "     (199.30833333333334, 2006.7880859375),\n",
       "     (1563.4503173828125, 2006.7880859375),\n",
       "     (1563.4503173828125, 1950.0816650390625)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'c7742d6152097208b9ec5bbc8d78f3d7',\n",
       "  'text': '3',\n",
       "  'metadata': {'coordinates': {'points': ((873.5666666666666,\n",
       "      2057.742777777778),\n",
       "     (873.5666666666666, 2085.4166666666665),\n",
       "     (886.4350249999999, 2085.4166666666665),\n",
       "     (886.4350249999999, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '31b1c3e59075b89f001b06d485e078e1',\n",
       "  'text': 'efficient attention mechanisms by sparsifying the attention matrix (B. Chen et al. 2021; Choromanski et al. 2021; Dai et al.',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 202.39277777777778),\n",
       "     (200.0, 230.06666666666652),\n",
       "     (1564.2516003277779, 230.06666666666652),\n",
       "     (1564.2516003277779, 202.39277777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2021',\n",
       "     'url': 'cite.0@chen2021scatterbrain',\n",
       "     'start_index': 81},\n",
       "    {'text': '2021',\n",
       "     'url': 'cite.0@choromanski2021rethinking',\n",
       "     'start_index': 106}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '2d8adbe6141634652dcfcdab0ee926d0',\n",
       "  'text': '2019), approximating the softmax (Arora et al. 2024), or developing kernel-based (linear) attentions (Aksenov et al. 2024; Kacham, Mirrokni, and P. Zhong 2024; Schlag, Irie, and Jürgen Schmidhuber 2021; S. Yang, B. Wang, Shen, et al. 2024). In this part, we focus on the later, i.e., linear attentions, where the softmax in standard attention is replaced with an alternative kernel function 𝜙 (., .), such that 𝜙 (𝑥, 𝑦) = 𝜙 (𝑥)𝜙 (𝑦). Accordingly, the attention can be written as:',\n",
       "  'metadata': {'detection_class_prob': 0.9403567910194397,\n",
       "   'coordinates': {'points': ((200.0, 211.0892791748047),\n",
       "     (200.0, 369.2322082519531),\n",
       "     (1568.9061279296875, 369.2322082519531),\n",
       "     (1568.9061279296875, 211.0892791748047)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2021',\n",
       "     'url': 'cite.0@chen2021scatterbrain',\n",
       "     'start_index': 81},\n",
       "    {'text': '2021',\n",
       "     'url': 'cite.0@choromanski2021rethinking',\n",
       "     'start_index': 106},\n",
       "    {'text': '2019', 'url': 'cite.0@dai2019transformerxl', 'start_index': 123},\n",
       "    {'text': '2024', 'url': 'cite.0@arora2024simple', 'start_index': 170},\n",
       "    {'text': '2024', 'url': 'cite.0@aksenov2024linear', 'start_index': 240},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@kacham2024polysketchformer',\n",
       "     'start_index': 277},\n",
       "    {'text': '2021', 'url': 'cite.0@schlag2021linear', 'start_index': 320},\n",
       "    {'text': '2024', 'url': 'cite.0@yang2024gatedattn', 'start_index': 357}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '820d81d701e72e294c7df161b385a055',\n",
       "  'text': 'y= y $QIK) 8 y $Q)*HK) — y, _ 9QI\" Dhan HRV) 6) 44 GOK) 9 AYE GQ) OK) 7 GQ) Diy (KD) *',\n",
       "  'metadata': {'detection_class_prob': 0.8185433745384216,\n",
       "   'coordinates': {'points': ((428.2182312011719, 390.1174991666671),\n",
       "     (428.2182312011719, 482.94342041015625),\n",
       "     (1580.0831298828125, 482.94342041015625),\n",
       "     (1580.0831298828125, 390.1174991666671)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '781fb1a5e2db41e37d462c3779de8705',\n",
       "  'text': 'resulting in a higher-throughput as terms ));_, $(Kj) and D/_, $(Kr) are re-using in each step. When choosing the kernel as identity matrix (Yutao Sun et al. 2023), the above formulation can also be written in a recurrent format:',\n",
       "  'metadata': {'detection_class_prob': 0.9172530770301819,\n",
       "   'coordinates': {'points': ((200.0, 502.54527694444465),\n",
       "     (200.0, 573.5322875976562),\n",
       "     (1559.9925452044442, 573.5322875976562),\n",
       "     (1559.9925452044442, 502.54527694444465)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': 'd7dbd1f0358b6cd65332e8937120ba04',\n",
       "  'text': 'M𝑡 = M𝑡 −1 + 𝐾 ⊤ 𝑡 𝑉𝑡 , y𝑡 = 𝑄𝑡 M𝑡 , (4) (5)',\n",
       "  'metadata': {'detection_class_prob': 0.5836780071258545,\n",
       "   'coordinates': {'points': ((762.4777777777775, 596.0965288888888),\n",
       "     (762.4777777777775, 681.5372924804688),\n",
       "     (1572.57421875, 681.5372924804688),\n",
       "     (1572.57421875, 596.0965288888888)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'd452334e1d09d58aeb47d41f975c17c9',\n",
       "  'text': 'which allows efficient inference for linear attentions.',\n",
       "  'metadata': {'coordinates': {'points': ((198.97499999999977,\n",
       "      695.8455555555553),\n",
       "     (198.97499999999977, 723.519444444444),\n",
       "     (796.1498483333329, 723.519444444444),\n",
       "     (796.1498483333329, 695.8455555555553)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'b8d96e998e21df57af4e0f807e3bf5b1',\n",
       "  'text': 'Modern Linear Models and Their Memory Perspective. As discussed earlier, one can define learning as a process for acquiring effective and useful memory. Building upon this, one can see the hidden state of Recurrent Neural Networks (RNNs) as a memory unit, which the model aims to compress the information into. Accordingly, in a general form of recurrent neural network, the hidden state can be treated as a memory unit and the recurrence process can be split into the read and write operations in the memory unit. That is, we let 𝑥 ∈ R𝑁 ×𝑑in be the input, M ∈ R𝑑 is the memory unit, and y ∈ R𝑑in is the output, then the general form of the recurrent neural network is defined as:',\n",
       "  'metadata': {'detection_class_prob': 0.9501790404319763,\n",
       "   'coordinates': {'points': ((199.16944444444442, 759.0455555555554),\n",
       "     (199.16944444444442, 959.1288833333333),\n",
       "     (1564.4229736328125, 959.1288833333333),\n",
       "     (1564.4229736328125, 759.0455555555554)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '0df1f91352937b2bedfce59e94888cf0',\n",
       "  'text': 'M𝑡 = 𝑓 (M𝑡 −1, 𝑥𝑡 ), Write Operation y𝑡 = 𝑔(M𝑡, 𝑥𝑡 ), Read Operation (6) (7)',\n",
       "  'metadata': {'detection_class_prob': 0.7139307856559753,\n",
       "   'coordinates': {'points': ((627.1306762695312, 982.4399999999999),\n",
       "     (627.1306762695312, 1059.58935546875),\n",
       "     (1564.5587158203125, 1059.58935546875),\n",
       "     (1564.5587158203125, 982.4399999999999)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '79c29d607ace971c4882534a8fbf2e72',\n",
       "  'text': 'where 𝑓 (., .) is the read and 𝑔(., .) is the write corresponding functions. Note that here the subscript of M𝑡 shows the state of the memory at time 𝑡.',\n",
       "  'metadata': {'detection_class_prob': 0.9162834882736206,\n",
       "   'coordinates': {'points': ((198.975, 1081.3011111111111),\n",
       "     (198.975, 1146.170654296875),\n",
       "     (1562.2532958984375, 1146.170654296875),\n",
       "     (1562.2532958984375, 1081.3011111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '9608ee09dca151e2488e2fa42deb50e8',\n",
       "  'text': 'In this perspective, the recurrence formula of linear Transformers (see Equation 4) is equivalent to additively compress and write keys and values, (𝐾𝑡, 𝑉𝑡 ), into a matrix-valued memory unit M𝑡 . Therefore, when dealing with long context data, this additive nature of the process results in memory overflow, significantly damaging the performance of the model. To address this, studies have focused on two promising directions: (1) Adding forget mechanism: several studies have presented adaptive (data-dependent) forgetting gate mechanisms for linear models, where it can erase the memory when it is needed. As examples of such models, we refer to GLA (S. Yang, B. Wang, Shen, et al. 2024), LRU (Orvieto et al. 2023), Griffin (De et al. 2024), xLSTM (Beck et al. 2024), and Mamba2 (Dao and Gu 2024), which the later is also connected to the discretized version of traditional state space models (Gu and Dao 2024).(2) Improving the write operation: To overcome the additive nature of memory write operation in traditional recurrent models, Widrow and Hoff (1988) presented Delta Rule, in which before adding a memory (i.e., a pair of key and value), the model first removes its past value. To enhance the parallelizable training and scaling, S. Yang, B. Wang, Yu Zhang, et al. (2024) present a fast paralellizable algorithm. Finally, very recently, S. Yang, Kautz, and Hatamizadeh (2024) improved the DeltaNets by adding a forget gate.',\n",
       "  'metadata': {'detection_class_prob': 0.9542672634124756,\n",
       "   'coordinates': {'points': ((199.16944444444442, 1164.3233333333333),\n",
       "     (199.16944444444442, 1563.8302001953125),\n",
       "     (1564.2681493133327, 1563.8302001953125),\n",
       "     (1564.2681493133327, 1164.3233333333333)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Equation 4', 'url': 'equation.2.4', 'start_index': 72},\n",
       "    {'text': '2024', 'url': 'cite.0@yang2024gatedattn', 'start_index': 684},\n",
       "    {'text': '2023',\n",
       "     'url': 'cite.0@orvieto2023resurrecting',\n",
       "     'start_index': 711},\n",
       "    {'text': '2024', 'url': 'cite.0@de2024griffin', 'start_index': 735},\n",
       "    {'text': '2024', 'url': 'cite.0@beck2024xlstm', 'start_index': 761},\n",
       "    {'text': '2024', 'url': 'cite.0@dao2024transformers', 'start_index': 791},\n",
       "    {'text': '2024', 'url': 'cite.0@gu2024mamba', 'start_index': 905},\n",
       "    {'text': '1988', 'url': 'cite.0@widrow1988adaptive', 'start_index': 1053},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@yang2024parallelizing',\n",
       "     'start_index': 1273}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '02f1078d9260e62223ea138eb40b265b',\n",
       "  'text': 'Memory Modules. Memory has always been one of the core parts of the neural network designs (Graves, Wayne, and Danihelka 2014; JH Schmidhuber 1992; Jürgen Schmidhuber and Hochreiter 1997; J. Zhang et al. 2024). The idea of seeing linear layers as the key-value (associative) memory system backs to fast weight programs, in which dynamic fast programs are incorporated into recurrent neural networks to serve as writable memory (JH Schmidhuber 1992). The two learning rules of Hebbian (Hebb 2005) and delta (Prados and Kak 1989) are the most popular learning rules for fast weight programs, which have been extensively explored in various studies (Irie, Schlag, et al. 2021; Munkhdalai, Sordoni, et al. 2019; Munkhdalai and H. Yu 2017; Schlag, Irie, and Jürgen Schmidhuber 2021; JH Schmidhuber 1992; S. Yang, Kautz, and Hatamizadeh 2024; S. Yang, B. Wang, Yu Zhang, et al. 2024). All these models, however, are based on momentary surprise, missing the token flow in the sequences (see Section 3.1), and most of them lacks a forgetting gate, resulting in a poor memory management.',\n",
       "  'metadata': {'detection_class_prob': 0.9524841904640198,\n",
       "   'coordinates': {'points': ((200.0, 1592.8177777777778),\n",
       "     (200.0, 1924.157470703125),\n",
       "     (1564.601318359375, 1924.157470703125),\n",
       "     (1564.601318359375, 1592.8177777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2014',\n",
       "     'url': 'cite.0@graves2014neuralturingmachines',\n",
       "     'start_index': 121},\n",
       "    {'text': '1992',\n",
       "     'url': 'cite.0@schmidhuber1992learning',\n",
       "     'start_index': 142},\n",
       "    {'text': '1997', 'url': 'cite.0@LSTM', 'start_index': 182},\n",
       "    {'text': '2024', 'url': 'cite.0@zhang2024memory', 'start_index': 204},\n",
       "    {'text': '1992',\n",
       "     'url': 'cite.0@schmidhuber1992learning',\n",
       "     'start_index': 443},\n",
       "    {'text': '2005', 'url': 'cite.0@hebb2005organization', 'start_index': 490},\n",
       "    {'text': '1989', 'url': 'cite.0@prados1989neural', 'start_index': 522},\n",
       "    {'text': '2021', 'url': 'cite.0@irie2021going', 'start_index': 668},\n",
       "    {'text': '2019',\n",
       "     'url': 'cite.0@munkhdalai2019metalearned',\n",
       "     'start_index': 702},\n",
       "    {'text': '2017', 'url': 'cite.0@munkhdalai2017neural', 'start_index': 729},\n",
       "    {'text': '2021', 'url': 'cite.0@schlag2021linear', 'start_index': 772},\n",
       "    {'text': '1992',\n",
       "     'url': 'cite.0@schmidhuber1992learning',\n",
       "     'start_index': 793},\n",
       "    {'text': '2024', 'url': 'cite.0@yang2024gated', 'start_index': 831},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@yang2024parallelizing',\n",
       "     'start_index': 872},\n",
       "    {'text': 'Section 3 . 1', 'url': 'subsection.3.1', 'start_index': 983}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '5ac1ba3a3c677ffbd2ba1f2763643f1d',\n",
       "  'text': 'We further discuss the connection of our architectures with recent models in Appendix C. Additional related work are discussed in Appendix A.',\n",
       "  'metadata': {'detection_class_prob': 0.9139958024024963,\n",
       "   'coordinates': {'points': ((198.67222222222222, 1941.5122222222221),\n",
       "     (198.67222222222222, 2004.591552734375),\n",
       "     (1564.6026611328125, 2004.591552734375),\n",
       "     (1564.6026611328125, 1941.5122222222221)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Appendix C', 'url': 'appendix.C', 'start_index': 77}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'a59947b4982cb13fb3ca46d876ca0db3',\n",
       "  'text': '4',\n",
       "  'metadata': {'coordinates': {'points': ((873.5666666666667,\n",
       "      2057.742777777778),\n",
       "     (873.5666666666667, 2085.4166666666665),\n",
       "     (886.4350250000001, 2085.4166666666665),\n",
       "     (886.4350250000001, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'f2d5eee84f47a83a977e1345c55eb217',\n",
       "  'text': '3 Learning to Memorize at Test Time',\n",
       "  'metadata': {'detection_class_prob': 0.8613103628158569,\n",
       "   'coordinates': {'points': ((196.84376525878906, 198.8762664794922),\n",
       "     (196.84376525878906, 239.42201232910156),\n",
       "     (893.6334838867188, 239.42201232910156),\n",
       "     (893.6334838867188, 198.8762664794922)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'b967e3da6fc83dd88880877381ed0e1c',\n",
       "  'text': 'To overcome the lack of long-term memory and to enable the model to learn, forget, and retrieve information, in this section, we present a neural long-term memory module, which is a meta models that learns to memorize at test time. In Section 3.1, we first discuss the motivation and the design of the neural memory. In Section 3.2, we discuss how our architecture design can benefit from a fast and parallelizable training. Finally, in Section 3.3, we augment our architecture using persistent memory module, in which we use learnable but data-independent parameters to learn meta information about the task.',\n",
       "  'metadata': {'detection_class_prob': 0.9515153169631958,\n",
       "   'coordinates': {'points': ((198.7576446533203, 254.4083333333333),\n",
       "     (198.7576446533203, 461.75396728515625),\n",
       "     (1564.4705810546875, 461.75396728515625),\n",
       "     (1564.4705810546875, 254.4083333333333)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Section 3 . 1',\n",
       "     'url': 'subsection.3.1',\n",
       "     'start_index': 123},\n",
       "    {'text': 'Section 3 . 2', 'url': 'subsection.3.2', 'start_index': 207},\n",
       "    {'text': 'Section 3 . 3', 'url': 'subsection.3.3', 'start_index': 323}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': 'f2d5eee84f47a83a977e1345c55eb217',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'f8fa76e0936c899cf39ec01e9b595adc',\n",
       "  'text': '3.1 Long-term Memory',\n",
       "  'metadata': {'detection_class_prob': 0.8635743856430054,\n",
       "   'coordinates': {'points': ((196.80340576171875, 507.6734755555555),\n",
       "     (196.80340576171875, 540.8823644444443),\n",
       "     (573.3630981445312, 540.8823644444443),\n",
       "     (573.3630981445312, 507.6734755555555)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0006445ff1e8f2f86b810dba8bd712fd',\n",
       "  'text': 'To design a neural long-term memory module, we need a model that can encode the abstraction of the past history into its parameters. An example of this can be LLMs that are shown to be memorizing their training data (Leybzon and Kervadec 2024; Schwarzschild et al. 2024; Staab et al. 2024). Therefore, a simple idea is to train a neural network and expect it to memorize its training data. Memorization, however, has almost always been known as an undesirable phenomena in neural networks as it limits the model generalization (Bayat et al. 2024), causes privacy concerns (Staab et al. 2024), and so results in poor performance at test time. Moreover, the memorization of the training data might not be helpful at test time, in which the data might be out-of-distribution. We argue that, we need an online meta-model that learns how to memorize/forget the data at test time. In this setup, the model is learning a function that is capable of memorization, but it is not overfitting to the training data, resulting in a better generalization at test time.',\n",
       "  'metadata': {'detection_class_prob': 0.9566864967346191,\n",
       "   'coordinates': {'points': ((199.16944444444442, 556.5566666666667),\n",
       "     (199.16944444444442, 854.2660522460938),\n",
       "     (1570.3927001953125, 854.2660522460938),\n",
       "     (1570.3927001953125, 556.5566666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@leybzon2024learning',\n",
       "     'start_index': 259},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@schwarzschild2024rethinking',\n",
       "     'start_index': 286},\n",
       "    {'text': '2024', 'url': 'cite.0@staab2024beyond', 'start_index': 305},\n",
       "    {'text': '2024', 'url': 'cite.0@bayat2024pitfalls', 'start_index': 562},\n",
       "    {'text': '2024', 'url': 'cite.0@staab2024beyond', 'start_index': 607}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': 'f8fa76e0936c899cf39ec01e9b595adc',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '7b63495029c283f428ffdadd9ea7a849',\n",
       "  'text': 'Learning Process and Surprise Metric. The key idea to train a long-term memory is to treat its training as an online learning problem, in which we aim to compress the past information 𝑥1, . . . , 𝑥𝑡 −1 into the parameters of our long-term neural memory module M𝑡 . As discussed earlier, an event that violates the expectations (i.e., is surprising) is more memorable for humans (Mandler 2014). Inspired by this, a simple definition of surprise for a model can be its gradient with respect to the input. The larger the gradient is, the more different the input data is from the past data. Accordingly, using this surprise score, we can update the memory as:',\n",
       "  'metadata': {'detection_class_prob': 0.9523562788963318,\n",
       "   'coordinates': {'points': ((200.0, 885.426111111111),\n",
       "     (200.0, 1085.81298828125),\n",
       "     (1563.9140625, 1085.81298828125),\n",
       "     (1563.9140625, 885.426111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2014',\n",
       "     'url': 'cite.0@mandler2014structure',\n",
       "     'start_index': 387}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': 'f8fa76e0936c899cf39ec01e9b595adc',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '7f0ddf714ace4c867c7a3a501e1b2228',\n",
       "  'text': 'M𝑡 = M𝑡 −1 − 𝜃𝑡 ∇ℓ (M𝑡 −1; 𝑥𝑡 ) . (8)',\n",
       "  'metadata': {'detection_class_prob': 0.6321243643760681,\n",
       "   'coordinates': {'points': ((701.0697631835938, 1108.0261111111108),\n",
       "     (701.0697631835938, 1148.56884765625),\n",
       "     (1561.6619961111114, 1148.56884765625),\n",
       "     (1561.6619961111114, 1108.0261111111108)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '45a1c2f2572d12b3131bb9670b88e092',\n",
       "  'text': 'SS',\n",
       "  'metadata': {'coordinates': {'points': ((898.0, 1150.0),\n",
       "     (898.0, 1162.0),\n",
       "     (1049.0, 1162.0),\n",
       "     (1049.0, 1150.0)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '09a7ed3ae5b1489ea7a108ed78920681',\n",
       "  'text': 'Surprise',\n",
       "  'metadata': {'coordinates': {'points': ((939.888888888889,\n",
       "      1166.503611111111),\n",
       "     (939.888888888889, 1186.7055555555553),\n",
       "     (1008.3128747222223, 1186.7055555555553),\n",
       "     (1008.3128747222223, 1166.503611111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '9e12d5abb2020b5b20bc8b25be98e18e',\n",
       "  'text': 'This surprise metric, however, can result in missing important information that comes after a big surprising moment.',\n",
       "  'metadata': {'coordinates': {'points': ((199.16944444444442,\n",
       "      1211.6927777777778),\n",
       "     (199.16944444444442, 1239.3666666666668),\n",
       "     (1564.2731238111116, 1239.3666666666668),\n",
       "     (1564.2731238111116, 1211.6927777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': '09a7ed3ae5b1489ea7a108ed78920681',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e2467f79f69f5b7014fbcce9b6d6eefe',\n",
       "  'text': 'That is, the gradient can become extremely small after several surprising steps, leading to stocking in a flat area (i.e., local minima), and missing information about some parts of the sequence. From the human memory perspective, an event might not consistently surprise us through a long-period of time although it is memorable. The reason is that the initial moment is surprising enough to get our attention through a long time frame, leading to memorizing the entire time frame. To improve the above surprise metric (Equation 8), we break the surprise metric into (1) past surprise, which measures the surprise amount of a very recent past; and (2) momentary surprise, which measures the surprise of incoming data:',\n",
       "  'metadata': {'detection_class_prob': 0.9550566673278809,\n",
       "   'coordinates': {'points': ((197.88540649414062, 1218.8453369140625),\n",
       "     (197.88540649414062, 1445.0951344444445),\n",
       "     (1572.213623046875, 1445.0951344444445),\n",
       "     (1572.213623046875, 1218.8453369140625)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Equation 8',\n",
       "     'url': 'equation.3.8',\n",
       "     'start_index': 637}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': '09a7ed3ae5b1489ea7a108ed78920681',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '721377ac16aff4dd450e3e88c8ec8f18',\n",
       "  'text': 'M𝑡 = M𝑡 −1 + 𝑆𝑡, (9)',\n",
       "  'metadata': {'detection_class_prob': 0.3135146498680115,\n",
       "   'coordinates': {'points': ((669.1361111111111, 1467.503888888889),\n",
       "     (669.1361111111111, 1511.6492919921875),\n",
       "     (1564.837158203125, 1511.6492919921875),\n",
       "     (1564.837158203125, 1467.503888888889)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '7710c0ce3ede508022f3c73edcbb4b04',\n",
       "  'text': 'Se=me Sra — Of VO (Mr-15 x2) « (10) ee SS',\n",
       "  'metadata': {'detection_class_prob': 0.5409674048423767,\n",
       "   'coordinates': {'points': ((665.923828125, 1504.1549072265625),\n",
       "     (665.923828125, 1558.1833333333334),\n",
       "     (1561.66091, 1558.1833333333334),\n",
       "     (1561.66091, 1504.1549072265625)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '2735a0a9882f4c8d2e8a634d2d2fa514',\n",
       "  'text': 'Past Surprise',\n",
       "  'metadata': {'coordinates': {'points': ((746.7916666666667,\n",
       "      1566.3174999999999),\n",
       "     (746.7916666666667, 1586.5194444444446),\n",
       "     (854.6902519444445, 1586.5194444444446),\n",
       "     (854.6902519444445, 1566.3174999999999)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'e8d3be1427d34dfefc47198134dfd664',\n",
       "  'text': 'Momentary Surprise',\n",
       "  'metadata': {'coordinates': {'points': ((913.4805555555554,\n",
       "      1567.4508333333335),\n",
       "     (913.4805555555554, 1587.6527777777778),\n",
       "     (1083.8637549999999, 1587.6527777777778),\n",
       "     (1083.8637549999999, 1567.4508333333335)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '6e6ed601d223acbaa1822b97c22b2e7e',\n",
       "  'text': 'Interestingly, this formulation is similar to gradient descent with momentum, where 𝑆𝑡 is the momentum element. Therefore, the momentum here act as a memory of surprise across time (sequence length). In this formulation, the term 𝜂𝑡 is a data-dependent surprise decay (a function of 𝑥𝑡 ), controlling how surprise decays over time, and the term 𝜃𝑡 is controlling how much of momentary surprise should be incorporated into the final surprise metric in a data-dependent manner. This data-dependency is particularly important in this design: While surprise of previous tokens might be needed to affect the surprise of the next token, it is mostly valid if all tokens are relevant and are in the same context. Accordingly, a data-dependent 𝜂 can control if memory needs to: (1) ignore the last surprise by setting 𝜂𝑡 → 0 (possibly due to the change of context), or (2) fully incorporate the last surprise by setting 𝜂𝑡 → 1 (possibly as the token is highly relevant to its recent past tokens).',\n",
       "  'metadata': {'detection_class_prob': 0.9540640711784363,\n",
       "   'coordinates': {'points': ((200.0, 1612.6427777777778),\n",
       "     (200.0, 1910.580322265625),\n",
       "     (1566.091064453125, 1910.580322265625),\n",
       "     (1566.091064453125, 1612.6427777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': 'e8d3be1427d34dfefc47198134dfd664',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '221928f9f396e6c6e7fb706b43f4285b',\n",
       "  'text': 'Objective. Our above surprise metric is based on a loss function ℓ (.; .), which is the objective that our memory is learning',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 1941.5122222222221),\n",
       "     (200.0, 1975.5787794444443),\n",
       "     (1559.991181371111, 1975.5787794444443),\n",
       "     (1559.991181371111, 1941.5122222222221)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': 'e8d3be1427d34dfefc47198134dfd664',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'f0b20f52f3bdd8310182721f098c1159',\n",
       "  'text': 'to act as it at test time. That is, our memory module is a meta model that learns a function based on the loss function ℓ (.; .).',\n",
       "  'metadata': {'detection_class_prob': 0.9256730079650879,\n",
       "   'coordinates': {'points': ((200.0, 1950.04833984375),\n",
       "     (200.0, 2006.8046875),\n",
       "     (1564.2637126666664, 2006.8046875),\n",
       "     (1564.2637126666664, 1950.04833984375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': 'e8d3be1427d34dfefc47198134dfd664',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'aa24309e71e21ba20240ca1fd2e21703',\n",
       "  'text': '5',\n",
       "  'metadata': {'coordinates': {'points': ((873.5666666666666,\n",
       "      2057.742777777778),\n",
       "     (873.5666666666666, 2085.4166666666665),\n",
       "     (886.4350249999999, 2085.4166666666665),\n",
       "     (886.4350249999999, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': 'e8d3be1427d34dfefc47198134dfd664',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '906e238358f3aa5c1933e93c37254f5c',\n",
       "  'text': 'In this work, we focus on associative memory, in which we aim to store the past data as the pairs of keys and values. Given',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 202.39277777777778),\n",
       "     (200.0, 236.54235666666668),\n",
       "     (1560.0059411777775, 236.54235666666668),\n",
       "     (1560.0059411777775, 202.39277777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'parent_id': 'e8d3be1427d34dfefc47198134dfd664',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '12a3bbf674b3fd40c20554c824f7b5a1',\n",
       "  'text': '𝑥𝑡 , similar to Transformers (Vaswani et al. 2017), we use two linear layers to project 𝑥𝑡 into a key and value:',\n",
       "  'metadata': {'detection_class_prob': 0.9224147200584412,\n",
       "   'coordinates': {'points': ((199.16944444444442, 212.03903198242188),\n",
       "     (199.16944444444442, 268.8795471191406),\n",
       "     (1562.93359375, 268.8795471191406),\n",
       "     (1562.93359375, 212.03903198242188)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'parent_id': 'e8d3be1427d34dfefc47198134dfd664',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '3603a13d47947893ce11ab1fc5277997',\n",
       "  'text': 'k𝑡 = 𝑥𝑡𝑊𝐾, v𝑡 = 𝑥𝑡𝑊𝑉 , (11)',\n",
       "  'metadata': {'detection_class_prob': 0.634596586227417,\n",
       "   'coordinates': {'points': ((694.9714965820312, 296.4844444444446),\n",
       "     (694.9714965820312, 332.3160705566406),\n",
       "     (1561.6609099999996, 332.3160705566406),\n",
       "     (1561.6609099999996, 296.4844444444446)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '64b121b3d8d99539c0ec401765c9b7b0',\n",
       "  'text': 'where 𝑊𝐾 and 𝑊𝑉 ∈ R𝑑in ×𝑑in. Next, we expect our memory module to learn the associations between keys and values. To',\n",
       "  'metadata': {'coordinates': {'points': ((198.975, 358.8258325000001),\n",
       "     (198.975, 393.22499916666675),\n",
       "     (1560.0052324333335, 393.22499916666675),\n",
       "     (1560.0052324333335, 358.8258325000001)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e64466181939b3445c23bbae8dbbc30b',\n",
       "  'text': 'this end, we define the loss as follows:',\n",
       "  'metadata': {'detection_class_prob': 0.9202572107315063,\n",
       "   'coordinates': {'points': ((200.0, 369.45849609375),\n",
       "     (200.0, 426.76611328125),\n",
       "     (1566.947509765625, 426.76611328125),\n",
       "     (1566.947509765625, 369.45849609375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '5ebdda765218a446054046c080a5cd82',\n",
       "  'text': 'ℓ (M𝑡 −1; 𝑥𝑡 ) = ∥M𝑡 −1 (k𝑡 ) − v𝑡 ∥2',\n",
       "  'metadata': {'coordinates': {'points': ((693.6027777777778,\n",
       "      450.9175000000002),\n",
       "     (693.6027777777778, 490.16514000000006),\n",
       "     (1064.9022375, 490.16514000000006),\n",
       "     (1064.9022375, 450.9175000000002)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '7e26ef6d719c5c128d04c053fce2a29b',\n",
       "  'text': '2',\n",
       "  'metadata': {'detection_class_prob': 0.6151119470596313,\n",
       "   'coordinates': {'points': ((697.6447143554688, 461.0958251953125),\n",
       "     (697.6447143554688, 491.9449768066406),\n",
       "     (1548.2830810546875, 491.9449768066406),\n",
       "     (1548.2830810546875, 461.0958251953125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '29ecb6d6fa6b5fd7c16def14ae543698',\n",
       "  'text': 'By optimizing the above loss function in the inner-loop of our meta model (memory), the model learns how to memorize the mapping between keys and values at test time. Note that, similar to meta-learning models (Nichol 2018; Zintgraf et al. 2019), training of the memory is in the inner-loop, and so parameters 𝑊𝐾 and 𝑊𝑉 are hyperparameters in the above loss function. Accordingly, in the inner loop, we optimize M’s weights, while in the outer-loop, we optimize other parameters of the entire architecture.',\n",
       "  'metadata': {'detection_class_prob': 0.9486731290817261,\n",
       "   'coordinates': {'points': ((200.0, 516.1511111111114),\n",
       "     (200.0, 683.2410278320312),\n",
       "     (1566.0045166015625, 683.2410278320312),\n",
       "     (1566.0045166015625, 516.1511111111114)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2018',\n",
       "     'url': 'cite.0@nichol2018first',\n",
       "     'start_index': 218},\n",
       "    {'text': '2019', 'url': 'cite.0@zintgraf2019fast', 'start_index': 240}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'd610f981f8ca84bf37800a4a9799e766',\n",
       "  'text': 'Forgetting Mechanism. When dealing with very large sequences (e.g., millions of tokens), it is crucial to manage which past information should be forgotten–even with a deep or a very large matrix-valued memory. To this end, we use an adaptive forgetting mechanism that allows the memory to forget the information that is not needed anymore, resulting in better managing the memory’s limited capacity. That is, given the next token 𝑥𝑡 , we modify the update rule as:',\n",
       "  'metadata': {'detection_class_prob': 0.9406565427780151,\n",
       "   'coordinates': {'points': ((200.0, 712.1872222222224),\n",
       "     (200.0, 845.2297973632812),\n",
       "     (1566.1424560546875, 845.2297973632812),\n",
       "     (1566.1424560546875, 712.1872222222224)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': 'e34f32de40fe59c025dfcbc3662bfbe7',\n",
       "  'text': 'M𝑡 = (1 − 𝛼𝑡 )M𝑡 −1 + 𝑆𝑡, (13)',\n",
       "  'metadata': {'detection_class_prob': 0.5927087664604187,\n",
       "   'coordinates': {'points': ((711.9166666666665, 872.6955555555554),\n",
       "     (711.9166666666665, 909.36181640625),\n",
       "     (1561.6609099999998, 909.36181640625),\n",
       "     (1561.6609099999998, 872.6955555555554)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'f0560b0479c22a952ebfcdba5c7ef400',\n",
       "  'text': '𝑆𝑡 = 𝜂𝑡𝑆𝑡 −1 − 𝜃𝑡 ∇ℓ (𝑀𝑡 −1; 𝑥𝑡 ),',\n",
       "  'metadata': {'coordinates': {'points': ((711.0861111111108,\n",
       "      914.2066666666666),\n",
       "     (711.0861111111108, 949.1012511111111),\n",
       "     (1047.8076999999994, 949.1012511111111),\n",
       "     (1047.8076999999994, 914.2066666666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '69f057e015044467f6bda8f5354e0f78',\n",
       "  'text': '= MeSe-1 — 8 VE (My-13 1); (14)',\n",
       "  'metadata': {'detection_class_prob': 0.5550870895385742,\n",
       "   'coordinates': {'points': ((723.9215087890625, 922.0646362304688),\n",
       "     (723.9215087890625, 948.4002685546875),\n",
       "     (1555.6673583984375, 948.4002685546875),\n",
       "     (1555.6673583984375, 922.0646362304688)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '3d9abd72ef022cd941f94e738c6d13cc',\n",
       "  'text': 'where 𝛼𝑡 ∈ [0, 1] is the gating mechanism that flexibly controls the memory; i.e., decides how much information should be forgotten. For example, it can update the memory without affecting the past abstraction by letting 𝛼𝑡 → 0, and can clear the entire memory by letting 𝛼𝑡 → 1. Later in this section, we show that this weight decay mechanism is closely related to the gating mechanism in modern RNNs (Dao and Gu 2024; Orvieto et al. 2023).',\n",
       "  'metadata': {'detection_class_prob': 0.9416041374206543,\n",
       "   'coordinates': {'points': ((198.975, 975.0899999999999),\n",
       "     (198.975, 1107.2740478515625),\n",
       "     (1564.720458984375, 1107.2740478515625),\n",
       "     (1564.720458984375, 975.0899999999999)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0e6be9a7aa550ac1fc6c6521d3c1aa13',\n",
       "  'text': 'Memory Architecture. In this paper, we focus on simple MLPs with 𝐿M ≥ 1 layers as the architecture of our long-term memory. The main reason behind this choice is that we want to focus on better motivating the design of the long-term memory and ways that it can be incorporated into an architecture. However, our formulation and architectural design opens a new research direction to design neural architectures that are more effective and efficient in memorization of data. Recently, there has been a promising line of work to design such architectures (Berges et al. 2024; Cetin et al. 2024; J. Zhang et al. 2024), which incorporating them into our framework (i.e., replacing simple MLPs with such architectures) can be an interesting future work.',\n",
       "  'metadata': {'detection_class_prob': 0.9546708464622498,\n",
       "   'coordinates': {'points': ((200.0, 1137.915),\n",
       "     (200.0, 1369.467041015625),\n",
       "     (1568.6455078125, 1369.467041015625),\n",
       "     (1568.6455078125, 1137.915)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@berges2024memory',\n",
       "     'start_index': 565},\n",
       "    {'text': '2024', 'url': 'cite.0@cetin2024evolved', 'start_index': 584},\n",
       "    {'text': '2024', 'url': 'cite.0@zhang2024memory', 'start_index': 606}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '64980f1cf18196777425072dead57c33',\n",
       "  'text': 'When using vector-valued or matrix-valued memory (De et al. 2024; Orvieto et al. 2023; S. Yang, B. Wang, Shen, et al. 2024), the memory module is compressing the past data and fit it into a line. That is, from the meta learning or online learning perspective (Yu Sun et al. 2024), using a matrix-valued memory M = 𝑊 ∈ R𝑑in ×𝑑in is equivalent to optimize ℓ (𝑊𝑡 −1; 𝑥𝑡 ) = ∥𝑊𝑡 −1k𝑡 − v𝑡 ∥2 2, which is an online linear regression objective and so the optimal solution assumes the underlying dependency of historical data is linear. On the other hand, we argue that deep memory modules (i.e., 𝐿M ≥ 2) . Aligning with the theoretical results that MLPs with at least two layers are strictly more expressive than linear models (Hornik, Stinchcombe, and White 1989), in Section 5.5, we show that deep memory modules are more effective in practice.',\n",
       "  'metadata': {'detection_class_prob': 0.9549524188041687,\n",
       "   'coordinates': {'points': ((198.67222222222222, 1386.9816666666666),\n",
       "     (198.67222222222222, 1653.0419921875),\n",
       "     (1568.328857421875, 1653.0419921875),\n",
       "     (1568.328857421875, 1386.9816666666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@de2024griffin',\n",
       "     'start_index': 60},\n",
       "    {'text': '2023',\n",
       "     'url': 'cite.0@orvieto2023resurrecting',\n",
       "     'start_index': 81},\n",
       "    {'text': '2024', 'url': 'cite.0@yang2024gatedattn', 'start_index': 118},\n",
       "    {'text': '2024', 'url': 'cite.0@sun2024learning', 'start_index': 273},\n",
       "    {'text': '1989', 'url': 'cite.0@hornik1989multilayer', 'start_index': 752},\n",
       "    {'text': 'Section 5 . 5', 'url': 'subsection.5.5', 'start_index': 762}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'fe6a3a3f6841a8526307b09c22f77413',\n",
       "  'text': 'Retrieving a Memory. In the above, we discuss how one can design and train a long-term memory module that learns to memorize at test time. A key remaining question is: How one can retrieve information from the memory? We simply use the forward pass without weight update (i.e., inference) to retrieve a memory correspond to a query. Formally, given an input 𝑥𝑡 , we use a linear layer 𝑊𝑄 to project the input, i.e., q𝑡 = 𝑥𝑡𝑊𝑄 and retrieve the corresponding (or useful) information from the memory 𝑦𝑡 by:',\n",
       "  'metadata': {'detection_class_prob': 0.9449653029441833,\n",
       "   'coordinates': {'points': ((197.80874633789062, 1682.6399999999999),\n",
       "     (197.80874633789062, 1848.4163818359375),\n",
       "     (1566.35986328125, 1848.4163818359375),\n",
       "     (1566.35986328125, 1682.6399999999999)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': 'd32317f62d05aab4849291f7c1fc3579',\n",
       "  'text': '𝑦𝑡 = M∗ (q𝑡 ). (15)',\n",
       "  'metadata': {'detection_class_prob': 0.5819500088691711,\n",
       "   'coordinates': {'points': ((795.5859985351562, 1875.4715288888888),\n",
       "     (795.5859985351562, 1924.876708984375),\n",
       "     (1565.6160888671875, 1924.876708984375),\n",
       "     (1565.6160888671875, 1875.4715288888888)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '8598fa8798930e07ace21b520c3f6ce9',\n",
       "  'text': '6',\n",
       "  'metadata': {'coordinates': {'points': ((873.5666666666671,\n",
       "      2057.742777777778),\n",
       "     (873.5666666666671, 2085.4166666666665),\n",
       "     (886.4350250000005, 2085.4166666666665),\n",
       "     (886.4350250000005, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'e1b54ab4c90134ed9f53185f7eba79cc',\n",
       "  'text': '(12)',\n",
       "  'metadata': {'coordinates': {'points': ((1519.4305555555554,\n",
       "      455.27055555555603),\n",
       "     (1519.4305555555554, 482.9444444444448),\n",
       "     (1561.66091, 482.9444444444448),\n",
       "     (1561.66091, 455.27055555555603)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '21240d78a98f95e3a80fece5c337b14b',\n",
       "  'text': '(14)',\n",
       "  'metadata': {'coordinates': {'points': ((1519.430555555555,\n",
       "      914.2066666666666),\n",
       "     (1519.430555555555, 941.8805555555555),\n",
       "     (1561.6609099999996, 941.8805555555555),\n",
       "     (1561.6609099999996, 914.2066666666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Image',\n",
       "  'element_id': '21e8d8c670b9ca2937cc5871dc580515',\n",
       "  'text': 'Linear Non-Linear Momentum Calculation Within-Chunk Cross-Chunk Weight Decay All gradients are pre-computed W/o Decay J Sum oeeea PeewrE oooss, (WeX —X)XT | ° rire W/ Decay ) Parallel Associati * 7 ©,By(WoX — X)XT viacumsum | _via Gradient aceleeeooeae aaa) Global Kernel via Matmul',\n",
       "  'metadata': {'coordinates': {'points': ((335.9972222222222,\n",
       "      202.39610592222226),\n",
       "     (335.9972222222222, 447.5833333333333),\n",
       "     (1423.9914222027778, 447.5833333333333),\n",
       "     (1423.9914222027778, 202.39610592222226)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'image_path': 'images\\\\figure-7-1.jpg',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'fb62de0f02d310605c1f661f093f2970',\n",
       "  'text': 'Figure 1: The illustration of how the training of neural memory can be done in parallel and using matmuls.',\n",
       "  'metadata': {'coordinates': {'points': ((277.66666666666663,\n",
       "      470.83166666666676),\n",
       "     (277.66666666666663, 503.3208122222223),\n",
       "     (1482.3338499999998, 503.3208122222223),\n",
       "     (1482.3338499999998, 470.83166666666676)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '6fd8e085dfe8d6cce56de02318f8e35d',\n",
       "  'text': '3.2 How to Parallelize the Long-term Memory Training',\n",
       "  'metadata': {'detection_class_prob': 0.8506954312324524,\n",
       "   'coordinates': {'points': ((198.6814727783203, 565.8325805664062),\n",
       "     (198.6814727783203, 599.1601422222221),\n",
       "     (1052.7046400000004, 599.1601422222221),\n",
       "     (1052.7046400000004, 565.8325805664062)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'c22f0eeef81576c8ca8e9f4624d517ac',\n",
       "  'text': 'As discussed above, the design of our long-term memory module is equivalent to training a meta model by optimizing associative memory loss function ℓ (M𝑡 −1; 𝑥𝑡 ) = ∥M𝑡 −1 (k𝑡 ) − v𝑡 ∥2 2 using gradient descent with momentum and weight decay. Therefore, in theory, the training of long-term memory module requires O (𝑁 ) FLOPs, where 𝑁 is the sequence length. However, in practice, we need to parallelize the training process and to fully take advantage of hardware accelerators (e.g., TPUs, GPUs), we need to tensorize the process and use more matmuls.',\n",
       "  'metadata': {'detection_class_prob': 0.9443891644477844,\n",
       "   'coordinates': {'points': ((199.03055555555554, 614.8316666666668),\n",
       "     (199.03055555555554, 780.7759399414062),\n",
       "     (1565.4493408203125, 780.7759399414062),\n",
       "     (1565.4493408203125, 614.8316666666668)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '6fd8e085dfe8d6cce56de02318f8e35d',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '5057f2388d58a9e33ee3c0656067a525',\n",
       "  'text': 'Next, we show that calculating the weights in the inner loop with mini-batch gradient descent, data-dependent learning',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 797.4816666666666),\n",
       "     (200.0, 825.1555555555555),\n",
       "     (1559.9998393866665, 825.1555555555555),\n",
       "     (1559.9998393866665, 797.4816666666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '6fd8e085dfe8d6cce56de02318f8e35d',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'af5aea9607d08f137520a90fbf271f59',\n",
       "  'text': 'rate, and weight decay can be reformulated so that it uses only matmuls and sum. We build upon the work of Yu Sun et al. (2024) that shows forward pass of a model optimizing with the mini-batch gradient descent (with constant learning rate) can be calculated using matmuls. We can split the sequence into chunks of size 𝑏 ≥ 1, and write the mini-batch gradient descent as:',\n",
       "  'metadata': {'detection_class_prob': 0.9428063631057739,\n",
       "   'coordinates': {'points': ((199.16944444444442, 805.2402954101562),\n",
       "     (199.16944444444442, 964.6571655273438),\n",
       "     (1565.5462646484375, 964.6571655273438),\n",
       "     (1565.5462646484375, 805.2402954101562)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@sun2024learning',\n",
       "     'start_index': 241}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '6fd8e085dfe8d6cce56de02318f8e35d',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '15a546393a24308c49cd39905052c60a',\n",
       "  'text': '𝑡',\n",
       "  'metadata': {'coordinates': {'points': ((1056.4250000000002,\n",
       "      982.7591658333332),\n",
       "     (1056.4250000000002, 1002.9611102777776),\n",
       "     (1063.5158825, 1002.9611102777776),\n",
       "     (1063.5158825, 982.7591658333332)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '39c8c34ff30bb9f8bddc11a5a0c02468',\n",
       "  'text': 'M𝑡 = (1 − 𝛼𝑡 )M𝑡 −1 − 𝜃𝑡 ∇ℓ (M𝑡 −1; 𝑥𝑡 ) = 𝛽𝑡 M0 − ∑︁ 𝑖=1 𝜃𝑖 𝛽𝑡 𝛽𝑖 ∇ℓ (M𝑡 ′ ; 𝑥𝑖 ), (16)',\n",
       "  'metadata': {'detection_class_prob': 0.8292020559310913,\n",
       "   'coordinates': {'points': ((485.43611111111113, 988.0106811523438),\n",
       "     (485.43611111111113, 1073.273681640625),\n",
       "     (1561.6609100000005, 1073.273681640625),\n",
       "     (1561.6609100000005, 988.0106811523438)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'b80b9fc27c3452f8040aec2d41b086ff',\n",
       "  'text': 'where t’ = t — mod(t, b), and f; =',\n",
       "  'metadata': {'coordinates': {'points': ((198.975, 1093.4647213888888),\n",
       "     (198.975, 1129.9149449999998),\n",
       "     (614.9269969444445, 1129.9149449999998),\n",
       "     (614.9269969444445, 1093.4647213888888)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0272091ba7da0eb2522957c9cfea4aac',\n",
       "  'text': '𝑗=1(1 − 𝛼 𝑗 ). For the sake of simplicity, we focus on the first chunk, i.e., 𝑡 = 𝑏 and so 𝑡 ′ = 0. Also, we explain the process for the case that M𝑡 = 𝑊𝑡 is linear. The process for MLPs with 𝑁𝑝 ≥ 2 is similar. Using our loss function, we have:',\n",
       "  'metadata': {'detection_class_prob': 0.9308575391769409,\n",
       "   'coordinates': {'points': ((199.03055555555554, 1097.3427777777777),\n",
       "     (199.03055555555554, 1198.4581298828125),\n",
       "     (1562.772705078125, 1198.4581298828125),\n",
       "     (1562.772705078125, 1097.3427777777777)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'parent_id': 'b80b9fc27c3452f8040aec2d41b086ff',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '8959576ee7da5e1e6587975c97528bb8',\n",
       "  'text': '∇ℓ (𝑊0; 𝑥𝑡 ) = (𝑊0𝑥𝑡 − 𝑥𝑡 )𝑥 ⊤ 𝑡 ⇒ 𝑏 ∑︁ 𝑖=1 𝜃𝑖 𝛽𝑏 𝛽𝑖 ∇ℓ (𝑊0; 𝑥𝑖 ) = Θ𝑏B𝑏 (𝑊0𝑋 − 𝑋 )𝑋 ⊤, (17)',\n",
       "  'metadata': {'detection_class_prob': 0.8069216012954712,\n",
       "   'coordinates': {'points': ((463.4621887207031, 1222.6008324999998),\n",
       "     (463.4621887207031, 1311.850830078125),\n",
       "     (1571.355712890625, 1311.850830078125),\n",
       "     (1571.355712890625, 1222.6008324999998)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'f854f2f1354928bb0c390a04ce5128c4',\n",
       "  'text': '94]) and By is defined analogously on',\n",
       "  'metadata': {'coordinates': {'points': ((580.1190377777776,\n",
       "      1335.1647213888887),\n",
       "     (580.1190377777776, 1375.6622166666666),\n",
       "     (1027.3602777777776, 1375.6622166666666),\n",
       "     (1027.3602777777776, 1335.1647213888887)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '9cc07247182dadbc361299717d73ca07',\n",
       "  'text': 'where ©, = diag ((%',\n",
       "  'metadata': {'coordinates': {'points': ((198.975, 1336.2819755555556),\n",
       "     (198.975, 1374.1955005555553),\n",
       "     (442.8994597222222, 1374.1955005555553),\n",
       "     (442.8994597222222, 1336.2819755555556)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'efeb2e094e1e5405c0027cd6b3d6e667',\n",
       "  'text': '𝜃2 . . . s. Note that, we do not need to store all Θ𝑘𝑏 and 𝛽𝑖 B𝑘𝑏 for 𝑘 = 1, . . . , 𝑁 /𝑏, instead, we store these matrices for each chunk, resulting in using less memory. Next, we extend this representation so we can also incorporate the momentum term. In a chunk wise gradient descent with momentum, if we look at the momentum term, we have:',\n",
       "  'metadata': {'detection_class_prob': 0.9403248429298401,\n",
       "   'coordinates': {'points': ((198.975, 1341.4583016666666),\n",
       "     (198.975, 1477.52880859375),\n",
       "     (1563.0775146484375, 1477.52880859375),\n",
       "     (1563.0775146484375, 1341.4583016666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '9cc07247182dadbc361299717d73ca07',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': 'ae2368e01cedf3ce88940e4691dddce9',\n",
       "  'text': '𝑆𝑡 = 𝜂𝑡𝑆𝑡 −1 − 𝜃𝑡 𝑢𝑡, (18)',\n",
       "  'metadata': {'detection_class_prob': 0.6020569801330566,\n",
       "   'coordinates': {'points': ((773.1472222222221, 1505.5372222222225),\n",
       "     (773.1472222222221, 1548.5462646484375),\n",
       "     (1561.6609099999998, 1548.5462646484375),\n",
       "     (1561.6609099999998, 1505.5372222222225)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '78bbac69d50c456e1af45aecc0ff37bb',\n",
       "  'text': 'where 𝑢𝑡 = ∇ℓ (𝑀𝑡 ′ ; 𝑥𝑡 ). Note that, we can compute all 𝑢𝑡 at the same time, and so Equation 18 is a linear recurrence with 𝑢𝑡 as an input, 𝑆𝑡 as the hidden state, and 𝜂𝑡 as input-dependent transition value. Accordingly, we can use parallel associative scan (J. T. Smith, Warrington, and Linderman 2023) to calculate 𝑆𝑡 s in this chunk.',\n",
       "  'metadata': {'detection_class_prob': 0.9316344857215881,\n",
       "   'coordinates': {'points': ((198.975, 1566.4177777777777),\n",
       "     (198.975, 1664.8833324999998),\n",
       "     (1565.34765625, 1664.8833324999998),\n",
       "     (1565.34765625, 1566.4177777777777)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Equation 18',\n",
       "     'url': 'equation.3.18',\n",
       "     'start_index': 86}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'c7d8864058502eab0f94e7e6d29cf9d7',\n",
       "  'text': 'Parameters as the Function of Chunks. Instead of making parameters like 𝛼𝑡, 𝜃𝑡 , and 𝜂𝑡 input-dependent (i.e., a function of token 𝑥𝑡 ), we can make them functions of their chunk. Despite losing expressive power, this formulation can help to make the training even faster. In this case, we are using the same value for each of 𝛼, 𝜃 , and 𝜂 in each chunk. Accordingly, in Equation 17, we can store Θ using a single scaler. Similarly we can make Equation 18 faster. That is, when 𝜂 and 𝜃 are learnable but time-invariant inside each chunk, this equation becomes a linear time-invariant system (LTI), which can be computed by a global convolution (Gu, Goel, and Re 2022). In our experiments, we make these parameters as the functions of tokens. However, such simplifications (i.e., as the function of chunks) can be the interest of future work to training larger models in more efficient manner.',\n",
       "  'metadata': {'detection_class_prob': 0.9561675190925598,\n",
       "   'coordinates': {'points': ((200.0, 1696.0344444444445),\n",
       "     (200.0, 1961.6810302734375),\n",
       "     (1565.9637451171875, 1961.6810302734375),\n",
       "     (1565.9637451171875, 1696.0344444444445)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Equation 17',\n",
       "     'url': 'equation.3.17',\n",
       "     'start_index': 371},\n",
       "    {'text': 'Equation 18', 'url': 'equation.3.18', 'start_index': 444},\n",
       "    {'text': '2022', 'url': 'cite.0@gu2022efficiently', 'start_index': 662}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '899cc9c4ab8aab7124fdb1ad196ee5c8',\n",
       "  'text': '7',\n",
       "  'metadata': {'coordinates': {'points': ((873.5666666666667,\n",
       "      2057.742777777778),\n",
       "     (873.5666666666667, 2085.4166666666665),\n",
       "     (886.4350250000001, 2085.4166666666665),\n",
       "     (886.4350250000001, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Image',\n",
       "  'element_id': '3acaef674b2068bdb8e9557dc8d101c0',\n",
       "  'text': 'Test Time Neural Memory a i) Bi le | a | aa g Ee 4 is) 3 Be 4 3 — 4 — | 8 ® 8 8 1) 3 2 oO Sequence = | Sl 2 Eo de 3 aa Learnable Data-Independent Weights # Ss re Aa',\n",
       "  'metadata': {'coordinates': {'points': ((268.00555555555553,\n",
       "      202.39253938333346),\n",
       "     (268.00555555555553, 588.8083333333333),\n",
       "     (1491.9470262555556, 588.8083333333333),\n",
       "     (1491.9470262555556, 202.39253938333346)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'image_path': 'images\\\\figure-8-2.jpg',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '74d8723728ccefea4bbe9767127807a8',\n",
       "  'text': 'Figure 2: Memory as a Context (MAC) Architecture. This architecture includes three branches of (1) core, (2) contextual (long-term) memory, and (3) persistent memory. The core branch concatenates the corresponding long-term and persistent memories with the input sequence. Next, attention performs on the sequence and decides what part of the information should store in the long-term memory. At the test time, parameters corresponds to contextual memory are still learning, parameters corresponds to the core branch are responsible for in-context learning, and parameters of persistent memory are responsible to store the knowledge about tasks and so are fixed.',\n",
       "  'metadata': {'detection_class_prob': 0.8252611756324768,\n",
       "   'coordinates': {'points': ((199.16944444444442, 612.0538888888891),\n",
       "     (199.16944444444442, 810.6336669921875),\n",
       "     (1563.0308497411106, 810.6336669921875),\n",
       "     (1563.0308497411106, 612.0538888888891)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '28479d8c9cec7c6aa6e79e080865b97c',\n",
       "  'text': '3.3 Persistent Memory',\n",
       "  'metadata': {'detection_class_prob': 0.8538755178451538,\n",
       "   'coordinates': {'points': ((198.134033203125, 873.2179199999999),\n",
       "     (198.134033203125, 906.4268088888888),\n",
       "     (562.6845703125, 906.4268088888888),\n",
       "     (562.6845703125, 873.2179199999999)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'effb7e6f8a9ffa6504b0867ccb940103',\n",
       "  'text': 'Our long-term memory can also be seen as a contextual memory, meaning that the output is fully depend on the context. Therefore, in addition to our long-term memory, we also use a set of learnable but input-independent parameters to act as task-related memory. This type of memory has been referred to as persistent or meta-memory in the literature (X. Dong et al. 2024; Sukhbaatar, Grave, et al. 2019). Given Ny = 1, we use learnable parameters P = [pi po «-- PN, | and append it to the start of our sequence: i.e., given a context window size of N, we modify the input as:',\n",
       "  'metadata': {'detection_class_prob': 0.9452491998672485,\n",
       "   'coordinates': {'points': ((198.63307189941406, 922.0983333333332),\n",
       "     (198.63307189941406, 1088.384521484375),\n",
       "     (1574.4747314453125, 1088.384521484375),\n",
       "     (1574.4747314453125, 922.0983333333332)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@dong2024hymba',\n",
       "     'start_index': 387},\n",
       "    {'text': '2019',\n",
       "     'url': 'cite.0@sukhbaatar2019augmenting',\n",
       "     'start_index': 419}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'parent_id': '28479d8c9cec7c6aa6e79e080865b97c',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '2e6e3c08562e473c45bc7cb4e71f4fb6',\n",
       "  'text': 'Xnew =[Pr P2 +.» PNp| ll x (19)',\n",
       "  'metadata': {'detection_class_prob': 0.7079141736030579,\n",
       "   'coordinates': {'points': ((690.4307250976562, 1110.47642),\n",
       "     (690.4307250976562, 1162.608642578125),\n",
       "     (1564.868408203125, 1162.608642578125),\n",
       "     (1564.868408203125, 1110.47642)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '872a90aa4708623e659ba34d1f5f755a',\n",
       "  'text': 'where || is concatenation. Next, we discuss the motivation of persistent memory from three perspective:',\n",
       "  'metadata': {'detection_class_prob': 0.8493790626525879,\n",
       "   'coordinates': {'points': ((198.97500000000008, 1176.701111111111),\n",
       "     (198.97500000000008, 1209.441162109375),\n",
       "     (1376.7501266666663, 1209.441162109375),\n",
       "     (1376.7501266666663, 1176.701111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'f10f6254f5013c0192660b8d960d5540',\n",
       "  'text': 'Memory Perspective. As discussed earlier, our neural long-term memory is a contextual memory, in which all parameters are input-dependent. An effective memory system, however, also needs input-independent parameters to store the abstraction of the task knowledge. That is, mastering a task requires the memorization of the knowledge that how the task can be done, and these parameters are responsible for storing such knowledge.',\n",
       "  'metadata': {'detection_class_prob': 0.9422780871391296,\n",
       "   'coordinates': {'points': ((200.0, 1239.8983333333333),\n",
       "     (200.0, 1372.7950439453125),\n",
       "     (1566.8309326171875, 1372.7950439453125),\n",
       "     (1566.8309326171875, 1239.8983333333333)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '30ebd242d27cb9d8545d856f5dc9918e',\n",
       "  'text': 'Feedforward Network Perspective. In the Transformer architectures, there are fully connected layers after the attention module, which are shown to be similar to attention weights but with data-independent parameters. That is, Sukhbaatar, Grave, et al. (2019) showed that replacing the ReLU in fully connected layers with Softmax can results in an attention-like weights, in which weights are data-independent:',\n",
       "  'metadata': {'detection_class_prob': 0.9413570761680603,\n",
       "   'coordinates': {'points': ((198.975, 1402.726111111111),\n",
       "     (198.975, 1534.774658203125),\n",
       "     (1566.135009765625, 1534.774658203125),\n",
       "     (1566.135009765625, 1402.726111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2019',\n",
       "     'url': 'cite.0@sukhbaatar2019augmenting',\n",
       "     'start_index': 253}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '4bbeb6aecece253c9b9e1f673b79c430',\n",
       "  'text': '𝐹 𝐹 𝑁 (𝑥) = 𝑊𝑉 Softmax (𝑊𝐾𝑥) . (20)',\n",
       "  'metadata': {'detection_class_prob': 0.6367090344429016,\n",
       "   'coordinates': {'points': ((700.2078247070312, 1563.2344444444445),\n",
       "     (700.2078247070312, 1596.345947265625),\n",
       "     (1561.66091, 1596.345947265625),\n",
       "     (1561.66091, 1563.2344444444445)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '70e29c842b35ef8803f365b27550c064',\n",
       "  'text': 'In fact, 𝑊𝐾 and 𝑊𝑉 are acting similar to 𝐾 and 𝑉 matrices in attention module when they are input-independent. The persistent memory weights are expected to have the same functionality, meaning that using them in the first part of the sequence leads to having input-independent attention weights (Sukhbaatar, Grave, et al. 2019).',\n",
       "  'metadata': {'detection_class_prob': 0.9349142909049988,\n",
       "   'coordinates': {'points': ((200.0, 1624.1177777777777),\n",
       "     (200.0, 1723.389892578125),\n",
       "     (1568.7908935546875, 1723.389892578125),\n",
       "     (1568.7908935546875, 1624.1177777777777)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'a038ad1176c9b94d3b97944b43be2b88',\n",
       "  'text': 'Technical Perspective. Attention with causal mask has implicit bias toward initial tokens in the sequence, and so attention weights are almost always highly active for initial tokens, resulting in performance damage. From the technical perspective, these learnable parameters at the start of the sequence can mitigate such effect by redistributing the attention weights more effectively (Han et al. 2024; Xiao et al. 2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9426199197769165,\n",
       "   'coordinates': {'points': ((198.975, 1753.7344444444443),\n",
       "     (198.975, 1885.52197265625),\n",
       "     (1565.6124267578125, 1885.52197265625),\n",
       "     (1565.6124267578125, 1753.7344444444443)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'ad14006689940d2d90c6756c8e59483b',\n",
       "  'text': '8',\n",
       "  'metadata': {'coordinates': {'points': ((873.5666666666667,\n",
       "      2057.742777777778),\n",
       "     (873.5666666666667, 2085.4166666666665),\n",
       "     (886.4350250000001, 2085.4166666666665),\n",
       "     (886.4350250000001, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Image',\n",
       "  'element_id': '06298160d888dd91485e488cff26182f',\n",
       "  'text': 'Segment Window + Long-term Memory HEH EEE iseuszataszesnsse femory @ Long-term Memory @ Persistent Memory',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 202.39645824722206),\n",
       "     (200.0, 477.2472222222221),\n",
       "     (852.7414673, 477.2472222222221),\n",
       "     (852.7414673, 202.39645824722206)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'image_path': 'images\\\\figure-9-3.jpg',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Image',\n",
       "  'element_id': 'b152eddac4496f6a1c0d2a599bb7502b',\n",
       "  'text': 'Sliding Window Long-term Memor (sutton Memory) (Short. and Long-term Memory) de eteeecaite PaeenOny : : : He +H +H HH +4} if | — Z T @ Short-term Memory @ Long-term Memory @ Persistent Memory',\n",
       "  'metadata': {'coordinates': {'points': ((907.2055555555555,\n",
       "      232.8381249138889),\n",
       "     (907.2055555555555, 507.6888888888889),\n",
       "     (1559.9470228555554, 507.6888888888889),\n",
       "     (1559.9470228555554, 232.8381249138889)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'image_path': 'images\\\\figure-9-4.jpg',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'FigureCaption',\n",
       "  'element_id': 'eb55fc3e45d8c83aea332766018d2178',\n",
       "  'text': '(a) Memory as a Context (MAC). We segment the sequence and use full causal attention in each window. Again, the first 𝑁𝑝 tokens are persistent memory and the next 𝑁𝑙 are long-term memory tokens',\n",
       "  'metadata': {'detection_class_prob': 0.8840398192405701,\n",
       "   'coordinates': {'points': ((199.25277777777777, 490.2544444444443),\n",
       "     (199.25277777777777, 609.941162109375),\n",
       "     (854.7462768554688, 609.941162109375),\n",
       "     (854.7462768554688, 490.2544444444443)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'FigureCaption',\n",
       "  'element_id': '7949821e04993b1ce668bc8bd7626efb',\n",
       "  'text': '(b) Memory as Gating (MAG). We use sliding window attention (SWA) as a short-term memory and our neural memory module as a long-term memory, combining by a gating.',\n",
       "  'metadata': {'detection_class_prob': 0.7996006608009338,\n",
       "   'coordinates': {'points': ((906.4583333333333, 520.6961111111111),\n",
       "     (906.4583333333333, 611.1847534179688),\n",
       "     (1562.9820556640625, 611.1847534179688),\n",
       "     (1562.9820556640625, 520.6961111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'b6a1e724ab3d050542173328ad6e3e8c',\n",
       "  'text': 'Figure 3: Attention masks for different variants of Titans.',\n",
       "  'metadata': {'detection_class_prob': 0.6857901811599731,\n",
       "   'coordinates': {'points': ((550.7899780273438, 638.8622222222223),\n",
       "     (550.7899780273438, 672.5655517578125),\n",
       "     (1203.774659444444, 672.5655517578125),\n",
       "     (1203.774659444444, 638.8622222222223)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '402945b3218d7f8699b00c438c111f65',\n",
       "  'text': '4 How to Incorporate Memory?',\n",
       "  'metadata': {'detection_class_prob': 0.8510892391204834,\n",
       "   'coordinates': {'points': ((197.81092834472656, 728.3688116666667),\n",
       "     (197.81092834472656, 768.2193672222221),\n",
       "     (800.3629760742188, 768.2193672222221),\n",
       "     (800.3629760742188, 728.3688116666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '57509458dff4d13c3b74d3ae9720aeb6',\n",
       "  'text': 'An important question that remained unanswered is: How one can effectively and efficiently incorporate the designed neural memory into a deep learning architecture? As discussed earlier, from a memory perspective, the pair of K and V matrices in transformers can be interpreted as an associative memory block. Due to their accurate modeling of dependencies and so their limited context window, we interpret them as short-term memory modules, attending to the current context window size. On the other hand, our neural memory with the ability to continuously learn from data and store it in its weights can play the role of a a long-term memory. In this section, we aim to answer the above question by proposing three different variants of Titans. Later in our experiments, we show that each of these variants has its own advantages/disadvantages and also can show a trade-off between the efficiency and effectiveness in very long-contexts.',\n",
       "  'metadata': {'detection_class_prob': 0.9557410478591919,\n",
       "   'coordinates': {'points': ((193.403076171875, 783.3555555555556),\n",
       "     (193.403076171875, 1090.0882568359375),\n",
       "     (1566.1307373046875, 1090.0882568359375),\n",
       "     (1566.1307373046875, 783.3555555555556)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'parent_id': '402945b3218d7f8699b00c438c111f65',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '655e547071615c3d79d703ec00480eb0',\n",
       "  'text': '4.1 Memory as a Context',\n",
       "  'metadata': {'detection_class_prob': 0.8554794192314148,\n",
       "   'coordinates': {'points': ((198.8147735595703, 1135.246826171875),\n",
       "     (198.8147735595703, 1170.0879200000002),\n",
       "     (599.763916015625, 1170.0879200000002),\n",
       "     (599.763916015625, 1135.246826171875)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'c9ef607219c7d2940784788581f6a978',\n",
       "  'text': 'In the first architecture design (see Figure 2), we treat the memory as a context to the current information. That is, given a long sequence 𝑥 ∈ R𝑁 ×𝑑in, we first chunk the sequence into fixed-size segments S(𝑖 ) for 𝑖 = 1, . . . , 𝑁 /𝐶. Given the incoming segment S(𝑡 ) , we consider it as the current context and its past segment as the historical information. Therefore, let M𝑡 −1 be the state of long-term memory before segment S(𝑡 ) , we use the input context as the query to the memory M𝑡 −1 to retrieve the corresponding information from the long-term memory. That is, we retrieve the past information that corresponds to S(𝑡 ) as:',\n",
       "  'metadata': {'detection_class_prob': 0.9499762654304504,\n",
       "   'coordinates': {'points': ((200.0, 1185.7622222222221),\n",
       "     (200.0, 1384.2930344444444),\n",
       "     (1564.783203125, 1384.2930344444444),\n",
       "     (1564.783203125, 1185.7622222222221)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Figure 2',\n",
       "     'url': 'figure.caption.4',\n",
       "     'start_index': 61}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'parent_id': '655e547071615c3d79d703ec00480eb0',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '4f6f2ae5f0514b557c9086396ccdf188',\n",
       "  'text': 'ℎ𝑡 = M∗',\n",
       "  'metadata': {'coordinates': {'points': ((792.8000000000001,\n",
       "      1411.1659733333333),\n",
       "     (792.8000000000001, 1444.626056111111),\n",
       "     (890.7706713888889, 1444.626056111111),\n",
       "     (890.7706713888889, 1411.1659733333333)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'b95107ab0f6455a43eba647c6bd613f2',\n",
       "  'text': '𝑡 −1(q𝑡 ),',\n",
       "  'metadata': {'coordinates': {'points': ((879.5777777777778,\n",
       "      1412.3583016666666),\n",
       "     (879.5777777777778, 1450.0012511111113),\n",
       "     (965.6799222222221, 1450.0012511111113),\n",
       "     (965.6799222222221, 1412.3583016666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'parent_id': '4f6f2ae5f0514b557c9086396ccdf188',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '11144424ed1c7cf1755ffb8d5b665681',\n",
       "  'text': 'hy = M;_1(40)s (21)',\n",
       "  'metadata': {'detection_class_prob': 0.5805140733718872,\n",
       "   'coordinates': {'points': ((788.71826171875, 1420.4012451171875),\n",
       "     (788.71826171875, 1445.533447265625),\n",
       "     (1551.6427001953125, 1445.533447265625),\n",
       "     (1551.6427001953125, 1420.4012451171875)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '37650981324017e9b72c5ba22b38d557',\n",
       "  'text': 'where q𝑡 = S(𝑡 )𝑊𝑄 . Next, we use this historical information along with our persistent memory parameters as the input',\n",
       "  'metadata': {'coordinates': {'points': ((198.975, 1473.8091658333335),\n",
       "     (198.975, 1510.1983277777776),\n",
       "     (1560.009836702222, 1510.1983277777776),\n",
       "     (1560.009836702222, 1473.8091658333335)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '4856e7d99480d8bb3854318afb214774',\n",
       "  'text': 'sequence to the attention module:',\n",
       "  'metadata': {'detection_class_prob': 0.9169612526893616,\n",
       "   'coordinates': {'points': ((200.0, 1483.263916015625),\n",
       "     (200.0, 1540.245849609375),\n",
       "     (1557.861572265625, 1540.245849609375),\n",
       "     (1557.861572265625, 1483.263916015625)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '9d66b5c6bc3d54d0f1c0041d0127ea8f',\n",
       "  'text': 'a(t) (t) Shs [pr pe + Pvp] Il he IS\", (22)',\n",
       "  'metadata': {'detection_class_prob': 0.6494177579879761,\n",
       "   'coordinates': {'points': ((645.5292358398438, 1567.6952769444445),\n",
       "     (645.5292358398438, 1617.4375),\n",
       "     (1561.66091, 1617.4375),\n",
       "     (1561.66091, 1567.6952769444445)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '14b37f33f01bda8e490d35e4a773abe5',\n",
       "  'text': 'yp = Attn (°°) . (23)',\n",
       "  'metadata': {'detection_class_prob': 0.603111207485199,\n",
       "   'coordinates': {'points': ((648.0194444444444, 1616.1153088888889),\n",
       "     (648.0194444444444, 1669.728271484375),\n",
       "     (1561.6609099999998, 1669.728271484375),\n",
       "     (1561.6609099999998, 1616.1153088888889)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'b50a4544f524051f552b1e71ad1cecdf',\n",
       "  'text': 'The structure of the attention map over the entire sequence is shown in Figure 3a. We then use 𝑦𝑡 to update the long-term',\n",
       "  'metadata': {'coordinates': {'points': ((199.16944444444442,\n",
       "      1696.4816666666666),\n",
       "     (199.16944444444442, 1728.530554722222),\n",
       "     (1560.0053053550002, 1728.530554722222),\n",
       "     (1560.0053053550002, 1696.4816666666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Figure 3a',\n",
       "     'url': 'figure.caption.5',\n",
       "     'start_index': 72}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '092b5469ed6d40bcc0276ae7f5c4acb9',\n",
       "  'text': 'memory module for the next segment and the final output:',\n",
       "  'metadata': {'detection_class_prob': 0.9298713207244873,\n",
       "   'coordinates': {'points': ((200.0, 1705.248046875),\n",
       "     (200.0, 1761.6248779296875),\n",
       "     (1563.021484375, 1761.6248779296875),\n",
       "     (1563.021484375, 1705.248046875)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Figure 3a',\n",
       "     'url': 'figure.caption.5',\n",
       "     'start_index': 72}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '01de1bf785cbc66a80e1ee05cf2a7409',\n",
       "  'text': 'M𝑡 = M𝑡 −1 (𝑦𝑡 ) , (24)',\n",
       "  'metadata': {'detection_class_prob': 0.44562700390815735,\n",
       "   'coordinates': {'points': ((773.6277777777776, 1789.94),\n",
       "     (773.6277777777776, 1831.8385009765625),\n",
       "     (1561.66091, 1831.8385009765625),\n",
       "     (1561.66091, 1789.94)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'aedda55d63dc37c58424b884d1ccfe30',\n",
       "  'text': '𝑜𝑡 = 𝑦𝑡 ⊗ M∗',\n",
       "  'metadata': {'coordinates': {'points': ((772.3833333333333,\n",
       "      1830.5631955555555),\n",
       "     (772.3833333333333, 1864.0232783333333),\n",
       "     (923.4651158333334, 1864.0232783333333),\n",
       "     (923.4651158333334, 1830.5631955555555)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '1d7fe364c821672a05f7d8be095518f6',\n",
       "  'text': '𝑡 (𝑦𝑡 ) . (25)',\n",
       "  'metadata': {'detection_class_prob': 0.46637457609176636,\n",
       "   'coordinates': {'points': ((777.696044921875, 1831.451111111111),\n",
       "     (777.696044921875, 1866.95263671875),\n",
       "     (1561.66091, 1866.95263671875),\n",
       "     (1561.66091, 1831.451111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'cb6e779e01c51671a06ca53afe6337d3',\n",
       "  'text': 'Note that, in the above, we are updating the weight of M𝑡 −1 through forward pass.',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 1891.6983333333333),\n",
       "     (200.0, 1926.5929177777775),\n",
       "     (1138.780081111111, 1926.5929177777775),\n",
       "     (1138.780081111111, 1891.6983333333333)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'fcc6acc990babf4055d5e1362def4cbc',\n",
       "  'text': 'This architecture has two key advantages: (1) Attention by having both historical and current context, has the ability to',\n",
       "  'metadata': {'coordinates': {'points': ((199.16944444444442,\n",
       "      1941.5122222222221),\n",
       "     (199.16944444444442, 1969.1861111111111),\n",
       "     (1560.0127839644447, 1969.1861111111111),\n",
       "     (1560.0127839644447, 1941.5122222222221)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0c19e19cb91a88c212853b914cbb695f',\n",
       "  'text': 'decides whether given the current data, the long-term memory information is needed. (2) The attention module helps',\n",
       "  'metadata': {'detection_class_prob': 0.9255869388580322,\n",
       "   'coordinates': {'points': ((200.0, 1949.7606201171875),\n",
       "     (200.0, 2006.645751953125),\n",
       "     (1560.9832763671875, 2006.645751953125),\n",
       "     (1560.9832763671875, 1949.7606201171875)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '42fc86b1a20e40638ebcd97b4b70d6c9',\n",
       "  'text': '9',\n",
       "  'metadata': {'coordinates': {'points': ((873.5666666666666,\n",
       "      2057.742777777778),\n",
       "     (873.5666666666666, 2085.4166666666665),\n",
       "     (886.4350249999999, 2085.4166666666665),\n",
       "     (886.4350249999999, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'b74ca1b3eca21aac9401a6be23956824',\n",
       "  'text': '(21)',\n",
       "  'metadata': {'coordinates': {'points': ((1519.4305555555554,\n",
       "      1412.0538888888889),\n",
       "     (1519.4305555555554, 1439.7277777777779),\n",
       "     (1561.66091, 1439.7277777777779),\n",
       "     (1561.66091, 1412.0538888888889)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Image',\n",
       "  'element_id': 'e0973ff38426a3e41d0899266a4a8796',\n",
       "  'text': 'Test Time Neural Memory s Sp EI £¢ ‘d oq 3 gs 3 oO = 8 32 g — 2 £4 8 = -—- i ( ap 2 | —————— o— 8a 2 ® Sequence = | Sl gE z° 29 i @ aq ARR Learnable Data-Independent Weights g os a a,',\n",
       "  'metadata': {'coordinates': {'points': ((268.00555555555553,\n",
       "      202.39253938333346),\n",
       "     (268.00555555555553, 588.8083333333333),\n",
       "     (1491.9470262555556, 588.8083333333333),\n",
       "     (1491.9470262555556, 202.39253938333346)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'image_path': 'images\\\\figure-10-5.jpg',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'eec6923f1cadf4624777ad881a214c1b',\n",
       "  'text': 'Figure 4: Memory as a Gate (MAG) Architecture. This architecture, similarly, has the three branches of (1) core, (2) contextual memory, and (3) persistent memory. It, however, incorporates only persistent memory into the context and combine memory with the core branch using a gating mechanism. At test time, the behavior is the same as Figure 2.',\n",
       "  'metadata': {'detection_class_prob': 0.919221818447113,\n",
       "   'coordinates': {'points': ((200.0, 612.0538888888891),\n",
       "     (200.0, 711.9276123046875),\n",
       "     (1565.5220947265625, 711.9276123046875),\n",
       "     (1565.5220947265625, 612.0538888888891)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'a8bc8542349c135a7bbe0cca45b2bf10',\n",
       "  'text': 'the long-term memory to store only useful information from the current context. That is, not all tokens in each segment are useful and memorizing all of them can result in memory overflow. Therefore, attention is helping the memory to understand which information is useful, better managing the memory capacity. (3) At test time: (i) persistent memory parameters are fixed as they encodes the knowledge about the task, which should not be changed; (ii) the attention module weights are in-context learner; and (iii) the long-term memory module is still learning (memorizing) the information at test time. That is, we update the weights of the neural memory even at test time as weights are encoding the abstraction of long past.',\n",
       "  'metadata': {'detection_class_prob': 0.9510798454284668,\n",
       "   'coordinates': {'points': ((198.975, 771.4566666666668),\n",
       "     (198.975, 1003.6691284179688),\n",
       "     (1564.644287109375, 1003.6691284179688),\n",
       "     (1564.644287109375, 771.4566666666668)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '2fabe7a7578807294a1126b897f45818',\n",
       "  'text': '4.2 Gated Memory',\n",
       "  'metadata': {'detection_class_prob': 0.8532147407531738,\n",
       "   'coordinates': {'points': ((197.83827209472656, 1049.2222900390625),\n",
       "     (197.83827209472656, 1083.3823644444444),\n",
       "     (501.66375732421875, 1083.3823644444444),\n",
       "     (501.66375732421875, 1049.2222900390625)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '867bf1458f070ccb73da1e9d329aa085',\n",
       "  'text': 'In the next variant (see Figure 4), in one branch, we directly use the input data to update the long-term memory, and in the',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 1099.0538888888889),\n",
       "     (200.0, 1126.7277777777779),\n",
       "     (1560.007255988889, 1126.7277777777779),\n",
       "     (1560.007255988889, 1099.0538888888889)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Figure 4',\n",
       "     'url': 'figure.caption.6',\n",
       "     'start_index': 42}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'parent_id': '2fabe7a7578807294a1126b897f45818',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '18fdfc9524244f90c442b37a064dbc97',\n",
       "  'text': 'second branch, we use a sliding window attention (SWA):',\n",
       "  'metadata': {'detection_class_prob': 0.9280877709388733,\n",
       "   'coordinates': {'points': ((200.0, 1107.58740234375),\n",
       "     (200.0, 1163.7940673828125),\n",
       "     (1563.8814697265625, 1163.7940673828125),\n",
       "     (1563.8814697265625, 1107.58740234375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Figure 4',\n",
       "     'url': 'figure.caption.6',\n",
       "     'start_index': 42}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'parent_id': '2fabe7a7578807294a1126b897f45818',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': 'a1db21deeeee535fdefb2ab43f160b02',\n",
       "  'text': 'F=[pi po -- pnp] ll x (26)',\n",
       "  'metadata': {'detection_class_prob': 0.626982569694519,\n",
       "   'coordinates': {'points': ((704.7227172851562, 1237.6180866666666),\n",
       "     (704.7227172851562, 1290.974365234375),\n",
       "     (1561.66091, 1290.974365234375),\n",
       "     (1561.66091, 1237.6180866666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '20ecc75c7b029fb11d2ea43284655e51',\n",
       "  'text': '𝑦 = SW-Attn∗ ( ˜𝑥) ,',\n",
       "  'metadata': {'coordinates': {'points': ((707.5916666666667, 1283.58264),\n",
       "     (707.5916666666667, 1317.0427227777777),\n",
       "     (914.224366666667, 1317.0427227777777),\n",
       "     (914.224366666667, 1283.58264)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': 'a4f07765dbe01d04b7c6ae9d59887c2f',\n",
       "  'text': '𝑜 = 𝑦 ⊗ M ( ˜𝑥), (28)',\n",
       "  'metadata': {'detection_class_prob': 0.6603898406028748,\n",
       "   'coordinates': {'points': ((703.380859375, 1297.9105224609375),\n",
       "     (703.380859375, 1370.5799560546875),\n",
       "     (1566.054931640625, 1370.5799560546875),\n",
       "     (1566.054931640625, 1297.9105224609375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'fbdb160c4360253238d89092b72280c9',\n",
       "  'text': 'where SW-Attn∗ is sliding window attention with prefix (see Figure 3b). Note that, contrary to the previous design, we are not segmenting the input data. Also, we abuse the notation and use M (𝑥) to refer to the final output of the memory after all recursion over the tokens of the sequence. In the above equation, ⊗ can be any non-linear gating. In our experiments, we normalize the outputs 𝑦 and M ( ˜𝑥) using learnable vector-valued weights, followed by a non-linearity 𝜎 (.).',\n",
       "  'metadata': {'detection_class_prob': 0.93864506483078,\n",
       "   'coordinates': {'points': ((198.975, 1386.8649999999998),\n",
       "     (198.975, 1518.37032),\n",
       "     (1568.2042236328125, 1518.37032),\n",
       "     (1568.2042236328125, 1386.8649999999998)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Figure 3b',\n",
       "     'url': 'figure.caption.5',\n",
       "     'start_index': 59}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'a7d5f0ded0b4d030b617bfbd1a5e6adc',\n",
       "  'text': 'The overall attention mask of this design is shown in Figure 3b. In this design, sliding window attention is act as a precise',\n",
       "  'metadata': {'coordinates': {'points': ((199.16944444444442,\n",
       "      1536.3038888888887),\n",
       "     (199.16944444444442, 1563.9777777777779),\n",
       "     (1559.986632139445, 1563.9777777777779),\n",
       "     (1559.986632139445, 1536.3038888888887)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Figure 3b',\n",
       "     'url': 'figure.caption.5',\n",
       "     'start_index': 54}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'a3066f9e6c038d0a442d9dbb2636dbc7',\n",
       "  'text': 'short-term memory, while the neural memory module is acting as a fading memory for the model. This architecture design can also be seen as a multi-head architecture where the structure of heads are different (X. Dong et al. 2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9376937747001648,\n",
       "   'coordinates': {'points': ((200.0, 1543.43115234375),\n",
       "     (200.0, 1634.78271484375),\n",
       "     (1565.6680908203125, 1634.78271484375),\n",
       "     (1565.6680908203125, 1543.43115234375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Figure 3b',\n",
       "     'url': 'figure.caption.5',\n",
       "     'start_index': 54}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '4732612417b4960385ebde44cc0871e2',\n",
       "  'text': '4.3 Memory as a Layer',\n",
       "  'metadata': {'detection_class_prob': 0.8616694211959839,\n",
       "   'coordinates': {'points': ((197.0912322998047, 1681.0794677734375),\n",
       "     (197.0912322998047, 1715.3934755555554),\n",
       "     (563.0821533203125, 1715.3934755555554),\n",
       "     (563.0821533203125, 1681.0794677734375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '3e1e2c8add9592980386e1aef1177b6d',\n",
       "  'text': 'The last variant uses the neural Memory As a Layer (MAL) of a deep neural network (see Figure 5). This architecture',\n",
       "  'metadata': {'coordinates': {'points': ((199.16944444444442, 1731.065),\n",
       "     (199.16944444444442, 1758.7388888888888),\n",
       "     (1560.0107914444445, 1758.7388888888888),\n",
       "     (1560.0107914444445, 1731.065)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Figure 5',\n",
       "     'url': 'figure.caption.7',\n",
       "     'start_index': 109}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'parent_id': '4732612417b4960385ebde44cc0871e2',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '9d9515ed38123932327c87e65f79ec1f',\n",
       "  'text': 'design is more common in the literature, where the hybrid models stack recurrent models with full or sliding window attentions. Given input 𝑥, we have:',\n",
       "  'metadata': {'detection_class_prob': 0.9348325133323669,\n",
       "   'coordinates': {'points': ((200.0, 1737.94482421875),\n",
       "     (200.0, 1828.5050048828125),\n",
       "     (1562.677734375, 1828.5050048828125),\n",
       "     (1562.677734375, 1737.94482421875)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Figure 5',\n",
       "     'url': 'figure.caption.7',\n",
       "     'start_index': 109}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'parent_id': '4732612417b4960385ebde44cc0871e2',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': 'd3934a7c915ba9336773d617799869d5',\n",
       "  'text': 'k= [pr po... pnp] lls (29) M(x),',\n",
       "  'metadata': {'detection_class_prob': 0.6469423770904541,\n",
       "   'coordinates': {'points': ((705.3078002929688, 1853.0264199999997),\n",
       "     (705.3078002929688, 1919.01220703125),\n",
       "     (1561.66091, 1919.01220703125),\n",
       "     (1561.66091, 1853.0264199999997)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'f57bd132df94d3e640be978dbd20e9b4',\n",
       "  'text': '𝑦 = M ( ˜𝑥),',\n",
       "  'metadata': {'coordinates': {'points': ((707.5916666666667,\n",
       "      1899.7122222222222),\n",
       "     (707.5916666666667, 1932.4482783333333),\n",
       "     (828.7910333333335, 1932.4482783333333),\n",
       "     (828.7910333333335, 1899.7122222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '2a92427521a3eb2830c3fb16d9593fe4',\n",
       "  'text': '𝑜 = SW-Attn (𝑦) , (31)',\n",
       "  'metadata': {'detection_class_prob': 0.4830491840839386,\n",
       "   'coordinates': {'points': ((708.0055555555558, 1941.3872222222221),\n",
       "     (708.0055555555558, 1977.03564453125),\n",
       "     (1561.6609100000005, 1977.03564453125),\n",
       "     (1561.6609100000005, 1941.3872222222221)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'a1995646a55c5e9fc50882c26eca4456',\n",
       "  'text': '10',\n",
       "  'metadata': {'coordinates': {'points': ((867.1305555555559,\n",
       "      2057.7427777777775),\n",
       "     (867.1305555555559, 2085.4166666666665),\n",
       "     (892.8672722222226, 2085.4166666666665),\n",
       "     (892.8672722222226, 2057.7427777777775)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'e4321467d09e8b91c8449d189ab6e02f',\n",
       "  'text': '(27)',\n",
       "  'metadata': {'coordinates': {'points': ((1519.4305555555559,\n",
       "      1284.4705555555556),\n",
       "     (1519.4305555555559, 1312.1444444444444),\n",
       "     (1561.6609100000005, 1312.1444444444444),\n",
       "     (1561.6609100000005, 1284.4705555555556)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '99c98b9a716ab051c272db7335ea7d6b',\n",
       "  'text': '(30)',\n",
       "  'metadata': {'coordinates': {'points': ((1519.4305555555559,\n",
       "      1899.8761111111112),\n",
       "     (1519.4305555555559, 1927.55),\n",
       "     (1561.6609100000005, 1927.55),\n",
       "     (1561.6609100000005, 1899.8761111111112)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Image',\n",
       "  'element_id': 'a6d9d7eebfdfcde428032ec0d5f05e4f',\n",
       "  'text': 'Test Time Neural Memory Contextual Memory Learning Core all Sequence Attention In-Context Learning & Learnable Data-Independent Weights Persistent Memory Fixed',\n",
       "  'metadata': {'coordinates': {'points': ((268.00555555555553,\n",
       "      202.39222831111096),\n",
       "     (268.00555555555553, 599.736111111111),\n",
       "     (1491.9470262555556, 599.736111111111),\n",
       "     (1491.9470262555556, 202.39222831111096)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'image_path': 'images\\\\figure-11-6.jpg',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'd8ff4760d5f162a20630acd7932263db',\n",
       "  'text': 'Figure 5: Memory as a Layer (MAL) Architecture. In this architecture, the memory layer is responsible to compress the past and current context before the attention module.',\n",
       "  'metadata': {'detection_class_prob': 0.8282893300056458,\n",
       "   'coordinates': {'points': ((200.0, 622.9816666666668),\n",
       "     (200.0, 687.8258056640625),\n",
       "     (1560.009486144444, 687.8258056640625),\n",
       "     (1560.009486144444, 622.9816666666668)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'f997e2b2b322b16e6ebf91c1178041c4',\n",
       "  'text': 'where SW-Attn is sliding window attention. The main drawback of this design is that the power of the model is limited by each of the layers and so it cannot take advantage of the complementary data processing of attention and neural memory module. In our experiments, for evaluating memory in this design, we use a similar architecture as H3 (D. Y. Fu et al. 2023), where we replace the the sequence model with our neural memory module (LMM).',\n",
       "  'metadata': {'detection_class_prob': 0.940243661403656,\n",
       "   'coordinates': {'points': ((198.975, 748.4455555555558),\n",
       "     (198.975, 880.9974975585938),\n",
       "     (1566.228515625, 880.9974975585938),\n",
       "     (1566.228515625, 748.4455555555558)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2023',\n",
       "     'url': 'cite.0@fu2023hungry',\n",
       "     'start_index': 359}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e86ed883bde531e5209e33c823e4be81',\n",
       "  'text': 'Memory Without Attention. Although in the above, we discussed MAL as the combination of LMMs and attention in a sequential manner, one simple variant of MAL is to treat LMM as a sequence model without any attention. From the memory perspective, as discussed in Section 1, we expect each part of the memory system to work independently, even if other components are disturbed. Therefore, a long-term memory module should still be a powerful model even without short-term memory (i.e., attention). We refer to this variant as LMM or Titans (LMM) in our experiments. We provide additional discussions on the connection of Titans and other modern recurrent models in Appendix C.',\n",
       "  'metadata': {'detection_class_prob': 0.9539770483970642,\n",
       "   'coordinates': {'points': ((200.0, 911.2705555555555),\n",
       "     (200.0, 1109.2110595703125),\n",
       "     (1567.0167236328125, 1109.2110595703125),\n",
       "     (1567.0167236328125, 911.2705555555555)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Section 1', 'url': 'section.1', 'start_index': 261}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '7d1090c61156ad97d688eafcfd49b940',\n",
       "  'text': '4.4 Architectural Details',\n",
       "  'metadata': {'detection_class_prob': 0.8619310855865479,\n",
       "   'coordinates': {'points': ((199.8319549560547, 1155.1644287109375),\n",
       "     (199.8319549560547, 1189.8295866666667),\n",
       "     (593.7836303710938, 1189.8295866666667),\n",
       "     (593.7836303710938, 1155.1644287109375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'cfbdb91dc0a6bc477a0bf573a865bb20',\n",
       "  'text': 'For the sake of simplicity and presentation, we avoid discussing the implementation details like using residual connection,',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 1205.503888888889),\n",
       "     (200.0, 1233.1777777777777),\n",
       "     (1563.0480628999996, 1233.1777777777777),\n",
       "     (1563.0480628999996, 1205.503888888889)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '7d1090c61156ad97d688eafcfd49b940',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0e9122ed2981e6d402c32553c79199ae',\n",
       "  'text': 'gating with linear layer, and normalization. In all blocks, we use residual connections. In our implementation, we use SiLU(.) activation (Elfwing, Uchibe, and Doya 2018) as the non-linear activation for computing query, key, and values and normalize queries and keys using ℓ2-norm.',\n",
       "  'metadata': {'detection_class_prob': 0.9444149732589722,\n",
       "   'coordinates': {'points': ((200.0, 1212.363037109375),\n",
       "     (200.0, 1336.9527777777778),\n",
       "     (1566.6048583984375, 1336.9527777777778),\n",
       "     (1566.6048583984375, 1212.363037109375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2018',\n",
       "     'url': 'cite.0@elfwing2018sigmoid',\n",
       "     'start_index': 315}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '7d1090c61156ad97d688eafcfd49b940',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '625973629c63ffbd8e835895e56a4a72',\n",
       "  'text': 'Convolution. Following the recent modern linear recurrent models (Gu and Dao 2024; S. Yang, Kautz, and Hatamizadeh 2024), we incorporate a 1D depthwise-separable convolution layer after each of the query, key, and value projections. While not significantly affect the performance, these 1D convolutions have shown performance improvement and are also computationally efficient.',\n",
       "  'metadata': {'detection_class_prob': 0.9431231021881104,\n",
       "   'coordinates': {'points': ((198.67222222222222, 1368.3288888888887),\n",
       "     (198.67222222222222, 1498.2186279296875),\n",
       "     (1569.9544677734375, 1498.2186279296875),\n",
       "     (1569.9544677734375, 1368.3288888888887)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024', 'url': 'cite.0@gu2024mamba', 'start_index': 77},\n",
       "    {'text': '2024', 'url': 'cite.0@yang2024gated', 'start_index': 115}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '7d1090c61156ad97d688eafcfd49b940',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'b5fb3dda78183bc2066a25b2d1c99169',\n",
       "  'text': 'Gating. We also follow the recent architectures that use normalization and gating with a linear layer before the final output projection (Mehta et al. 2023).',\n",
       "  'metadata': {'detection_class_prob': 0.9205619096755981,\n",
       "   'coordinates': {'points': ((200.0, 1531.153888888889),\n",
       "     (200.0, 1592.0361111111113),\n",
       "     (1566.552490234375, 1592.0361111111113),\n",
       "     (1566.552490234375, 1531.153888888889)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '7d1090c61156ad97d688eafcfd49b940',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '40de9074be1b31a699ef7773aa6d2ad8',\n",
       "  'text': 'Theorem 4.1. Contrary to Transformers, diagonal linear recurrent models, and DeltaNet, all of which are limited to TC0 (Merrill,',\n",
       "  'metadata': {'coordinates': {'points': ((199.0861111111111,\n",
       "      1611.6008333333334),\n",
       "     (199.0861111111111, 1648.32569),\n",
       "     (1563.0177991555554, 1648.32569),\n",
       "     (1563.0177991555554, 1611.6008333333334)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '7d1090c61156ad97d688eafcfd49b940',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '5f25004b7417db9f699a57fa44ecfd6c',\n",
       "  'text': 'Petty, and Sabharwal 2024), Titans are capable of solving problems beyond TC 0, meaning that Titans are theoretically more expressive than Transformers and most modern linear recurrent models in state tracking tasks.',\n",
       "  'metadata': {'detection_class_prob': 0.9426270127296448,\n",
       "   'coordinates': {'points': ((200.0, 1622.9024658203125),\n",
       "     (200.0, 1714.7423566666664),\n",
       "     (1565.390869140625, 1714.7423566666664),\n",
       "     (1565.390869140625, 1622.9024658203125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@merrill2024the',\n",
       "     'start_index': 150}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '7d1090c61156ad97d688eafcfd49b940',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'cfa3a575fd3817cf4e4fda1b3228636b',\n",
       "  'text': '5 Experiments',\n",
       "  'metadata': {'detection_class_prob': 0.8551798462867737,\n",
       "   'coordinates': {'points': ((198.04727172851562, 1767.907958984375),\n",
       "     (198.04727172851562, 1808.6804783333332),\n",
       "     (495.02960205078125, 1808.6804783333332),\n",
       "     (495.02960205078125, 1767.907958984375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e3cb3e3df256cf71b36abdfcb57a8c59',\n",
       "  'text': 'Next, we evaluate the performance of Titans and its variants in language modeling, commonsense reasoning, needle',\n",
       "  'metadata': {'detection_class_prob': 0.9443007111549377,\n",
       "   'coordinates': {'points': ((198.08029174804688, 1823.8166666666668),\n",
       "     (198.08029174804688, 1928.6317138671875),\n",
       "     (1564.968017578125, 1928.6317138671875),\n",
       "     (1564.968017578125, 1823.8166666666668)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '.', 'url': 'Hfootnote.1', 'start_index': 61},\n",
       "    {'text': '.', 'url': 'Hfootnote.1', 'start_index': 61}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': 'cfa3a575fd3817cf4e4fda1b3228636b',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0757247660c446e70f6b54aa7360638c',\n",
       "  'text': '1In the first version of the work, we aim to provide insights/evidences about why the learning paradigms of Titans are effective. We are working on',\n",
       "  'metadata': {'coordinates': {'points': ((230.48888888888888,\n",
       "      1950.9088888888887),\n",
       "     (230.48888888888888, 1976.1027777777779),\n",
       "     (1559.9979700899994, 1976.1027777777779),\n",
       "     (1559.9979700899994, 1950.9088888888887)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': 'cfa3a575fd3817cf4e4fda1b3228636b',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '2e49a10ea482dee884d9ca170c7fe001',\n",
       "  'text': 'finalizing the results of larger models and will report them in the next version.',\n",
       "  'metadata': {'detection_class_prob': 0.9321843385696411,\n",
       "   'coordinates': {'points': ((200.0, 1959.3563232421875),\n",
       "     (200.0, 2006.4149169921875),\n",
       "     (1560.4755859375, 2006.4149169921875),\n",
       "     (1560.4755859375, 1959.3563232421875)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': 'cfa3a575fd3817cf4e4fda1b3228636b',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '8c0e876fbcc34b3f2c4505fcd2c95403',\n",
       "  'text': '11',\n",
       "  'metadata': {'coordinates': {'points': ((867.1305555555556,\n",
       "      2057.742777777778),\n",
       "     (867.1305555555556, 2085.4166666666665),\n",
       "     (892.8672722222223, 2085.4166666666665),\n",
       "     (892.8672722222223, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': 'cfa3a575fd3817cf4e4fda1b3228636b',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0098411969ee1e6028f605d4bcddab8e',\n",
       "  'text': '§5.6, and §5.7); (2) What is the actual context length of Titans? (see §5.3 and §5.4); (3) How do Titans scale with respect to context length? (see §5.8); (4) How the depth of memory can affect both performance and efficiency? (see §5.5); and (5) What is the contribution of each Titans’ component in its performance? (see §5.9).',\n",
       "  'metadata': {'detection_class_prob': 0.933875560760498,\n",
       "   'coordinates': {'points': ((198.67222222222222, 202.39277777777778),\n",
       "     (198.67222222222222, 303.04248046875),\n",
       "     (1566.6962890625, 303.04248046875),\n",
       "     (1566.6962890625, 202.39277777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '5 . 6', 'url': 'subsection.5.6', 'start_index': 1},\n",
       "    {'text': '5 . 7', 'url': 'subsection.5.7', 'start_index': 11},\n",
       "    {'text': '5 . 3', 'url': 'subsection.5.3', 'start_index': 72},\n",
       "    {'text': '5 . 4', 'url': 'subsection.5.4', 'start_index': 81},\n",
       "    {'text': '5 . 8', 'url': 'subsection.5.8', 'start_index': 149},\n",
       "    {'text': '5 . 5', 'url': 'subsection.5.5', 'start_index': 230}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': 'cfa3a575fd3817cf4e4fda1b3228636b',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '767636bcfe635f847f80a633df9c9861',\n",
       "  'text': '5.1 Experimental Setup',\n",
       "  'metadata': {'detection_class_prob': 0.8617863059043884,\n",
       "   'coordinates': {'points': ((198.5486602783203, 348.1585388183594),\n",
       "     (198.5486602783203, 381.48514222222207),\n",
       "     (575.4789428710938, 381.48514222222207),\n",
       "     (575.4789428710938, 348.1585388183594)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '993a4c5d969cb202b84d112e1c04f884',\n",
       "  'text': 'Models. In our experiments, we focus on the three variants of Titans, which we refer to as: Titans with (1) Memory as a Context (MAC), (2) Memory as a Gate (MAG), and (3) Memory as a Layer (MAL) as well as (4) neural memory module alone. The reason behind using our long-term memory as a separate module is based on our definition of learning. As discussed in Section 1, we define learning a process for acquiring effective and useful memory. Accordingly, we expect our long-term memory to effectively learn from data, even without attention. For each of these models, we consider four scales with: (i) 170M, (ii) 340M, (iii) 400M, and (iv) 760M parameters. While the first three are trained on 15B tokens sampled from FineWeb-Edu dataset (Penedo et al. 2024), the last one is trained on 30B tokens from the same dataset.',\n",
       "  'metadata': {'detection_class_prob': 0.9535374045372009,\n",
       "   'coordinates': {'points': ((198.975, 410.5427777777777),\n",
       "     (198.975, 643.736083984375),\n",
       "     (1571.53955078125, 643.736083984375),\n",
       "     (1571.53955078125, 410.5427777777777)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Section 1', 'url': 'section.1', 'start_index': 359}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': '767636bcfe635f847f80a633df9c9861',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'febb6cae14b8f768549a0faa0467bfc9',\n",
       "  'text': 'Baselines. We compare our models with the state-of-the-art linear recurrent models, Transformers, and hybrid models (recurrent + attention). More specifically in language tasks, we compare with Transformer++ (Touvron et al. 2023), RetNet (Yutao Sun et al. 2023), Gated Linear Attention (GLA) (S. Yang, B. Wang, Shen, et al. 2024), Mamba (Gu and Dao 2024), Mamba2 (Dao and Gu 2024), DeltaNet (S. Yang, B. Wang, Yu Zhang, et al. 2024), TTT (Yu Sun et al. 2024), and Gated DeltaNet (S. Yang, Kautz, and Hatamizadeh 2024). In needle in haystack tasks, we also compare with GPT4 (Achiam et al. 2023), Llama3 with RAG (Touvron et al. 2023), RecurrentGemma2-9B (Botev et al. 2024), and Mistral (Jiang et al. 2023) models, all of which are provided in the benchmark (Yuri Kuratov et al. 2024). In time series tasks, we compare with Mamba-based (Behrouz, Santacatterina, and Zabih 2024), Transformer-based (Y. Liu et al. 2023; Nie et al. 2022; Yunhao Zhang and Yan 2023), and linear models (Das et al. 2023; Z. Li et al. 2023; H. Wu et al. 2023; Zeng et al. 2023).',\n",
       "  'metadata': {'detection_class_prob': 0.953460156917572,\n",
       "   'coordinates': {'points': ((199.16944444444442, 672.9927777777779),\n",
       "     (199.16944444444442, 971.8728637695312),\n",
       "     (1566.31396484375, 971.8728637695312),\n",
       "     (1566.31396484375, 672.9927777777779)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2023',\n",
       "     'url': 'cite.0@touvron2023llama',\n",
       "     'start_index': 223},\n",
       "    {'text': '2023', 'url': 'cite.0@sun2023retentive', 'start_index': 255},\n",
       "    {'text': '2024', 'url': 'cite.0@yang2024gatedattn', 'start_index': 323},\n",
       "    {'text': '2024', 'url': 'cite.0@gu2024mamba', 'start_index': 348},\n",
       "    {'text': '2024', 'url': 'cite.0@dao2024transformers', 'start_index': 374},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@yang2024parallelizing',\n",
       "     'start_index': 426},\n",
       "    {'text': '2024', 'url': 'cite.0@sun2024learning', 'start_index': 452},\n",
       "    {'text': '2024', 'url': 'cite.0@yang2024gated', 'start_index': 511},\n",
       "    {'text': '2023', 'url': 'cite.0@achiam2023gpt', 'start_index': 588},\n",
       "    {'text': '2023', 'url': 'cite.0@touvron2023llama', 'start_index': 627},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@botev2024recurrentgemma',\n",
       "     'start_index': 667},\n",
       "    {'text': '2023', 'url': 'cite.0@jiang2023mistral', 'start_index': 700},\n",
       "    {'text': '2024', 'url': 'cite.0@kuratov2024babilong', 'start_index': 778},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@behrouz2024mambamixer',\n",
       "     'start_index': 871},\n",
       "    {'text': '2023', 'url': 'cite.0@liu2023itransformer', 'start_index': 911},\n",
       "    {'text': '2022', 'url': 'cite.0@nie2022time', 'start_index': 928}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': '767636bcfe635f847f80a633df9c9861',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '2f1d0f392effad35785493f3e9dbe77b',\n",
       "  'text': 'Training. In the training, we follow the training procedure of S. Yang, Kautz, and Hatamizadeh (2024), and use LLama 2 tokenizer with a vocabulary size of 32K and use training length of 4K tokens. We employ AdamW optimizer with learning rate of 4𝑒-4 with cosine annealing schedule with batch size of 0.5M tokens, and weight decay of 0.1.',\n",
       "  'metadata': {'detection_class_prob': 0.93450528383255,\n",
       "   'coordinates': {'points': ((199.0861111111111, 1001.8622222222222),\n",
       "     (199.0861111111111, 1100.464111328125),\n",
       "     (1565.51513671875, 1100.464111328125),\n",
       "     (1565.51513671875, 1001.8622222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@yang2024gated',\n",
       "     'start_index': 96}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': '767636bcfe635f847f80a633df9c9861',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '39cb78456cdcc2ce4c4fe062816ccc92',\n",
       "  'text': '5.2 Language Modeling',\n",
       "  'metadata': {'detection_class_prob': 0.8633062839508057,\n",
       "   'coordinates': {'points': ((197.72181701660156, 1145.8643798828125),\n",
       "     (197.72181701660156, 1180.9545866666667),\n",
       "     (572.2686767578125, 1180.9545866666667),\n",
       "     (572.2686767578125, 1145.8643798828125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e775e217658dde3282ad00ce4a9a3097',\n",
       "  'text': 'We first focus on the perplexity in language modeling and also commonsense reasoning tasks. The results for Titans’ variants and also baselines with three different sizes of 340M, 400M, and 760M are reported in Table 1. Among non-hybrid models, including Transformer++, our neural memory module achieves the best performance in both perplexity and accuracy measures. Comparing our neural memory module and TTT, which is also a gradient-based recurrent model can show us the importance of our weight decay as well as the momentum. As discussed earlier, the weight decay can be interpreted as a gating mechanism to forget the past data, when it is needed. Also, momentum can help us better manage the memory by providing additional memory for the surprise metric. While some baselines also take advantage of gating mechanism, e.g., Mamba, Mamba2, and Gated DeltaNet, the superior performance of our neural memory module shows the importance of both our surprise mechanism and having deep and non-linear memory. We further discuss the later in Section 5.5.',\n",
       "  'metadata': {'detection_class_prob': 0.9554047584533691,\n",
       "   'coordinates': {'points': ((198.67222222222222, 1196.626111111111),\n",
       "     (198.67222222222222, 1525.4429931640625),\n",
       "     (1567.996826171875, 1525.4429931640625),\n",
       "     (1567.996826171875, 1196.626111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Table 1',\n",
       "     'url': 'table.caption.8',\n",
       "     'start_index': 231}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': '39cb78456cdcc2ce4c4fe062816ccc92',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0d3b1ec75c73d1cdee06d2073bf9d998',\n",
       "  'text': 'Comparing the hybrid models, we found that all three variants of Titans (MAC, MAG, and MAL) outperform both Samba (Mamba + attention) and Gated DeltaNet-H2 (Gated DeltaNet + atttention). We attribute the superior performance of Titans (MAL) to the power of neural memory module as the architecture design and used attention are all the same. Comparing Titans (MAG) and (MAC), we find that while their performance are close, MAC performs better when dealing with longer dependencies in the data. Interestingly, both MAG and MAC outperform MAL variant, which due to using the same modules, we attribute this to the architecture design of these models. This finding is particularly important as the current hybrid models (except Hymba (X. Dong et al. 2024)) in the literature are using MAL-style combination of recurrent models and attention.',\n",
       "  'metadata': {'detection_class_prob': 0.9574702978134155,\n",
       "   'coordinates': {'points': ((199.16944444444442, 1545.3177777777776),\n",
       "     (199.16944444444442, 1809.2642822265625),\n",
       "     (1566.637451171875, 1809.2642822265625),\n",
       "     (1566.637451171875, 1545.3177777777776)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@dong2024hymba',\n",
       "     'start_index': 746}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': '39cb78456cdcc2ce4c4fe062816ccc92',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'ee5e23d702741ae81942bad2cd360674',\n",
       "  'text': '5.3 Needle in a Haystack',\n",
       "  'metadata': {'detection_class_prob': 0.8665764331817627,\n",
       "   'coordinates': {'points': ((196.60450744628906, 1853.6009521484375),\n",
       "     (196.60450744628906, 1890.4518088888888),\n",
       "     (596.41845703125, 1890.4518088888888),\n",
       "     (596.41845703125, 1853.6009521484375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '17ecbfba394dc6af481adcc7890c5fe8',\n",
       "  'text': 'Scaling a model to longer context window is not always equivalent to being effective for very long sequences (Hsieh et al. 2024). The needle-in-a-haystack (NIAH) task is designed to measure the actual effective context length of models. In this task, we evaluate the model on retrieving a piece of information (i.e., the “needle”) from long distractor texts (i.e.,',\n",
       "  'metadata': {'detection_class_prob': 0.9367905259132385,\n",
       "   'coordinates': {'points': ((200.0, 1906.1261111111112),\n",
       "     (200.0, 2004.8243408203125),\n",
       "     (1564.3790283203125, 2004.8243408203125),\n",
       "     (1564.3790283203125, 1906.1261111111112)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@hsieh2024ruler',\n",
       "     'start_index': 147}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': 'ee5e23d702741ae81942bad2cd360674',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '04c1c33e52bc71528878346400dea054',\n",
       "  'text': '12',\n",
       "  'metadata': {'coordinates': {'points': ((867.1305555555555,\n",
       "      2057.742777777778),\n",
       "     (867.1305555555555, 2085.4166666666665),\n",
       "     (892.8672722222221, 2085.4166666666665),\n",
       "     (892.8672722222221, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': 'ee5e23d702741ae81942bad2cd360674',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '3258a588b3fff4fb2efa8056bfa139cc',\n",
       "  'text': 'Table 1: Performance of Titans and recurrent- and Transformer-based baselines on language modeling and common-sense',\n",
       "  'metadata': {'coordinates': {'points': ((199.16944444444442,\n",
       "      197.96500000000017),\n",
       "     (199.16944444444442, 225.63888888888894),\n",
       "     (1560.0095461194444, 225.63888888888894),\n",
       "     (1560.0095461194444, 197.96500000000017)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'ee5e23d702741ae81942bad2cd360674',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'FigureCaption',\n",
       "  'element_id': '9e76e442a42d0ef79390227fe5a4d912',\n",
       "  'text': 'reasoning tasks. Hybrid models are marked with ∗. The best results among simple and hybrid models are highlighted.',\n",
       "  'metadata': {'detection_class_prob': 0.9193933010101318,\n",
       "   'coordinates': {'points': ((200.0, 207.19430541992188),\n",
       "     (200.0, 267.585693359375),\n",
       "     (1559.9769387244442, 267.585693359375),\n",
       "     (1559.9769387244442, 207.19430541992188)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'ee5e23d702741ae81942bad2cd360674',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Table',\n",
       "  'element_id': 'f326c8f48f3c77fa751d5c7ff95f9f6b',\n",
       "  'text': 'Model Wiki. LMB. LMB. PIQA Hella. Wino. ARC-e ARC-c SIQA BoolQ Avg. ppl ↓ ppl ↓ acc ↑ acc ↑ acc_n ↑ acc ↑ acc ↑ acc_n ↑ acc ↑ acc ↑ ↑ 340M params / 15B tokens Transformer++ 31.52 41.08 30.76 62.98 34.76 50.53 45.21 24.05 36.81 58.24 42.92 RetNet 32.50 49.73 28.24 62.61 34.15 50.91 44.27 23.62 36.79 59.72 42.54 GLA 28.51 43.02 28.73 64.05 35.96 50.00 54.19 24.29 37.13 58.39 44.09 Mamba 30.83 40.21 29.94 63.79 35.88 49.82 49.24 24.56 35.41 60.07 43.59 DeltaNet 28.65 47.30 28.43 63.52 35.95 49.63 52.68 25.37 37.96 58.79 44.04 TTT 27.44 34.19 30.06 63.97 35.71 50.08 53.01 26.11 37.32 59.83 44.51 Gated DeltaNet 27.01 30.94 34.11 63.08 38.12 51.60 55.28 26.77 34.89 59.54 45.42 Titans (LMM) 26.18 29.97 34.98 64.73 39.61 51.85 55.60 28.14 34.52 59.99 46.17 Titans (MAC)∗ 25.43 28.13 36.00 65.32 40.35 51.21 58.17 29.00 38.63 60.18 47.36 Titans (MAG)∗ 25.07 28.72 36.71 64.88 40.56 52.49 57.72 28.16 39.75 60.01 47.54 Titans (MAL)∗ 24.69 28.80 35.74 64.97 39.44 51.97 56.58 28.21 38.14 57.32 46.55 400M params / 15B tokens Transformer++ 30.63 37.37 29.64 64.27 37.72 51.53 54.95 27.36 38.07 61.59 45.64 RetNet 29.92 46.83 29.16 65.23 36.97 51.85 56.01 27.55 37.30 59.66 45.47 HGRN2 32.33 47.14 26.12 64.52 35.45 52.24 55.97 25.51 37.35 59.02 44.52 GLA 27.96 36.66 27.86 65.94 37.41 49.56 56.01 26.36 38.94 59.84 45.24 Mamba 29.22 39.88 29.82 65.72 37.93 50.11 58.37 26.70 37.76 61.13 45.94 Mamba2 26.34 33.19 32.03 65.77 39.73 52.48 59.00 27.64 37.92 60.72 46.91 DeltaNet 27.69 44.04 29.96 64.52 37.03 50.82 56.77 27.13 38.22 60.09 45.57 TTT 26.11 31.52 33.25 65.70 39.11 51.68 58.04 28.99 38.26 59.87 46.86 Gated DeltaNet 25.47 29.24 34.40 65.94 40.46 51.46 59.80 28.58 37.43 60.03 47.26 Samba∗ 25.32 29.47 36.86 66.09 39.24 51.45 60.12 27.20 38.68 58.22 47.23 Gated DeltaNet-H2∗ 24.19 28.09 36.77 66.43 40.79 52.17 59.55 29.09 39.04 58.56 47.69 Titans (LMM) 25.03 28.99 35.21 65.85 40.91 52.19 59.97 29.20 38.74 60.85 47.83 Titans (MAC)∗ 25.61 27.73 36.92 66.39 41.18 52.80 60.24 29.69 40.07 61.93 48.65 Titans (MAG)∗ 23.59 27.81 37.24 66.80 40.92 53.21 60.01 29.45 39.91 61.28 48.60 Titans (MAL)∗ 23.93 27.89 36.84 66.29 40.74 52.26 59.85 29.71 38.92 58.40 47.87 760M params / 30B tokens Transformer++ 25.21 27.64 35.78 66.92 42.19 51.95 60.38 32.46 39.51 60.37 48.69 RetNet 26.08 24.45 34.51 67.19 41.63 52.09 63.17 32.78 38.36 57.92 48.46 Mamba 28.12 23.96 32.80 66.04 39.15 52.38 61.49 30.34 37.96 57.62 47.22 Mamba2 22.94 28.37 33.54 67.90 42.71 49.77 63.48 31.09 40.06 58.15 48.34 DeltaNet 24.37 24.60 37.06 66.93 41.98 50.65 64.87 31.39 39.88 59.02 48.97 TTT 24.17 23.51 34.74 67.25 43.92 50.99 64.53 33.81 40.16 59.58 47.32 Gated DeltaNet 21.18 22.09 35.54 68.01 44.95 50.73 66.87 33.09 39.21 59.14 49.69 Samba∗ 20.63 22.71 39.72 69.19 47.35 52.01 66.92 33.20 38.98 61.24 51.08 Gated DeltaNet-H2∗ 19.88 20.83 39.18 68.95 48.22 52.57 67.01 35.49 39.39 61.11 51.49 Titans (LMM) 20.04 21.96 37.40 69.28 48.46 52.27 66.31 35.84 40.13 62.76 51.56 Titans (MAC) 19.93 20.12 39.62 70.46 49.01 53.18 67.86 36.01 41.87 62.05 52.51 Titans (MAG) 18.61 19.86 40.98 70.25 48.94 52.89 68.23 36.19 40.38 62.11 52.50 Titans (MAL) 19.07 20.33 40.05 69.99 48.82 53.02 67.54 35.65 30.98 61.72 50.97',\n",
       "  'metadata': {'detection_class_prob': 0.9166533946990967,\n",
       "   'coordinates': {'points': ((280.84796142578125, 270.0185852050781),\n",
       "     (280.84796142578125, 1669.321044921875),\n",
       "     (1482.90869140625, 1669.321044921875),\n",
       "     (1482.90869140625, 270.0185852050781)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'text_as_html': '<table><thead><tr><th>Model</th><th>Wiki. ppl!</th><th>LMB. ppl)</th><th>| LMB. | acct</th><th>PIQA accT</th><th>Hella. accnf</th><th>Wino. acct</th><th>ARC-e accT</th><th>ARC-c accnf</th><th>SIQA accT</th><th>BoolQ acct</th><th>Avg. T</th></tr></thead><tbody><tr><td colspan=\"12\">340M params / 15B tokens</td></tr><tr><td>Transformer++</td><td>31.52</td><td>41.08</td><td>30.76</td><td>62.98</td><td>34.76</td><td>50.53</td><td>45.21</td><td>24.05</td><td>36.81</td><td>58.24</td><td>42.92</td></tr><tr><td>RetNet</td><td>32.50</td><td>49.73</td><td>28.24</td><td>= 62.61</td><td>34.15</td><td>50.91</td><td>44.27</td><td>23.62</td><td>36.79</td><td>59.72</td><td>42.54</td></tr><tr><td>GLA</td><td>28.51</td><td>43.02</td><td>28.73</td><td>64.05</td><td>35.96</td><td>50.00</td><td>54.19</td><td>24.29</td><td>37.13</td><td>58.39</td><td>44.09</td></tr><tr><td>Mamba</td><td>30.83</td><td>40.21</td><td>29.94</td><td>63.79</td><td>35.88</td><td>49.82</td><td>49.24</td><td>24.56</td><td>35.41</td><td>60.07</td><td>43.59</td></tr><tr><td>DeltaNet</td><td>28.65</td><td>47.30</td><td>28.43</td><td>63.52</td><td>35.95</td><td>49.63</td><td>52.68</td><td>25.37</td><td>37.96</td><td>58.79</td><td>44.04</td></tr><tr><td>TIT</td><td>27.44</td><td>34.19</td><td>30.06</td><td>63.97</td><td>35.71</td><td>50.08</td><td>53.01</td><td>26.11</td><td>37.32</td><td>59.83</td><td>44.51</td></tr><tr><td>Gated DeltaNet</td><td>27.01</td><td>30.94</td><td>34.11</td><td>63.08</td><td>38.12</td><td>51.60</td><td>55.28</td><td>26.77</td><td>34.89</td><td>59.54</td><td>45.42</td></tr><tr><td>Titans (LMM)</td><td>26.18</td><td>29.97</td><td>34.98</td><td>64.73</td><td>39.61</td><td>51.85</td><td>55.60</td><td>28.14</td><td>34.52</td><td>59.99</td><td>46.17</td></tr><tr><td>Titans (MAC)*</td><td>25.43</td><td>28.13</td><td>36.00</td><td>65.32</td><td>40.35</td><td>51.21</td><td>58.17</td><td>29.00</td><td>38.63</td><td>60.18</td><td>47.36</td></tr><tr><td>Titans (MAG)*</td><td>25.07</td><td>28.72</td><td>36.71</td><td>64.88</td><td>40.56</td><td>52.49</td><td>57.72</td><td>28.16</td><td>39.75,</td><td>60.01</td><td>47.54</td></tr><tr><td>Titans (MAL)*</td><td>24.69</td><td>28.80</td><td>35.74</td><td>64.97</td><td>39.44</td><td>51.97</td><td>56.58</td><td>28.21</td><td>38.14</td><td>57.32</td><td>46.55</td></tr><tr><td colspan=\"12\">400M params / 15B tokens</td></tr><tr><td>Transformer++</td><td>30.63</td><td>37.37</td><td>29.64</td><td>64.27</td><td>37.72</td><td>51.53</td><td>54.95</td><td>27.36</td><td>38.07</td><td>61.59</td><td>45.64</td></tr><tr><td>RetNet</td><td>29.92</td><td>46.83</td><td>29.16</td><td>65.23</td><td>36.97</td><td>51.85</td><td>56.01</td><td>27.55</td><td>37.30</td><td>59.66</td><td>45.47</td></tr><tr><td>HGRN2</td><td>32.33</td><td>47.14</td><td>26.12</td><td>64.52</td><td>35.45</td><td>52.24</td><td>55.97</td><td>25.51</td><td>37.35</td><td>59.02</td><td>44.52</td></tr><tr><td>GLA</td><td>27.96</td><td>36.66</td><td>27.86</td><td></td><td>37.41</td><td>49.56</td><td>56.01</td><td>26.36</td><td></td><td>59.84</td><td>45.24</td></tr><tr><td></td><td></td><td></td><td></td><td>65.94</td><td></td><td></td><td></td><td></td><td>38.94</td><td></td><td></td></tr><tr><td>Mamba</td><td>29.22</td><td>39.88</td><td>29.82</td><td>65.72</td><td>37.93</td><td>50.11</td><td>58.37</td><td>26.70</td><td>37.76</td><td>61.13</td><td>45.94</td></tr><tr><td>Mamba2</td><td>26.34</td><td>33.19</td><td>32.03</td><td>65.77</td><td>39.73</td><td>52.48</td><td>59.00</td><td>27.64</td><td>37.92</td><td>60.72</td><td>46.91</td></tr><tr><td>DeltaNet</td><td>27.69</td><td>44.04</td><td>29.96</td><td>64.52</td><td>37.03</td><td>50.82</td><td>56.77</td><td>27.13</td><td>38.22</td><td>60.09</td><td>45.57</td></tr><tr><td>TIT</td><td>26.11</td><td>31.52</td><td>33.25</td><td>65.70</td><td>39.11</td><td>51.68</td><td>58.04</td><td>28.99</td><td>38.26</td><td>59.87</td><td>46.86</td></tr><tr><td>Gated DeltaNet</td><td>25.47</td><td>29.24</td><td>34.40</td><td>65.94</td><td>40.46</td><td>51.46</td><td>59.80</td><td>28.58</td><td>37.43</td><td>60.03</td><td>47.26</td></tr><tr><td>Samba*</td><td>25.32</td><td>29.47</td><td>36.86</td><td>66.09</td><td>39.24</td><td>51.45</td><td>60.12</td><td>27.20</td><td>38.68</td><td>58.22</td><td>47.23</td></tr><tr><td>Gated DeltaNet-H2* |</td><td>24.19</td><td>28.09</td><td>36.77</td><td>66.43</td><td>40.79</td><td>52.17</td><td>59.55</td><td>29.09</td><td>39.04</td><td>58.56</td><td>47.69</td></tr><tr><td>Titans (LMM)</td><td>25.03</td><td>28.99</td><td>| 35.21</td><td>65.85</td><td>40.91</td><td>52.19</td><td>59.97</td><td>29.20</td><td>38.74</td><td>60.85</td><td>47.83</td></tr><tr><td>Titans (MAC)*</td><td>25.61</td><td>27.73</td><td>36.92</td><td>66.39</td><td>41.18</td><td>52.80</td><td>60.24</td><td>29.69</td><td>40.07</td><td>61.93</td><td>48.65</td></tr><tr><td>Titans (MAG)*</td><td>23.59</td><td>27.81</td><td>37.24</td><td>66.80</td><td>40.92</td><td>53.21</td><td>60.01</td><td>29.45</td><td>39.91</td><td>61.28</td><td>48.60</td></tr><tr><td rowspan=\"2\">Titans (MAL)*</td><td>23.93</td><td>27.89</td><td>36.84</td><td>66.29</td><td>40.74</td><td>52.26</td><td>59.85</td><td>29.71</td><td>38.92</td><td>58.40</td><td>47.87</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td colspan=\"12\">760M params / 30B tokens</td></tr><tr><td>Transformer++</td><td>25.21</td><td>27.64</td><td>35.78</td><td>66.92</td><td>42.19</td><td>51.95</td><td>60.38</td><td>32.46</td><td>39.51</td><td>60.37</td><td>48.69</td></tr><tr><td>RetNet</td><td>26.08</td><td>24.45</td><td>34.51</td><td>67.19</td><td>41.63</td><td>52.09</td><td>63.17</td><td>32.78</td><td>38.36</td><td>57.92</td><td>48.46</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Mamba</td><td>28.12</td><td>23.96</td><td>32.80</td><td>66.04</td><td>39.15</td><td>52.38</td><td>61.49</td><td>30.34</td><td>37.96</td><td>57.62</td><td>47.22</td></tr><tr><td>Mamba2</td><td>22.94</td><td>28.37</td><td>33.54</td><td>67.90</td><td>42.71</td><td>49.77</td><td>63.48</td><td>31.09</td><td>40.06</td><td>58.15</td><td>48.34</td></tr><tr><td>DeltaNet</td><td>24.37</td><td>24.60</td><td>37.06</td><td>66.93</td><td>41.98</td><td>50.65</td><td>64.87</td><td>31.39</td><td>39.88</td><td>59.02</td><td>48.97</td></tr><tr><td>TIT</td><td>24.17</td><td>23.51</td><td>34.74</td><td>67.25</td><td>43.92</td><td>50.99</td><td>64.53</td><td>33.81</td><td>40.16</td><td>59.58</td><td>47.32</td></tr><tr><td>Gated DeltaNet</td><td>21.18</td><td>22.09</td><td>35.54</td><td>68.01</td><td>44.95</td><td>50.73</td><td>66.87</td><td>33.09</td><td>39.21</td><td>59.14</td><td>49.69</td></tr><tr><td>Samba*</td><td>20.63</td><td>22.71</td><td>39.72</td><td>69.19</td><td>47.35</td><td>52.01</td><td>66.92</td><td>33.20</td><td>38.98</td><td>61.24</td><td>51.08</td></tr><tr><td>Gated DeltaNet-H2*</td><td>19.88</td><td>20.83</td><td>39.18</td><td>68.95</td><td>48.22</td><td>52.57</td><td>67.01</td><td>35.49</td><td>39.39</td><td>61.11</td><td>51.49</td></tr><tr><td>Titans (LMM)</td><td>20.04</td><td>21.96</td><td>37.40</td><td>69.28</td><td>48.46</td><td>52.27</td><td>66.31</td><td>35.84</td><td>40.13</td><td>62.76</td><td>51.56</td></tr><tr><td>Titans (MAC)</td><td>19.93</td><td>20.12</td><td>39.62</td><td>70.46</td><td>49.01</td><td>53.18</td><td>67.86</td><td>36.01</td><td>41.87</td><td>62.05</td><td>52.51</td></tr><tr><td>Titans (MAG)</td><td>18.61</td><td>19.86</td><td>40.98</td><td>70.25</td><td>48.94</td><td>52.89</td><td>68.23</td><td>36.19</td><td>40.38</td><td>62.11</td><td>52.50</td></tr><tr><td>Titans (MAL)</td><td>19.07</td><td>20.33</td><td>40.05</td><td>69.99</td><td>48.82</td><td>53.02</td><td>67.54</td><td>35.65</td><td>30.98</td><td>61.72</td><td>50.97</td></tr></tbody></table>',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'ee5e23d702741ae81942bad2cd360674',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '5c51bae9e7b87b2c27ceaad6adb8992a',\n",
       "  'text': 'the “haystack”). In this part, we use Single NIAH (S-NIAH) task from RULER benchmark (Hsieh et al. 2024) and evaluate',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 1723.24),\n",
       "     (200.0, 1750.9138888888888),\n",
       "     (1560.0055955555554, 1750.9138888888888),\n",
       "     (1560.0055955555554, 1723.24)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@hsieh2024ruler',\n",
       "     'start_index': 99}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'ee5e23d702741ae81942bad2cd360674',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'FigureCaption',\n",
       "  'element_id': '38849a19de1196bebcdda36360e934d6',\n",
       "  'text': 'Titans and baselines on sequences with length 2K, 4K, 8K, and 16K. The results are reported in Table 2. Neural Memory module achieves the best results compare to baselines in all three tasks. We attribute this superior performance to three key differences of Titans with existing sequence models: (1) Compared to TTT, our Neural Memory can better handle the memory capacity by using momentum and also the forgetting mechanism (i.e., weight decay). Therefore, with increasing the sequence length, the performance of Neural Memory does not drop and show a consistent trend; (2) Compared to Mamba2, which has the gating (forgetting) mechanism, Titans have deep non-linear memory, resulting in better memory management. Also, contrary to our neural memory and DeltaNet, Mamba2 is not capable of removing a memory and so',\n",
       "  'metadata': {'detection_class_prob': 0.6737350225448608,\n",
       "   'coordinates': {'points': ((198.4200897216797, 1730.409912109375),\n",
       "     (198.4200897216797, 1986.7840576171875),\n",
       "     (1561.7860107421875, 1986.7840576171875),\n",
       "     (1561.7860107421875, 1730.409912109375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@hsieh2024ruler',\n",
       "     'start_index': 99},\n",
       "    {'text': 'Table 2', 'url': 'table.caption.9', 'start_index': 213}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'ee5e23d702741ae81942bad2cd360674',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '7e8d49e59562858dc30123b725dabef6',\n",
       "  'text': '13',\n",
       "  'metadata': {'coordinates': {'points': ((867.1305555555555,\n",
       "      2057.742777777778),\n",
       "     (867.1305555555555, 2085.4166666666665),\n",
       "     (892.8672722222221, 2085.4166666666665),\n",
       "     (892.8672722222221, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'ee5e23d702741ae81942bad2cd360674',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'be81182e888fd2f84ca92ced2ac20a6c',\n",
       "  'text': 'Table 2: Performance of Titans and baselines on S-NIAH task from RULER benchmark. The best results among simple',\n",
       "  'metadata': {'coordinates': {'points': ((199.16944444444442,\n",
       "      202.03444444444472),\n",
       "     (199.16944444444442, 229.70833333333346),\n",
       "     (1551.6992516666667, 229.70833333333346),\n",
       "     (1551.6992516666667, 202.03444444444472)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': 'ee5e23d702741ae81942bad2cd360674',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'FigureCaption',\n",
       "  'element_id': '821fda1f2372016c494cb8d57abcdae3',\n",
       "  'text': 'and hybrid models are highlighted.',\n",
       "  'metadata': {'detection_class_prob': 0.9149815440177917,\n",
       "   'coordinates': {'points': ((200.00000000000014, 210.7920379638672),\n",
       "     (200.00000000000014, 280.1686706542969),\n",
       "     (1550.5684814453125, 280.1686706542969),\n",
       "     (1550.5684814453125, 210.7920379638672)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': 'ee5e23d702741ae81942bad2cd360674',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Image',\n",
       "  'element_id': '42a87d2fbce36a12043c0574713a246a',\n",
       "  'text': 'Model  S-NIAH-PK  S-NIAH-N  S-NIAH-W  2K  4K  8K  16K  2K  4K  8K  16K  2K  4K  8K  16K  TTT  98.4  98.8  98.0  88.4  60.2  36.6  10.2  4.4  78.8  28.0  4.4  0.0  Mamba2  98.6  61.4  31.0  5.4  98.4  55.8  14.2  0.0  42.2  4.2  0.0  0.0  DeltaNet  96.8  98.8  98.6  71.4  47.2  15.4  12.8  5.4  46.2  20.0  1.6  0.0  Titans (LMM)  99.8  98.4  98.2  96.2  100.0  99.8  93.4  80.2  90.4  89.4  85.8  80.6  Titans (MAC)  99.2  98.8  99.0  98.4  99.6  98.2  97.6  97.4  98.2  98.2  95.6  95.2  Titans (MAG)  99.4  98.0  97.4  97.4  99.2  98.8  97.2  98.6  98.0  98.0  90.2  88.2  Titans (MAL)  98.8  98.6  98.8  97.8  99.8  98.1  96.8  96.4  98.0  97.4  92.0  90.4  (a) Few-shot Setup  (b) Fine-Tuning Setup ',\n",
       "  'metadata': {'detection_class_prob': 0.8545629382133484,\n",
       "   'coordinates': {'points': ((395.8653869628906, 316.42633056640625),\n",
       "     (395.8653869628906, 1042.736572265625),\n",
       "     (1352.8878173828125, 1042.736572265625),\n",
       "     (1352.8878173828125, 316.42633056640625)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'image_path': 'images\\\\figure-14-7.jpg',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Image',\n",
       "  'element_id': '5680d96ce15b94a68ce2dd02093b867e',\n",
       "  'text': '@- Llama3.1-70B + GPr4 = RMEFT © Qwen2.5-72B a GPT4o-mini —#~ Titans (MAC)-FT + Llama3.1-8B + RAG © —@- Mamba-FT 100) -iaiaiiieliben = 90 sis ~ re NS i S 80 EOS > 70h4— g NL s Ut B 60 8 < sol, hie. = 40 ay 7 10° ‘10* 10° 10% 10 Sequence Length',\n",
       "  'metadata': {'coordinates': {'points': ((917.5805555555555,\n",
       "      653.2239466666668),\n",
       "     (917.5805555555555, 994.1416666666669),\n",
       "     (1366.3760855555556, 994.1416666666669),\n",
       "     (1366.3760855555556, 653.2239466666668)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'image_path': 'images\\\\figure-14-8.jpg',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'fa105d80cb73fc7dd6285cbfaeced69e',\n",
       "  'text': 'Figure 6: Performance of Titans and baselines on BABILong benchmark. Titans (MAC) outperforms all baselines, including',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 1064.4316666666668),\n",
       "     (200.0, 1092.1055555555556),\n",
       "     (1560.0072559888893, 1092.1055555555556),\n",
       "     (1560.0072559888893, 1064.4316666666668)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'FigureCaption',\n",
       "  'element_id': '8c32e47abcb229be1c387a2de56c00b7',\n",
       "  'text': 'extremely large models, e.g., GPT4.',\n",
       "  'metadata': {'detection_class_prob': 0.9033907651901245,\n",
       "   'coordinates': {'points': ((200.0, 1073.912841796875),\n",
       "     (200.0, 1127.3084716796875),\n",
       "     (1561.974609375, 1127.3084716796875),\n",
       "     (1561.974609375, 1073.912841796875)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e246e1de1bf32616da30e78b32998e23',\n",
       "  'text': 'we can see a significant drop in performance when increasing the sequence length; (3) Compared to DeltaNet, although it',\n",
       "  'metadata': {'coordinates': {'points': ((198.975, 1165.8233333333335),\n",
       "     (198.975, 1193.4972222222223),\n",
       "     (1560.0106176999996, 1193.4972222222223),\n",
       "     (1560.0106176999996, 1165.8233333333335)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'fe2bb1ccdb8b2859aaf2637bdce55e75',\n",
       "  'text': 'is capable of removing memory using delta rule, it cannot erase the memory, lacking forgetting mechanism. Finally, As expected we can see on par or better results when using Titans variants, where the best results correspond to MAC.',\n",
       "  'metadata': {'detection_class_prob': 0.9368510842323303,\n",
       "   'coordinates': {'points': ((200.0, 1174.1148681640625),\n",
       "     (200.0, 1263.5576171875),\n",
       "     (1565.7198486328125, 1263.5576171875),\n",
       "     (1565.7198486328125, 1174.1148681640625)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'db5f6808d6ddb8066174c9b3c25b2dea',\n",
       "  'text': '5.4 BABILong Benchmark',\n",
       "  'metadata': {'detection_class_prob': 0.8660844564437866,\n",
       "   'coordinates': {'points': ((198.65325927734375, 1311.01416015625),\n",
       "     (198.65325927734375, 1344.6851422222223),\n",
       "     (618.3074340820312, 1344.6851422222223),\n",
       "     (618.3074340820312, 1311.01416015625)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '5a045e9e7ef6d5583ed32428ed49e224',\n",
       "  'text': 'In the previous section we discussed the results on a simple NIAH tasks where a single needle needs to be retrieved. Although Titans showed better performance compared to baselines, their true advantage over very long sequences is still hidden. To this end, in this section, we use a harder task from BABILong benchmark (Yuri Kuratov et al. 2024), in which the model needs to reason across facts distributed in extremely long documents. We follow the original experimental setup and training process in the benchmark. There are two settings: (1) Few-shot setting, in which we use large pre-trained models, and (2) fine-tuning setting, where we fine-tune the MAC variant of Titans to compare it with other fine-tuned baselines. The results for few-shot setting are reported in Figure 6a. In this setup, we can see Titans outperform all baselines–i.e., Mamba2.8B (Gu and Dao 2024), RWKV-6-7B (Peng, Goldstein, et al. 2024), RecurrentGemma-9B (Botev et al. 2024), Gemma-9B (Team et al. 2024), Llama3.1-8B (Touvron et al. 2023), GPT-4, and GPT4o-mini (Achiam et al. 2023). These results are achieved while Titans (MAC) is having much less number of parameters than baselines.',\n",
       "  'metadata': {'detection_class_prob': 0.9541263580322266,\n",
       "   'coordinates': {'points': ((199.03055555555554, 1360.3566666666666),\n",
       "     (199.03055555555554, 1691.16650390625),\n",
       "     (1564.258767865, 1691.16650390625),\n",
       "     (1564.258767865, 1360.3566666666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@kuratov2024babilong',\n",
       "     'start_index': 364},\n",
       "    {'text': 'Figure 6a', 'url': 'figure.caption.10', 'start_index': 796},\n",
       "    {'text': '2024', 'url': 'cite.0@gu2024mamba', 'start_index': 893},\n",
       "    {'text': '2024', 'url': 'cite.0@peng2024eagle', 'start_index': 935},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@botev2024recurrentgemma',\n",
       "     'start_index': 974},\n",
       "    {'text': '2024', 'url': 'cite.0@team2024gemma', 'start_index': 1003},\n",
       "    {'text': '2023', 'url': 'cite.0@touvron2023llama', 'start_index': 1038},\n",
       "    {'text': '2023', 'url': 'cite.0@achiam2023gpt', 'start_index': 1082}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': 'db5f6808d6ddb8066174c9b3c25b2dea',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '4b9242a2128397895bca6b5e58173ce4',\n",
       "  'text': 'In the fine-tuning setup, we compare the small fine-tuned version of Titans (MAC) with: (i) the fine-tuned version of small models (almost the same number of parameters as Titans) such as Mamba (Gu and Dao 2024), RMT (Bulatov, Yury Kuratov, and Burtsev 2022), (ii) large models with Retrieval-Augmented Generation (RAG) (P. Lewis et al. 2020) such as Llama3.1- 8B (Touvron et al. 2023), and (iii) extremely large models such as GPT-4 (Achiam et al. 2023), GPT4o-mini, Qwen2.5-72B (A. Yang et al. 2024), and Llama3.1-70B (Touvron et al. 2023). Baseline results are reported by (Yuri Kuratov et al. 2024). The results of Titans and baselines are reported in Figure 6b. Titans outperform all models even extremely large models like GPT4. Also, compared to Transformer-based with memory models like RMT, Titans show better performance mainly due to their powerful memory. That is, RMT compress the historical data into 16 size vector-valued memory, while Titans with in-context online memory learner are capable of encoding the past into the parameters of the model. Interestingly, even',\n",
       "  'metadata': {'detection_class_prob': 0.9518201947212219,\n",
       "   'coordinates': {'points': ((199.19722222222222, 1709.0483333333334),\n",
       "     (199.19722222222222, 2006.9635009765625),\n",
       "     (1565.4959716796875, 2006.9635009765625),\n",
       "     (1565.4959716796875, 1709.0483333333334)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024', 'url': 'cite.0@gu2024mamba', 'start_index': 203},\n",
       "    {'text': '2022', 'url': 'cite.0@bulatov2022recurrent', 'start_index': 250},\n",
       "    {'text': '2020', 'url': 'cite.0@lewis2020retrieval', 'start_index': 334},\n",
       "    {'text': '2023', 'url': 'cite.0@touvron2023llama', 'start_index': 377},\n",
       "    {'text': '2023', 'url': 'cite.0@achiam2023gpt', 'start_index': 446},\n",
       "    {'text': '2024', 'url': 'cite.0@yang2024qwen2', 'start_index': 493},\n",
       "    {'text': '2023', 'url': 'cite.0@touvron2023llama', 'start_index': 533},\n",
       "    {'text': '2024', 'url': 'cite.0@kuratov2024babilong', 'start_index': 594},\n",
       "    {'text': 'Figure 6b', 'url': 'figure.caption.10', 'start_index': 653}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': 'db5f6808d6ddb8066174c9b3c25b2dea',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '7e395ad161d6e47970de5a813477ce0e',\n",
       "  'text': '14',\n",
       "  'metadata': {'coordinates': {'points': ((867.1305555555555,\n",
       "      2057.742777777778),\n",
       "     (867.1305555555555, 2085.4166666666665),\n",
       "     (892.8672722222221, 2085.4166666666665),\n",
       "     (892.8672722222221, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': 'db5f6808d6ddb8066174c9b3c25b2dea',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Image',\n",
       "  'element_id': '6ec25947a652ad98829719d0459223d1',\n",
       "  'text': '_| -— Mamba +— LMM (Ly, =3) 17.5) —e— LMM (L. + LMM (Ly =4) 2 FI Ey = fo i — —+ 2000 4000 8000 16000 32000 Sequence Length',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 202.39695555555573),\n",
       "     (200.0, 473.23055555555567),\n",
       "     (652.84296, 473.23055555555567),\n",
       "     (652.84296, 202.39695555555573)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'image_path': 'images\\\\figure-15-9.jpg',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Image',\n",
       "  'element_id': 'e9511a8b88ad5ae9d78ecf5bfcab173f',\n",
       "  'text': '13.4 13.2) 213.0 FI Ey #128 fo 12.6 12.4 —_ 2000 4000 8000 76000 32000 Sequence Length',\n",
       "  'metadata': {'coordinates': {'points': ((662.0972222222222,\n",
       "      202.39695555555573),\n",
       "     (662.0972222222222, 473.23055555555567),\n",
       "     (1114.9401822222223, 473.23055555555567),\n",
       "     (1114.9401822222223, 202.39695555555573)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'image_path': 'images\\\\figure-15-10.jpg',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Image',\n",
       "  'element_id': 'bc768cc27ac8b79442611b5f1a8210d3',\n",
       "  'text': '2000 4000 3000 16000 32000 Sequence Length',\n",
       "  'metadata': {'coordinates': {'points': ((1124.1944444444443,\n",
       "      202.62647555555557),\n",
       "     (1124.1944444444443, 473.23055555555567),\n",
       "     (1577.0374044444445, 473.23055555555567),\n",
       "     (1577.0374044444445, 202.62647555555557)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'image_path': 'images\\\\figure-15-11.jpg',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Image',\n",
       "  'element_id': '41a39c6bd83eece2e90eff16250da4c6',\n",
       "  'text': '(a) 170M Parameters  (b) 360M Parameters  (c) 760M Parameters ',\n",
       "  'metadata': {'detection_class_prob': 0.9234110116958618,\n",
       "   'coordinates': {'points': ((217.23411560058594, 206.51914978027344),\n",
       "     (217.23411560058594, 519.6882934570312),\n",
       "     (1553.3426513671875, 519.6882934570312),\n",
       "     (1553.3426513671875, 206.51914978027344)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'image_path': 'images\\\\figure-15-12.jpg',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'c965e9a8aada8d7e7caff73f9df657af',\n",
       "  'text': 'Figure 7: The effect of memory depth on the perplexity. Deeper long-term memory results in better scaling in longer',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 543.5205555555557),\n",
       "     (200.0, 571.1944444444445),\n",
       "     (1560.5308459666664, 571.1944444444445),\n",
       "     (1560.5308459666664, 543.5205555555557)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'FigureCaption',\n",
       "  'element_id': '53686cbf28b59b250989f07826fe4fc9',\n",
       "  'text': 'sequences.',\n",
       "  'metadata': {'detection_class_prob': 0.8924880623817444,\n",
       "   'coordinates': {'points': ((200.0, 553.0755004882812),\n",
       "     (200.0, 607.6875610351562),\n",
       "     (1557.4742431640625, 607.6875610351562),\n",
       "     (1557.4742431640625, 553.0755004882812)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '1b13085c26c029f9b8ea1189ef2421a2',\n",
       "  'text': 'Table 3: Performance on long-term forecasting. The best results are highlighted .',\n",
       "  'metadata': {'coordinates': {'points': ((458.9083333333333,\n",
       "      645.3150000000003),\n",
       "     (458.9083333333333, 672.988888888889),\n",
       "     (1300.2565644444444, 672.988888888889),\n",
       "     (1300.2565644444444, 645.3150000000003)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Table',\n",
       "  'element_id': 'fe80ecb57d19e6a9bc501d12653c54c2',\n",
       "  'text': 'Neural Memory Simba iTransformer RLinear PatchTST Crossformer TiDE TimesNet DLinear MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE MSE MAE ETTm1 0.358 0.387 0.383 0.396 0.407 0.410 0.414 0.407 0.387 0.400 0.513 0.496 0.419 0.419 0.400 0.406 0.403 0.407 ETTm2 0.261 0.309 0.271 0.327 0.288 0.332 0.286 0.327 0.281 0.326 0.757 0.610 0.358 0.404 0.291 0.333 0.350 0.401 ETTh1 0.420 0.421 0.441 0.432 0.454 0.447 0.446 0.434 0.469 0.454 0.529 0.522 0.541 0.507 0.458 0.450 0.456 0.452 ETTh2 0.336 0.382 0.361 0.391 0.383 0.407 0.374 0.398 0.387 0.407 0.942 0.684 0.611 0.550 0.414 0.427 0.559 0.515 ECL 0.162 0.261 0.169 0.274 0.178 0.270 0.219 0.298 0.205 0.290 0.244 0.334 0.251 0.344 0.192 0.295 0.212 0.300 Traffic 0.415 0.289 0.493 0.291 0.428 0.282 0.626 0.378 0.481 0.304 0.550 0.304 0.760 0.473 0.620 0.336 0.625 0.383 Weather 0.231 0.265 0.255 0.280 0.258 0.278 0.272 0.291 0.259 0.281 0.259 0.315 0.271 0.320 0.259 0.287 0.265 0.317',\n",
       "  'metadata': {'detection_class_prob': 0.9363962411880493,\n",
       "   'coordinates': {'points': ((254.84336853027344, 713.1383056640625),\n",
       "     (254.84336853027344, 980.8899536132812),\n",
       "     (1501.0079345703125, 980.8899536132812),\n",
       "     (1501.0079345703125, 713.1383056640625)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'text_as_html': '<table><thead><tr><th></th><th colspan=\"2\">Neural Memory</th><th colspan=\"2\">Simba</th><th colspan=\"2\">iTransformer</th><th>RLinear</th><th colspan=\"2\">PatchTST</th><th colspan=\"2\">Crossformer</th><th colspan=\"2\">TiDE</th><th colspan=\"2\">TimesNet</th><th colspan=\"2\">DLinear</th></tr><tr><th></th><th>MSE</th><th>MAE</th><th>MSE</th><th>MAE</th><th>MSE</th><th>MAE</th><th>MSE</th><th>MSE</th><th>MAE</th><th>MSE</th><th>MAE</th><th>MSE</th><th>MAE</th><th>MSE</th><th>MAE</th><th>MSE</th><th>MAE</th></tr></thead><tbody><tr><td>ETTm1</td><td>0.358</td><td>0.387</td><td>0.383</td><td>= 0.396</td><td>0.407</td><td>0.410</td><td>0.414 =</td><td>0.387</td><td>0.400</td><td>0.513</td><td>0.496</td><td>0.419</td><td>= 0.419</td><td>0.400</td><td>0.406</td><td>0.403</td><td>0.407</td></tr><tr><td>ETTm2</td><td>0.261</td><td>0.309</td><td>0.271</td><td>0.327</td><td>0.288</td><td>0.332</td><td>0.286 =</td><td>0.281</td><td>0.326</td><td>0.757</td><td>0.610</td><td>0.358</td><td>0.404</td><td>0.291</td><td>0.333</td><td>0.350</td><td>=—0.401</td></tr><tr><td>ETTh1</td><td>0.420</td><td>0.421</td><td>0.441</td><td>0.432</td><td>0.454</td><td>0.447</td><td>0.446</td><td>0.469</td><td>= 0.454</td><td>0.529</td><td>0.522</td><td>0.541</td><td>0.507</td><td>0.458</td><td>0.450</td><td>0.456</td><td>0.452</td></tr><tr><td>ETTh2</td><td>0.336</td><td>0.382</td><td>0.361</td><td>0.391</td><td>0.383</td><td>0.407</td><td>0.374</td><td>0.387</td><td>0.407</td><td>0.942</td><td>0.684</td><td>0.611</td><td>0.550</td><td>0.414</td><td>0.427</td><td>0.559</td><td>= 0.515</td></tr><tr><td>ECL</td><td>0.162</td><td>0.261</td><td>0.169</td><td>= 0.274</td><td>0.178</td><td>0.270</td><td>0.219 =</td><td>0.205</td><td>0.290</td><td>0.244</td><td>0.334</td><td>0.251</td><td>0.344</td><td>0.192</td><td>0.295</td><td>0.212</td><td>=0.300</td></tr><tr><td>Traffic</td><td>0.415</td><td>0.289</td><td>0.493</td><td>0.291</td><td>0.428</td><td>0.282</td><td>0.626</td><td>0.481</td><td>0.304</td><td>0.550</td><td>0.304</td><td>0.760</td><td>0.473</td><td>0.620</td><td>0.336</td><td>0.625</td><td>0.383</td></tr><tr><td>Weather</td><td>0.231</td><td>0.265</td><td>0.255</td><td>= 0.280</td><td>0.258</td><td>0.278</td><td>0.272</td><td>0.259</td><td>= 0.281</td><td>0.259</td><td>0.315</td><td>0.271</td><td>0.320</td><td>0.259</td><td>= 0.287</td><td>0.265</td><td>= 0.317</td></tr></tbody></table>',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '434d9873e308875724f7bf356d1c12b4',\n",
       "  'text': 'augmenting Llama3.1-8B model with RAG performs worse than Titans with about ×70 less parameters.',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 1037.4622222222222),\n",
       "     (200.0, 1069.3425422222222),\n",
       "     (1365.6825577777777, 1069.3425422222222),\n",
       "     (1365.6825577777777, 1037.4622222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '9b2c6b5deabe6b6517d1812ff9118cde',\n",
       "  'text': '5.5 The Effect of Deep Memory',\n",
       "  'metadata': {'detection_class_prob': 0.8681725859642029,\n",
       "   'coordinates': {'points': ((197.95777893066406, 1116.9262533333335),\n",
       "     (197.95777893066406, 1150.1351422222224),\n",
       "     (692.5165405273438, 1150.1351422222224),\n",
       "     (692.5165405273438, 1116.9262533333335)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '11d174183be9fbe23cebc304d203809b',\n",
       "  'text': 'In this section, we evaluate the effect of deep memory in both wall-clock training time and model performance2. To this',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 1163.2341666666666),\n",
       "     (200.0, 1193.4805555555556),\n",
       "     (1560.0003107111108, 1193.4805555555556),\n",
       "     (1560.0003107111108, 1163.2341666666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '.', 'url': 'Hfootnote.2', 'start_index': 138}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'parent_id': '9b2c6b5deabe6b6517d1812ff9118cde',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '1734a4e78f32d022f39bdb269f4f793f',\n",
       "  'text': 'end, we focus on different variants of our neural memory module, where 𝐿M = 1, 2, 3, 4. We also use Mamba as a baseline for the model performance. For a fair comparison, we use the same training process for all models and train them on a subset of the Pile dataset (L. Gao et al. 2020).',\n",
       "  'metadata': {'detection_class_prob': 0.9466488361358643,\n",
       "   'coordinates': {'points': ((200.0, 1174.880615234375),\n",
       "     (200.0, 1296.033935546875),\n",
       "     (1560.0112442133334, 1296.033935546875),\n",
       "     (1560.0112442133334, 1174.880615234375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '.', 'url': 'Hfootnote.2', 'start_index': 138}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'parent_id': '9b2c6b5deabe6b6517d1812ff9118cde',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'c5302c285f312832979a25c0bfdbdda4',\n",
       "  'text': 'We report the perplexity of our models and baselines as the function of the sequence length in Figure 7. Interestingly, with',\n",
       "  'metadata': {'coordinates': {'points': ((198.67222222222222,\n",
       "      1315.2483333333332),\n",
       "     (198.67222222222222, 1342.9222222222222),\n",
       "     (1560.008378355555, 1342.9222222222222),\n",
       "     (1560.008378355555, 1315.2483333333332)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Figure 7',\n",
       "     'url': 'figure.caption.11',\n",
       "     'start_index': 95}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'parent_id': '9b2c6b5deabe6b6517d1812ff9118cde',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '22caa86808cb446522414a69b4faa1de',\n",
       "  'text': 'the increase of memory depth, 𝐿M, the model can achieve better perplexity over all sequence length. Also, deeper memory modules are more robust to the sequence length when the model has less number of parameters. With the increase of the number of parameters, all models show better performance on longer sequences.',\n",
       "  'metadata': {'detection_class_prob': 0.9428799748420715,\n",
       "   'coordinates': {'points': ((200.0, 1323.0491943359375),\n",
       "     (200.0, 1446.423583984375),\n",
       "     (1563.3824462890625, 1446.423583984375),\n",
       "     (1563.3824462890625, 1323.0491943359375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Figure 7',\n",
       "     'url': 'figure.caption.11',\n",
       "     'start_index': 95}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'parent_id': '9b2c6b5deabe6b6517d1812ff9118cde',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '510311511a08ebeb7e1a46c62f03200c',\n",
       "  'text': 'We also evaluate the effect of memory depth (𝐿M = 1, 2, 3, 4) on the training throughput. We report the training throughput (the number of tokens per second) as the function of sequence length in Figure 8. All models scale linearly with respect to the context length (i.e., constant trend in the number of tokens per second with respect to sequence length). Also, by increasing the memory depth, as expected, we can see a linear trend that a deeper memory results in a slower training. Therefore, it is not always efficient to use deeper memory modules, showing a trade-off between effectiveness and efficiency.',\n",
       "  'metadata': {'detection_class_prob': 0.9418091177940369,\n",
       "   'coordinates': {'points': ((198.975, 1464.687222222222),\n",
       "     (198.975, 1728.46728515625),\n",
       "     (1084.2504882, 1728.46728515625),\n",
       "     (1084.2504882, 1464.687222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Figure 8',\n",
       "     'url': 'figure.caption.12',\n",
       "     'start_index': 195}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'parent_id': '9b2c6b5deabe6b6517d1812ff9118cde',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Image',\n",
       "  'element_id': 'd1436dceb56024791b6a8770d169a69c',\n",
       "  'text': '45 - . = = LMM (Ly =1) + LMM (Ly =3) #40 —— LMM (Ly=2) + LMM (Ly =4) e |. . —— B 3 35) 2 4 3 = 30 + + & =] 25 + oe . + { 2000 4000 8000 16000 32000 Sequence Length',\n",
       "  'metadata': {'coordinates': {'points': ((1111.1972222222223,\n",
       "      1461.4617355555556),\n",
       "     (1111.1972222222223, 1729.6805555555554),\n",
       "     (1559.9742122222221, 1729.6805555555554),\n",
       "     (1559.9742122222221, 1461.4617355555556)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'image_path': 'images\\\\figure-15-13.jpg',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'fa9d60deec6cd075a7ecfca7f26e475c',\n",
       "  'text': '5.6 Time Series Forecasting',\n",
       "  'metadata': {'detection_class_prob': 0.8799609541893005,\n",
       "   'coordinates': {'points': ((200.0, 1800.3568088888887),\n",
       "     (200.0, 1833.5656977777776),\n",
       "     (632.2801066666667, 1833.5656977777776),\n",
       "     (632.2801066666667, 1800.3568088888887)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '5e7a61bfce587d76acace66b4ebf09c8',\n",
       "  'text': 'Figure 8: The effect of memory depth on',\n",
       "  'metadata': {'coordinates': {'points': ((1111.1972222222223,\n",
       "      1752.9261111111111),\n",
       "     (1111.1972222222223, 1780.6),\n",
       "     (1560.0129056999997, 1780.6),\n",
       "     (1560.0129056999997, 1752.9261111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'FigureCaption',\n",
       "  'element_id': 'a9befff25d43bcbfbafb81d152ee73d9',\n",
       "  'text': 'training throughput',\n",
       "  'metadata': {'detection_class_prob': 0.5338314771652222,\n",
       "   'coordinates': {'points': ((1104.86572265625, 1761.0892333984375),\n",
       "     (1104.86572265625, 1816.961669921875),\n",
       "     (1565.711181640625, 1816.961669921875),\n",
       "     (1565.711181640625, 1761.0892333984375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'parent_id': '5e7a61bfce587d76acace66b4ebf09c8',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '7ff588c5aa0e966db8d145ce7d11cb3e',\n",
       "  'text': 'To show the effectiveness of our memory module in a broader tasks, we also evaluate its performance in time series',\n",
       "  'metadata': {'coordinates': {'points': ((199.16944444444442,\n",
       "      1849.2372222222223),\n",
       "     (199.16944444444442, 1876.911111111111),\n",
       "     (1560.0107914444447, 1876.911111111111),\n",
       "     (1560.0107914444447, 1849.2372222222223)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'parent_id': '5e7a61bfce587d76acace66b4ebf09c8',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'b9f273370467ebdb07c025043ce05de3',\n",
       "  'text': 'forecasting tasks. To this end, we use Simba framework (Patro and Agneeswaran 2024) for time series forecasting, and',\n",
       "  'metadata': {'detection_class_prob': 0.9361444115638733,\n",
       "   'coordinates': {'points': ((200.0, 1857.79833984375),\n",
       "     (200.0, 1913.3341064453125),\n",
       "     (1559.9945260000004, 1913.3341064453125),\n",
       "     (1559.9945260000004, 1857.79833984375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'parent_id': '5e7a61bfce587d76acace66b4ebf09c8',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '9723de2be1d489ae21369a74e4453181',\n",
       "  'text': '2Note that, in this experiment, we only focus on the neural memory module to evaluate the effect of memory depth in the memorization process.',\n",
       "  'metadata': {'coordinates': {'points': ((230.48888888888888,\n",
       "      1934.9866666666665),\n",
       "     (230.48888888888888, 1960.1805555555554),\n",
       "     (1563.4115417808332, 1960.1805555555554),\n",
       "     (1563.4115417808332, 1934.9866666666665)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'parent_id': '5e7a61bfce587d76acace66b4ebf09c8',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '988737679076a9eee3cfa5e20cfef1db',\n",
       "  'text': 'Combining neural memory with attention as we do in Titans variants, can additionally enhance the performance of the model over long sequences.',\n",
       "  'metadata': {'detection_class_prob': 0.8751121163368225,\n",
       "   'coordinates': {'points': ((200.0, 1943.901611328125),\n",
       "     (200.0, 1989.947265625),\n",
       "     (1562.83984375, 1989.947265625),\n",
       "     (1562.83984375, 1943.901611328125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'parent_id': '5e7a61bfce587d76acace66b4ebf09c8',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '755a3db5f6fcbe95c20f0152d8555547',\n",
       "  'text': '15',\n",
       "  'metadata': {'coordinates': {'points': ((867.1305555555556,\n",
       "      2057.7427777777775),\n",
       "     (867.1305555555556, 2085.4166666666665),\n",
       "     (892.8672722222223, 2085.4166666666665),\n",
       "     (892.8672722222223, 2057.7427777777775)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'parent_id': '5e7a61bfce587d76acace66b4ebf09c8',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '8676945b07ccfd0b87e5db9e6dd3b8c5',\n",
       "  'text': 'Table 4: Downstream evaluation of pre-trained DNA models on GenomicsBenchmarks (Grešová et al. 2023). We report',\n",
       "  'metadata': {'coordinates': {'points': ((199.16944444444442,\n",
       "      197.96500000000017),\n",
       "     (199.16944444444442, 225.63888888888894),\n",
       "     (1560.0048138844438, 225.63888888888894),\n",
       "     (1560.0048138844438, 197.96500000000017)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2023',\n",
       "     'url': 'cite.0@grevsova2023genomic',\n",
       "     'start_index': 95}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'parent_id': '5e7a61bfce587d76acace66b4ebf09c8',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'FigureCaption',\n",
       "  'element_id': '3e65e6f56a682fb0b87d890470dda2a9',\n",
       "  'text': 'top-1 classification accuracy (%).',\n",
       "  'metadata': {'detection_class_prob': 0.8962758779525757,\n",
       "   'coordinates': {'points': ((200.0, 207.50033569335938),\n",
       "     (200.0, 262.038330078125),\n",
       "     (1556.0098876953125, 262.038330078125),\n",
       "     (1556.0098876953125, 207.50033569335938)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2023',\n",
       "     'url': 'cite.0@grevsova2023genomic',\n",
       "     'start_index': 95}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'parent_id': '5e7a61bfce587d76acace66b4ebf09c8',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Table',\n",
       "  'element_id': '020b306f4cbd17fd4fdb07308c03cecc',\n",
       "  'text': 'Model Enhancer Cohn CNN 69.5 68.9 93.3 84.6 68.0 DNABERT 74.0 85.7 88.1 85.6 75.1 GPT 70.5 83.5 91.5 87.7 73.0 HyenaDNA 74.2 89.2 93.8 96.6 80.9 Transformer++ 73.4 89.5 89.9 94.4 79.5 Mamba 73.0 - - 96.6 - Based 74.6 89.5 89.5 96.8 79.0 Neural Memory Module 75.2 89.6 89.3 96.6 79.9',\n",
       "  'metadata': {'detection_class_prob': 0.9018147587776184,\n",
       "   'coordinates': {'points': ((364.7044677734375, 292.1773376464844),\n",
       "     (364.7044677734375, 561.2373046875),\n",
       "     (1361.913330078125, 561.2373046875),\n",
       "     (1361.913330078125, 292.1773376464844)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'text_as_html': '<table><thead><tr><th>Model</th><th>Enhancer Cohn</th><th>EnhancerEns</th><th>Human Reg.</th><th>Non-TATA Promoters</th><th>Human OCR E</th></tr></thead><tbody><tr><td>CNN</td><td>69.5</td><td>68.9</td><td>93.3</td><td>84.6</td><td>68.0</td></tr><tr><td>DNABERT</td><td>74.0</td><td>85.7</td><td>88.1</td><td>85.6</td><td>75.1</td></tr><tr><td>GPT</td><td>70.5</td><td>83.5</td><td>91.5</td><td>87.7</td><td>73.0</td></tr><tr><td>HyenaDNA</td><td>74.2</td><td>89.2</td><td>93.8</td><td>96.6</td><td>80.9</td></tr><tr><td>Transformer++</td><td>73.4</td><td>89.5</td><td>89.9</td><td>94.4</td><td>79.5</td></tr><tr><td>Mamba</td><td>73.0</td><td>-</td><td>-</td><td>96.6</td><td>-</td></tr><tr><td>Based</td><td>74.6</td><td>89.5</td><td>89.5</td><td>96.8</td><td>79.0</td></tr><tr><td>Neural Memory Module</td><td>75.2</td><td>89.6</td><td>89.3</td><td>96.6</td><td>79.9</td></tr></tbody></table>',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'parent_id': '5e7a61bfce587d76acace66b4ebf09c8',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'f1930162ce8fb055daf0455ca3bfecad',\n",
       "  'text': 'Enhancer Ens Human Reg. Non-TATA Promoters Human OCR Ens.',\n",
       "  'metadata': {'coordinates': {'points': ((758.5441105917499,\n",
       "      300.60162344444416),\n",
       "     (758.5441105917499, 321.2006826388887),\n",
       "     (1384.8585053988334, 321.2006826388887),\n",
       "     (1384.8585053988334, 300.60162344444416)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'parent_id': '5e7a61bfce587d76acace66b4ebf09c8',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '32396d879ec1435a8bc2e957672e84df',\n",
       "  'text': 'replace its Mamba module with our neural memory. We report the results on common time series forecasting benchmark',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 617.9316666666668),\n",
       "     (200.0, 645.6055555555555),\n",
       "     (1560.7081802466673, 645.6055555555555),\n",
       "     (1560.7081802466673, 617.9316666666668)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'parent_id': '5e7a61bfce587d76acace66b4ebf09c8',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '2f3a6bc6f66768a2a59e5129dbc1401b',\n",
       "  'text': 'datasets–ETT, ECL, Traffic, and Weather (H. Zhou et al. 2021). The results are reported in Table 3. Our neural memory module is outperforming all baselines, including Mamba-based, linear-based, and Transformer-based architectures.',\n",
       "  'metadata': {'detection_class_prob': 0.8954199552536011,\n",
       "   'coordinates': {'points': ((200.0, 626.2957763671875),\n",
       "     (200.0, 717.1416625976562),\n",
       "     (1565.2095947265625, 717.1416625976562),\n",
       "     (1565.2095947265625, 626.2957763671875)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2021',\n",
       "     'url': 'cite.0@zhou2021informer',\n",
       "     'start_index': 169},\n",
       "    {'text': 'Table 3', 'url': 'table.caption.13', 'start_index': 204}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'parent_id': '5e7a61bfce587d76acace66b4ebf09c8',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'c354c5e7d5b49658ec1a6000ab7e87b7',\n",
       "  'text': '5.7 DNA Modeling',\n",
       "  'metadata': {'detection_class_prob': 0.851783812046051,\n",
       "   'coordinates': {'points': ((198.2525177001953, 763.3439331054688),\n",
       "     (198.2525177001953, 797.0212533333333),\n",
       "     (502.4660949707031, 797.0212533333333),\n",
       "     (502.4660949707031, 763.3439331054688)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '10de833b7d8378dd8e8964794af0ec0b',\n",
       "  'text': 'In order to understand the capability of Titans beyond natural language, we further evaluate the performance of our',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 812.6927777777777),\n",
       "     (200.0, 840.3666666666666),\n",
       "     (1560.5308459666658, 840.3666666666666),\n",
       "     (1560.5308459666658, 812.6927777777777)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'parent_id': 'c354c5e7d5b49658ec1a6000ab7e87b7',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '9d6324f083700645380b6cb85e13637b',\n",
       "  'text': 'neural memory module on DNA modeling tasks. To this end, we evaluate pre-trained models on the downstream tasks in GenomicsBenchmarks (Grešová et al. 2023). We follow the same experimental setups from Nguyen et al. (2024), and re-use the reported results of baselines by Arora et al. (2024). The performance of Titans (LMM) and baselines are reported in Table 4. We find that LMM is competitive with state-of-the-art architectures across different downstream genomics tasks.',\n",
       "  'metadata': {'detection_class_prob': 0.946012556552887,\n",
       "   'coordinates': {'points': ((200.0, 820.7929077148438),\n",
       "     (200.0, 1012.0374145507812),\n",
       "     (1562.5748291015625, 1012.0374145507812),\n",
       "     (1562.5748291015625, 820.7929077148438)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2023',\n",
       "     'url': 'cite.0@grevsova2023genomic',\n",
       "     'start_index': 283},\n",
       "    {'text': '2024', 'url': 'cite.0@nguyen2024hyenadna', 'start_index': 349},\n",
       "    {'text': '2024', 'url': 'cite.0@arora2024simple', 'start_index': 418},\n",
       "    {'text': 'Table 4', 'url': 'table.caption.14', 'start_index': 487}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'parent_id': 'c354c5e7d5b49658ec1a6000ab7e87b7',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '0277bbcf74858a081bab5b133f4a909a',\n",
       "  'text': '5.8 Efficiency',\n",
       "  'metadata': {'detection_class_prob': 0.8462503552436829,\n",
       "   'coordinates': {'points': ((196.75523376464844, 1055.302734375),\n",
       "     (196.75523376464844, 1091.4101422222222),\n",
       "     (426.0948486328125, 1091.4101422222222),\n",
       "     (426.0948486328125, 1055.302734375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '696157b3dfc7c7fe6dd3b2ddd5637071',\n",
       "  'text': 'In this part, we compare the efficiency of our neural memory as well as Titans with state-of-the-art sequence models. The training throughput of models for different sequence length × batch size are reported in Figure 9. Comparing recurrent models, including our neural memory module, we can see our memory module is slightly slower than Mamba2 and Gated DeltaNet, mainly due to: (1) having deep memory and more expressive transition process (memory update), and (2) highly optimized kernel in the implementation of Mamba2. Interestingly, Titans (MAL) are faster than baselines as well as the memory module. The main reason for this better throughput is the highly optimized kernel of Flash- Attention (Dao 2024), which is used for implementing SWA and full attention module in Titans.',\n",
       "  'metadata': {'detection_class_prob': 0.9486216306686401,\n",
       "   'coordinates': {'points': ((198.00833333333333, 1107.0816666666667),\n",
       "     (198.00833333333333, 1471.76171875),\n",
       "     (1089.8770751953125, 1471.76171875),\n",
       "     (1089.8770751953125, 1107.0816666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Figure 9',\n",
       "     'url': 'figure.caption.15',\n",
       "     'start_index': 221},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@dao2024flashattention',\n",
       "     'start_index': 717}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'parent_id': '0277bbcf74858a081bab5b133f4a909a',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Image',\n",
       "  'element_id': '3cdd5939d13177913e45136ba788e3a2',\n",
       "  'text': '—,,_, “© Gated DeltaNet_ + Titans (MAL) ~ ba2 ~@ Titans (MAG) ae Mamba 4- Titans (MAC) 45, ~\\\\- Transformer++ — —#- LMM 10? Tokens/Second 25| NY 2K en TK',\n",
       "  'metadata': {'coordinates': {'points': ((1111.1972222222223,\n",
       "      1115.7336266666666),\n",
       "     (1111.1972222222223, 1414.9166666666667),\n",
       "     (1559.9717822222221, 1414.9166666666667),\n",
       "     (1559.9717822222221, 1115.7336266666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'image_path': 'images\\\\figure-16-14.jpg',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '6bd3a433494572b1a337396d888c9d90',\n",
       "  'text': 'Figure 9: Training throughput compari-',\n",
       "  'metadata': {'coordinates': {'points': ((1111.1972222222223,\n",
       "      1438.162222222222),\n",
       "     (1111.1972222222223, 1465.8361111111112),\n",
       "     (1564.6699784177779, 1465.8361111111112),\n",
       "     (1564.6699784177779, 1438.162222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'FigureCaption',\n",
       "  'element_id': '572d1394a44faac426dc4bfc700db6e6',\n",
       "  'text': 'son of Titans and baselines.',\n",
       "  'metadata': {'detection_class_prob': 0.802072286605835,\n",
       "   'coordinates': {'points': ((1103.30322265625, 1446.6357421875),\n",
       "     (1103.30322265625, 1503.1563720703125),\n",
       "     (1573.0343017578125, 1503.1563720703125),\n",
       "     (1573.0343017578125, 1446.6357421875)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'parent_id': '6bd3a433494572b1a337396d888c9d90',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'e11fd238b71573de34e50de961d78951',\n",
       "  'text': '5.9 Ablation Study',\n",
       "  'metadata': {'detection_class_prob': 0.8695608377456665,\n",
       "   'coordinates': {'points': ((199.21348571777344, 1515.399658203125),\n",
       "     (199.21348571777344, 1551.8434755555554),\n",
       "     (500.90574222222233, 1551.8434755555554),\n",
       "     (500.90574222222233, 1515.399658203125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '336ffce7c0006f19400a1a804cd84bc1',\n",
       "  'text': 'Finally, we perform ablation studies on the different architectural choices in Titans. We consider our neural memory module as a base model and then changing one component at a time: (1) replacing deep memory with linear memory, removing (2) convolution, (3) momentum in the surprise measure, (4) weight decay (or forgot mechanism), and (5) persistent memory. The results are reported in Table 5. All components of neural memory design are positively contributing to its performance, where the greatest contribution comes from weight decay, momentum, convolution, and persistent memory, respectively.',\n",
       "  'metadata': {'detection_class_prob': 0.9450936913490295,\n",
       "   'coordinates': {'points': ((200.0, 1567.5149999999999),\n",
       "     (200.0, 1767.3814697265625),\n",
       "     (1570.572998046875, 1767.3814697265625),\n",
       "     (1570.572998046875, 1567.5149999999999)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Table 5',\n",
       "     'url': 'table.caption.16',\n",
       "     'start_index': 406}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'parent_id': 'e11fd238b71573de34e50de961d78951',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '06ca8c647727425d18f335e2d8cc54bd',\n",
       "  'text': 'The Effect of Architectural Design. To evaluate the effect of architecture design, we compare the performance of three represented variants of Titans in three aspects of (i) language modeling, (ii) commen-sense reasoning, and (iii) long context NIAH (BABILong) tasks. The results are reported in Table 5. We find that MAC and MAG have close performance in language modeling and common-sense reasoning tasks, while MAC achieve significantly better performance in long-context NIAH. Both of these models achieve better performance than MAL. These results along with Figure 9, show a trade-off between fast training and more expressive design.',\n",
       "  'metadata': {'detection_class_prob': 0.9524518847465515,\n",
       "   'coordinates': {'points': ((199.0861111111111, 1796.7594444444444),\n",
       "     (199.0861111111111, 1995.7353515625),\n",
       "     (1566.4866943359375, 1995.7353515625),\n",
       "     (1566.4866943359375, 1796.7594444444444)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'Table 5',\n",
       "     'url': 'table.caption.16',\n",
       "     'start_index': 294},\n",
       "    {'text': 'Figure 9', 'url': 'figure.caption.15', 'start_index': 560}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'parent_id': 'e11fd238b71573de34e50de961d78951',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '99cd1dda52623ec9526f77eb2126591a',\n",
       "  'text': '16',\n",
       "  'metadata': {'coordinates': {'points': ((867.1305555555556,\n",
       "      2057.742777777778),\n",
       "     (867.1305555555556, 2085.4166666666665),\n",
       "     (892.8672722222223, 2085.4166666666665),\n",
       "     (892.8672722222223, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'parent_id': 'e11fd238b71573de34e50de961d78951',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '369eed2987c7c1916eeeba1d48c226e3',\n",
       "  'text': 'Table 5: Ablation Study on Titans. All components of Titans are positively contributing to its performance.',\n",
       "  'metadata': {'coordinates': {'points': ((275.94166666666666,\n",
       "      197.96500000000017),\n",
       "     (275.94166666666666, 225.63888888888894),\n",
       "     (1483.215069444445, 225.63888888888894),\n",
       "     (1483.215069444445, 197.96500000000017)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'parent_id': 'e11fd238b71573de34e50de961d78951',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Table',\n",
       "  'element_id': '27762e6e16f02471a71feb3f67e7e47d',\n",
       "  'text': 'Model Language Modeling ppl ↓ Reasoning acc ↑ Long Context acc ↑ LMM 27.01 47.83 92.68 +Attn (MAC) 26.67 48.65 97.95 +Attn (MAG) 25.70 48.60 96.70 +Attn (MAL) 25.91 47.87 96.91 Linear Memory 28.49 46.97 85.34 w/o Convolution 28.73 45.82 90.28 w/o Momentum 28.98 45.49 87.12 w/o Weight Decay 29.04 45.11 85.60 w/o Persistent Memory 27.63 46.35 92.49',\n",
       "  'metadata': {'detection_class_prob': 0.9273986220359802,\n",
       "   'coordinates': {'points': ((512.8308715820312, 265.9290771484375),\n",
       "     (512.8308715820312, 616.736083984375),\n",
       "     (1247.7249755859375, 616.736083984375),\n",
       "     (1247.7249755859375, 265.9290771484375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'text_as_html': '<table><thead><tr><th>Model</th><th>Language Modeling ppl J</th><th>Reasoning acc T</th><th>Long Context acc T</th></tr></thead><tbody><tr><td>LMM</td><td>27.01</td><td>47.83</td><td>92.68</td></tr><tr><td>+Attn (MAC)</td><td>26.67</td><td>48.65</td><td>97.95</td></tr><tr><td>+Attn (MAG)</td><td>25.70</td><td>48.60</td><td>96.70</td></tr><tr><td>+Attn (MAL)</td><td>25.91</td><td>47.87</td><td>96.91</td></tr><tr><td>Linear Memory</td><td>28.49</td><td>46.97</td><td>85.34</td></tr><tr><td>w/o Convolution</td><td>28.73</td><td>45.82</td><td>90.28</td></tr><tr><td>w/o Momentum</td><td>28.98</td><td>45.49</td><td>87.12</td></tr><tr><td>w/o Weight Decay</td><td>29.04</td><td>45.11</td><td>85.60</td></tr><tr><td>w/o Persistent Memory</td><td>27.63</td><td>46.35</td><td>92.49</td></tr></tbody></table>',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'parent_id': 'e11fd238b71573de34e50de961d78951',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'a367729757636a56e8163f1377462bce',\n",
       "  'text': '6 Conclusion',\n",
       "  'metadata': {'detection_class_prob': 0.8624047040939331,\n",
       "   'coordinates': {'points': ((196.0810089111328, 673.929922777778),\n",
       "     (196.0810089111328, 713.7804783333333),\n",
       "     (466.7868957519531, 713.7804783333333),\n",
       "     (466.7868957519531, 673.929922777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '5840be1376efbc7893bc3c3f47df169d',\n",
       "  'text': 'In this paper, we present a neural long-term memory that, as a meta in-context learner, learns to memorize at test time.',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 737.4150000000002),\n",
       "     (200.0, 765.088888888889),\n",
       "     (1564.2545060861103, 765.088888888889),\n",
       "     (1564.2545060861103, 737.4150000000002)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'parent_id': 'a367729757636a56e8163f1377462bce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '8d99444edffc7b53b42f9796ccc4891b',\n",
       "  'text': 'The neural memory module is a recurrent model in nature, and is adaptively memorizing tokens that are more surprising or are close to surprising tokens. Comparing to modern recurrent models, it has more expressive memory update and storing mechanism. Using this memory, we present Titans architectures, and its three variants, in which we suggest to incorporate the memory module as (1) a context, (2) gating, and (3) a layer. Our experimental evaluation on diverse tasks tasks validate that Titans are more effective than Transformers and recent modern linear recurrent models, specifically for long context. That is, Titans can scale to larger than 2M context window size with better accuracy than baselines.',\n",
       "  'metadata': {'detection_class_prob': 0.9448438882827759,\n",
       "   'coordinates': {'points': ((199.16944444444442, 745.9639892578125),\n",
       "     (199.16944444444442, 968.3486328125),\n",
       "     (1570.300048828125, 968.3486328125),\n",
       "     (1570.300048828125, 745.9639892578125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'parent_id': 'a367729757636a56e8163f1377462bce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '144b8aead5700f0f9add8c5f1d9f0c69',\n",
       "  'text': 'Titans are implemented in Pytorch and JAX and we intend to make the code we used to train and evaluate our models',\n",
       "  'metadata': {'coordinates': {'points': ((199.16944444444442,\n",
       "      986.4816666666666),\n",
       "     (199.16944444444442, 1014.1555555555556),\n",
       "     (1560.0107914444445, 1014.1555555555556),\n",
       "     (1560.0107914444445, 986.4816666666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'parent_id': 'a367729757636a56e8163f1377462bce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'a7578ddd82f0c9679f5796bc5a2498a0',\n",
       "  'text': 'available soon.',\n",
       "  'metadata': {'detection_class_prob': 0.9105446934700012,\n",
       "   'coordinates': {'points': ((198.4379119873047, 993.5421142578125),\n",
       "     (198.4379119873047, 1050.5699462890625),\n",
       "     (1569.28564453125, 1050.5699462890625),\n",
       "     (1569.28564453125, 993.5421142578125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'parent_id': 'a367729757636a56e8163f1377462bce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'fb419e81a6dd7e1d6a2c38921b86fd25',\n",
       "  'text': '17',\n",
       "  'metadata': {'coordinates': {'points': ((867.1305555555556,\n",
       "      2057.742777777778),\n",
       "     (867.1305555555556, 2085.4166666666665),\n",
       "     (892.8672722222223, 2085.4166666666665),\n",
       "     (892.8672722222223, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'parent_id': 'a367729757636a56e8163f1377462bce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "  'text': 'References',\n",
       "  'metadata': {'detection_class_prob': 0.8416945338249207,\n",
       "   'coordinates': {'points': ((195.32904052734375, 196.8306121826172),\n",
       "     (195.32904052734375, 240.04158944444433),\n",
       "     (401.1822204589844, 240.04158944444433),\n",
       "     (401.1822204589844, 196.8306121826172)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '3e2f8fccd81b6c814f92a2a4f595b687',\n",
       "  'text': '[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. “Gpt-4 technical report”. In: arXiv preprint arXiv:2303.08774 (2023).',\n",
       "  'metadata': {'detection_class_prob': 0.9282832145690918,\n",
       "   'coordinates': {'points': ((225.73611111111111, 252.9761111111112),\n",
       "     (225.73611111111111, 353.5423566666667),\n",
       "     (1562.872314453125, 353.5423566666667),\n",
       "     (1562.872314453125, 252.9761111111112)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '2738f2035ce6078195e26956bd9164a6',\n",
       "  'text': '[2] Yaroslav Aksenov, Nikita Balagansky, Sofia Maria Lo Cicero Vaina, Boris Shaposhnikov, Alexey Gorbatovski, and Daniil Gavrilov. “Linear Transformers with Learnable Kernel Functions are Better In-Context Models”. In: arXiv preprint arXiv:2402.10644 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9298158884048462,\n",
       "   'coordinates': {'points': ((225.03121948242188, 352.60388888888895),\n",
       "     (225.03121948242188, 453.1701344444444),\n",
       "     (1568.842529296875, 453.1701344444444),\n",
       "     (1568.842529296875, 352.60388888888895)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'a805a7e69239f84b50ce09ff7eb4caef',\n",
       "  'text': '[3] Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul, Brendan Shillingford, and Nando De Freitas. “Learning to learn by gradient descent by gradient descent”. In: Advances in neural information processing systems 29 (2016).',\n",
       "  'metadata': {'detection_class_prob': 0.9288116693496704,\n",
       "   'coordinates': {'points': ((223.5616912841797, 452.22888888888895),\n",
       "     (223.5616912841797, 552.7951344444444),\n",
       "     (1570.71240234375, 552.7951344444444),\n",
       "     (1570.71240234375, 452.22888888888895)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'aa6b9ba4aec4d373959831b02f3010fa',\n",
       "  'text': '[4] Cem Anil, Yuhuai Wu, Anders Andreassen, Aitor Lewkowycz, Vedant Misra, Vinay Ramasesh, Ambrose Slone, Guy Gur-Ari, Ethan Dyer, and Behnam Neyshabur. “Exploring length generalization in large language models”. In: Advances in Neural Information Processing Systems 35 (2022), pp. 38546–38556.',\n",
       "  'metadata': {'detection_class_prob': 0.9269450306892395,\n",
       "   'coordinates': {'points': ((222.81700134277344, 551.8566666666667),\n",
       "     (222.81700134277344, 652.4229122222225),\n",
       "     (1571.403564453125, 652.4229122222225),\n",
       "     (1571.403564453125, 551.8566666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'fedf4fde6ef19b666400925c127fa11a',\n",
       "  'text': '[5] Simran Arora, Sabri Eyuboglu, Michael Zhang, Aman Timalsina, Silas Alberti, James Zou, Atri Rudra, and Christo- pher Re. “Simple linear attention language models balance the recall-throughput tradeoff”. In: Forty-first International Conference on Machine Learning. 2024. url: https://openreview.net/forum?id=e93ffDcpH3.',\n",
       "  'metadata': {'detection_class_prob': 0.9245644807815552,\n",
       "   'coordinates': {'points': ((223.0419464111328, 651.4816666666667),\n",
       "     (223.0419464111328, 752.0479122222222),\n",
       "     (1575.37646484375, 752.0479122222222),\n",
       "     (1575.37646484375, 651.4816666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ? id = e93ffDcpH3',\n",
       "     'url': 'https://openreview.net/forum?id=e93ffDcpH3',\n",
       "     'start_index': 569}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '3c797362696502a0e3c03d6e903d13bd',\n",
       "  'text': '[6] Dzmitry Bahdanau. “Neural machine translation by jointly learning to align and translate”. In: arXiv preprint arXiv:1409.0473 (2014).',\n",
       "  'metadata': {'detection_class_prob': 0.8986682891845703,\n",
       "   'coordinates': {'points': ((225.73611111111106, 751.1094444444444),\n",
       "     (225.73611111111106, 818.4673566666667),\n",
       "     (1565.320068359375, 818.4673566666667),\n",
       "     (1565.320068359375, 751.1094444444444)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'a0055f59c637913b94df2d1bc83c2b33',\n",
       "  'text': '[7] Reza Bayat, Mohammad Pezeshki, Elvis Dohmatob, David Lopez-Paz, and Pascal Vincent. “The Pitfalls of Memo- rization: When Memorization Hurts Generalization”. In: arXiv preprint arXiv:2412.07684 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.8623228073120117,\n",
       "   'coordinates': {'points': ((225.73611111111106, 817.526111111111),\n",
       "     (225.73611111111106, 884.8840233333332),\n",
       "     (1570.2103271484375, 884.8840233333332),\n",
       "     (1570.2103271484375, 817.526111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '9cd5a4f706779be82ac96763f1ad3180',\n",
       "  'text': '[8] Maximilian Beck, Korbinian Pöppel, Markus Spanring, Andreas Auer, Oleksandra Prudnikova, Michael Kopp, Günter Klambauer, Johannes Brandstetter, and Sepp Hochreiter. “xLSTM: Extended Long Short-Term Memory”. In: arXiv preprint arXiv:2405.04517 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9255558848381042,\n",
       "   'coordinates': {'points': ((225.73611111111106, 883.9427777777776),\n",
       "     (225.73611111111106, 984.5118011111111),\n",
       "     (1568.4385986328125, 984.5118011111111),\n",
       "     (1568.4385986328125, 883.9427777777776)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '939ce46a8eef44b55ebe587198dd5ee6',\n",
       "  'text': '[9] Ali Behrouz, Michele Santacatterina, and Ramin Zabih. “Mambamixer: Efficient selective state space models with dual token and channel selection”. In: arXiv preprint arXiv:2403.19888 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9102137088775635,\n",
       "   'coordinates': {'points': ((225.73611111111106, 983.5705555555555),\n",
       "     (225.73611111111106, 1050.9284677777778),\n",
       "     (1562.3333740234375, 1050.9284677777778),\n",
       "     (1562.3333740234375, 983.5705555555555)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '70742a31d29e54710858d678d0f3cda5',\n",
       "  'text': '[10] Vincent-Pierre Berges, Barlas Oğuz, Daniel Haziza, Wen-tau Yih, Luke Zettlemoyer, and Gargi Gosh. “Memory Layers at Scale”. In: arXiv preprint arXiv:2412.09764 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9108033180236816,\n",
       "   'coordinates': {'points': ((212.86944444444424, 1049.987222222222),\n",
       "     (212.86944444444424, 1117.3451344444445),\n",
       "     (1565.0843505859375, 1117.3451344444445),\n",
       "     (1565.0843505859375, 1049.987222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '267318c96080a80db740f69cb4acdd5f',\n",
       "  'text': '[11] Alberto Bietti, Vivien Cabannes, Diane Bouchacourt, Herve Jegou, and Leon Bottou. “Birth of a transformer: A memory viewpoint”. In: Advances in Neural Information Processing Systems 36 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.8379277586936951,\n",
       "   'coordinates': {'points': ((212.86944444444438, 1116.4038888888888),\n",
       "     (212.86944444444438, 1183.7645788888888),\n",
       "     (1566.1783447265625, 1183.7645788888888),\n",
       "     (1566.1783447265625, 1116.4038888888888)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'eef9f0ee0403fee1344de617a7e1efa4',\n",
       "  'text': '[12] Yonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, et al. “Piqa: Reasoning about physical commonsense in natural language”. In: Proceedings of the AAAI conference on artificial intelligence. Vol. 34. 05. 2020, pp. 7432–7439.',\n",
       "  'metadata': {'detection_class_prob': 0.8776463270187378,\n",
       "   'coordinates': {'points': ((212.86944444444438, 1182.8233333333333),\n",
       "     (212.86944444444438, 1250.1812455555555),\n",
       "     (1567.5328369140625, 1250.1812455555555),\n",
       "     (1567.5328369140625, 1182.8233333333333)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '64d5e4395794b48785bc0c1517fae4bc',\n",
       "  'text': '[13] Aleksandar Botev, Soham De, Samuel L Smith, Anushan Fernando, George-Cristian Muraru, Ruba Haroun, Leonard Berrada, Razvan Pascanu, Pier Giuseppe Sessa, Robert Dadashi, et al. “RecurrentGemma: Moving Past Transformers for Efficient Open Language Models”. In: arXiv preprint arXiv:2404.07839 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9177321791648865,\n",
       "   'coordinates': {'points': ((212.86944444444438, 1249.2399999999998),\n",
       "     (212.86944444444438, 1349.8062455555555),\n",
       "     (1569.1826171875, 1349.8062455555555),\n",
       "     (1569.1826171875, 1249.2399999999998)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'f4ff3067dbecf1feb72db2eab1b36323',\n",
       "  'text': '[14] Léon Bottou and Vladimir Vapnik. “Local learning algorithms”. In: Neural computation 4.6 (1992), pp. 888–900.',\n",
       "  'metadata': {'detection_class_prob': 0.8178014159202576,\n",
       "   'coordinates': {'points': ((212.86944444444424, 1348.8677777777777),\n",
       "     (212.86944444444424, 1383.0173566666667),\n",
       "     (1535.019287109375, 1383.0173566666667),\n",
       "     (1535.019287109375, 1348.8677777777777)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '9717100ca7820abdbf9b6cc56b816f65',\n",
       "  'text': '[15] Aydar Bulatov, Yuri Kuratov, Yermek Kapushev, and Mikhail S Burtsev. “Scaling transformer to 1m tokens and beyond with rmt”. In: arXiv preprint arXiv:2304.11062 (2023).',\n",
       "  'metadata': {'detection_class_prob': 0.8804656267166138,\n",
       "   'coordinates': {'points': ((212.86944444444438, 1382.076111111111),\n",
       "     (212.86944444444438, 1449.4340233333332),\n",
       "     (1559.997300466667, 1449.4340233333332),\n",
       "     (1559.997300466667, 1382.076111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'cf3ff24b33d832cf62cad7402a688f60',\n",
       "  'text': '[16] Aydar Bulatov, Yury Kuratov, and Mikhail Burtsev. “Recurrent memory transformer”. In: Advances in Neural Information Processing Systems 35 (2022), pp. 11079–11091.',\n",
       "  'metadata': {'detection_class_prob': 0.911705493927002,\n",
       "   'coordinates': {'points': ((212.86944444444438, 1448.4927777777777),\n",
       "     (212.86944444444438, 1515.85069),\n",
       "     (1568.8035888671875, 1515.85069),\n",
       "     (1568.8035888671875, 1448.4927777777777)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'e1a9ea52f5025115f65a617d07301582',\n",
       "  'text': '[17] Edoardo Cetin, Qi Sun, Tianyu Zhao, and Yujin Tang. “An Evolved Universal Transformer Memory”. In: arXiv preprint arXiv:2410.13166 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9065442085266113,\n",
       "   'coordinates': {'points': ((212.86944444444447, 1514.912222222222),\n",
       "     (212.86944444444447, 1582.2701344444445),\n",
       "     (1565.142333984375, 1582.2701344444445),\n",
       "     (1565.142333984375, 1514.912222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'c82bc2127c83e6e1d5b7592fedb458de',\n",
       "  'text': '[18] Beidi Chen, Tri Dao, Eric Winsor, Zhao Song, Atri Rudra, and Christopher Ré. “Scatterbrain: Unifying sparse and low-rank attention”. In: Advances in Neural Information Processing Systems 34 (2021), pp. 17413–17426.',\n",
       "  'metadata': {'detection_class_prob': 0.9051321148872375,\n",
       "   'coordinates': {'points': ((212.86944444444447, 1581.328888888889),\n",
       "     (212.86944444444447, 1648.686801111111),\n",
       "     (1570.8846435546875, 1648.686801111111),\n",
       "     (1570.8846435546875, 1581.328888888889)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'accd409576762cd4b7d296ff6cc6fc17',\n",
       "  'text': '[19] Krzysztof Marcin Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song, Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Quincy Davis, Afroz Mohiuddin, Lukasz Kaiser, David Benjamin Belanger, Lucy J Colwell, and Adrian Weller. “Rethinking Attention with Performers”. In: International Conference on Learning Representations. 2021. url: https://openreview.net/forum?id=Ua6zuk0WRH.',\n",
       "  'metadata': {'detection_class_prob': 0.929196834564209,\n",
       "   'coordinates': {'points': ((212.86944444444438, 1647.7455555555555),\n",
       "     (212.86944444444438, 1779.8624788888887),\n",
       "     (1574.648193359375, 1779.8624788888887),\n",
       "     (1574.648193359375, 1647.7455555555555)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ? id = Ua6zuk0WRH',\n",
       "     'url': 'https://openreview.net/forum?id=Ua6zuk0WRH',\n",
       "     'start_index': 349}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'cf70d9df16e5d63880426e159394ef8b',\n",
       "  'text': '[20] Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina Toutanova. “BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions”. In: Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Ed. by Jill Burstein, Christy Doran, and Thamar Solorio. Minneapolis, Minnesota: Association for Computational Linguistics, June 2019, pp. 2924–2936. doi: 10.18653/v1/N19-1300. url: https: //aclanthology.org/N19-1300/.',\n",
       "  'metadata': {'detection_class_prob': 0.9478564858436584,\n",
       "   'coordinates': {'points': ((212.86944444444438, 1780.5816666666667),\n",
       "     (212.86944444444438, 1979.1152566666665),\n",
       "     (1564.2596328333334, 1979.1152566666665),\n",
       "     (1564.2596328333334, 1780.5816666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '10 . 18653 / v1 / N19 - 1300',\n",
       "     'url': 'https://doi.org/10.18653/v1/N19-1300',\n",
       "     'start_index': 519},\n",
       "    {'text': 'https :',\n",
       "     'url': 'https://aclanthology.org/N19-1300/',\n",
       "     'start_index': 546},\n",
       "    {'text': '// aclanthology . org / N19 - 1300 /.',\n",
       "     'url': 'https://aclanthology.org/N19-1300/',\n",
       "     'start_index': 553}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '8bd77ab3d238f5d2889649ea39e62100',\n",
       "  'text': '18',\n",
       "  'metadata': {'coordinates': {'points': ((867.1333333333333,\n",
       "      2057.742777777778),\n",
       "     (867.1333333333333, 2085.4166666666665),\n",
       "     (892.87005, 2085.4166666666665),\n",
       "     (892.87005, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'c2fb800a7f864c1e81fd875ea9bfaec6',\n",
       "  'text': '[21] Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. “Think you have solved question answering? try arc, the ai2 reasoning challenge”. In: arXiv preprint arXiv:1803.05457 (2018).',\n",
       "  'metadata': {'detection_class_prob': 0.9293677806854248,\n",
       "   'coordinates': {'points': ((212.8694444444444, 202.39277777777778),\n",
       "     (212.8694444444444, 300.06475830078125),\n",
       "     (1564.2729163000004, 300.06475830078125),\n",
       "     (1564.2729163000004, 202.39277777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '82dd37c327fd20d57e0173dec94f9c20',\n",
       "  'text': '[22] Nelson Cowan. “What are the differences between long-term, short-term, and working memory?” In: Progress in brain research 169 (2008), pp. 323–338.',\n",
       "  'metadata': {'detection_class_prob': 0.9089279770851135,\n",
       "   'coordinates': {'points': ((212.86944444444447, 302.0205555555558),\n",
       "     (212.86944444444447, 369.37846777777787),\n",
       "     (1564.532958984375, 369.37846777777787),\n",
       "     (1564.532958984375, 302.0205555555558)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '7123205c7bc238f114e5af151b10b750',\n",
       "  'text': '[23] Zihang Dai, Zhilin Yang, Yiming Yang, Jaime G. Carbonell, Quoc Viet Le, and Ruslan Salakhutdinov. “Transformer- XL: Attentive Language Models beyond a Fixed-Length Context”. In: ACL (1). Ed. by Anna Korhonen, David R. Traum, and Lluís Màrquez. Association for Computational Linguistics, 2019, pp. 2978–2988. isbn: 978-1-950737-48-2.',\n",
       "  'metadata': {'detection_class_prob': 0.9225428104400635,\n",
       "   'coordinates': {'points': ((212.86944444444438, 368.43722222222243),\n",
       "     (212.86944444444438, 467.312255859375),\n",
       "     (1567.12548828125, 467.312255859375),\n",
       "     (1567.12548828125, 368.43722222222243)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '1d609fbc6e3728f4a3947470bbe56d25',\n",
       "  'text': '[24] Tri Dao. “FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning”. In: The Twelfth Inter- national Conference on Learning Representations. 2024. url: https://openreview.net/forum?id=mZn2Xyh9Ec.',\n",
       "  'metadata': {'detection_class_prob': 0.8119913935661316,\n",
       "   'coordinates': {'points': ((212.8694444444444, 468.0650000000001),\n",
       "     (212.8694444444444, 535.4229122222225),\n",
       "     (1568.7291259765625, 535.4229122222225),\n",
       "     (1568.7291259765625, 468.0650000000001)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ? id = mZn2Xyh9Ec',\n",
       "     'url': 'https://openreview.net/forum?id=mZn2Xyh9Ec',\n",
       "     'start_index': 60}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '1412890c8e3d5feeb161580088dab77b',\n",
       "  'text': '[25] Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher Ré. “FlashAttention: Fast and Memory-Efficient',\n",
       "  'metadata': {'coordinates': {'points': ((212.86944444444455,\n",
       "      534.4816666666667),\n",
       "     (212.86944444444455, 562.1555555555558),\n",
       "     (1559.9973004666667, 562.1555555555558),\n",
       "     (1559.9973004666667, 534.4816666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'e52528854f16431cde9712adc4ee1214',\n",
       "  'text': 'Exact Attention with IO-Awareness”. In: Advances in Neural Information Processing Systems. Ed. by S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh. Vol. 35. Curran Associates, Inc., 2022, pp. 16344–16359. url: https://proceedings.neurips.cc/paper_files/paper/2022/file/67d57c32e20fd0a7a302cb81d36e40d5- Paper-Conference.pdf.',\n",
       "  'metadata': {'detection_class_prob': 0.9345605373382568,\n",
       "   'coordinates': {'points': ((219.263916015625, 542.2435302734375),\n",
       "     (219.263916015625, 699.8069233333334),\n",
       "     (1576.0330810546875, 699.8069233333334),\n",
       "     (1576.0330810546875, 542.2435302734375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// proceedings . neurips . cc / paper _ files / paper / 2022 / file / 67d57c32e20fd0a7a302cb81d36e40d5 -',\n",
       "     'url': 'https://proceedings.neurips.cc/paper_files/paper/2022/file/67d57c32e20fd0a7a302cb81d36e40d5-Paper-Conference.pdf',\n",
       "     'start_index': 337},\n",
       "    {'text': 'Paper - Conference . pdf',\n",
       "     'url': 'https://proceedings.neurips.cc/paper_files/paper/2022/file/67d57c32e20fd0a7a302cb81d36e40d5-Paper-Conference.pdf',\n",
       "     'start_index': 430}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '661fa5b533b3978e85f0b3d8ab06d816',\n",
       "  'text': '[26] Tri Dao and Albert Gu. “Transformers are SSMs: Generalized models and efficient algorithms through structured state space duality”. In: arXiv preprint arXiv:2405.21060 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9015275835990906,\n",
       "   'coordinates': {'points': ((212.86944444444438, 700.5261111111114),\n",
       "     (212.86944444444438, 767.8840233333334),\n",
       "     (1562.8834228515625, 767.8840233333334),\n",
       "     (1562.8834228515625, 700.5261111111114)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '38c2dc53aa2b5c64a7170ce043adc63d',\n",
       "  'text': '[27] Abhimanyu Das, Weihao Kong, Andrew Leach, Shaan K Mathur, Rajat Sen, and Rose Yu. “Long-term Forecasting with TiDE: Time-series Dense Encoder”. In: Transactions on Machine Learning Research (2023). issn: 2835-8856. url: https://openreview.net/forum?id=pCbC3aQB5W.',\n",
       "  'metadata': {'detection_class_prob': 0.9265975952148438,\n",
       "   'coordinates': {'points': ((212.8694444444443, 766.9427777777776),\n",
       "     (212.8694444444443, 865.8513677777778),\n",
       "     (1571.010009765625, 865.8513677777778),\n",
       "     (1571.010009765625, 766.9427777777776)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ? id = pCbC3aQB5W',\n",
       "     'url': 'https://openreview.net/forum?id=pCbC3aQB5W',\n",
       "     'start_index': 225}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '180d382ef81ebf3bdac7f49a2288affe',\n",
       "  'text': '[28] Soham De, Samuel L Smith, Anushan Fernando, Aleksandar Botev, George Cristian-Muraru, Albert Gu, Ruba Haroun, Leonard Berrada, Yutian Chen, Srivatsan Srinivasan, et al. “Griffin: Mixing gated linear recurrences with local attention for efficient language models”. In: arXiv preprint arXiv:2402.19427 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9309122562408447,\n",
       "   'coordinates': {'points': ((212.86944444444438, 866.5705555555555),\n",
       "     (212.86944444444438, 967.1368011111111),\n",
       "     (1571.615966796875, 967.1368011111111),\n",
       "     (1571.615966796875, 866.5705555555555)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'b2f3400a328b769869a25132ca339baa',\n",
       "  'text': '[29] Juechu Dong, Boyuan Feng, Driss Guessous, Yanbo Liang, and Horace He. “Flex Attention: A Programming Model for Generating Optimized Attention Kernels”. In: arXiv preprint arXiv:2412.05496 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.8994935750961304,\n",
       "   'coordinates': {'points': ((212.86944444444438, 966.1955555555555),\n",
       "     (212.86944444444438, 1033.5534677777778),\n",
       "     (1570.4847412109375, 1033.5534677777778),\n",
       "     (1570.4847412109375, 966.1955555555555)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '8c555af3f66d16bab2b169a24302af6d',\n",
       "  'text': '[30] Xin Dong, Yonggan Fu, Shizhe Diao, Wonmin Byeon, Zijia Chen, Ameya Sunil Mahabaleshwarkar, Shih-Yang Liu, Matthijs Van Keirsbilck, Min-Hung Chen, Yoshi Suhara, et al. “Hymba: A Hybrid-head Architecture for Small Language Models”. In: arXiv preprint arXiv:2411.13676 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9272312521934509,\n",
       "   'coordinates': {'points': ((212.86944444444455, 1032.615),\n",
       "     (212.86944444444455, 1133.1812455555555),\n",
       "     (1569.2747802734375, 1133.1812455555555),\n",
       "     (1569.2747802734375, 1032.615)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '926518ca9ed7388cd045a37d239a5b17',\n",
       "  'text': '[31] Stefan Elfwing, Eiji Uchibe, and Kenji Doya. “Sigmoid-weighted linear units for neural network function approxi- mation in reinforcement learning”. In: Neural networks 107 (2018), pp. 3–11.',\n",
       "  'metadata': {'detection_class_prob': 0.9024097919464111,\n",
       "   'coordinates': {'points': ((208.5481414794922, 1132.2399999999998),\n",
       "     (208.5481414794922, 1199.5979122222222),\n",
       "     (1567.8973388671875, 1199.5979122222222),\n",
       "     (1567.8973388671875, 1132.2399999999998)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'a96735968891a796e1093d5420ea2311',\n",
       "  'text': '[32] Yukun Feng, Feng Li, Ziang Song, Boyuan Zheng, and Philipp Koehn. “Learn to remember: Transformer with recurrent memory for document-level machine translation”. In: arXiv preprint arXiv:2205.01546 (2022).',\n",
       "  'metadata': {'detection_class_prob': 0.8318759799003601,\n",
       "   'coordinates': {'points': ((212.86944444444438, 1198.6566666666665),\n",
       "     (212.86944444444438, 1266.0173566666665),\n",
       "     (1566.1385498046875, 1266.0173566666665),\n",
       "     (1566.1385498046875, 1198.6566666666665)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '7ca89c868863d6b10f5dae3bd2d496f3',\n",
       "  'text': '[33] Daniel Y Fu, Tri Dao, Khaled Kamal Saab, Armin W Thomas, Atri Rudra, and Christopher Re. “Hungry Hungry Hippos: Towards Language Modeling with State Space Models”. In: The Eleventh International Conference on Learning Representations. 2023. url: https://openreview.net/forum?id=COZDy0WYGg.',\n",
       "  'metadata': {'detection_class_prob': 0.9171264171600342,\n",
       "   'coordinates': {'points': ((212.86944444444455, 1265.076111111111),\n",
       "     (212.86944444444455, 1365.6423566666667),\n",
       "     (1565.7921142578125, 1365.6423566666667),\n",
       "     (1565.7921142578125, 1265.076111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ? id = COZDy0WYGg',\n",
       "     'url': 'https://openreview.net/forum?id=COZDy0WYGg',\n",
       "     'start_index': 251}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'c8c0c3b0ac7921a93fbc6ec87c372e24',\n",
       "  'text': '[34] Yossi Gandelsman, Yu Sun, Xinlei Chen, and Alexei Efros. “Test-time training with masked autoencoders”. In: Advances in Neural Information Processing Systems 35 (2022), pp. 29374–29385.',\n",
       "  'metadata': {'detection_class_prob': 0.9040347933769226,\n",
       "   'coordinates': {'points': ((212.86944444444455, 1364.701111111111),\n",
       "     (212.86944444444455, 1432.0590233333332),\n",
       "     (1563.2716749999997, 1432.0590233333332),\n",
       "     (1563.2716749999997, 1364.701111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '2556a1f33e24e6a7b0f2f9f6bb5f3304',\n",
       "  'text': '[35] Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, et al. “The pile: An 800gb dataset of diverse text for language modeling”. In: arXiv preprint arXiv:2101.00027 (2020).',\n",
       "  'metadata': {'detection_class_prob': 0.9284109473228455,\n",
       "   'coordinates': {'points': ((212.86944444444447, 1431.1205555555555),\n",
       "     (212.86944444444447, 1531.686801111111),\n",
       "     (1570.7281494140625, 1531.686801111111),\n",
       "     (1570.7281494140625, 1431.1205555555555)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'c33ff1872f68e0ccdc722ad716b80fd6',\n",
       "  'text': '[36] Felix A Gers, Jürgen Schmidhuber, and Fred Cummins. “Learning to forget: Continual prediction with LSTM”. In: Neural computation 12.10 (2000), pp. 2451–2471.',\n",
       "  'metadata': {'detection_class_prob': 0.9097015261650085,\n",
       "   'coordinates': {'points': ((212.86944444444438, 1530.7455555555555),\n",
       "     (212.86944444444438, 1598.1034677777775),\n",
       "     (1568.39697265625, 1598.1034677777775),\n",
       "     (1568.39697265625, 1530.7455555555555)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '91a4e32a282922597094660a5622c8b2',\n",
       "  'text': '[37] Alex Graves, Greg Wayne, and Ivo Danihelka. Neural Turing Machines. 2014. arXiv: 1410.5401 [cs.NE]. url: https://arxiv.org/abs/1410.5401.',\n",
       "  'metadata': {'detection_class_prob': 0.9143458604812622,\n",
       "   'coordinates': {'points': ((212.8694444444444, 1597.162222222222),\n",
       "     (212.8694444444444, 1662.8624788888887),\n",
       "     (1566.314697265625, 1662.8624788888887),\n",
       "     (1566.314697265625, 1597.162222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '1410 . 5401 [ cs . NE ].',\n",
       "     'url': 'https://arxiv.org/abs/1410.5401',\n",
       "     'start_index': 86}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'dc0f06bade97691fb0cf5e46931a72b2',\n",
       "  'text': '[38] Klaus Greff, Rupesh K Srivastava, Jan Koutník, Bas R Steunebrink, and Jürgen Schmidhuber. “LSTM: A search space',\n",
       "  'metadata': {'coordinates': {'points': ((212.86944444444447,\n",
       "      1663.5816666666667),\n",
       "     (212.86944444444447, 1691.2555555555555),\n",
       "     (1559.9917656888888, 1691.2555555555555),\n",
       "     (1559.9917656888888, 1663.5816666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '211ecb333349675e6821ce19618eea79',\n",
       "  'text': 'odyssey”. In: IEEE transactions on neural networks and learning systems 28.10 (2016), pp. 2222–2232.',\n",
       "  'metadata': {'detection_class_prob': 0.8899675607681274,\n",
       "   'coordinates': {'points': ((225.14430236816406, 1671.33154296875),\n",
       "     (225.14430236816406, 1730.9395788888887),\n",
       "     (1565.5889892578125, 1730.9395788888887),\n",
       "     (1565.5889892578125, 1671.33154296875)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'fc7ce83dbe0ff9429f693b0ae9ede054',\n",
       "  'text': '[39] Katarína Grešová, Vlastimil Martinek, David Čechák, Petr Šimeček, and Panagiotis Alexiou. “Genomic benchmarks: a collection of datasets for genomic sequence classification”. In: BMC Genomic Data 24.1 (2023), p. 25.',\n",
       "  'metadata': {'detection_class_prob': 0.7562036514282227,\n",
       "   'coordinates': {'points': ((212.86944444444438, 1729.9983333333332),\n",
       "     (212.86944444444438, 1797.3562455555557),\n",
       "     (1584.2481689453125, 1797.3562455555557),\n",
       "     (1584.2481689453125, 1729.9983333333332)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '0bc598aed32cce872cd8364a61f96751',\n",
       "  'text': '[40] Albert Gu and Tri Dao. “Mamba: Linear-Time Sequence Modeling with Selective State Spaces”. In: First Conference on Language Modeling. 2024. url: https://openreview.net/forum?id=tEYskw1VY2.',\n",
       "  'metadata': {'detection_class_prob': 0.8621627688407898,\n",
       "   'coordinates': {'points': ((212.86944444444438, 1796.4149999999997),\n",
       "     (212.86944444444438, 1863.77569),\n",
       "     (1569.128662109375, 1863.77569),\n",
       "     (1569.128662109375, 1796.4149999999997)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ? id = tEYskw1VY2',\n",
       "     'url': 'https://openreview.net/forum?id=tEYskw1VY2',\n",
       "     'start_index': 33}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '51e684a92bb7b02d4388d94c086eb674',\n",
       "  'text': '[41] Albert Gu, Karan Goel, and Christopher Re. “Efficiently Modeling Long Sequences with Structured State Spaces”. In: International Conference on Learning Representations. 2022. url: https : / / openreview . net / forum ? id = uYLFoz1vlAC.',\n",
       "  'metadata': {'detection_class_prob': 0.9330478310585022,\n",
       "   'coordinates': {'points': ((212.86944444444455, 1862.8344444444444),\n",
       "     (212.86944444444455, 1961.7402566666665),\n",
       "     (1568.7193603515625, 1961.7402566666665),\n",
       "     (1568.7193603515625, 1862.8344444444444)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https : / / openreview . net / forum ? id =',\n",
       "     'url': 'https://openreview.net/forum?id=uYLFoz1vlAC',\n",
       "     'start_index': 183},\n",
       "    {'text': 'uYLFoz1vlAC',\n",
       "     'url': 'https://openreview.net/forum?id=uYLFoz1vlAC',\n",
       "     'start_index': 227}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'fd50ffa9ed7ba8535df4f01aded5be00',\n",
       "  'text': '19',\n",
       "  'metadata': {'coordinates': {'points': ((867.1305555555552,\n",
       "      2057.7427777777775),\n",
       "     (867.1305555555552, 2085.4166666666665),\n",
       "     (892.8672722222219, 2085.4166666666665),\n",
       "     (892.8672722222219, 2057.7427777777775)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '1fbbea9dcec6954a5050b821c4b27c1b',\n",
       "  'text': '[42] Chi Han, Qifan Wang, Hao Peng, Wenhan Xiong, Yu Chen, Heng Ji, and Sinong Wang. “LM-Infinite: Zero-Shot',\n",
       "  'metadata': {'coordinates': {'points': ((212.8694444444444,\n",
       "      202.39277777777778),\n",
       "     (212.8694444444444, 230.06666666666652),\n",
       "     (1559.9973004666663, 230.06666666666652),\n",
       "     (1559.9973004666663, 202.39277777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '21fc05a3d82fb88f73c69fff9a6b4958',\n",
       "  'text': 'Extreme Length Generalization for Large Language Models”. In: Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). Ed. by Kevin Duh, Helena Gomez, and Steven Bethard. Mexico City, Mexico: Association for Computational Linguistics, June 2024, pp. 3991–4008. doi: 10.18653/v1/2024.naacl-long.222. url: https://aclanthology. org/2024.naacl-long.222.',\n",
       "  'metadata': {'detection_class_prob': 0.9473839402198792,\n",
       "   'coordinates': {'points': ((216.13760375976562, 209.43060302734375),\n",
       "     (216.13760375976562, 400.92636777777795),\n",
       "     (1566.906388888889, 400.92636777777795),\n",
       "     (1566.906388888889, 209.43060302734375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '10 . 18653 / v1 / 2024 . naacl - long . 222',\n",
       "     'url': 'https://doi.org/10.18653/v1/2024.naacl-long.222',\n",
       "     'start_index': 485},\n",
       "    {'text': 'https :// aclanthology .',\n",
       "     'url': 'https://aclanthology.org/2024.naacl-long.222',\n",
       "     'start_index': 523},\n",
       "    {'text': 'org / 2024 . naacl - long . 222',\n",
       "     'url': 'https://aclanthology.org/2024.naacl-long.222',\n",
       "     'start_index': 545}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '58853991ba3795ef150f4a7fe2ab6c53',\n",
       "  'text': '[43] Ramin Hasani, Mathias Lechner, Tsun-Hsuan Wang, Makram Chahine, Alexander Amini, and Daniela Rus. “Liquid Structural State-Space Models”. In: The Eleventh International Conference on Learning Representations. 2023. url: https://openreview.net/forum?id=g4OTKRKfS7R.',\n",
       "  'metadata': {'detection_class_prob': 0.9291703701019287,\n",
       "   'coordinates': {'points': ((212.86944444444438, 401.6455555555555),\n",
       "     (212.86944444444438, 500.5541455555557),\n",
       "     (1565.3060302734375, 500.5541455555557),\n",
       "     (1565.3060302734375, 401.6455555555555)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ? id = g4OTKRKfS7R',\n",
       "     'url': 'https://openreview.net/forum?id=g4OTKRKfS7R',\n",
       "     'start_index': 225}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'f9f579d7702c842a5e9bbaf3fe2a02fc',\n",
       "  'text': '[44] Zexue He, Leonid Karlinsky, Donghyun Kim, Julian McAuley, Dmitry Krotov, and Rogerio Feris. “CAMELoT: Towards Large Language Models with Training-Free Consolidated Associative Memory”. In: arXiv preprint arXiv:2402.13449 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9310929775238037,\n",
       "   'coordinates': {'points': ((212.86944444444447, 501.2733333333336),\n",
       "     (212.86944444444447, 601.839578888889),\n",
       "     (1568.3333740234375, 601.839578888889),\n",
       "     (1568.3333740234375, 501.2733333333336)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '37604c2aeb8a0a665bb543f80ea4654a',\n",
       "  'text': '[45] Donald Olding Hebb. The organization of behavior: A neuropsychological theory. Psychology press, 2005.',\n",
       "  'metadata': {'detection_class_prob': 0.846422016620636,\n",
       "   'coordinates': {'points': ((212.8694444444444, 600.8983333333337),\n",
       "     (212.8694444444444, 635.0479122222225),\n",
       "     (1462.09912109375, 635.0479122222225),\n",
       "     (1462.09912109375, 600.8983333333337)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '85ff9dfbde5feb627636523ec23e6f5d',\n",
       "  'text': '[46]',\n",
       "  'metadata': {'coordinates': {'points': ((212.86944444444455,\n",
       "      634.1094444444448),\n",
       "     (212.86944444444455, 661.7833333333335),\n",
       "     (258.3099700000001, 661.7833333333335),\n",
       "     (258.3099700000001, 634.1094444444448)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'ba42cbe1ba2010e7b9abb03703c585f3',\n",
       "  'text': 'John J Hopfield. “Neural networks and physical systems with emergent collective computational abilities.” In: Proceedings of the national academy of sciences 79.8 (1982), pp. 2554–2558.',\n",
       "  'metadata': {'detection_class_prob': 0.908971905708313,\n",
       "   'coordinates': {'points': ((220.43829345703125, 634.1094444444444),\n",
       "     (220.43829345703125, 701.4673566666668),\n",
       "     (1573.6435546875, 701.4673566666668),\n",
       "     (1573.6435546875, 634.1094444444444)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '6a32d18d00b4d2f3dac1639184a4ddc8',\n",
       "  'text': '[47] Kurt Hornik, Maxwell Stinchcombe, and Halbert White. “Multilayer feedforward networks are universal approxi- mators”. In: Neural networks 2.5 (1989), pp. 359–366.',\n",
       "  'metadata': {'detection_class_prob': 0.9008928537368774,\n",
       "   'coordinates': {'points': ((212.86944444444438, 700.5261111111114),\n",
       "     (212.86944444444438, 767.8840233333334),\n",
       "     (1564.7615966796875, 767.8840233333334),\n",
       "     (1564.7615966796875, 700.5261111111114)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'c1b78343ee89abb9b93281b79f014a09',\n",
       "  'text': '[48] Cheng-Ping Hsieh, Simeng Sun, Samuel Kriman, Shantanu Acharya, Dima Rekesh, Fei Jia, and Boris Ginsburg. “RULER: What’s the Real Context Size of Your Long-Context Language Models?” In: First Conference on Language Modeling. 2024. url: https://openreview.net/forum?id=kIoBbc76Sy.',\n",
       "  'metadata': {'detection_class_prob': 0.9126501679420471,\n",
       "   'coordinates': {'points': ((212.86944444444447, 766.9427777777776),\n",
       "     (212.86944444444447, 867.5118011111111),\n",
       "     (1571.36328125, 867.5118011111111),\n",
       "     (1571.36328125, 766.9427777777776)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ? id = kIoBbc76Sy',\n",
       "     'url': 'https://openreview.net/forum?id=kIoBbc76Sy',\n",
       "     'start_index': 240}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '5b32ec41867cb404db75092b5d17a036',\n",
       "  'text': '[49] DeLesley Hutchins, Imanol Schlag, Yuhuai Wu, Ethan Dyer, and Behnam Neyshabur. “Block-recurrent transformers”. In: Advances in neural information processing systems 35 (2022), pp. 33248–33261.',\n",
       "  'metadata': {'detection_class_prob': 0.9002556204795837,\n",
       "   'coordinates': {'points': ((212.86944444444455, 866.5705555555555),\n",
       "     (212.86944444444455, 933.9284677777777),\n",
       "     (1567.771728515625, 933.9284677777777),\n",
       "     (1567.771728515625, 866.5705555555555)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '0fc19dc898ec2ff4cc691cfbec83c9e1',\n",
       "  'text': '[50] Kazuki Irie, Róbert Csordás, and Jürgen Schmidhuber. “The dual form of neural networks revisited: Connecting test time predictions to training patterns via spotlights of attention”. In: International Conference on Machine Learning. PMLR. 2022, pp. 9639–9659.',\n",
       "  'metadata': {'detection_class_prob': 0.9240564107894897,\n",
       "   'coordinates': {'points': ((212.86944444444438, 932.987222222222),\n",
       "     (212.86944444444438, 1030.9283447265625),\n",
       "     (1569.8016357421875, 1030.9283447265625),\n",
       "     (1569.8016357421875, 932.987222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '84e80600d4096ead1e4ab3e4156fb662',\n",
       "  'text': '[51] Kazuki Irie, Imanol Schlag, Róbert Csordás, and Jürgen Schmidhuber. “Going beyond linear transformers with recurrent fast weight programmers”. In: Advances in neural information processing systems 34 (2021), pp. 7703–7717.',\n",
       "  'metadata': {'detection_class_prob': 0.8279474377632141,\n",
       "   'coordinates': {'points': ((212.8694444444444, 1032.615),\n",
       "     (212.8694444444444, 1099.9729122222222),\n",
       "     (1566.0423583984375, 1099.9729122222222),\n",
       "     (1566.0423583984375, 1032.615)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'b2f7f0d256df8e2d3de8f369565a9c7a',\n",
       "  'text': '[52] Vidit Jain and Erik Learned-Miller. “Online domain adaptation of a pre-trained cascade of classifiers”. In: CVPR 2011. IEEE. 2011, pp. 577–584.',\n",
       "  'metadata': {'detection_class_prob': 0.8178349733352661,\n",
       "   'coordinates': {'points': ((212.8694444444444, 1099.0316666666665),\n",
       "     (212.8694444444444, 1166.3895788888888),\n",
       "     (1564.4793701171875, 1166.3895788888888),\n",
       "     (1564.4793701171875, 1099.0316666666665)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '197365196eed4c06c8eb35e13e9b0138',\n",
       "  'text': '[53] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. “Mistral 7B”. In: arXiv preprint arXiv:2310.06825 (2023).',\n",
       "  'metadata': {'detection_class_prob': 0.9288909435272217,\n",
       "   'coordinates': {'points': ((212.8694444444444, 1165.4483333333333),\n",
       "     (212.8694444444444, 1266.0173566666665),\n",
       "     (1569.4532470703125, 1266.0173566666665),\n",
       "     (1569.4532470703125, 1165.4483333333333)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '612f6adb2f1aeca8d724baeef0998fbf',\n",
       "  'text': '[54] Praneeth Kacham, Vahab Mirrokni, and Peilin Zhong. “PolySketchFormer: Fast Transformers via Sketching Polyno- mial Kernels”. In: Forty-first International Conference on Machine Learning. 2024. url: https://openreview.net/ forum?id=ghYrfdJfjK.',\n",
       "  'metadata': {'detection_class_prob': 0.9269412159919739,\n",
       "   'coordinates': {'points': ((212.8694444444444, 1265.076111111111),\n",
       "     (212.8694444444444, 1363.9819233333333),\n",
       "     (1570.786376953125, 1363.9819233333333),\n",
       "     (1570.786376953125, 1265.076111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net /',\n",
       "     'url': 'https://openreview.net/forum?id=ghYrfdJfjK',\n",
       "     'start_index': 202},\n",
       "    {'text': 'forum ? id = ghYrfdJfjK',\n",
       "     'url': 'https://openreview.net/forum?id=ghYrfdJfjK',\n",
       "     'start_index': 226}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '396bdfb6cf8251c192df8980b3af55c5',\n",
       "  'text': '[55] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. “Scaling laws for neural language models”. In: arXiv preprint arXiv:2001.08361 (2020).',\n",
       "  'metadata': {'detection_class_prob': 0.9312649965286255,\n",
       "   'coordinates': {'points': ((212.568359375, 1364.701111111111),\n",
       "     (212.568359375, 1460.0240478515625),\n",
       "     (1569.978271484375, 1460.0240478515625),\n",
       "     (1569.978271484375, 1364.701111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'b9f730a1e3d937774d12c8a670084be0',\n",
       "  'text': '[56] Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and François Fleuret. “Transformers are rnns: Fast au- toregressive transformers with linear attention”. In: International conference on machine learning. PMLR. 2020, pp. 5156–5165.',\n",
       "  'metadata': {'detection_class_prob': 0.926834762096405,\n",
       "   'coordinates': {'points': ((212.86944444444447, 1464.328888888889),\n",
       "     (212.86944444444447, 1560.1353759765625),\n",
       "     (1570.65185546875, 1560.1353759765625),\n",
       "     (1570.65185546875, 1464.328888888889)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '4994340a1ffc957694e674123a82c354',\n",
       "  'text': '[57] Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis. “Generalization through Memorization: Nearest Neighbor Language Models”. In: International Conference on Learning Representations. 2020. url: https://openreview.net/forum?id=HklBjCEKvH.',\n",
       "  'metadata': {'detection_class_prob': 0.9287479519844055,\n",
       "   'coordinates': {'points': ((210.14068603515625, 1563.953888888889),\n",
       "     (210.14068603515625, 1662.8624788888887),\n",
       "     (1572.1239013671875, 1662.8624788888887),\n",
       "     (1572.1239013671875, 1563.953888888889)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ? id = HklBjCEKvH',\n",
       "     'url': 'https://openreview.net/forum?id=HklBjCEKvH',\n",
       "     'start_index': 226}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'bc91f95a8fccc831b6f54d0627b3c658',\n",
       "  'text': '[58] Yuri Kuratov, Aydar Bulatov, Petr Anokhin, Ivan Rodkin, Dmitry Igorevich Sorokin, Artyom Sorokin, and Mikhail Burtsev. “BABILong: Testing the Limits of LLMs with Long Context Reasoning-in-a-Haystack”. In: The Thirty- eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 2024. url: https : //openreview.net/forum?id=u7m2CG84BQ.',\n",
       "  'metadata': {'detection_class_prob': 0.9385219812393188,\n",
       "   'coordinates': {'points': ((212.86944444444447, 1663.5816666666667),\n",
       "     (212.86944444444447, 1795.6958122222222),\n",
       "     (1570.595458984375, 1795.6958122222222),\n",
       "     (1570.595458984375, 1663.5816666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :',\n",
       "     'url': 'https://openreview.net/forum?id=u7m2CG84BQ',\n",
       "     'start_index': 322},\n",
       "    {'text': '// openreview . net / forum ? id = u7m2CG84BQ',\n",
       "     'url': 'https://openreview.net/forum?id=u7m2CG84BQ',\n",
       "     'start_index': 330}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'd83a5185b07fbb3cb05081c4e83b2fe4',\n",
       "  'text': '[59] Hung Le, Truyen Tran, and Svetha Venkatesh. “Self-attentive associative memory”. In: International conference on machine learning. PMLR. 2020, pp. 5682–5691.',\n",
       "  'metadata': {'detection_class_prob': 0.9187585115432739,\n",
       "   'coordinates': {'points': ((212.86944444444447, 1796.4149999999997),\n",
       "     (212.86944444444447, 1863.77569),\n",
       "     (1563.44189453125, 1863.77569),\n",
       "     (1563.44189453125, 1796.4149999999997)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'dcdd71942adf816502b95c5a957a2942',\n",
       "  'text': '[60] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. “Retrieval-augmented generation for knowledge-intensive nlp tasks”. In: Advances in Neural Information Processing Systems 33 (2020), pp. 9459–9474.',\n",
       "  'metadata': {'detection_class_prob': 0.9357931017875671,\n",
       "   'coordinates': {'points': ((212.86944444444435, 1862.8344444444444),\n",
       "     (212.86944444444435, 1963.40069),\n",
       "     (1567.6470947265625, 1963.40069),\n",
       "     (1567.6470947265625, 1862.8344444444444)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '7cfb434be67b849528ca568db856274b',\n",
       "  'text': '20',\n",
       "  'metadata': {'coordinates': {'points': ((867.1305555555556,\n",
       "      2057.7427777777775),\n",
       "     (867.1305555555556, 2085.4166666666665),\n",
       "     (892.8672722222223, 2085.4166666666665),\n",
       "     (892.8672722222223, 2057.7427777777775)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '9245e1318eaaa8209a6706973c595ac4',\n",
       "  'text': '[61] Danny Leybzon and Corentin Kervadec. “Learning, Forgetting, Remembering: Insights From Tracking LLM Mem- orization During Training”. In: Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP. 2024, pp. 43–57.',\n",
       "  'metadata': {'detection_class_prob': 0.9275368452072144,\n",
       "   'coordinates': {'points': ((212.8694444444444, 202.39277777777778),\n",
       "     (212.8694444444444, 302.9618011111113),\n",
       "     (1565.2808837890625, 302.9618011111113),\n",
       "     (1565.2808837890625, 202.39277777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'bda042f7810e9c0fd28e6df7e40ad32d',\n",
       "  'text': '[62] Zhe Li, Shiyi Qi, Yiduo Li, and Zenglin Xu. “Revisiting long-term time series forecasting: An investigation on linear mapping”. In: arXiv preprint arXiv:2305.10721 (2023).',\n",
       "  'metadata': {'detection_class_prob': 0.9175124764442444,\n",
       "   'coordinates': {'points': ((212.86944444444438, 302.0205555555558),\n",
       "     (212.86944444444438, 369.37846777777787),\n",
       "     (1569.8525390625, 369.37846777777787),\n",
       "     (1569.8525390625, 302.0205555555558)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'cd565e0c696037462b8d68d5cfcfb84a',\n",
       "  'text': '[63] Bo Liu, Rui Wang, Lemeng Wu, Yihao Feng, Peter Stone, and Qiang Liu. “Longhorn: State space models are amortized online learners”. In: arXiv preprint arXiv:2407.14207 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9080849885940552,\n",
       "   'coordinates': {'points': ((212.86944444444438, 368.43722222222243),\n",
       "     (212.86944444444438, 435.79513444444444),\n",
       "     (1572.627685546875, 435.79513444444444),\n",
       "     (1572.627685546875, 368.43722222222243)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'ec540ae1e9d6beba7e82614554b3673e',\n",
       "  'text': '[64] Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. “Lost in the middle: How language models use long contexts”. In: Transactions of the Association for Computational Linguistics 12 (2024), pp. 157–173.',\n",
       "  'metadata': {'detection_class_prob': 0.9220607280731201,\n",
       "   'coordinates': {'points': ((212.86944444444455, 434.8566666666667),\n",
       "     (212.86944444444455, 535.4229122222225),\n",
       "     (1569.8511962890625, 535.4229122222225),\n",
       "     (1569.8511962890625, 434.8566666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'a92d15aa40541d96f74aa2112fa6f079',\n",
       "  'text': '[65] Yong Liu, Tengge Hu, Haoran Zhang, Haixu Wu, Shiyu Wang, Lintao Ma, and Mingsheng Long. “itransformer: Inverted transformers are effective for time series forecasting”. In: arXiv preprint arXiv:2310.06625 (2023).',\n",
       "  'metadata': {'detection_class_prob': 0.89239501953125,\n",
       "   'coordinates': {'points': ((212.86944444444438, 534.4816666666667),\n",
       "     (212.86944444444438, 602.0623168945312),\n",
       "     (1568.9495849609375, 602.0623168945312),\n",
       "     (1568.9495849609375, 534.4816666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '363cb3b0271dc02b2cb6044c7bc3d44d',\n",
       "  'text': '[66] George Mandler. “The structure of value: Accounting for taste”. In: Affect and cognition. Psychology Press, 2014, pp. 3–36.',\n",
       "  'metadata': {'detection_class_prob': 0.8881871700286865,\n",
       "   'coordinates': {'points': ((212.86944444444455, 600.8983333333333),\n",
       "     (212.86944444444455, 665.1192626953125),\n",
       "     (1565.2939453125, 665.1192626953125),\n",
       "     (1565.2939453125, 600.8983333333333)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '5aeaa0497b64bfaf2a87445a715a298f',\n",
       "  'text': '[67] Harsh Mehta, Ankit Gupta, Ashok Cutkosky, and Behnam Neyshabur. “Long Range Language Modeling via Gated State Spaces”. In: The Eleventh International Conference on Learning Representations. 2023. url: https : //openreview.net/forum?id=5MkYIYCbva.',\n",
       "  'metadata': {'detection_class_prob': 0.9304193258285522,\n",
       "   'coordinates': {'points': ((212.8694444444444, 667.3177777777779),\n",
       "     (212.8694444444444, 766.2235900000003),\n",
       "     (1566.8189697265625, 766.2235900000003),\n",
       "     (1566.8189697265625, 667.3177777777779)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :',\n",
       "     'url': 'https://openreview.net/forum?id=5MkYIYCbva',\n",
       "     'start_index': 206},\n",
       "    {'text': '// openreview . net / forum ? id = 5MkYIYCbva',\n",
       "     'url': 'https://openreview.net/forum?id=5MkYIYCbva',\n",
       "     'start_index': 214}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '563f8a71a3db37e1995b36bda311bab1',\n",
       "  'text': '[68]',\n",
       "  'metadata': {'coordinates': {'points': ((212.8694444444443,\n",
       "      766.9427777777779),\n",
       "     (212.8694444444443, 794.6166666666668),\n",
       "     (258.30996999999985, 794.6166666666668),\n",
       "     (258.30996999999985, 766.9427777777779)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '334dc07ef6234466b8619075c20b1e15',\n",
       "  'text': 'Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. “Pointer Sentinel Mixture Models”. In: International Conference on Learning Representations. 2017. url: https://openreview.net/forum?id=Byj72udxe.',\n",
       "  'metadata': {'detection_class_prob': 0.72942715883255,\n",
       "   'coordinates': {'points': ((216.45787048339844, 766.9427777777779),\n",
       "     (216.45787048339844, 846.8300170898438),\n",
       "     (1567.5665283203125, 846.8300170898438),\n",
       "     (1567.5665283203125, 766.9427777777779)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ? id = Byj72udxe',\n",
       "     'url': 'https://openreview.net/forum?id=Byj72udxe',\n",
       "     'start_index': 423}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '57b672c19d2975c6aa2a2b89bfb99df4',\n",
       "  'text': '[69] William Merrill, Jackson Petty, and Ashish Sabharwal. “The Illusion of State in State-Space Models”. In: Forty-first',\n",
       "  'metadata': {'detection_class_prob': 0.5419095754623413,\n",
       "   'coordinates': {'points': ((212.8694444444444, 833.3622222222222),\n",
       "     (212.8694444444444, 867.5118011111111),\n",
       "     (1560.0009814222224, 867.5118011111111),\n",
       "     (1560.0009814222224, 833.3622222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '9b14f2201376ab190f3d9c9d391412d7',\n",
       "  'text': 'International Conference on Machine Learning. 2024. url: https://openreview.net/forum?id=QZgo9JZpLq.',\n",
       "  'metadata': {'detection_class_prob': 0.5192927718162537,\n",
       "   'coordinates': {'points': ((216.8472442626953, 866.5705555555555),\n",
       "     (216.8472442626953, 900.7201344444444),\n",
       "     (1531.2598876953125, 900.7201344444444),\n",
       "     (1531.2598876953125, 866.5705555555555)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ? id = QZgo9JZpLq',\n",
       "     'url': 'https://openreview.net/forum?id=QZgo9JZpLq',\n",
       "     'start_index': 644}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'a149b43ea2e99cf62f6f5bf35b1c458e',\n",
       "  'text': '[70] Ravi Teja Mullapudi, Steven Chen, Keyi Zhang, Deva Ramanan, and Kayvon Fatahalian. “Online model distillation for efficient video inference”. In: Proceedings of the IEEE/CVF International conference on computer vision. 2019, pp. 3573–3582.',\n",
       "  'metadata': {'detection_class_prob': 0.9187974333763123,\n",
       "   'coordinates': {'points': ((212.8694444444447, 899.7788888888888),\n",
       "     (212.8694444444447, 995.8250122070312),\n",
       "     (1567.339599609375, 995.8250122070312),\n",
       "     (1567.339599609375, 899.7788888888888)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '087a67c6e64dfbd73532687915c575fa',\n",
       "  'text': '[71] Tsendsuren Munkhdalai, Manaal Faruqui, and Siddharth Gopal. “Leave no context behind: Efficient infinite context transformers with infini-attention”. In: arXiv preprint arXiv:2404.07143 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.8968675136566162,\n",
       "   'coordinates': {'points': ((212.8694444444444, 999.4038888888888),\n",
       "     (212.8694444444444, 1066.7645788888888),\n",
       "     (1562.6968994140625, 1066.7645788888888),\n",
       "     (1562.6968994140625, 999.4038888888888)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'fe7058cfdb37ae7abf8a34fb70542843',\n",
       "  'text': '[72] Tsendsuren Munkhdalai, Alessandro Sordoni, Tong Wang, and Adam Trischler. “Metalearned neural memory”. In: Advances in Neural Information Processing Systems 32 (2019).',\n",
       "  'metadata': {'detection_class_prob': 0.9015272259712219,\n",
       "   'coordinates': {'points': ((212.86944444444438, 1065.8233333333333),\n",
       "     (212.86944444444438, 1133.1812455555555),\n",
       "     (1564.3822021484375, 1133.1812455555555),\n",
       "     (1564.3822021484375, 1065.8233333333333)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'bed1173f766596693d33fa9150b6c97c',\n",
       "  'text': '[73] Tsendsuren Munkhdalai and Hong Yu. “Neural semantic encoders”. In: Proceedings of the conference. Association for Computational Linguistics. Meeting. Vol. 1. NIH Public Access. 2017, p. 397.',\n",
       "  'metadata': {'detection_class_prob': 0.8919792771339417,\n",
       "   'coordinates': {'points': ((212.86944444444447, 1132.2399999999998),\n",
       "     (212.86944444444447, 1199.5979122222222),\n",
       "     (1564.0413818359375, 1199.5979122222222),\n",
       "     (1564.0413818359375, 1132.2399999999998)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '2d6e01e1eb797f2862de3ee763602bab',\n",
       "  'text': '[74] Eric Nguyen, Michael Poli, Marjan Faizi, Armin Thomas, Michael Wornow, Callum Birch-Sykes, Stefano Massaroli, Aman Patel, Clayton Rabideau, Yoshua Bengio, et al. “Hyenadna: Long-range genomic sequence modeling at single nucleotide resolution”. In: Advances in neural information processing systems 36 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9300422668457031,\n",
       "   'coordinates': {'points': ((210.95529174804688, 1198.6566666666665),\n",
       "     (210.95529174804688, 1299.22569),\n",
       "     (1572.59814453125, 1299.22569),\n",
       "     (1572.59814453125, 1198.6566666666665)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '7e82e4f33f5b5eaa85f008f8e6e7020e',\n",
       "  'text': '[75] A Nichol. “On first-order meta-learning algorithms”. In: arXiv preprint arXiv:1803.02999 (2018).',\n",
       "  'metadata': {'detection_class_prob': 0.8335362076759338,\n",
       "   'coordinates': {'points': ((212.86944444444438, 1298.2844444444443),\n",
       "     (212.86944444444438, 1332.4340233333332),\n",
       "     (1351.6136599999998, 1332.4340233333332),\n",
       "     (1351.6136599999998, 1298.2844444444443)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '38bc1e365e0946ca62103e06ed7d2e38',\n",
       "  'text': '[76] Yuqi Nie, Nam H Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. “A time series is worth 64 words: Long-term forecasting with transformers”. In: arXiv preprint arXiv:2211.14730 (2022).',\n",
       "  'metadata': {'detection_class_prob': 0.9055324792861938,\n",
       "   'coordinates': {'points': ((212.86944444444424, 1331.4927777777775),\n",
       "     (212.86944444444424, 1398.85069),\n",
       "     (1566.486328125, 1398.85069),\n",
       "     (1566.486328125, 1331.4927777777775)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '69eb859e881f15a901b8504f7a6936ae',\n",
       "  'text': '[77] Hideyuki Okano, Tomoo Hirano, and Evan Balaban. “Learning and memory”. In: Proceedings of the National Academy of Sciences 97.23 (2000), pp. 12403–12404.',\n",
       "  'metadata': {'detection_class_prob': 0.9112675786018372,\n",
       "   'coordinates': {'points': ((212.86944444444438, 1397.9094444444443),\n",
       "     (212.86944444444438, 1465.2701344444445),\n",
       "     (1563.8050537109375, 1465.2701344444445),\n",
       "     (1563.8050537109375, 1397.9094444444443)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'a78fca6f1cf17692cdcaad22450fab1b',\n",
       "  'text': '[78] Antonio Orvieto, Samuel L Smith, Albert Gu, Anushan Fernando, Caglar Gulcehre, Razvan Pascanu, and Soham De. “Resurrecting recurrent neural networks for long sequences”. In: International Conference on Machine Learning. PMLR. 2023, pp. 26670–26698.',\n",
       "  'metadata': {'detection_class_prob': 0.9280918836593628,\n",
       "   'coordinates': {'points': ((212.86944444444447, 1464.328888888889),\n",
       "     (212.86944444444447, 1561.4949951171875),\n",
       "     (1566.6651611328125, 1561.4949951171875),\n",
       "     (1566.6651611328125, 1464.328888888889)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'd0c47b3640992ab136840035d4c8125d',\n",
       "  'text': '[79] Denis Paperno, Germán Kruszewski, Angeliki Lazaridou, Ngoc Quan Pham, Raffaella Bernardi, Sandro Pezzelle, Marco Baroni, Gemma Boleda, and Raquel Fernández. “The LAMBADA dataset: Word prediction requiring a broad discourse context”. In: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Ed. by Katrin Erk and Noah A. Smith. Berlin, Germany: Association for Computational Linguistics, Aug. 2016, pp. 1525–1534. doi: 10.18653/v1/P16-1144. url: https://aclanthology.org/P16-1144/.',\n",
       "  'metadata': {'detection_class_prob': 0.9328086972236633,\n",
       "   'coordinates': {'points': ((212.8694444444444, 1563.953888888889),\n",
       "     (212.8694444444444, 1729.2791455555553),\n",
       "     (1575.8616943359375, 1729.2791455555553),\n",
       "     (1575.8616943359375, 1563.953888888889)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '10 . 18653 / v1 / P16 - 1144',\n",
       "     'url': 'https://doi.org/10.18653/v1/P16-1144',\n",
       "     'start_index': 482},\n",
       "    {'text': 'https :// aclanthology . org / P16 - 1144 /.',\n",
       "     'url': 'https://aclanthology.org/P16-1144/',\n",
       "     'start_index': 509}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '0d269f2317422295d3875d1b283b96d4',\n",
       "  'text': '[80] Badri N. Patro and Vijay S. Agneeswaran. SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time series. 2024. arXiv: 2403.15360 [cs.CV].',\n",
       "  'metadata': {'detection_class_prob': 0.9093729853630066,\n",
       "   'coordinates': {'points': ((212.86944444444455, 1729.9983333333332),\n",
       "     (212.86944444444455, 1797.3562455555557),\n",
       "     (1565.7232666015625, 1797.3562455555557),\n",
       "     (1565.7232666015625, 1729.9983333333332)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2403 . 15360 [ cs . CV ].',\n",
       "     'url': 'https://arxiv.org/abs/2403.15360',\n",
       "     'start_index': 26}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '39742196086308c336f4fb6964e23484',\n",
       "  'text': '[81] Guilherme Penedo, Hynek Kydlíček, Loubna Ben allal, Anton Lozhkov, Margaret Mitchell, Colin Raffel, Leandro',\n",
       "  'metadata': {'coordinates': {'points': ((212.86944444444455,\n",
       "      1796.4149999999997),\n",
       "     (212.86944444444455, 1824.088888888889),\n",
       "     (1559.9960274677776, 1824.088888888889),\n",
       "     (1559.9960274677776, 1796.4149999999997)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'f883825b0a76d377561ba1ff7e94fe21',\n",
       "  'text': 'Von Werra, and Thomas Wolf. “The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale”. In: The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 2024. url: https://openreview.net/forum?id=n6SCkn2QaG.',\n",
       "  'metadata': {'detection_class_prob': 0.9344808459281921,\n",
       "   'coordinates': {'points': ((215.3038787841797, 1803.9774169921875),\n",
       "     (215.3038787841797, 1928.531923333333),\n",
       "     (1571.5167236328125, 1928.531923333333),\n",
       "     (1571.5167236328125, 1803.9774169921875)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ? id = n6SCkn2QaG',\n",
       "     'url': 'https://openreview.net/forum?id=n6SCkn2QaG',\n",
       "     'start_index': 332}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '6fd27be0c7b9039f381ec8abc62b4b5b',\n",
       "  'text': '[82] Bo Peng. RWKV-LM. Version 1.0.0. Aug. 2021. doi: 10.5281/ zenodo.5196577. url: https://github.com/ BlinkDL/RWKV-LM.',\n",
       "  'metadata': {'detection_class_prob': 0.916765034198761,\n",
       "   'coordinates': {'points': ((211.0111541748047, 1929.251111111111),\n",
       "     (211.0111541748047, 1994.94859),\n",
       "     (1571.77978515625, 1994.94859),\n",
       "     (1571.77978515625, 1929.251111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '10 . 5281 / zenodo . 5196577',\n",
       "     'url': 'https://doi.org/10.5281/zenodo.5196577',\n",
       "     'start_index': 54},\n",
       "    {'text': 'https :// github . com /',\n",
       "     'url': 'https://github.com/BlinkDL/RWKV-LM',\n",
       "     'start_index': 84},\n",
       "    {'text': 'BlinkDL / RWKV - LM',\n",
       "     'url': 'https://github.com/BlinkDL/RWKV-LM',\n",
       "     'start_index': 0}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'a2a065d6f522e40381d78bc56a08e2d4',\n",
       "  'text': '21',\n",
       "  'metadata': {'coordinates': {'points': ((867.1333333333333,\n",
       "      2057.7427777777775),\n",
       "     (867.1333333333333, 2085.4166666666665),\n",
       "     (892.87005, 2085.4166666666665),\n",
       "     (892.87005, 2057.7427777777775)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'a85d9a4675e2942f5c8737972329f958',\n",
       "  'text': '[83] Bo Peng, Eric Alcaide, Quentin Gregory Anthony, Alon Albalak, Samuel Arcadinho, Stella Biderman, Huanqi Cao, Xin Cheng, Michael Nguyen Chung, Leon Derczynski, Xingjian Du, Matteo Grella, Kranthi Kiran GV, Xuzheng He, Haowen Hou, Przemyslaw Kazienko, Jan Kocon, Jiaming Kong, Bartłomiej Koptyra, Hayden Lau, Jiaju Lin, Krishna Sri Ipsit Mantri, Ferdinand Mom, Atsushi Saito, Guangyu Song, Xiangru Tang, Johan S. Wind, Stanisław Woźniak, Zhenyuan Zhang, Qinghua Zhou, Jian Zhu, and Rui-Jie Zhu. “RWKV: Reinventing RNNs for the Transformer Era”. In: The 2023 Conference on Empirical Methods in Natural Language Processing. 2023. url: https://openreview. net/forum?id=7SaXczaBpG.',\n",
       "  'metadata': {'detection_class_prob': 0.9509968757629395,\n",
       "   'coordinates': {'points': ((212.64462280273438, 202.39277777777778),\n",
       "     (212.64462280273438, 434.1347011111114),\n",
       "     (1577.00439453125, 434.1347011111114),\n",
       "     (1577.00439453125, 202.39277777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview .',\n",
       "     'url': 'https://openreview.net/forum?id=7SaXczaBpG',\n",
       "     'start_index': 636},\n",
       "    {'text': 'net / forum ? id = 7SaXczaBpG',\n",
       "     'url': 'https://openreview.net/forum?id=7SaXczaBpG',\n",
       "     'start_index': 656}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'b1b0b96ad903c1d353bff7607c32f197',\n",
       "  'text': '[84] Bo Peng, Daniel Goldstein, Quentin Anthony, Alon Albalak, Eric Alcaide, Stella Biderman, Eugene Cheah, Xingjian Du, Teddy Ferdinan, Haowen Hou, et al. “Eagle and finch: Rwkv with matrix-valued states and dynamic recurrence”. In: arXiv preprint arXiv:2404.05892 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9296343922615051,\n",
       "   'coordinates': {'points': ((212.4974365234375, 434.8566666666667),\n",
       "     (212.4974365234375, 535.4229122222225),\n",
       "     (1570.9840087890625, 535.4229122222225),\n",
       "     (1570.9840087890625, 434.8566666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'd8d31cfcfb768b8c8debc8325c6a144d',\n",
       "  'text': '[85] DL Prados and SC Kak. “Neural network capacity using delta rule”. In: Electronics Letters 25.3 (1989), pp. 197–199. [86] Zhen Qin, Yiran Zhong, and Hui Deng. “Exploring Transformer Extrapolation”. In: Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 38. 17. 2024, pp. 18897–18905.',\n",
       "  'metadata': {'detection_class_prob': 0.8864221572875977,\n",
       "   'coordinates': {'points': ((212.86944444444424, 534.481666666667),\n",
       "     (212.86944444444424, 635.8010864257812),\n",
       "     (1569.8192138671875, 635.8010864257812),\n",
       "     (1569.8192138671875, 534.481666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'e5d1eec20425a2b2418d6f0cd5aa0075',\n",
       "  'text': '[87] Liliang Ren, Yang Liu, Yadong Lu, Yelong Shen, Chen Liang, and Weizhu Chen. “Samba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling”. In: arXiv preprint arXiv:2406.07522 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9055854082107544,\n",
       "   'coordinates': {'points': ((212.86944444444447, 634.1094444444444),\n",
       "     (212.86944444444447, 701.4673566666668),\n",
       "     (1572.44091796875, 701.4673566666668),\n",
       "     (1572.44091796875, 634.1094444444444)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '4f36e8ffdb2f6163a45874abcc7a6e39',\n",
       "  'text': '[88] Ivan Rodkin, Yuri Kuratov, Aydar Bulatov, and Mikhail Burtsev. “Associative recurrent memory transformer”. In: arXiv preprint arXiv:2407.04841 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.8901927471160889,\n",
       "   'coordinates': {'points': ((211.77732849121094, 700.5261111111114),\n",
       "     (211.77732849121094, 767.8840233333334),\n",
       "     (1567.2939453125, 767.8840233333334),\n",
       "     (1567.2939453125, 700.5261111111114)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'ce064b579d0ec61590c5bb8cabad0296',\n",
       "  'text': '[89] Aurko Roy, Mohammad Saffar, Ashish Vaswani, and David Grangier. “Efficient content-based sparse attention with routing transformers”. In: Transactions of the Association for Computational Linguistics 9 (2021), pp. 53–68.',\n",
       "  'metadata': {'detection_class_prob': 0.8964818716049194,\n",
       "   'coordinates': {'points': ((212.86944444444447, 766.9427777777776),\n",
       "     (212.86944444444447, 834.3006899999999),\n",
       "     (1566.4276123046875, 834.3006899999999),\n",
       "     (1566.4276123046875, 766.9427777777776)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '2f962983fd2e4ca6472eb97cbaa1db3e',\n",
       "  'text': '[90] Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. “Winogrande: An adversarial winograd schema challenge at scale”. In: Communications of the ACM 64.9 (2021), pp. 99–106.',\n",
       "  'metadata': {'detection_class_prob': 0.8856917023658752,\n",
       "   'coordinates': {'points': ((209.63363647460938, 833.3622222222222),\n",
       "     (209.63363647460938, 900.7201344444444),\n",
       "     (1574.8765869140625, 900.7201344444444),\n",
       "     (1574.8765869140625, 833.3622222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '798c9210fedecb2ff12b9b7a3c72ada7',\n",
       "  'text': '[91] Maarten Sap, Hannah Rashkin, Derek Chen, Ronan Le Bras, and Yejin Choi. “Social IQa: Commonsense Reasoning',\n",
       "  'metadata': {'coordinates': {'points': ((212.86944444444438,\n",
       "      899.7788888888888),\n",
       "     (212.86944444444438, 927.4527777777777),\n",
       "     (1559.9962211849997, 927.4527777777777),\n",
       "     (1559.9962211849997, 899.7788888888888)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '29e0c908135ce0b2623b6aee4123e6bd',\n",
       "  'text': 'about Social Interactions”. In: Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). Ed. by Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan. Hong Kong, China: Association for Computational Linguistics, Nov. 2019, pp. 4463–4473. doi: 10.18653/v1/D19-1454. url: https://aclanthology.org/D19-1454/.',\n",
       "  'metadata': {'detection_class_prob': 0.9288128614425659,\n",
       "   'coordinates': {'points': ((212.25694274902344, 906.700927734375),\n",
       "     (212.25694274902344, 1065.1041455555555),\n",
       "     (1571.5223388671875, 1065.1041455555555),\n",
       "     (1571.5223388671875, 906.700927734375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '10 . 18653 / v1 / D19 - 1454',\n",
       "     'url': 'https://doi.org/10.18653/v1/D19-1454',\n",
       "     'start_index': 475},\n",
       "    {'text': 'https :// aclanthology . org / D19 - 1454 /.',\n",
       "     'url': 'https://aclanthology.org/D19-1454/',\n",
       "     'start_index': 502}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'd6bab19846123e03c60c32b1fdc31d06',\n",
       "  'text': '[92] Imanol Schlag, Kazuki Irie, and Jürgen Schmidhuber. “Linear transformers are secretly fast weight programmers”. In: International Conference on Machine Learning. PMLR. 2021, pp. 9355–9366.',\n",
       "  'metadata': {'detection_class_prob': 0.9075857996940613,\n",
       "   'coordinates': {'points': ((212.86944444444438, 1065.8233333333333),\n",
       "     (212.86944444444438, 1133.1812455555555),\n",
       "     (1567.985107421875, 1133.1812455555555),\n",
       "     (1567.985107421875, 1065.8233333333333)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'b45303afad08f315effc80be93d8c19a',\n",
       "  'text': '[93] JH Schmidhuber. “Learning to control fast-weight memories: An alternative to recurrent nets. Accepted for publication in”. In: Neural Computation (1992).',\n",
       "  'metadata': {'detection_class_prob': 0.9082035422325134,\n",
       "   'coordinates': {'points': ((209.47036743164062, 1132.2399999999998),\n",
       "     (209.47036743164062, 1199.5979122222222),\n",
       "     (1560.9659423828125, 1199.5979122222222),\n",
       "     (1560.9659423828125, 1132.2399999999998)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '5d74c0db54c6df7bc4be69ade9f64cf9',\n",
       "  'text': '[94] Jürgen Schmidhuber. “Reducing the ratio between learning complexity and number of time varying variables in fully recurrent nets”. In: ICANN’93: Proceedings of the International Conference on Artificial Neural Networks Amsterdam, The Netherlands 13–16 September 1993 3. Springer. 1993, pp. 460–463.',\n",
       "  'metadata': {'detection_class_prob': 0.9287434816360474,\n",
       "   'coordinates': {'points': ((212.86944444444438, 1198.6566666666665),\n",
       "     (212.86944444444438, 1299.22569),\n",
       "     (1569.2467041015625, 1299.22569),\n",
       "     (1569.2467041015625, 1198.6566666666665)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '9b150dd69e0b9256760b2a978d9901c7',\n",
       "  'text': '[95] Jürgen Schmidhuber and Sepp Hochreiter. “Long Short-term Memory”. In: Neural Computation MIT-Press (1997). [96] Avi Schwarzschild, Zhili Feng, Pratyush Maini, Zachary C Lipton, and J Zico Kolter. “Rethinking llm memorization through the lens of adversarial compression”. In: arXiv preprint arXiv:2404.15146 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.8829230070114136,\n",
       "   'coordinates': {'points': ((212.86944444444424, 1298.2844444444443),\n",
       "     (212.86944444444424, 1398.85069),\n",
       "     (1564.9110107421875, 1398.85069),\n",
       "     (1564.9110107421875, 1298.2844444444443)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '32c2faa27e5bd76521e44a3f8d6eca73',\n",
       "  'text': '[97] Jimmy T.H. Smith, Andrew Warrington, and Scott Linderman. “Simplified State Space Layers for Sequence Modeling”. In: The Eleventh International Conference on Learning Representations. 2023. url: https://openreview.net/forum? id=Ai8Hw3AXqks.',\n",
       "  'metadata': {'detection_class_prob': 0.928068995475769,\n",
       "   'coordinates': {'points': ((212.86944444444438, 1397.9094444444443),\n",
       "     (212.86944444444438, 1496.8180344444445),\n",
       "     (1572.157470703125, 1496.8180344444445),\n",
       "     (1572.157470703125, 1397.9094444444443)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ?',\n",
       "     'url': 'https://openreview.net/forum?id=Ai8Hw3AXqks',\n",
       "     'start_index': 284}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '3fbe6725c37acd19c95b5ac50e586f25',\n",
       "  'text': '[98] Robin Staab, Mark Vero, Mislav Balunovic, and Martin Vechev. “Beyond Memorization: Violating Privacy via Inference with Large Language Models”. In: The Twelfth International Conference on Learning Representations. 2024. url: https://openreview.net/forum?id=kmn0BhQk7p.',\n",
       "  'metadata': {'detection_class_prob': 0.9269329905509949,\n",
       "   'coordinates': {'points': ((212.86944444444447, 1497.537222222222),\n",
       "     (212.86944444444447, 1596.4430344444445),\n",
       "     (1567.3453369140625, 1596.4430344444445),\n",
       "     (1567.3453369140625, 1497.537222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ? id = kmn0BhQk7p',\n",
       "     'url': 'https://openreview.net/forum?id=kmn0BhQk7p',\n",
       "     'start_index': 230}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'c38aa92580f5f9102fbc3d25dcd263e9',\n",
       "  'text': '[99] Sainbayar Sukhbaatar, Edouard Grave, Guillaume Lample, Herve Jegou, and Armand Joulin. “Augmenting self- attention with persistent memory”. In: arXiv preprint arXiv:1907.01470 (2019).',\n",
       "  'metadata': {'detection_class_prob': 0.8968758583068848,\n",
       "   'coordinates': {'points': ((209.27264404296875, 1597.162222222222),\n",
       "     (209.27264404296875, 1664.5229122222222),\n",
       "     (1564.683043333333, 1664.5229122222222),\n",
       "     (1564.683043333333, 1597.162222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '9932bad0035bb92345502f3476137c42',\n",
       "  'text': '[100]',\n",
       "  'metadata': {'coordinates': {'points': ((199.99999999999983,\n",
       "      1663.5816666666667),\n",
       "     (199.99999999999983, 1691.2555555555555),\n",
       "     (258.3088838888887, 1691.2555555555555),\n",
       "     (258.3088838888887, 1663.5816666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'ed5b21bb0d1c8e6b116bb5b2111d9a45',\n",
       "  'text': 'Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et al. “End-to-end memory networks”. In: Advances in neural information processing systems 28 (2015).',\n",
       "  'metadata': {'detection_class_prob': 0.9013057351112366,\n",
       "   'coordinates': {'points': ((212.10508728027344, 1663.5816666666667),\n",
       "     (212.10508728027344, 1730.9395788888887),\n",
       "     (1560.354248046875, 1730.9395788888887),\n",
       "     (1560.354248046875, 1663.5816666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'b6327f97da8b1e7002bb4fe27fc06302',\n",
       "  'text': '[101] Yu Sun, Xinhao Li, Karan Dalal, Jiarui Xu, Arjun Vikram, Genghan Zhang, Yann Dubois, Xinlei Chen, Xiaolong Wang, Sanmi Koyejo, et al. “Learning to (learn at test time): Rnns with expressive hidden states”. In: arXiv preprint arXiv:2407.04620 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9278379678726196,\n",
       "   'coordinates': {'points': ((200.0, 1729.9983333333332),\n",
       "     (200.0, 1830.5645788888887),\n",
       "     (1569.6258544921875, 1830.5645788888887),\n",
       "     (1569.6258544921875, 1729.9983333333332)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'c7bfca5d43bfaed9f6162d9988fbfd74',\n",
       "  'text': '[102] Yutao Sun, Li Dong, Shaohan Huang, Shuming Ma, Yuqing Xia, Jilong Xue, Jianyong Wang, and Furu Wei. “Retentive network: A successor to transformer for large language models”. In: arXiv preprint arXiv:2307.08621 (2023).',\n",
       "  'metadata': {'detection_class_prob': 0.8898824453353882,\n",
       "   'coordinates': {'points': ((200.0, 1829.626111111111),\n",
       "     (200.0, 1896.9840233333334),\n",
       "     (1566.685791015625, 1896.9840233333334),\n",
       "     (1566.685791015625, 1829.626111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '54de770b6fdd03363f17df8c63551577',\n",
       "  'text': '[103] Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivière, Mihir Sanjay Kale, Juliette Love, et al. “Gemma: Open models based on gemini research and technology”. In: arXiv preprint arXiv:2403.08295 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9135253429412842,\n",
       "   'coordinates': {'points': ((200.00000000000014, 1896.0427777777775),\n",
       "     (200.00000000000014, 1996.6090233333334),\n",
       "     (1571.2227783203125, 1996.6090233333334),\n",
       "     (1571.2227783203125, 1896.0427777777775)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '9990396932fc985e8bfd0961788a4c61',\n",
       "  'text': '22',\n",
       "  'metadata': {'coordinates': {'points': ((867.1305555555555,\n",
       "      2057.7427777777775),\n",
       "     (867.1305555555555, 2085.4166666666665),\n",
       "     (892.8672722222221, 2085.4166666666665),\n",
       "     (892.8672722222221, 2057.7427777777775)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '2a12848ae887876ddbb9728e8ef3b986',\n",
       "  'text': '[104] W Scott Terry. Learning and memory: Basic principles, processes, and procedures. Routledge, 2017.',\n",
       "  'metadata': {'detection_class_prob': 0.8305689096450806,\n",
       "   'coordinates': {'points': ((200.0, 202.39277777777778),\n",
       "     (200.0, 236.54235666666668),\n",
       "     (1370.9954872222222, 236.54235666666668),\n",
       "     (1370.9954872222222, 202.39277777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '542de7f35b46be731e3e0bc8fa34b907',\n",
       "  'text': '[105] Matteo Tiezzi, Michele Casoni, Alessandro Betti, Tommaso Guidi, Marco Gori, and Stefano Melacci. “On the',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 235.60388888888895),\n",
       "     (200.0, 263.2777777777777),\n",
       "     (1559.9973004666667, 263.2777777777777),\n",
       "     (1559.9973004666667, 235.60388888888895)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '3eaad4f57819f23ac118137caea76a9e',\n",
       "  'text': 'resurgence of recurrent models for long sequences: Survey and research opportunities in the transformer era”. In: arXiv preprint arXiv:2402.08132 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9219294786453247,\n",
       "   'coordinates': {'points': ((215.618408203125, 243.19244384765625),\n",
       "     (215.618408203125, 336.1701344444447),\n",
       "     (1563.2734738027777, 336.1701344444447),\n",
       "     (1563.2734738027777, 243.19244384765625)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '9113cafcfc6cd9cb4028cba9df989b82',\n",
       "  'text': '[106] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. “Llama: Open and efficient foundation language models”. In: arXiv preprint arXiv:2302.13971 (2023).',\n",
       "  'metadata': {'detection_class_prob': 0.9289218783378601,\n",
       "   'coordinates': {'points': ((200.0, 335.22888888888895),\n",
       "     (200.0, 435.79513444444444),\n",
       "     (1570.6680908203125, 435.79513444444444),\n",
       "     (1570.6680908203125, 335.22888888888895)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'a4c5fdaa98cd41b684ba0d6f7275102f',\n",
       "  'text': '[107] Jos Van Der Westhuizen and Joan Lasenby. “The unreasonable effectiveness of the forget gate”. In: arXiv preprint arXiv:1804.04849 (2018).',\n",
       "  'metadata': {'detection_class_prob': 0.9036277532577515,\n",
       "   'coordinates': {'points': ((200.0, 434.8566666666667),\n",
       "     (200.0, 502.21457888888904),\n",
       "     (1563.489501953125, 502.21457888888904),\n",
       "     (1563.489501953125, 434.8566666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '83255dde299d2e12f351dab4197612e8',\n",
       "  'text': '[108] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. “Attention is All you Need”. In: Advances in Neural Information Processing Systems. Ed. by I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett. Vol. 30. Cur- ran Associates, Inc., 2017. url: https : / / proceedings . neurips . cc / paper _ files / paper / 2017 / file / 3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.',\n",
       "  'metadata': {'detection_class_prob': 0.9346182346343994,\n",
       "   'coordinates': {'points': ((199.99999999999994, 501.2733333333336),\n",
       "     (199.99999999999994, 666.59859),\n",
       "     (1580.15185546875, 666.59859),\n",
       "     (1580.15185546875, 501.2733333333336)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https : / / proceedings . neurips . cc / paper _ files / paper / 2017 / file /',\n",
       "     'url': 'https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf',\n",
       "     'start_index': 362},\n",
       "    {'text': '3f5ee243547dee91fbd053c1c4a845aa - Paper . pdf',\n",
       "     'url': 'https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf',\n",
       "     'start_index': 441}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '030a885bf11aa5edffdc5ac9610e9e92',\n",
       "  'text': '[109]',\n",
       "  'metadata': {'coordinates': {'points': ((200.00000000000009,\n",
       "      667.3177777777779),\n",
       "     (200.00000000000009, 694.9916666666667),\n",
       "     (258.30888388888894, 694.9916666666667),\n",
       "     (258.30888388888894, 667.3177777777779)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'ca5967123754a143982b583f8623ca8f',\n",
       "  'text': 'Shida Wang. “LongSSM: On the Length Extension of State-space Models in Language Modelling”. In: arXiv preprint arXiv:2406.02080 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.900538444519043,\n",
       "   'coordinates': {'points': ((205.34962463378906, 667.3177777777779),\n",
       "     (205.34962463378906, 734.6756900000003),\n",
       "     (1560.0118323222223, 734.6756900000003),\n",
       "     (1560.0118323222223, 667.3177777777779)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'b1526505e19514cef5b845584322c3c0',\n",
       "  'text': '[110] Yu Wang, Yifan Gao, Xiusi Chen, Haoming Jiang, Shiyang Li, Jingfeng Yang, Qingyu Yin, Zheng Li, Xian Li, Bing Yin, Jingbo Shang, and Julian McAuley. “MEMORYLLM: Towards Self-Updatable Large Language Models”. In: Forty-first International Conference on Machine Learning. 2024. url: https://openreview.net/forum?id=p0lKWzdikQ.',\n",
       "  'metadata': {'detection_class_prob': 0.9253214597702026,\n",
       "   'coordinates': {'points': ((200.0, 733.7344444444444),\n",
       "     (200.0, 834.3006899999999),\n",
       "     (1576.404052734375, 834.3006899999999),\n",
       "     (1576.404052734375, 733.7344444444444)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ? id = p0lKWzdikQ',\n",
       "     'url': 'https://openreview.net/forum?id=p0lKWzdikQ',\n",
       "     'start_index': 286}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'b6fc9d7894a7f133a7b549a1f4e7019d',\n",
       "  'text': '[111] Yu Wang, Chi Han, Tongtong Wu, Xiaoxin He, Wangchunshu Zhou, Nafis Sadeq, Xiusi Chen, Zexue He, Wei Wang, Gholamreza Haffari, et al. “Towards LifeSpan Cognitive Systems”. In: arXiv preprint arXiv:2409.13265 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.6857630610466003,\n",
       "   'coordinates': {'points': ((200.00000000000014, 833.3622222222222),\n",
       "     (200.00000000000014, 901.1973266601562),\n",
       "     (1575.837646484375, 901.1973266601562),\n",
       "     (1575.837646484375, 833.3622222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '20bac5ec7d70e92faac644dbf993cf07',\n",
       "  'text': '[112] Zhiwei Wang, Yao Ma, Zitao Liu, and Jiliang Tang. “R-transformer: Recurrent neural network enhanced transformer”. In: arXiv preprint arXiv:1907.05572 (2019).',\n",
       "  'metadata': {'detection_class_prob': 0.8642727732658386,\n",
       "   'coordinates': {'points': ((199.99999999999983, 899.7788888888888),\n",
       "     (199.99999999999983, 967.1368011111111),\n",
       "     (1580.4820556640625, 967.1368011111111),\n",
       "     (1580.4820556640625, 899.7788888888888)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'd360435dcee0f2ed244fd0b384576257',\n",
       "  'text': 'Jason Weston, Sumit Chopra, and Antoine Bordes. “Memory networks”. In: arXiv preprint arXiv:1410.3916 (2014).',\n",
       "  'metadata': {'detection_class_prob': 0.8178769946098328,\n",
       "   'coordinates': {'points': ((199.99999999999991, 966.1955555555555),\n",
       "     (199.99999999999991, 1000.3451344444444),\n",
       "     (1568.9691162109375, 1000.3451344444444),\n",
       "     (1568.9691162109375, 966.1955555555555)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '7ea39358812acd303e70e395973f1972',\n",
       "  'text': '[114] Bernard Widrow and Marcian E Hoff. “Adaptive switching circuits”. In: Neurocomputing: foundations of research. 1988, pp. 123–134.',\n",
       "  'metadata': {'detection_class_prob': 0.8637577891349792,\n",
       "   'coordinates': {'points': ((200.0, 999.4038888888888),\n",
       "     (200.0, 1062.786865234375),\n",
       "     (1564.2630270000002, 1062.786865234375),\n",
       "     (1564.2630270000002, 999.4038888888888)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'a02a85702ac4d9d21c0c8852f3e53756',\n",
       "  'text': '[115] Ronald J Williams and David Zipser. “A learning algorithm for continually running fully recurrent neural networks”. In: Neural computation 1.2 (1989), pp. 270–280.',\n",
       "  'metadata': {'detection_class_prob': 0.915719211101532,\n",
       "   'coordinates': {'points': ((200.0, 1065.8233333333333),\n",
       "     (200.0, 1133.1812455555555),\n",
       "     (1569.8358154296875, 1133.1812455555555),\n",
       "     (1569.8358154296875, 1065.8233333333333)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'f1bb7df1d5a9337c615306be150b0e3f',\n",
       "  'text': '[116] Daniel B Willingham. “Systems of memory in the human brain”. In: Neuron 18.1 (1997), pp. 5–8.',\n",
       "  'metadata': {'detection_class_prob': 0.8550569415092468,\n",
       "   'coordinates': {'points': ((199.771728515625, 1132.2399999999998),\n",
       "     (199.771728515625, 1166.3895788888888),\n",
       "     (1376.1343994140625, 1166.3895788888888),\n",
       "     (1376.1343994140625, 1132.2399999999998)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '5c73cda04129382fc27f135bc6044443',\n",
       "  'text': '[117] Chao-Yuan Wu, Christoph Feichtenhofer, Haoqi Fan, Kaiming He, Philipp Krahenbuhl, and Ross Girshick. “Long- term feature banks for detailed video understanding”. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019, pp. 284–293.',\n",
       "  'metadata': {'detection_class_prob': 0.9293369650840759,\n",
       "   'coordinates': {'points': ((200.0, 1165.448333333333),\n",
       "     (200.0, 1266.0173566666665),\n",
       "     (1571.5032958984375, 1266.0173566666665),\n",
       "     (1571.5032958984375, 1165.448333333333)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '72e11671b4c0e1ed7e26003db857ddc4',\n",
       "  'text': '[118] Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang, and Mingsheng Long. “TimesNet: Temporal 2D- Variation Modeling for General Time Series Analysis”. In: The Eleventh International Conference on Learning Representations. 2023. url: https://openreview.net/forum?id=ju_Uqw384Oq.',\n",
       "  'metadata': {'detection_class_prob': 0.9247042536735535,\n",
       "   'coordinates': {'points': ((199.99999999999994, 1265.076111111111),\n",
       "     (199.99999999999994, 1365.6423566666667),\n",
       "     (1573.9576416015625, 1365.6423566666667),\n",
       "     (1573.9576416015625, 1265.076111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ? id = ju _ Uqw384Oq',\n",
       "     'url': 'https://openreview.net/forum?id=ju_Uqw384Oq',\n",
       "     'start_index': 242}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'c1e1f2abc0753030facbd22d05f7e50b',\n",
       "  'text': '[119] Qingyang Wu, Zhenzhong Lan, Kun Qian, Jing Gu, Alborz Geramifard, and Zhou Yu. “Memformer: A memory- augmented transformer for sequence modeling”. In: arXiv preprint arXiv:2010.06891 (2020).',\n",
       "  'metadata': {'detection_class_prob': 0.8952859044075012,\n",
       "   'coordinates': {'points': ((200.0, 1364.701111111111),\n",
       "     (200.0, 1432.0590233333332),\n",
       "     (1575.46044921875, 1432.0590233333332),\n",
       "     (1575.46044921875, 1364.701111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '577727594d33fb3750f8b78b421927be',\n",
       "  'text': '[120] Guangxuan Xiao, Yuandong Tian, Beidi Chen, Song Han, and Mike Lewis. “Efficient Streaming Language Models with Attention Sinks”. In: The Twelfth International Conference on Learning Representations. 2024. url: https: //openreview.net/forum?id=NG7sS51zVF.',\n",
       "  'metadata': {'detection_class_prob': 0.9219179749488831,\n",
       "   'coordinates': {'points': ((200.0, 1431.1205555555555),\n",
       "     (200.0, 1530.0263677777775),\n",
       "     (1579.558349609375, 1530.0263677777775),\n",
       "     (1579.558349609375, 1431.1205555555555)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :',\n",
       "     'url': 'https://openreview.net/forum?id=NG7sS51zVF',\n",
       "     'start_index': 214},\n",
       "    {'text': '// openreview . net / forum ? id = NG7sS51zVF',\n",
       "     'url': 'https://openreview.net/forum?id=NG7sS51zVF',\n",
       "     'start_index': 221}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '0fde5bf676a2235ea8f3907bbafb7b2c',\n",
       "  'text': '[121] An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, et al. “Qwen2. 5 Technical Report”. In: arXiv preprint arXiv:2412.15115 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.8988270163536072,\n",
       "   'coordinates': {'points': ((199.99999999999991, 1530.7455555555555),\n",
       "     (199.99999999999991, 1598.1034677777775),\n",
       "     (1574.86767578125, 1598.1034677777775),\n",
       "     (1574.86767578125, 1530.7455555555555)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '9b45bf4d73c5463626493f3e1ffc8719',\n",
       "  'text': '[122]',\n",
       "  'metadata': {'coordinates': {'points': ((199.99999999999983,\n",
       "      1597.162222222222),\n",
       "     (199.99999999999983, 1624.8361111111112),\n",
       "     (258.3088838888887, 1624.8361111111112),\n",
       "     (258.3088838888887, 1597.162222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'a74fd3684dca06cc2c2180d77967892c',\n",
       "  'text': 'Songlin Yang, Jan Kautz, and Ali Hatamizadeh. “Gated Delta Networks: Improving Mamba2 with Delta Rule”. In: arXiv preprint arXiv:2412.06464 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.8875871896743774,\n",
       "   'coordinates': {'points': ((213.52435302734375, 1597.162222222222),\n",
       "     (213.52435302734375, 1664.5229122222222),\n",
       "     (1573.7567138671875, 1664.5229122222222),\n",
       "     (1573.7567138671875, 1597.162222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'e89c293baa2b79a65558c34a007ab85e',\n",
       "  'text': '[123]',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 1663.5816666666667),\n",
       "     (200.0, 1691.2555555555555),\n",
       "     (258.3088838888889, 1691.2555555555555),\n",
       "     (258.3088838888889, 1663.5816666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'db87bc8d07170452ea71ec9455c38d10',\n",
       "  'text': 'Songlin Yang, Bailin Wang, Yikang Shen, Rameswar Panda, and Yoon Kim. “Gated Linear Attention Transformers with Hardware-Efficient Training”. In: Forty-first International Conference on Machine Learning. 2024. url: https: //openreview.net/forum?id=ia5XvxFUJT.',\n",
       "  'metadata': {'detection_class_prob': 0.9332243800163269,\n",
       "   'coordinates': {'points': ((209.1600341796875, 1663.5816666666667),\n",
       "     (209.1600341796875, 1762.4874788888887),\n",
       "     (1574.3201904296875, 1762.4874788888887),\n",
       "     (1574.3201904296875, 1663.5816666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :',\n",
       "     'url': 'https://openreview.net/forum?id=ia5XvxFUJT',\n",
       "     'start_index': 459},\n",
       "    {'text': '// openreview . net / forum ? id = ia5XvxFUJT',\n",
       "     'url': 'https://openreview.net/forum?id=ia5XvxFUJT',\n",
       "     'start_index': 466}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '7e1b1ea188905d119dd3ebbce22f422a',\n",
       "  'text': '[124]',\n",
       "  'metadata': {'coordinates': {'points': ((200.00000000000009,\n",
       "      1763.2066666666667),\n",
       "     (200.00000000000009, 1790.8805555555555),\n",
       "     (258.30888388888894, 1790.8805555555555),\n",
       "     (258.30888388888894, 1763.2066666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '6431f5aae0a485d128848a448c6faf98',\n",
       "  'text': 'Songlin Yang, Bailin Wang, Yu Zhang, Yikang Shen, and Yoon Kim. “Parallelizing Linear Transformers with the Delta Rule over Sequence Length”. In: The Thirty-eighth Annual Conference on Neural Information Processing Systems. 2024. url: https://openreview.net/forum?id=y8Rm4VNRPH.',\n",
       "  'metadata': {'detection_class_prob': 0.9306691884994507,\n",
       "   'coordinates': {'points': ((212.37603759765625, 1763.2066666666667),\n",
       "     (212.37603759765625, 1862.1152566666665),\n",
       "     (1569.53076171875, 1862.1152566666665),\n",
       "     (1569.53076171875, 1763.2066666666667)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ? id = y8Rm4VNRPH',\n",
       "     'url': 'https://openreview.net/forum?id=y8Rm4VNRPH',\n",
       "     'start_index': 739}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '74385ec1817dc35c2f395b5be5423d4c',\n",
       "  'text': '[125] Luca Zancato, Arjun Seshadri, Yonatan Dukler, Aditya Golatkar, Yantao Shen, Benjamin Bowman, Matthew Trager, Alessandro Achille, and Stefano Soatto. “B’MOJO: Hybrid State Space Realizations of Foundation Models with Eidetic and Fading Memory”. In: The Thirty-eighth Annual Conference on Neural Information Processing Systems. 2024. url: https://openreview.net/forum?id=RnQdRY1h5v.',\n",
       "  'metadata': {'detection_class_prob': 0.9307580590248108,\n",
       "   'coordinates': {'points': ((200.0, 1862.8344444444444),\n",
       "     (200.0, 1994.94859),\n",
       "     (1570.2584228515625, 1994.94859),\n",
       "     (1570.2584228515625, 1862.8344444444444)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': 'https :// openreview . net / forum ? id = RnQdRY1h5v',\n",
       "     'url': 'https://openreview.net/forum?id=RnQdRY1h5v',\n",
       "     'start_index': 343}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '58c83ce7b8d1322d7f51ef040470ba63',\n",
       "  'text': '23',\n",
       "  'metadata': {'coordinates': {'points': ((867.1305555555555,\n",
       "      2057.7427777777775),\n",
       "     (867.1305555555555, 2085.4166666666665),\n",
       "     (892.8672722222221, 2085.4166666666665),\n",
       "     (892.8672722222221, 2057.7427777777775)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '0a021b55ca01d40b0d032fd83f6aebff',\n",
       "  'text': '[126] Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. “HellaSwag: Can a Machine Really Finish Your Sentence?” In: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Ed. by Anna Korhonen, David Traum, and Lluís Màrquez. Florence, Italy: Association for Computational Linguistics, July 2019, pp. 4791–4800. doi: 10.18653/v1/P19-1472. url: https://aclanthology.org/P19-1472/.',\n",
       "  'metadata': {'detection_class_prob': 0.919060468673706,\n",
       "   'coordinates': {'points': ((200.0, 202.39277777777778),\n",
       "     (200.0, 334.5097011111114),\n",
       "     (1563.8358154296875, 334.5097011111114),\n",
       "     (1563.8358154296875, 202.39277777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 24,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'f2b54fa93578f9ecbc9a243916b83cf6',\n",
       "  'text': '[127] Ailing Zeng, Muxi Chen, Lei Zhang, and Qiang Xu. “Are transformers effective for time series forecasting?” In: Proceedings of the AAAI conference on artificial intelligence. Vol. 37. 2023, pp. 11121–11128.',\n",
       "  'metadata': {'detection_class_prob': 0.8880152106285095,\n",
       "   'coordinates': {'points': ((199.99999999999983, 335.22888888888895),\n",
       "     (199.99999999999983, 403.1347961425781),\n",
       "     (1568.7403564453125, 403.1347961425781),\n",
       "     (1568.7403564453125, 335.22888888888895)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 24,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '781cf590e4c360c35f53f161d17bc0b6',\n",
       "  'text': '[128] Hao Zhang, Alexander C Berg, Michael Maire, and Jitendra Malik. “SVM-KNN: Discriminative nearest neighbor classification for visual category recognition”. In: 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’06). Vol. 2. IEEE. 2006, pp. 2126–2136.',\n",
       "  'metadata': {'detection_class_prob': 0.9237822890281677,\n",
       "   'coordinates': {'points': ((200.0, 401.6455555555555),\n",
       "     (200.0, 502.21457888888904),\n",
       "     (1570.148193359375, 502.21457888888904),\n",
       "     (1570.148193359375, 401.6455555555555)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 24,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '7d83a2ccdcf6fc41a9353242cd58a2ad',\n",
       "  'text': '[129] Jianyu Zhang, Niklas Nolte, Ranajoy Sadhukhan, Beidi Chen, and Léon Bottou. “Memory Mosaics”. In: arXiv preprint arXiv:2405.06394 (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.8927627205848694,\n",
       "   'coordinates': {'points': ((200.0, 501.2733333333336),\n",
       "     (200.0, 568.6312455555556),\n",
       "     (1563.6253662109375, 568.6312455555556),\n",
       "     (1563.6253662109375, 501.2733333333336)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 24,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'e97b974d36429ad957fe79dcb32e376f',\n",
       "  'text': '[130] Yunhao Zhang and Junchi Yan. “Crossformer: Transformer utilizing cross-dimension dependency for multivariate time series forecasting”. In: The eleventh international conference on learning representations. 2023.',\n",
       "  'metadata': {'detection_class_prob': 0.800880491733551,\n",
       "   'coordinates': {'points': ((200.0, 567.6900000000002),\n",
       "     (200.0, 635.0479122222222),\n",
       "     (1567.3720703125, 635.0479122222222),\n",
       "     (1567.3720703125, 567.6900000000002)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 24,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '48521c4d4a240b4caec9abcf9bd2723e',\n",
       "  'text': '[131] Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang. “Informer: Beyond efficient transformer for long sequence time-series forecasting”. In: Proceedings of the AAAI conference on artificial intelligence. Vol. 35. 12. 2021, pp. 11106–11115.',\n",
       "  'metadata': {'detection_class_prob': 0.921810507774353,\n",
       "   'coordinates': {'points': ((200.0, 634.1094444444444),\n",
       "     (200.0, 734.6756900000003),\n",
       "     (1575.0091552734375, 734.6756900000003),\n",
       "     (1575.0091552734375, 634.1094444444444)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 24,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '31b3abcc69f4eed2943e61908a2eb766',\n",
       "  'text': '[132] Luisa Zintgraf, Kyriacos Shiarli, Vitaly Kurin, Katja Hofmann, and Shimon Whiteson. “Fast context adaptation via meta-learning”. In: International Conference on Machine Learning. PMLR. 2019, pp. 7693–7702.',\n",
       "  'metadata': {'detection_class_prob': 0.9019168615341187,\n",
       "   'coordinates': {'points': ((198.49061584472656, 733.7344444444444),\n",
       "     (198.49061584472656, 801.0923566666667),\n",
       "     (1561.7681884765625, 801.0923566666667),\n",
       "     (1561.7681884765625, 733.7344444444444)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 24,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'f38df2c3daecdcadc18337bc2c908bf2',\n",
       "  'text': '24',\n",
       "  'metadata': {'coordinates': {'points': ((867.1305555555555,\n",
       "      2057.742777777778),\n",
       "     (867.1305555555555, 2085.4166666666665),\n",
       "     (892.8672722222221, 2085.4166666666665),\n",
       "     (892.8672722222221, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 24,\n",
       "   'parent_id': '867642d9def453fac13e17c0debc3ad1',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'a23c743a726a422fba0de2e7e95fb90a',\n",
       "  'text': 'A Related Work',\n",
       "  'metadata': {'detection_class_prob': 0.8510819673538208,\n",
       "   'coordinates': {'points': ((200.0, 197.47247314453125),\n",
       "     (200.0, 240.04158944444433),\n",
       "     (519.9432373046875, 240.04158944444433),\n",
       "     (519.9432373046875, 197.47247314453125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 25,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '968bb32d2db2548a4cf8d400e6289e9e',\n",
       "  'text': 'There are diverse perspectives that can independently lead to the design of Titans or its components. Accordingly, to further situate our work in a broader context, we review three categories of studies:',\n",
       "  'metadata': {'detection_class_prob': 0.9304509162902832,\n",
       "   'coordinates': {'points': ((199.16944444444442, 263.6788888888889),\n",
       "     (199.16944444444442, 329.7239685058594),\n",
       "     (1561.053955078125, 329.7239685058594),\n",
       "     (1561.053955078125, 263.6788888888889)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 25,\n",
       "   'parent_id': 'a23c743a726a422fba0de2e7e95fb90a',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'bf7b60f80dca3dfad259e622ba633f23',\n",
       "  'text': 'A.1 Linear Recurrent Models',\n",
       "  'metadata': {'detection_class_prob': 0.8645645380020142,\n",
       "   'coordinates': {'points': ((200.0, 376.1134033203125),\n",
       "     (200.0, 409.56014222222194),\n",
       "     (660.622802734375, 409.56014222222194),\n",
       "     (660.622802734375, 376.1134033203125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 25,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '7249416ce2a4e7e59b72ba9701d8636a',\n",
       "  'text': 'Recently, to address the computational cost of Transformers in both training and inference, linear recurrent models have attracted much attention (Tiezzi et al. 2024), mainly due to their fast inference and training. The first generation of models–such as RetNet (Yutao Sun et al. 2023), LRU (Orvieto et al. 2023), RWKV (Peng, Alcaide, et al. 2023), S5 (J. T. Smith, Warrington, and Linderman 2023), and S4 (Gu, Goel, and Re 2022)–uses data-independent transition matrix/decay mechanism. The second generation of such models started to incorporate gating mechanism, a widely used techniques in traditional RNNs (Gers, Jürgen Schmidhuber, and Cummins 2000; Greff et al. 2016; Van Der Westhuizen and Lasenby 2018), into such linear architectures–e.g., Griffin (De et al. 2024), SSMs (Behrouz, Santacatterina, and Zabih 2024; Dao and Gu 2024; Gu and Dao 2024; Hasani et al. 2023), RWKV6 (Peng, Goldstein, et al. 2024). The third generation of linear recurrent models are based on more complex memory updating rule based on meta-learning, online learning, and/or delta-rule, resulting in more expressive and effective models such as: Longhorn (B. Liu et al. 2024), Gated DeltaNet (S. Yang, Kautz, and Hatamizadeh 2024), TTT (Yu Sun et al. 2024), and DeltaNet (S. Yang, B. Wang, Yu Zhang, et al. 2024). Our LMM model can be seen as the next generation of such models, in which we incorporate the token flow into the memory updating mechanism, having more powerful memory updating process. See Appendix C for a detailed discussion of different recurrent models and Titans.',\n",
       "  'metadata': {'detection_class_prob': 0.9524243474006653,\n",
       "   'coordinates': {'points': ((200.0, 425.2316666666669),\n",
       "     (200.0, 887.6248779296875),\n",
       "     (1564.256858366666, 887.6248779296875),\n",
       "     (1564.256858366666, 425.2316666666669)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@tiezzi2024resurgence',\n",
       "     'start_index': 189},\n",
       "    {'text': '2023', 'url': 'cite.0@sun2023retentive', 'start_index': 308},\n",
       "    {'text': '2023',\n",
       "     'url': 'cite.0@orvieto2023resurrecting',\n",
       "     'start_index': 335},\n",
       "    {'text': '2023', 'url': 'cite.0@peng2023rwkv', 'start_index': 370},\n",
       "    {'text': '2023', 'url': 'cite.0@smith2023simplified', 'start_index': 420},\n",
       "    {'text': '2022', 'url': 'cite.0@gu2022efficiently', 'start_index': 452},\n",
       "    {'text': '2000', 'url': 'cite.0@gers2000learning', 'start_index': 677},\n",
       "    {'text': '2016', 'url': 'cite.0@greff2016lstm', 'start_index': 695},\n",
       "    {'text': '2018', 'url': 'cite.0@van2018unreasonable', 'start_index': 732},\n",
       "    {'text': '2024', 'url': 'cite.0@de2024griffin', 'start_index': 793},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@behrouz2024mambamixer',\n",
       "     'start_index': 841},\n",
       "    {'text': '2024', 'url': 'cite.0@dao2024transformers', 'start_index': 858},\n",
       "    {'text': '2024', 'url': 'cite.0@gu2024mamba', 'start_index': 875},\n",
       "    {'text': '2023', 'url': 'cite.0@hasani2023liquid', 'start_index': 895},\n",
       "    {'text': '2024', 'url': 'cite.0@peng2024eagle', 'start_index': 933},\n",
       "    {'text': '2024', 'url': 'cite.0@liu2024longhorn', 'start_index': 1177},\n",
       "    {'text': '2024', 'url': 'cite.0@yang2024gated', 'start_index': 1232},\n",
       "    {'text': '2024', 'url': 'cite.0@sun2024learning', 'start_index': 1258},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@yang2024parallelizing',\n",
       "     'start_index': 1314},\n",
       "    {'text': 'Appendix C', 'url': 'appendix.C', 'start_index': 1510}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 25,\n",
       "   'parent_id': 'bf7b60f80dca3dfad259e622ba633f23',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '18e700de39e52656c3412939258d07fc',\n",
       "  'text': 'A.2 Transformer-based Architectures',\n",
       "  'metadata': {'detection_class_prob': 0.8608254790306091,\n",
       "   'coordinates': {'points': ((196.95957946777344, 933.9984130859375),\n",
       "     (196.95957946777344, 969.6184755555557),\n",
       "     (789.4044189453125, 969.6184755555557),\n",
       "     (789.4044189453125, 933.9984130859375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 25,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '9bbaf1b7078c6de81070943bfc7c1dca',\n",
       "  'text': 'Transformers. Transformers (Vaswani et al. 2017) as the de facto backbone for many deep learning models are based on attention mechanism (Bahdanau 2014). They, however, suffer from quadratic computational cost, limiting their ability to scale to long context window. To improve the memory consumption and throughput of softmax attention for longer sequences, various studies focused on I/O aware implementations of attention (Dao 2024; Dao, D. Fu, et al. 2022), designing more efficient attention mechanisms by sparsifying the attention matrix (B. Chen et al. 2021; Choromanski et al. 2021; Dai et al. 2019; J. Dong et al. 2024; Roy et al. 2021), approximating the softmax (Arora et al. 2024), or developing kernel-based (linear) attentions (Aksenov et al. 2024; Kacham, Mirrokni, and P. Zhong 2024; Schlag, Irie, and Jürgen Schmidhuber 2021; S. Yang, B. Wang, Shen, et al. 2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9554130434989929,\n",
       "   'coordinates': {'points': ((199.0861111111111, 998.676111111111),\n",
       "     (199.0861111111111, 1263.0526123046875),\n",
       "     (1569.68017578125, 1263.0526123046875),\n",
       "     (1569.68017578125, 998.676111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2017', 'url': 'cite.0@transformers', 'start_index': 43},\n",
       "    {'text': '2014', 'url': 'cite.0@bahdanau2014neural', 'start_index': 147},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@dao2024flashattention',\n",
       "     'start_index': 429},\n",
       "    {'text': '2022', 'url': 'cite.0@flashattention-1', 'start_index': 454},\n",
       "    {'text': '2021', 'url': 'cite.0@chen2021scatterbrain', 'start_index': 557},\n",
       "    {'text': '2021',\n",
       "     'url': 'cite.0@choromanski2021rethinking',\n",
       "     'start_index': 582},\n",
       "    {'text': '2019', 'url': 'cite.0@dai2019transformerxl', 'start_index': 599},\n",
       "    {'text': '2024', 'url': 'cite.0@dong2024flex', 'start_index': 620},\n",
       "    {'text': '2021', 'url': 'cite.0@roy2021efficient', 'start_index': 637},\n",
       "    {'text': '2024', 'url': 'cite.0@arora2024simple', 'start_index': 684},\n",
       "    {'text': '2024', 'url': 'cite.0@aksenov2024linear', 'start_index': 754},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@kacham2024polysketchformer',\n",
       "     'start_index': 791},\n",
       "    {'text': '2021', 'url': 'cite.0@schlag2021linear', 'start_index': 834}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 25,\n",
       "   'parent_id': '18e700de39e52656c3412939258d07fc',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '32605ca2e3191eb119f920d2c0620054',\n",
       "  'text': 'Segment-based Transformers. Another line of research to improve the efficiency of Transformers is segment-based or Chunk Transformers (Dai et al. 2019). The main drawback of chunk Transformers is that segments are fully separated and so the context window is limited to the length of the chunks. To address this issue, various studies discuss the importance of a memory so it can help the model to transfer information across chunks (Bulatov, Yuri Kuratov, et al. 2023; Bulatov, Yury Kuratov, and Burtsev 2022; Feng et al. 2022; Hutchins et al. 2022; Rodkin et al. 2024; Z. Wang et al. 2019; Q. Wu et al. 2020; Zancato et al. 2024). The key differences of Titans with these models are: (1) The memory in such models are simple small size vectors, lacking expressive power to compress complex information; (2) The memory module lacks forget mechanism, leading to a fast memory overflow; (3) only focus on momentary surprise, missing the information flow. More specifically, recalling Recurrent Memory Transformers (RMT) (Bulatov, Yuri Kuratov, et al. 2023; Bulatov, Yury Kuratov, and Burtsev 2022; Rodkin et al. 2024), one can treat Titans (MAC) as the generalization of RMT, where we use a neural memory module instead of a vector-valued small size memory.',\n",
       "  'metadata': {'detection_class_prob': 0.9546858072280884,\n",
       "   'coordinates': {'points': ((199.19722222222222, 1294.3372222222222),\n",
       "     (199.19722222222222, 1660.6866455078125),\n",
       "     (1563.750732421875, 1660.6866455078125),\n",
       "     (1563.750732421875, 1294.3372222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2019',\n",
       "     'url': 'cite.0@dai2019transformerxl',\n",
       "     'start_index': 144},\n",
       "    {'text': '2023', 'url': 'cite.0@bulatov2023scaling', 'start_index': 462},\n",
       "    {'text': '2022', 'url': 'cite.0@bulatov2022recurrent', 'start_index': 503},\n",
       "    {'text': '2022', 'url': 'cite.0@feng2022learn', 'start_index': 521},\n",
       "    {'text': '2022', 'url': 'cite.0@hutchins2022block', 'start_index': 543},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@rodkin2024associative',\n",
       "     'start_index': 563},\n",
       "    {'text': '2019', 'url': 'cite.0@wang2019r', 'start_index': 584},\n",
       "    {'text': '2020', 'url': 'cite.0@wu2020memformer', 'start_index': 603},\n",
       "    {'text': '2024', 'url': 'cite.0@zancato2024bmojo', 'start_index': 624},\n",
       "    {'text': '2023', 'url': 'cite.0@bulatov2023scaling', 'start_index': 1044},\n",
       "    {'text': '2022',\n",
       "     'url': 'cite.0@bulatov2022recurrent',\n",
       "     'start_index': 1085},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@rodkin2024associative',\n",
       "     'start_index': 1105}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 25,\n",
       "   'parent_id': '18e700de39e52656c3412939258d07fc',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '41905710e4b87601e969518d3d416c72',\n",
       "  'text': 'Memory for Large Language Models. Another interesting research direction has been to incorporate external memory modules to LLMs after training (Z. He et al. 2024; Khandelwal et al. 2020; Y. Wang, Y. Gao, et al. 2024). Such models are different from our approach as we incorporate the memory as a part of initial architecture and so we train it in an end-to-end manner. Also, most of these explicit memory modules suffer from the same limitations as chunk-based Transformers (mentioned above). For a detailed discussion of such models, we refer to the recent study of Y. Wang, Han, et al. (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9520406126976013,\n",
       "   'coordinates': {'points': ((199.16944444444442, 1689.6233333333334),\n",
       "     (199.16944444444442, 1887.388916015625),\n",
       "     (1564.5279541015625, 1887.388916015625),\n",
       "     (1564.5279541015625, 1689.6233333333334)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@he2024camelot',\n",
       "     'start_index': 158},\n",
       "    {'text': '2020',\n",
       "     'url': 'cite.0@Khandelwal2020Generalization',\n",
       "     'start_index': 182},\n",
       "    {'text': '2024', 'url': 'cite.0@wang2024memoryllm', 'start_index': 212}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 25,\n",
       "   'parent_id': '18e700de39e52656c3412939258d07fc',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '6f201ce7215051f26bd1649cd4cc2f13',\n",
       "  'text': '25',\n",
       "  'metadata': {'coordinates': {'points': ((867.1305555555556,\n",
       "      2057.742777777778),\n",
       "     (867.1305555555556, 2085.4166666666665),\n",
       "     (892.8672722222223, 2085.4166666666665),\n",
       "     (892.8672722222223, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 25,\n",
       "   'parent_id': '18e700de39e52656c3412939258d07fc',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'ec73933ac8248ef90145a62a83535713',\n",
       "  'text': 'A.3 Test Time Training and Fast Weight Programs',\n",
       "  'metadata': {'detection_class_prob': 0.8472745418548584,\n",
       "   'coordinates': {'points': ((199.34396362304688, 204.5290311111109),\n",
       "     (199.34396362304688, 237.7632598876953),\n",
       "     (981.28759765625, 237.7632598876953),\n",
       "     (981.28759765625, 204.5290311111109)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 26,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'bfa8a390148606502d4a07bb2816ec46',\n",
       "  'text': 'Memory Design and Augmentation with Memory. In the literature, a substantial research effort have been toward designing memory modules that are capable of either memorizing the knowledge abstraction (e.g., persistent mem- ory) (Sukhbaatar, Grave, et al. 2019), or memorizing the data-dependent information (also known as contextual memory), through recurrence (Bulatov, Yury Kuratov, and Burtsev 2022; Rodkin et al. 2024; Zancato et al. 2024), Transformers (Berges et al. 2024; Cetin et al. 2024; Feng et al. 2022; Le, Tran, and Venkatesh 2020; Munkhdalai, Faruqui, and Gopal 2024; J. Zhang et al. 2024), gradient (Irie, Csordás, and Jürgen Schmidhuber 2022; Munkhdalai, Sordoni, et al. 2019), or other learning paradigms (Sukhbaatar, Weston, Fergus, et al. 2015; Weston, Chopra, and Bordes 2014). These memory models, however, either (1) are based on momentary surprise, missing the data flow and events, (2) lack forget mechanisms to remove the memory, leading to a fast memory overflow (3) are fixed-size shallow (matrix valued) memory, resulting in poor performance in long context, and (4) are based on fixed parameters at test time, lacking test time adaption.',\n",
       "  'metadata': {'detection_class_prob': 0.9551926255226135,\n",
       "   'coordinates': {'points': ((200.0, 266.7955555555557),\n",
       "     (200.0, 600.5435180664062),\n",
       "     (1570.71240234375, 600.5435180664062),\n",
       "     (1570.71240234375, 266.7955555555557)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2019',\n",
       "     'url': 'cite.0@sukhbaatar2019augmenting',\n",
       "     'start_index': 253},\n",
       "    {'text': '2022', 'url': 'cite.0@bulatov2022recurrent', 'start_index': 395},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@rodkin2024associative',\n",
       "     'start_index': 415},\n",
       "    {'text': '2024', 'url': 'cite.0@zancato2024bmojo', 'start_index': 436},\n",
       "    {'text': '2024', 'url': 'cite.0@berges2024memory', 'start_index': 471},\n",
       "    {'text': '2024', 'url': 'cite.0@cetin2024evolved', 'start_index': 490},\n",
       "    {'text': '2022', 'url': 'cite.0@feng2022learn', 'start_index': 508},\n",
       "    {'text': '2020', 'url': 'cite.0@le2020self', 'start_index': 538},\n",
       "    {'text': '2024', 'url': 'cite.0@munkhdalai2024leave', 'start_index': 575},\n",
       "    {'text': '2024', 'url': 'cite.0@zhang2024memory', 'start_index': 597},\n",
       "    {'text': '2022', 'url': 'cite.0@irie2022dual', 'start_index': 652},\n",
       "    {'text': '2019',\n",
       "     'url': 'cite.0@munkhdalai2019metalearned',\n",
       "     'start_index': 686},\n",
       "    {'text': '2015', 'url': 'cite.0@sukhbaatar2015end', 'start_index': 757},\n",
       "    {'text': '2014', 'url': 'cite.0@weston2014memory', 'start_index': 790}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 26,\n",
       "   'parent_id': 'ec73933ac8248ef90145a62a83535713',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'd2059827adc00ad43ae783f7089239c4',\n",
       "  'text': 'Fast Weight Programs. The idea of seeing linear layers as the key-value (associative) memory system backs to fast weight programs, in which dynamic fast programs are incorporated into recurrent neural networks to serve as writable memory (Schlag, Irie, and Jürgen Schmidhuber 2021; JH Schmidhuber 1992; Jürgen Schmidhuber 1993). The two learning rules of Hebbian (Hebb 2005) and delta (Prados and Kak 1989) are the most popular learning rules for fast weight programs, which have been extensively explored in various studies (Irie, Schlag, et al. 2021; Munkhdalai, Sordoni, et al. 2019; Munkhdalai and H. Yu 2017; Schlag, Irie, and Jürgen Schmidhuber 2021; JH Schmidhuber 1992; S. Yang, Kautz, and Hatamizadeh 2024; S. Yang, B. Wang, Yu Zhang, et al. 2024). All these models, however, are based on momentary surprise, missing the token flow in the sequences (see Section 3.1), and most of them lacks a forgetting gate, resulting in a poor memory management.',\n",
       "  'metadata': {'detection_class_prob': 0.9537719488143921,\n",
       "   'coordinates': {'points': ((198.975, 628.8761111111111),\n",
       "     (198.975, 926.1392822265625),\n",
       "     (1566.78955078125, 926.1392822265625),\n",
       "     (1566.78955078125, 628.8761111111111)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2021',\n",
       "     'url': 'cite.0@schlag2021linear',\n",
       "     'start_index': 276},\n",
       "    {'text': '1992',\n",
       "     'url': 'cite.0@schmidhuber1992learning',\n",
       "     'start_index': 297},\n",
       "    {'text': '1993',\n",
       "     'url': 'cite.0@schmidhuber1993reducing',\n",
       "     'start_index': 322},\n",
       "    {'text': '2005', 'url': 'cite.0@hebb2005organization', 'start_index': 369},\n",
       "    {'text': '1989', 'url': 'cite.0@prados1989neural', 'start_index': 401},\n",
       "    {'text': '2021', 'url': 'cite.0@irie2021going', 'start_index': 547},\n",
       "    {'text': '2019',\n",
       "     'url': 'cite.0@munkhdalai2019metalearned',\n",
       "     'start_index': 581},\n",
       "    {'text': '2017', 'url': 'cite.0@munkhdalai2017neural', 'start_index': 608},\n",
       "    {'text': '2021', 'url': 'cite.0@schlag2021linear', 'start_index': 651},\n",
       "    {'text': '1992',\n",
       "     'url': 'cite.0@schmidhuber1992learning',\n",
       "     'start_index': 672},\n",
       "    {'text': '2024', 'url': 'cite.0@yang2024gated', 'start_index': 710},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@yang2024parallelizing',\n",
       "     'start_index': 751},\n",
       "    {'text': 'Section 3 . 1', 'url': 'subsection.3.1', 'start_index': 862}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 26,\n",
       "   'parent_id': 'ec73933ac8248ef90145a62a83535713',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '4e0465ef94883879fa17c61398678e1e',\n",
       "  'text': 'Test Time Training. The key ideas of learning at test time or learning to learn (i.e., (Andrychowicz et al. 2016)) backs to very early studies on local learning Bottou and Vapnik 1992, in which each test data sample is trained on its neighbors before making a prediction (Gandelsman et al. 2022; H. Zhang et al. 2006). This approach further has shown promising performance in vision tasks (Jain and Learned-Miller 2011; Mullapudi et al. 2019), mostly due to their ability to mitigate out-of-distribution samples. The most similar studies to ours in this direction are MNM (Munkhdalai, Sordoni, et al. 2019) and TTT-layer (Yu Sun et al. 2024), which we discussed the key differences in Appendix C.',\n",
       "  'metadata': {'detection_class_prob': 0.9524902701377869,\n",
       "   'coordinates': {'points': ((199.0861111111111, 957.7455555555555),\n",
       "     (199.0861111111111, 1157.6739501953125),\n",
       "     (1566.9964599609375, 1157.6739501953125),\n",
       "     (1566.9964599609375, 957.7455555555555)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2016',\n",
       "     'url': 'cite.0@andrychowicz2016learning',\n",
       "     'start_index': 108},\n",
       "    {'text': '1992', 'url': 'cite.0@bottou1992local', 'start_index': 179},\n",
       "    {'text': '2022', 'url': 'cite.0@gandelsman2022test', 'start_index': 290},\n",
       "    {'text': '2006', 'url': 'cite.0@zhang2006svm', 'start_index': 312},\n",
       "    {'text': '2011', 'url': 'cite.0@jain2011online', 'start_index': 414},\n",
       "    {'text': '2019', 'url': 'cite.0@mullapudi2019online', 'start_index': 437},\n",
       "    {'text': '2019',\n",
       "     'url': 'cite.0@munkhdalai2019metalearned',\n",
       "     'start_index': 601}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 26,\n",
       "   'parent_id': 'ec73933ac8248ef90145a62a83535713',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '6baac9157846f5af0f64d63c9b2f1507',\n",
       "  'text': 'B Language Modeling and Common-sense Reasoning Datasets',\n",
       "  'metadata': {'detection_class_prob': 0.853956401348114,\n",
       "   'coordinates': {'points': ((197.41592407226562, 1210.8538818359375),\n",
       "     (197.41592407226562, 1251.2221450000002),\n",
       "     (1348.5328616666666, 1251.2221450000002),\n",
       "     (1348.5328616666666, 1210.8538818359375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 26,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'f6c113293be5734cca3b2c24402b779e',\n",
       "  'text': 'Following recent studies on linear recurrent models (Dao and Gu 2024; S. Yang, Kautz, and Hatamizadeh 2024; S. Yang, B. Wang, Yu Zhang, et al. 2024), we use Wikitext (Merity et al. 2017), LMB (Paperno et al. 2016), PIQA (Bisk et al. 2020), HellaSwag (Zellers et al. 2019), WinoGrande (Sakaguchi et al. 2021), ARC-easy (ARC-e) and ARC-challenge (ARC-c) (P. Clark et al. 2018), SIQA (Sap et al. 2019), and BoolQ (C. Clark et al. 2019). Also, the baselines results for 400M models are from the reported results by S. Yang, Kautz, and Hatamizadeh (2024).',\n",
       "  'metadata': {'detection_class_prob': 0.9474785923957825,\n",
       "   'coordinates': {'points': ((200.0, 1274.8566666666666),\n",
       "     (200.0, 1441.7156982421875),\n",
       "     (1572.387939453125, 1441.7156982421875),\n",
       "     (1572.387939453125, 1274.8566666666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@dao2024transformers',\n",
       "     'start_index': 64},\n",
       "    {'text': '2024', 'url': 'cite.0@yang2024gated', 'start_index': 102},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@yang2024parallelizing',\n",
       "     'start_index': 143},\n",
       "    {'text': '2017', 'url': 'cite.0@merity2017pointer', 'start_index': 181},\n",
       "    {'text': '2016',\n",
       "     'url': 'cite.0@paperno-etal-2016-lambada',\n",
       "     'start_index': 208},\n",
       "    {'text': '2020', 'url': 'cite.0@bisk2020piqa', 'start_index': 233},\n",
       "    {'text': '2019',\n",
       "     'url': 'cite.0@zellers-etal-2019-hellaswag',\n",
       "     'start_index': 266},\n",
       "    {'text': '2021',\n",
       "     'url': 'cite.0@sakaguchi2021winogrande',\n",
       "     'start_index': 302},\n",
       "    {'text': '2018', 'url': 'cite.0@clark2018think', 'start_index': 369},\n",
       "    {'text': '2019', 'url': 'cite.0@sap-etal-2019-social', 'start_index': 393},\n",
       "    {'text': '2019',\n",
       "     'url': 'cite.0@clark-etal-2019-boolq',\n",
       "     'start_index': 427}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 26,\n",
       "   'parent_id': '6baac9157846f5af0f64d63c9b2f1507',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '32ac3d76b7ae279024a642d3b256783a',\n",
       "  'text': 'C Long-term Memory Module (LMM) as a Sequence Model',\n",
       "  'metadata': {'detection_class_prob': 0.8558773398399353,\n",
       "   'coordinates': {'points': ((196.16053771972656, 1492.846923828125),\n",
       "     (196.16053771972656, 1535.1249227777778),\n",
       "     (1277.3179931640625, 1535.1249227777778),\n",
       "     (1277.3179931640625, 1492.846923828125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 26,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '09feebb366635492ba65a549f2b9514e',\n",
       "  'text': 'In this section, we discuss how LMM as a sequence model is connected to modern linear recurrent models. For the sake of simplicity, we start with a linear memory, where M𝑡 = 𝑊𝑡 ∈ R𝑑in ×𝑑in. In this case, our objective function becomes 2 ∥M𝑡 k𝑡 − v𝑡 ∥2 ℓ (M; 𝑥𝑡 ) = 1 2, in which we use gradient descent with momentum and weight decay for the optimization. Accordingly, revisiting the recurrent formula in Equation 13:',\n",
       "  'metadata': {'detection_class_prob': 0.9411402344703674,\n",
       "   'coordinates': {'points': ((199.03055555555554, 1558.7594444444444),\n",
       "     (199.03055555555554, 1690.577880859375),\n",
       "     (1565.9735107421875, 1690.577880859375),\n",
       "     (1565.9735107421875, 1558.7594444444444)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 26,\n",
       "   'parent_id': '32ac3d76b7ae279024a642d3b256783a',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': 'a95f6335e637528682c8dba5a90464a2',\n",
       "  'text': 'M; = diag (1 - a7) Mr + St (32) S; = diag (y;) S;-1 — diag (@;) (Mi-1k; ke - v; k;) : (33)',\n",
       "  'metadata': {'detection_class_prob': 0.5204486846923828,\n",
       "   'coordinates': {'points': ((572.2598266601562, 1714.537222222222),\n",
       "     (572.2598266601562, 1795.898193359375),\n",
       "     (1575.0819091796875, 1795.898193359375),\n",
       "     (1575.0819091796875, 1714.537222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 26,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '6582d45cf6262e5a5d94c3d8f3526d44',\n",
       "  'text': 'LMM is Generalized Gated DeltaNet. As discussed by S. Yang, Kautz, and Hatamizadeh (2024), DeltaNet (S. Yang, B. Wang, Yu Zhang, et al. 2024) can alternatively be interpreted as an online learning problem that optimizes the L = 1 2 ∥S𝑡 k𝑡 − v𝑡 ∥2 resulting in: 2,',\n",
       "  'metadata': {'detection_class_prob': 0.9331384897232056,\n",
       "   'coordinates': {'points': ((199.19722222222222, 1842.1899999999998),\n",
       "     (199.19722222222222, 1940.8453369140625),\n",
       "     (1565.67138671875, 1940.8453369140625),\n",
       "     (1565.67138671875, 1842.1899999999998)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@yang2024gated',\n",
       "     'start_index': 84},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@yang2024parallelizing',\n",
       "     'start_index': 153}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 26,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': '24efa924e2b1dd73f671bc9d5039b668',\n",
       "  'text': 'Set = Sr — VL = 8, (I= Okyk7) + Orvik? (34)',\n",
       "  'metadata': {'detection_class_prob': 0.6225360631942749,\n",
       "   'coordinates': {'points': ((624.261474609375, 1960.5986422222222),\n",
       "     (624.261474609375, 1999.6540288888887),\n",
       "     (1565.1314697265625, 1999.6540288888887),\n",
       "     (1565.1314697265625, 1960.5986422222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 26,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'bd3dcb116b070fb8a64c1eca73db0c74',\n",
       "  'text': '26',\n",
       "  'metadata': {'coordinates': {'points': ((867.1333333333337,\n",
       "      2057.742777777778),\n",
       "     (867.1333333333337, 2085.4166666666665),\n",
       "     (892.8700500000003, 2085.4166666666665),\n",
       "     (892.8700500000003, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 26,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '78ae709687459196a381cf539188994e',\n",
       "  'text': 'In this formulation, Gated DeltaNet is the same as above but with an additional weight decay term (S. Yang, Kautz, and',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 202.39277777777778),\n",
       "     (200.0, 230.06666666666652),\n",
       "     (1560.0130675055548, 230.06666666666652),\n",
       "     (1560.0130675055548, 202.39277777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '5cf6298129b1c1ef01ebcc27a4b73c38',\n",
       "  'text': 'Hatamizadeh 2024). Comparing Equation 32 and Equation 34, we can see that setting 𝜂𝑡 = 0 results in both formulations to be equivalent. Accordingly, we can say LMM is generalizing the very recent study of Gated DeltaNet (S. Yang, Kautz, and Hatamizadeh 2024) from three aspects:',\n",
       "  'metadata': {'detection_class_prob': 0.941305935382843,\n",
       "   'coordinates': {'points': ((200.0, 210.97552490234375),\n",
       "     (200.0, 333.3111267089844),\n",
       "     (1565.7769775390625, 333.3111267089844),\n",
       "     (1565.7769775390625, 210.97552490234375)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@yang2024gated',\n",
       "     'start_index': 131},\n",
       "    {'text': 'Equation 32', 'url': 'equation.C.32', 'start_index': 148},\n",
       "    {'text': 'Equation 34', 'url': 'equation.C.34', 'start_index': 164}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'ed7ca0d9e3715ab208d85958f907811c',\n",
       "  'text': 'Momentum-based Rule: The Delta Rule is based on momentary surprise, meaning that the flow of tokens cannot',\n",
       "  'metadata': {'coordinates': {'points': ((245.63333333333333,\n",
       "      351.83444444444467),\n",
       "     (245.63333333333333, 379.50833333333344),\n",
       "     (1559.9992361888894, 379.50833333333344),\n",
       "     (1559.9992361888894, 351.83444444444467)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '4da181f7bcfa5dfd708e181d64e19e90',\n",
       "  'text': 'affect the memory update rule. LMM, however, is based on a momentum rule, which consider both past and momentary surprise.',\n",
       "  'metadata': {'detection_class_prob': 0.9354394674301147,\n",
       "   'coordinates': {'points': ((237.36114501953125, 359.3262939453125),\n",
       "     (237.36114501953125, 448.61663818359375),\n",
       "     (1559.9921547444444, 448.61663818359375),\n",
       "     (1559.9921547444444, 359.3262939453125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '220082fa41bf412f549e1494af238c03',\n",
       "  'text': 'Deep Memory: While Gated DeltaNet is limited to a linear (matrix-valued) memory as it requires finding the closed',\n",
       "  'metadata': {'coordinates': {'points': ((245.63333333333333,\n",
       "      468.0650000000001),\n",
       "     (245.63333333333333, 495.7388888888889),\n",
       "     (1559.9994068711108, 495.7388888888889),\n",
       "     (1559.9994068711108, 468.0650000000001)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '992fc0b5554dac11aae00bd9dff4e7d3',\n",
       "  'text': 'recurrence form, LMM allows using deep memory module by using a gradient-based formulation, resulting in higher expressive power.',\n",
       "  'metadata': {'detection_class_prob': 0.9363850355148315,\n",
       "   'coordinates': {'points': ((234.09703063964844, 475.3846130371094),\n",
       "     (234.09703063964844, 570.173095703125),\n",
       "     (1561.90869140625, 570.173095703125),\n",
       "     (1561.90869140625, 475.3846130371094)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '0de21ca84516b046828efa2a6cafd824',\n",
       "  'text': 'Non-Linear Recurrence: While DeltaNet and Gated DeltaNet are based on linear recurrence, our LMM is using',\n",
       "  'metadata': {'coordinates': {'points': ((245.63333333333333,\n",
       "      587.1455555555558),\n",
       "     (245.63333333333333, 614.8194444444446),\n",
       "     (1559.988638422222, 614.8194444444446),\n",
       "     (1559.988638422222, 587.1455555555558)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '5bd4ad88cbb062448ec7d1c0cc2fb49d',\n",
       "  'text': 'inter-chunk non-linear recurrence and intra-chunk linear recurrence. This design allows LMM having a higher expressive power.',\n",
       "  'metadata': {'detection_class_prob': 0.9349726438522339,\n",
       "   'coordinates': {'points': ((235.08010864257812, 595.0479125976562),\n",
       "     (235.08010864257812, 687.198486328125),\n",
       "     (1561.217041015625, 687.198486328125),\n",
       "     (1561.217041015625, 595.0479125976562)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'a9f1a3c18051cf2d70c6264765dbc620',\n",
       "  'text': 'Here, we discussed Gated DeltaNet as a sample of recent generation of recurrent models. Similar approaches such',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 703.3761111111112),\n",
       "     (200.0, 731.05),\n",
       "     (1559.9945260000002, 731.05),\n",
       "     (1559.9945260000002, 703.3761111111112)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '7bd9ee8117ce6c6673a00c7ad482da6d',\n",
       "  'text': 'as RWKV-7 (Peng 2021) are also using the same formulation and loss function, and so LMM is generalizing all such models.',\n",
       "  'metadata': {'detection_class_prob': 0.936514675617218,\n",
       "   'coordinates': {'points': ((200.0, 713.5591430664062),\n",
       "     (200.0, 801.0422973632812),\n",
       "     (1567.1929931640625, 801.0422973632812),\n",
       "     (1567.1929931640625, 713.5591430664062)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2021', 'url': 'cite.0@rwkv-repo', 'start_index': 128}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '35bf77d30b251d9ab2f255f6d30c1e3d',\n",
       "  'text': 'LMM is Generalized Longhorn. Similar to DeltaNet, Longhorn (B. Liu et al. 2024) uses the same loss function but it',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 832.9927777777776),\n",
       "     (200.0, 867.0593349999999),\n",
       "     (1559.987369888889, 867.0593349999999),\n",
       "     (1559.987369888889, 832.9927777777776)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@liu2024longhorn',\n",
       "     'start_index': 74}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '658e096dd210ea10fdda172c4066d86a',\n",
       "  'text': 'derives the closed form using implicit online learning:',\n",
       "  'metadata': {'detection_class_prob': 0.9248551726341248,\n",
       "   'coordinates': {'points': ((200.0, 841.6473388671875),\n",
       "     (200.0, 899.4852905273438),\n",
       "     (1563.770751953125, 899.4852905273438),\n",
       "     (1563.770751953125, 841.6473388671875)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@liu2024longhorn',\n",
       "     'start_index': 74}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Formula',\n",
       "  'element_id': 'e994aadc3f817e392c781daca9b58aa0',\n",
       "  'text': 'Seat = Sp (I= dykek}) + Syvek7, (35)',\n",
       "  'metadata': {'detection_class_prob': 0.6339044570922852,\n",
       "   'coordinates': {'points': ((702.9913940429688, 922.9264200000001),\n",
       "     (702.9913940429688, 961.9790288888889),\n",
       "     (1561.6609099999998, 961.9790288888889),\n",
       "     (1561.6609099999998, 922.9264200000001)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'fe41073bb92f243b8d5a49535b837b5b',\n",
       "  'text': '𝜃𝑡',\n",
       "  'metadata': {'coordinates': {'points': ((363.5694444444444, 989.4258325),\n",
       "     (363.5694444444444, 1012.6035402777778),\n",
       "     (380.32288472222217, 1012.6035402777778),\n",
       "     (380.32288472222217, 989.4258325)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '29e6c92d2c0cf8bae359ed4de31cd9ce',\n",
       "  'text': 'where 𝛿𝑡 =',\n",
       "  'metadata': {'coordinates': {'points': ((198.975, 994.2816666666666),\n",
       "     (198.975, 1026.8538338888889),\n",
       "     (321.97460888888884, 1026.8538338888889),\n",
       "     (321.97460888888884, 994.2816666666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '4044a13f88ce78c34eada79de7739236',\n",
       "  'text': '. It, however, lacks a forgetting gate, resulting in a faster memory overflow. Therefore, in addition two',\n",
       "  'metadata': {'coordinates': {'points': ((418.0777777777778,\n",
       "      994.2816666666666),\n",
       "     (418.0777777777778, 1021.9555555555555),\n",
       "     (1559.9870600855552, 1021.9555555555555),\n",
       "     (1559.9870600855552, 994.2816666666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'parent_id': '29e6c92d2c0cf8bae359ed4de31cd9ce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'a8177a33e509ff18b41a112a042a8df4',\n",
       "  'text': '1+𝜃𝑡 k𝑡 k⊤ 𝑡 the abovementioned aspects of (1) Momentum-based Rule, (2) Deep Memory, and (3) Non-Linear Recurrence, LMM has the advantage of using an additional (4) Forget Gate, leading to a better memory management.',\n",
       "  'metadata': {'detection_class_prob': 0.9326969981193542,\n",
       "   'coordinates': {'points': ((200.0, 1002.7481689453125),\n",
       "     (200.0, 1102.04638671875),\n",
       "     (1565.3812255859375, 1102.04638671875),\n",
       "     (1565.3812255859375, 1002.7481689453125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'parent_id': '29e6c92d2c0cf8bae359ed4de31cd9ce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e8107652f3dbb2f7af129f361f45c68d',\n",
       "  'text': 'LMM is Generalized TTT Layer. To the best of our knowledge, TTT (Yu Sun et al. 2024), is the only modern linear',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 1136.4816666666666),\n",
       "     (200.0, 1170.548223888889),\n",
       "     (1560.5247308333335, 1170.548223888889),\n",
       "     (1560.5247308333335, 1136.4816666666666)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@sun2024learning',\n",
       "     'start_index': 79}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'parent_id': '29e6c92d2c0cf8bae359ed4de31cd9ce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e3c2732f0197449cd61a02cf742243d8',\n",
       "  'text': 'recurrent models with a gradient-based updating rule. In addition to different architectural designs and also objective functions, our LMM has three key differences with presented TTT layers (Yu Sun et al. 2024):',\n",
       "  'metadata': {'detection_class_prob': 0.9423872232437134,\n",
       "   'coordinates': {'points': ((200.0, 1146.055908203125),\n",
       "     (200.0, 1234.0982666015625),\n",
       "     (1567.9151611328125, 1234.0982666015625),\n",
       "     (1567.9151611328125, 1146.055908203125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@sun2024learning',\n",
       "     'start_index': 79}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'parent_id': '29e6c92d2c0cf8bae359ed4de31cd9ce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '76a820f3eedb82b3eaca556366667dcf',\n",
       "  'text': '1. Forgetting Mechanism: TTT layers are updating memory at each time, without having the chance to forget the',\n",
       "  'metadata': {'coordinates': {'points': ((236.39166666666665, 1252.715),\n",
       "     (236.39166666666665, 1280.388888888889),\n",
       "     (1560.0045685999994, 1280.388888888889),\n",
       "     (1560.0045685999994, 1252.715)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'parent_id': '29e6c92d2c0cf8bae359ed4de31cd9ce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'f0d66903700f7d080c72d5a9af1fd80e',\n",
       "  'text': 'past data. Accordingly, when fixing the memory size, the model cannot manage the memory for long sequences. A forget mechanism, such as LMM’s, allows clearing the memory when very past information is not needed anymore. We show that in a general case, this forget mechanism is equivalent to weight decay and provide a fast method to incorporate it into the parallel training.',\n",
       "  'metadata': {'detection_class_prob': 0.9225931167602539,\n",
       "   'coordinates': {'points': ((236.03915405273438, 1260.4791259765625),\n",
       "     (236.03915405273438, 1419.3419189453125),\n",
       "     (1564.2493916111114, 1419.3419189453125),\n",
       "     (1564.2493916111114, 1260.4791259765625)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'parent_id': '29e6c92d2c0cf8bae359ed4de31cd9ce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '1fa7bba5e0f672f4f5227eedcd5d8cab',\n",
       "  'text': '2. Momentum-based Update Rule: TTT layers are based on momentary surprise, meaning that the flow of tokens',\n",
       "  'metadata': {'coordinates': {'points': ((236.39166666666665,\n",
       "      1438.2122222222222),\n",
       "     (236.39166666666665, 1465.8861111111112),\n",
       "     (1559.9995054888886, 1465.8861111111112),\n",
       "     (1559.9995054888886, 1438.2122222222222)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'parent_id': '29e6c92d2c0cf8bae359ed4de31cd9ce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '4085555dd8b7fe895c6c45edcf35e5d6',\n",
       "  'text': 'cannot affect the memory update rule. LMM, however, is based on a momentum rule, which consider both past and momentary surprise. See Section 3.1 for the motivation of this design.',\n",
       "  'metadata': {'detection_class_prob': 0.9307817220687866,\n",
       "   'coordinates': {'points': ((232.07418823242188, 1447.000732421875),\n",
       "     (232.07418823242188, 1538.9959716796875),\n",
       "     (1564.1539306640625, 1538.9959716796875),\n",
       "     (1564.1539306640625, 1447.000732421875)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'parent_id': '29e6c92d2c0cf8bae359ed4de31cd9ce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'cbaa8c4851d22ec52d7c6f9db2b90b3b',\n",
       "  'text': '3. Deep Memory: While TTT-layers allows for deeper memory, the advantages/disadvantages of such deeper memory',\n",
       "  'metadata': {'coordinates': {'points': ((236.39166666666665,\n",
       "      1557.5566666666664),\n",
       "     (236.39166666666665, 1585.2305555555554),\n",
       "     (1560.7095742077775, 1585.2305555555554),\n",
       "     (1560.7095742077775, 1557.5566666666664)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'parent_id': '29e6c92d2c0cf8bae359ed4de31cd9ce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '5694b6b22b585cfcb90f599f2fd0e495',\n",
       "  'text': 'modules have not been experimentally evaluated.',\n",
       "  'metadata': {'detection_class_prob': 0.9281383156776428,\n",
       "   'coordinates': {'points': ((229.75120544433594, 1566.2559814453125),\n",
       "     (229.75120544433594, 1624.42822265625),\n",
       "     (1563.8663330078125, 1624.42822265625),\n",
       "     (1563.8663330078125, 1566.2559814453125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'parent_id': '29e6c92d2c0cf8bae359ed4de31cd9ce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '9c0518738c781b10f2f5f102a297122a',\n",
       "  'text': 'To the best of our knowledge, our neural long-term memory module is the first linear recurrent model with momentum-',\n",
       "  'metadata': {'coordinates': {'points': ((199.16944444444442,\n",
       "      1643.4288888888889),\n",
       "     (199.16944444444442, 1671.1027777777776),\n",
       "     (1564.6706315511115, 1671.1027777777776),\n",
       "     (1564.6706315511115, 1643.4288888888889)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'parent_id': '29e6c92d2c0cf8bae359ed4de31cd9ce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '201532de74885ecf159c86b0877944b8',\n",
       "  'text': 'based update rule.',\n",
       "  'metadata': {'detection_class_prob': 0.9310884475708008,\n",
       "   'coordinates': {'points': ((200.0, 1652.7628173828125),\n",
       "     (200.0, 1704.3111111111111),\n",
       "     (1566.9254150390625, 1704.3111111111111),\n",
       "     (1566.9254150390625, 1652.7628173828125)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'parent_id': '29e6c92d2c0cf8bae359ed4de31cd9ce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'abeadb8f6cd901e714dfed18267087f0',\n",
       "  'text': 'Finally, as a key difference with all the above and other recent linear recurrent studies, note that the hybrid variants of',\n",
       "  'metadata': {'coordinates': {'points': ((200.0, 1726.4511111111112),\n",
       "     (200.0, 1754.125),\n",
       "     (1559.9865835938879, 1754.125),\n",
       "     (1559.9865835938879, 1726.4511111111112)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'parent_id': '29e6c92d2c0cf8bae359ed4de31cd9ce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'f2141e3c24abe309c99088bf712cc58f',\n",
       "  'text': 'modern linear models–such as Griffin (De et al. 2024), DeltaNet (S. Yang, B. Wang, Yu Zhang, et al. 2024), Gated DeltaNet (S. Yang, Kautz, and Hatamizadeh 2024), H3 (D. Y. Fu et al. 2023), Mamba2 (Dao and Gu 2024), Samba (Ren et al. 2024), etc.–all are based on sequential layer-wise design. We present Titans to show how effectively one can incorporate such memory modules into an architecture.',\n",
       "  'metadata': {'detection_class_prob': 0.9490077495574951,\n",
       "   'coordinates': {'points': ((199.19722222222222, 1734.12841796875),\n",
       "     (199.19722222222222, 1890.4754638671875),\n",
       "     (1569.865478515625, 1890.4754638671875),\n",
       "     (1569.865478515625, 1734.12841796875)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'links': [{'text': '2024',\n",
       "     'url': 'cite.0@de2024griffin',\n",
       "     'start_index': 169},\n",
       "    {'text': '2024',\n",
       "     'url': 'cite.0@yang2024parallelizing',\n",
       "     'start_index': 221},\n",
       "    {'text': '2024', 'url': 'cite.0@yang2024gated', 'start_index': 276},\n",
       "    {'text': '2023', 'url': 'cite.0@fu2023hungry', 'start_index': 303},\n",
       "    {'text': '2024', 'url': 'cite.0@dao2024transformers', 'start_index': 329},\n",
       "    {'text': '2024', 'url': 'cite.0@ren2024samba', 'start_index': 354}],\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'parent_id': '29e6c92d2c0cf8bae359ed4de31cd9ce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '50c421a5c884436b537331311264b66d',\n",
       "  'text': '27',\n",
       "  'metadata': {'coordinates': {'points': ((867.1305555555556,\n",
       "      2057.742777777778),\n",
       "     (867.1305555555556, 2085.4166666666665),\n",
       "     (892.8672722222223, 2085.4166666666665),\n",
       "     (892.8672722222223, 2057.742777777778)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1700,\n",
       "    'layout_height': 2200},\n",
       "   'last_modified': '2025-01-25T14:52:27',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 27,\n",
       "   'parent_id': '29e6c92d2c0cf8bae359ed4de31cd9ce',\n",
       "   'file_directory': 'PDF STORE',\n",
       "   'filename': '2501.00663v1.pdf'}}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [el for el in raw_pdf_elements if el.category == \"Image\"]\n",
    "\n",
    "# print(images[5].text)\n",
    "# print(images[5].metadata.text_as_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's display the images extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAOAAmADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3+iiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK5OTxVqWp6pdWPhjSI75LSQw3N/d3PkW6yjrGpCszsOhwMA966mYusEjRjLhSVHqccVy/wzjgj+G2gtbtvEtos0jbtxaV/mkJPrvLZoAIPFd/Yaxa6Z4m0mPTzev5Vpe21z59tNLjIjJKqyOcHAK4OODniurrj/imIh8NNblkfy2ghE0MgOCkqsChB7HcBVjSbq4k+IfiC3kmkMMdhYukRYlUZjPuIHQE4GfXAoA6iqGkatDrNlJdQJIiJcTW5EgGd0UjRseCeCVJHtXPXvmXnxO/suW4uRZS6DIzxRTvGN3nqNwKkENjjIwa5vTNLg0b4XeLNRsJr6K6RNWRHN9M4TZLMFZQzkBhtHzAbieSck0AeqUVyOk+E7e+0G2m1m5vLvUrmCN57kXcqFHwDiLaw8sA8DbgnHOSSTzp13UptB0aCa/me7svFaaXcTqShnRJWUbsddybSR0JzQB6hVB9WhTX4NHKSefNayXSuANoVGRSDznOZB27GsL4l3VxZfD3Vbi1nlgnQRbZInKsuZUBwRyODWbfeGdOn+KdozvqAM2mXM77NSuF+YTQYAxINq/MflGF6ccCgDvqKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK4e30zxD4Llng0LT4dY0KaZ5orLz1gnsy5LMqFvkePcSQCVI3Yya7iigDiJNL8ReML2zOvWcGkaJazrcNp6z+fPdOhJQSsvyKgO1to3ZK8mrd/aavpHjC413TtNOp2t9aRW9xbwypHNG8bOVdfMKqykSEEZBGB1rrKKAOR07RdXl8fHxPfiGCGTTGsktFfc0P7xXXcehY/PnHA4ALday9T07UtH+G/jKxvIbcwG31O5gnimLFllMkgDKVGCN5B5I4r0Kq2oWNvqmm3Wn3ieZbXUTwzJuI3IwIIyORwT0oA5TRLvxPpPh/T9PbRv7WkS3RIb2K6SKNlwAplDnerAddqvnGR1wIZfBV/F4Ogt4p7efW4NSGsGRsxxS3PnGRl7kKQSoP0NdvDEkEMcMYwkahVGc4AGBT6AOC8U2HiTxt4XuNJj0v+xt5R5DeTxyGUqwYInls2ASBlmwcDG05yNzUtO1JfF2nazZQQXEMdnPaTxvMY2Xe8bhl+Ug/6sgjjqK6GigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK5bxjLetdeHrCz1K508X2omGaa22b9gglfA3qw6ovauprjfHdtcXeo+E4LW+ksZn1ZttxEiOyf6NOTgOCvIyOQetAE1x4U1qO3d7DxtrQugMx/ao7aSLP8AtKIlJH0IpfDXjax1Twroup6pc21jc6haPcFHbYv7sfvWGeijryehHNJP4R1a9ge2vPG2tSW0g2yJFFbQsw7jekQYfgQa57xLoGmp8QPh1oyWyjTbeG9VLc5ZSsccZUHPXBVTznOOaAO0/wCEt0A6OmrLq1s9g8hhjmRtwkkyRsQDlm4OAMk44p+m+JtK1W9ayt55Y7xU8z7NdW8lvKUzjcEkVWK54yBisW5X7R8W7CG5TMFpo8k9mCvyiVpVSRh7hNg9g59aXx4sUS+Hr1X2X0OtWqWrDhm8x9kifQxlyR/s57UAQaH4ujhn16LVryWWWLWLiC1ghgaaXykWM4WONSxALcnHGeTXT6VrWn63BJLp9yswicxyoVKPE46q6MAyt7EA1yfw9tbRdb8a3aKpvH1yWKRu4RUQqPplmP4+1S393ZaP8TJ715/Kibw9LcaiB0CQyr5bkDnOGmHrge1AGrN430CBpt13O8UDFJrmGzmlgiI+8GlVCi475bjvVbxFr66fqfheePUYYdMu7mU3ExdfLeIW0sgJY8bcqpzntVHQZ9fk8O2sGieG9P0jShCFtRqV4zyiPHys0SKevUgyZ9cGuT0aG31Hwl8KotRKyRfazw/QlIZdg+mVUYoA9JtfF2i3d5DarczRSznEBubWWBZz1xG0ihXOOflJ4qtrN5Na3WtyQauBJDo/mx2AjGYmBkxNu75wFx/se9Q/EmOFvh1rkkzbGt7VriGQHDJMnzRsD2IYLisXVmdvFXiVpF2yHwnEWHod9xmgDa0PUprix8NXl5q2JJtGNxPamMFrhtsJMuR025IwBz5ntS+G/FUetahrdsZifs1+0NviB1/diKNuSR13M3X2rG8Of8hHwD/2LM38rStrwv8A8f8A4v8A+ww3/pNBQBdsdWs9N8H2epalrcNzbJbRtJqTgRrPkDD47bieAPXAp+n+J9J1O9FlDNNFdFC6QXdrLbPIo6sqyqpYDuRnFec2TXr6Z8Kre1t7a5H2J7hYLqdoY3mS3XYdwRzkK0jAY7e1dNr1v4h1F9JlvrPQtO+yalbzR3Q1eRmU7wrIoNuoYurMmNwyWFAG9feK9H0+8mtJZriWeAAzpaWk1wYcjI8zy1bZkc/NjjmtHT9Qs9VsIb7T7mK5tZhujliYMrDp1+oI+orjbGx17QrvVrvw22la3pd7ez3TW8lwYZ45yQHRZAGVgGVhhgpXoTxWx4LvNPu9IuvsOnT6bJFezLeWc7bmhuC29xnJBBLhhtOMMMY6UAdHRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFUNQ0m31K8025meRX0+4NxEEIAZjG8eGyOmHPTHOKv0UAFZN94ftNQ8RaTrcsky3OlrOsKIwCN5qhW3DGTwoxgj8a1qKAMrWtAttaa0neWa2vbNzJa3duQJISRhsZBBBHBUgg+nAqvD4ZV9Yt9U1LUbvULi1z9lSXYkULEbSwRFGWIJGWzjJxit2igDl7fwTa6fq19qumajfWd7fTtNcupR1lB5CsjKRgHODwwyfmwcVcsvC1lb/2jJeSz6lc6lGIbua7IJkjAIEYVQFVAGbgAZyScnmtyigDmrbwi8GmxaU+u6nNpkS+WLdzGC8eMCNpAgcqBxwQSOpNUx8N9HOkadpcl1qElppty9xaKZlVoiysAoZVDYUsWU53AgckDFdjXjmg/E0ah8eNT0YuTp00f2C39PNh3MW69CTKMjr8lAHoM3hQ35tk1bWb/AFG1t5FlFtKIkSV1OVMmxF34ODjhcgEg1au/Ddnealf38kk4lvtPGnyBWG0Rgucjj737xuTkcDitiigDGsvDVnYT6RLFLOW0qxawg3MMNG3l5Lcct+6Xpgcnj0Lbw8lnrd7qNtqF7HHev5txZ/uzC8mwJv5TeDhV6MBx0rZooA55/BunN4b0zRVmu410sR/Y7uOQLPEyLtDggYJwSCCMHJyKcPDBudRsrzVdVu9RNi3mW8MqxpGsuCPMIRRuYAnGTgZyADW/RQBzsfhU2N3ezaTq97p8d7I001ugjkjErHLSIHUlSTyRnbnnFaGiaJa6FZPb2zSyNLK0888zAyTSscs7EADJ46AAAAAACtKigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigCvqENzcadcw2dyLa5kiZIpym/ymIwG298HnHfFfNmifDe0X416p4cstTvLd9LtkvLO8IV3WcCFgzDADDc544+tfTdeNeH/+TovE/wD2Dl/9At6APZFztG7G7HOOlLRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHlHxB+Kmp6P4mj8K+EtMTUNZADTmVWZY8ruChQRk7SGJzgD15xgf8Jf8a/8AoXtP/wC+U/8AjtRaUAf2lPEuRnFscf8AfMVer1DlZmc5tOx5b/wl/wAbP+he0/8A75T/AOO0f8Jf8bP+he0//vlP/jtepUUudke1Z5b/AMJf8bP+he0//vlP/jtH/CX/ABs/6F7T/wDvlP8A47Xoeual/Y2g6hqflGX7JbvN5YON21ScZ7dKx4tP8RXGlR3kPiXN9JGJFj+yxG1yRkDG3zNvbO/PenzMftGcp/wl/wAbP+he0/8A75T/AOO0f8Jf8bP+he0//vlP/jtd9FrMdv4fg1PWQumkxqZ0mYARueCue/PT1ptr4n0S8t7qeHUYSlqnmXG4lGiXGdzKcEDg84o5mHtJHB/8Jf8AGz/oXtP/AO+U/wDjtc5aQ/Fey8b3vi2LQIP7SvIvJlDGMx7cIOBv4+4veuoh+JUA0TU9WbXNPecTvHa2DKAEUSlVJIO5iyDd1FdwPEuiNp8V+NTtjayqzxyh+HCsEbHrhmA+pAo5mNzkjgv+Ev8AjZ/0L2n/APfKf/HaP+Ev+Nn/AEL2n/8AfKf/AB2u3XxfoDWhuRqcJQSeUVwd+/GduzG7OOenSrkOuaXcaS2qxX9u1ggJa43gIuODknpj3o5mL2kux55/wl/xs/6F7T/++U/+O0f8Jf8AGz/oXtP/AO+U/wDjtd7p3iTR9WuHt7K+SWdU8wx7WViv94AgEj3FWV1bT20o6ot5AbAIZDcbxsCjqc0uZh7SR5z/AMJf8bP+he0//vlP/jtH/CX/ABs/6F7T/wDvlP8A47XqEbrLGsiHKsAwPqDTqOdh7Rnlv/CX/Gz/AKF7T/8AvlP/AI7SHxj8a0G4+HbAgc4CKf5S16nRRzsPas534Y/EyTxo97pWrWS2Ou2OTNEgIR1DbSQCSVIOAQc9RzzgejV4b4JAX9pHxIFAA+wE8f8AbCvcq0NVqgooooGFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAeCaT/AMnKeJf+vY/yhr1evG/Ft7P8Ovjhd+ItSsppNK1SHbHLFgkjagbGeMhl6ehB71t/8Lx8I/3dR/78D/4qokncxnFt6HpNFebf8Lx8I/3dR/78D/4qj/hePhH+7qP/AH4H/wAVU2ZHJLsdxr2pQ6PoV5qFxA88EEZaWNQCSn8XB7AZJ9hWMngzTokF1oWpX+lh13x/ZLktBzyD5T5THsAK59vjf4PdSrJqBUjBBtxgj/vquebxx8LmkLf2bqKoesC71hP/AGyEmzHtimkylFnV6Xqj65e+EbzV/KO4XixsoxHLcIwWNwP9qMSsPrx2rZ1vavjXw0bf/j7ZpxNt6m38s53f7O/y8e9cjd/FvwDfaeLC5srt7VQAsX2ZQEx024b5SOxHSoNK+KPw90VpHsbTUUlkGHlkQyyMB0Bd3LY9s4osws+xpx/8ki1L/r8uf/Stq6nU7eKfxvoDSoGMNtdyJns2YRn8ia4lfi14BXTpdOFjdmzlLmSBrVSrbyWbILdySaS0+LXgKwW3W2tL6MWyukOIM7FcgsBlu5A/KizCz7HXWVvF/wALP1afy180aXajdjnmSXP/AKCv5VlS3Ftb3OrWslmtw9z4kjjtoWkMcfm/Z4ZQXIB4yrNjBye1Zq/GXwSl7JerBfi5ljWN5Ps4yyqSQPvdizfnVW6+Knw+vre5gubG8kjuZRNKDbgFpAFUNkNkMAqjIx0osws+x0WpNqSePPCS6hdWJZ5bnZDbxMrAeQ+SWLHI+7xgc1kXBth4lknHmf8ACHC+X7RtI8n7aOCx/wCmO7aG7eZg+tZUPxC+GkEaKmnX7MkglWWRGeUMAQD5jOW4ye/c1oL8XfAa6X/Zgs7sWPl+V5H2VdmzGMY3UWY7PseqUV5lD8a/BtvBHDEmorHGoVR5AOAOB/FUn/C8fCP93Uf+/A/+KpWZHI+x6TRXm3/C8fCP93Uf+/A/+KpD8cvCIUkJqJI7CBef/HqLMOSXYZ4L/wCTkvEn/Xgf5QV7jXhPweW+8TfErxB42No9vp00Jt4i4+8xKYAPQkLHzjoSK92rRHQtgooopjCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAIbqztr63a3vLaG4gb70cyB1P1B4rL/AOEO8L/9C3o//gDF/wDE1tUUAYv/AAh3hf8A6FvR/wDwBi/+Jo/4Q7wv/wBC3o//AIAxf/E1tUUAYv8Awh3hf/oW9H/8AYv/AImj/hDvC/8A0Lej/wDgDF/8TW1RQBi/8Id4X/6FvR//AABi/wDiaP8AhDvC/wD0Lej/APgDF/8AE1tUUAYv/CHeF/8AoW9H/wDAGL/4mvLdF1rwnqPxs1Tw3/YGkmy8gW1sfsUeDcRFmfA28Zy4z38ta9kvlum0+4WxeJLsxsIWlBKK+PlLAdQD2r5j0L4eXsPxnvtDstcI1HSYkv4r2WHIllHlOQy7s7SZCDyePWgD6K/4Q7wv/wBC3o//AIAxf/E0f8Id4X/6FvR//AGL/wCJrZXO0bgAccgHNLQBi/8ACHeF/wDoW9H/APAGL/4mj/hDvC//AELej/8AgDF/8TW1RQBi/wDCHeF/+hb0f/wBi/8AiaP+EO8L/wDQt6P/AOAMX/xNbVFAGL/wh3hf/oW9H/8AAGL/AOJo/wCEO8L/APQt6P8A+AMX/wATW1RQAyKKOCJYoo1jjUYVEGAB7Cn0UUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRXlnxB+K93oHiCPwx4Y0sanrhAaQOrMkWRuC7VwWO3k8gAEdecc5/wsH4x/9CfYf+A7/wDx2iwHu1FeE/8ACwfjH/0J9h/4Dv8A/HaP+Fg/GP8A6E+w/wDAd/8A47TswPdqK8J/4WD8Y/8AoT7D/wAB3/8AjtH/AAsH4x/9CfYf+A7/APx2izA92orwn/hYPxj/AOhPsP8AwHf/AOO0f8LB+Mf/AEJ9h/4Dv/8AHaLMD3avGvD/APydF4n/AOwcv/oFvWd/wsH4x/8AQn2H/gO//wAdrmrO5+KFl47vvF8XhWI6jewiGVGiPlBcIOBvzn5F7+tFmB9N0V4T/wALB+Mf/Qn2H/gO/wD8do/4WD8Y/wDoT7D/AMB3/wDjtFmB7tRXhP8AwsH4x/8AQn2H/gO//wAdo/4WD8Y/+hPsP/Ad/wD47RZge7UV4T/wsH4x/wDQn2H/AIDv/wDHaP8AhYPxj/6E+w/8B3/+O0WYHu1FeE/8LB+Mf/Qn2H/gO/8A8doPxC+MYBJ8H2HHpbyH/wBq0WYHu1FeffDP4mp45W7sL6y+wa1ZDM8AztYZwWUHkYPBB6ZHJ7eg0gCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDwXSAG/aW8SFhki2OCe3yxCvWq8l0f/k5XxL/ANezfyhr1qtYbEsKKKKsQUUUUAYnh3UrnUX1gXLBha6lLbxYUDCKFIHv1NXLyeSPVtNiW8iiSVpA0LLlpsJkBT2x1NZHg7/WeIv+wzP/AOgpUmtf8jh4Y/66XP8A6JNLoMluPGfhy2I83V7YDGSwJYKM4yxAwvIPXFaF/q+n6XZrd3t5DDA5Co7N98noF/vE+grC8CWVt/whMMRhQpcPOZQRnfmRwc+vHH0rmNL/ALVm/wCEIFncafG/9hbrdr+F5VaTbHu2hWX59uOfTd70rgehabrWm6vBLNY3kcyRHbLg4MZxnDA8jj1qpaeLtAv72O0ttUgkmlJEQGQJCOfkYjDfgTXJauJrK91O58RXOnXbPpLRTWenwywNLG0iqhdy7ADJYDocM3XBq94l/tOC20Vb2bTLaH+1rFIraCNmcnzk+VXJHRd38PIHai4HT3HiDSrS6FrPexpcNMIBFyWLlVbAHfh1OegzzWlXO6HawjxZ4nu9g89riGLceyi3iOB6cn+XpXRU0IKKKKYBRRRQB5b4KVU/aS8ShAFBsWJA9T5BP617lXh3gz/k5PxJ/wBeB/lBXuNYPcsKKKKQBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHzx4l1Bvh78eL3XNWtZjpmpw4imjXOQVQEjnkqy4I64IPcZ6j/hc/gn/AKCE/wD4Cv8A4V6rqGm2GrWptdRsra8tycmK4iWRc+uCCKx/+EB8Hf8AQq6L/wCAEX/xNUpNCscF/wALn8E/9BCf/wABX/wo/wCF0eCf+ghP/wCAr/4V3v8AwgPg7/oVdF/8AIv/AImj/hAfB3/Qq6L/AOAEX/xNPnYWOC/4XP4J/wCghP8A+Ar/AOFH/C5/BP8A0EJ//AV/8K73/hAfB3/Qq6L/AOAEX/xNH/CA+Dv+hV0X/wAAIv8A4mjnYWPJbjxt8Kbq6muZkZppnLyP9nlG5j1JxVmx+Ivwz05omtHkiaJ2dCLaUlWZdpIz6jivUf8AhAfB3/Qq6L/4ARf/ABNH/CA+Dv8AoVdF/wDACL/4mlzsLHndp8XPANjbLbWt3LFCmdqLayYGTk9vUmqdz8Rvhnd6VBpkzO1pbhRAgtpFMW0YGxgMqQOMg5r1D/hAfB3/AEKui/8AgBF/8TXmmj3ngjUfjRqvhceGtFNosAgtj9hjwbiLc0gA28EhmGf+mQ9afOwsV7T4hfDGxsbiziLtDcjbOJreWVpRjGGZ8lh9TVeDxp8KbeGWIefIkgCnz455SACCApckqMgHAx0HpXrf/CA+Dv8AoVdF/wDACL/4mj/hAfB3/Qq6L/4ARf8AxNLmYWPO4Pi54CtnmeG7mRpmDSEWsmWIUKCePRQPwqf/AIXP4J/6CE//AICv/hXe/wDCA+Dv+hV0X/wAi/8AiaP+EB8Hf9Crov8A4ARf/E0+dhY4L/hc/gn/AKCE/wD4Cv8A4Uf8Ln8E/wDQQn/8BX/wrvf+EB8Hf9Crov8A4ARf/E0f8ID4O/6FXRf/AAAi/wDiaOdhY4L/AIXP4J/6CE//AICv/hSN8aPBQUkX1wxA6C2fJ/Su+/4QHwd/0Kui/wDgBF/8TR/wgPg7/oVdE/8AACL/AOJo52Fjyr4QvdeKPil4i8Zx2kkGmSQm3RnHViY8DPQkKmTjpkete71FbWtvZWyW9rBFBBGNqRRIFVR6ADgVLUDCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiue8T+N/Dvg+APrWpRQSMu5IF+eVx7IOcZGM9PegDoaK8Vm/aKsJpNuk+GNTvFHUu6oR+Ch6j/4aCuv+hFv/wDwIP8A8boA9uorxH/hoK6/6EW//wDAg/8Axuj/AIaCuv8AoRb/AP8AAg//ABugD26ivEf+Ggrr/oRb/wD8CD/8bo/4aCuv+hFv/wDwIP8A8boA9uorxH/hoK6/6EW//wDAg/8Axuj/AIaCuv8AoRb/AP8AAg//ABugD2a/+2f2dcjT/K+2mJhB5xOwPj5S2OcZxnHavmHQvAGrW/xnvdIstbjbVtJRdQS7mibZPJiNyrAHIBMhBPPHbmu4/wCGgrr/AKEW/wD/AAIP/wAbrhdN+J01n8XNW8WDw5cyPeWohNgJSHjwsY3E7P8AY9B96gD6nUkqCRg45HpS14j/AMNBXX/Qi3//AIEH/wCN0f8ADQV1/wBCLf8A/gQf/jdAHt1FeI/8NBXX/Qi3/wD4EH/43R/w0Fdf9CLf/wDgQf8A43QB7dRXiP8Aw0Fdf9CLf/8AgQf/AI3R/wANBXX/AEIt/wD+BB/+N0Ae3UV4j/w0Fdf9CLf/APgQf/jdH/DQV1/0It//AOBB/wDjdAHt1FeI/wDDQV1/0It//wCBB/8AjdH/AA0Fdf8AQi3/AP4EH/43QB7dRXiP/DQV1/0It/8A+BB/+N0f8NBXX/Qi3/8A4EH/AON0Ae3UV4pH+0TawuP7U8KalaRnoyyByfwYL/OvQvCfxE8M+M0A0nUF+1bdzWc42TL6/L3x6qSPegDqaKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOF+KHxATwJoCNbos2r3pMdnCRkZGMu3sMjjuSB6kcb4K+Ev2yX/AISXx0ZNR1e6Im+zXBysfpvH8R6fL0HTFVHjHjX9pG5S7xNY6DCDFH/CGTb19/Mcn/gIHavaqAIre2gtIVhtoI4Yl+6kaBVH4Cpa8Y8aeK/FXiX4gv4I8I3X2AW65ubrdtJOAxO4AlVGQOOSfaqf/CsPib/0UC4/8GFzUSqRi7Nge50V4Z/wrD4m/wDRQLj/AMGFzR/wrD4m/wDRQLj/AMGFzS9tDuOx7nRXhn/CsPib/wBFAuP/AAYXNH/CsPib/wBFAuP/AAYXNHtodwse50V4Z/wrD4m/9FAuP/Bhc0f8Kw+Jv/RQLj/wYXNHtodwse5143oP/JzfiL/rxH/oEFUP+FYfE3/ooFx/4MLmqcfwZ8dxanJqcfi+NNQlXbJdLcziVxxwXxkjgd+wo9tDuKx7/RXhn/CsPib/ANFAuP8AwYXNH/CsPib/ANFAuP8AwYXNHtodx2Pc6K8M/wCFYfE3/ooFx/4MLmj/AIVh8Tf+igXH/gwuaPbQ7hY9zorwz/hWHxN/6KBcf+DC5o/4Vh8Tf+igXH/gwuaPbQ7hY9zorwz/AIVh8Tf+igXH/gwuaUfDH4nKdy+P5iRyAb+5xR7aHcLHuVFeU/C7xnr914h1Twf4pYS6lp6F0nwAzKpAIJH3vvKQepBOa9WrQQUUUUAMlijnjaOaNJI24KuoIP4GvLvHHwesdQDax4VH9k63CfNjFu3lxyMOeAPuN6EYGevqPVKKAOD+E3xDuPFdnc6Nra+T4h035bhWG0zKDjft7EHhh0yQe+B6TXg/jSL/AIQ745+GtfsgI49WdYbpezZYRucf7rqfqM17xQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB4Z8N/+S3ePP8ArrL/AOjq9mrxn4b/APJbfHn/AF2l/wDR1ezUAeI+Ff8Ak5LxL/17yf8AtKvaa8W8K/8AJyXiX/r3k/8AaVe01wYn4ykZXiTVTougXV5GN1xgR26f35nO2NfxYisTwZFd6Fe33hi/vpbySBI7u2nmYs8kTjD8n0kV/oGWl16CfxD4usdHt7ua1g02P+0LieBUZllJKwrh1Zf+ejcjsDxxVDxFpNz4fvtN8WS65f3o06XyrpblIFAtZSFkP7uNCdp2vzn7pqUla3cDcufFTi/uLbTNE1DVVtX8u5ntjEqRv1KAu672HGQucZx14rK8N+JbWPRtf1e4mnkthq0ixJtZpCSIwsap13bjjb6mmeHNe0nwxb6hpOuaja2F5FfXM4+0yBPtEckrSJImfv5DY4zggisS0Z5dIutYFrNHbWfilr+aHyzv8gqBvK4zkBw5HUYPemorawGz4g8T3b2Fpb3ekajo81xqNktu8zxkTD7THuTMbthtu4lTjIB64Nd5XA+KvFGjaxY6da6TeW+pytqdjI5tZFkFuguI/ncj7uThQDyS3TrXZ6q14uj3racFa+FvIbcN0Mm07c/jioktFpYDzqdriTXdQh+2358Wx6iDawxzyeStoXXaxjB2eX5eQxIzuB5yRXqFeUjUPDkHh2xutE1CMeK7f51t8l7u5uGH7yKaP77BiCDnhcAggKK7XwVfyX/hi3NzPLJfxFo71JvvxTZyyH6ZwPUYPeqqLS4HK6rqeqaT8R9X1WGaWbTNPs7U3tmMsDC/mbpEH95Nob3G72rf8U3pefwjNaXDeTc6vF80b8SIYZSOnUHg0mkgH4neJgRkGxsePxmrmNUsrrw94p8NaCsTvo76yt1YS5z5H7uUPAfYFgV9iR/DT0b+X6AdpfeKHi1Gax0vRr7VpbYgXLWxjRISQDtLSMoLYIO0Z6jOKin8caXDpFpqRS5MU939ieLyj5sM2GyjJ13ArjAzkkYzms3RNZ0zwrd6zpuu6hb2E8moz3kUl1II1nikbcpVm4bGdpA5G3p0rLJ+3XlrqywvHZ6h4nhmtRIhXei22wSYPZihI9sHvSUV1QHTy+Lvsws4rrRdRivr4Sm1s/3bSSbCvBw+1SQ+eTwFbJGOYIvGsks82nr4e1P+2oQGfTt0W4RnpJ5m/wAvb2+9nPGKuagoPjrQiQCRZXpHt80FVrED/hZ+snHP9lWfP/bSelZWvYDW0PWo9bs5Jltp7WaGVoJ7e4UB4pFwSDgkHggggkEEVpVzvhn/AJCvir/sLj/0lt66KokrMDxHTdUsdH/aI8TX2o3UVtax2XzSSHAHyw1d8S/tBaXaGS38PWL30o4W5uMxxZ9Qv3mH/fNN8OKG/aV8RqwBU2RBB7/LDXWeJfhB4S8SM832I6fdsP8AXWWEyfUpjafyz716cPhRJm6f8bvCEen26X+rSTXYQedJHZSKpfvtGOBnpWtp3xf8D6lOIY9bSGQnA+0xPED/AMCYYH4mtHT/AAF4cg0+3hvfD+hXNyiBZJ10yJPMI/i24OM9cVT1v4VeDdctTE2iW1nJj5ZrFBAyn1wowfxBqgOyR1kRXRgysMhgcgj1pa8O8Hanq/wy8eR+B9dujcaRekfYLhs4Utwu3k4BPylex56cn3GgDx343qP7c8Dvj5hfsAf+BRf4Cvb68R+N/wDyGPBP/YQb/wBCir26gAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDwz4b/8lt8ef9dpf/R1ezV4z8N/+S2+PP8ArtL/AOjq9moA8P8AGGj+JfBHxOm8a6FpkmqWV4mLiKNCxTIAZTjJHKhg2MDv7r/wvLW/+hCu/wDv+/8A8ar1LxJ4y0DwlDHJrWox2xkz5ce0u749FUE49+lcv/wvHwL/ANBG4/8AAWT/AAqJU4yd2gucr/wvLW/+hCu/+/7/APxqj/heWt/9CFd/9/3/APjVdV/wvHwL/wBBG4/8BZP8KP8AhePgX/oI3H/gLJ/hU+wp9h3OSf42atIys/w+uGZDlS0rkqfb91T/APheWt/9CFd/9/3/APjVdV/wvHwL/wBBG4/8BZP8KP8AhePgX/oI3H/gLJ/hR7Cn2C5yUfxs1aHd5fw+uE3HJ2yuMn1/1VP/AOF5a3/0IV3/AN/3/wDjVdV/wvHwL/0Ebj/wFk/wo/4Xj4F/6CNx/wCAsn+FHsKfYLnJD42asJTKPh9cCQjBfzWyR9fKpi/H3UXumtl8Fym4UZaIXTbwPceXnuPzrsP+F4+Bf+gjcf8AgLJ/hXnOlfEDw5afGzWPFEt440u6tRFE4hcsW2xDlccfcNHsKfYLm5/wvLW/+hCu/wDv+/8A8ao/4Xlrf/QhXf8A3/f/AONV1X/C8fAv/QRuP/AWT/Cj/hePgX/oI3H/AICyf4Uewp9guclJ8bNWmCiX4fXD7TkbpWOD6/6qn/8AC8tb/wChCu/+/wC//wAarqv+F4+Bf+gjcf8AgLJ/hR/wvHwL/wBBG4/8BZP8KPYU+wXOV/4Xlrf/AEIV3/3/AH/+NUf8Ly1v/oQrv/v+/wD8arqv+F4+Bf8AoI3H/gLJ/hR/wvHwL/0Ebj/wFk/wo9hT7Bc5X/heWt/9CFd/9/3/APjVH/C8NcY7V8BXZY8D9855/wC/VdV/wvHwL/0Ebj/wFk/wo/4Xj4F/6CNx/wCAsn+FHsKfYLmN8KvDfiC58Wat438SWrWdxfIY4bd1KNglSTtPIAChRnk8/j69WZoXiHSfEuni+0e9ju7fO0smQVPoQeQfY1p1qtBBRRRQB4v+0DEsMfhnUUG25hu3VXHp8rfzUV7RXjX7Qv8AyCNA/wCv1v8A0GvZaAPHvjf/AMhjwT/2EG/9Cir26vEfjf8A8hjwT/2EG/8AQoq9uoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA8M+G//JbfHn/XaX/0dXs1eM/Df/ktvjz/AK7S/wDo6vZqAPAG0228W/tC6vba0n2q2s4iYoXJ2YQIAMemWJx3P1r0z/hCPCn/AELek/8AgHH/AIV594d/5ON8S/8AXCT/ANpV6/XRTS5TkrN8xg/8IR4U/wChb0n/AMA4/wDCj/hCPCn/AELek/8AgHH/AIVvUVpZGXM+5g/8IR4U/wChb0n/AMA4/wDCj/hCPCn/AELek/8AgHH/AIVvUUWQcz7nL6l4a8FaRp8t/feH9Kjtosb3FgrkZIA4VSTyR0FZ4svAjMAPCTZJxz4anH/tGtH4iEr4F1FlUsw8ohQcZ/epxVi11vWp7uKKbwnfW8TsA8z3VuwQepCyEn8BUu17FJu17i/8IR4U/wChb0n/AMA4/wDCj/hCPCn/AELek/8AgHH/AIVzc/jOyu9X1KKfxfBosVpO1tFbosRkdk4Z3MitwWyABjgZzzUP/CwluNN06J9Z0+yea5nhn1IYMbJDt+aMNxufemAcgZbrileI+WZ1X/CEeFP+hb0n/wAA4/8ACg+CfCgGT4b0n/wDj/wrn7DxvY2upzwDxHDrdmLKW6EgEYmiMQDMrbAqkFSSDgY2nrmtS2g8S3GjR6q2rZvJIxONPEMYt8EZ8vdt35xxu3decdqd12FaS3ZLY+FfBmpWFvfWnh/SZLa4jWWJ/sKDcrDIOCuRwe9T/wDCEeFP+hb0n/wDj/wo8Ef8iH4f/wCwdB/6LFb1NJWJbadrmD/whHhT/oW9J/8AAOP/AAo/4Qjwp/0Lek/+Acf+Fb1FOyDmfcwf+EI8Kf8AQt6T/wCAcf8AhQfA/hRgQfDek8+log/pW9RRZBzPueQ/DazTw58b/EWg2DMunm1LiInOOY2X8t7Aexr3OvFPCv8Aycj4g/68j/6DDXtdcktzuj8KCiiikUeNftC/8gjQP+v1v/Qa9lrxr9oX/kEaB/1+t/6DXstAHj3xv/5DHgn/ALCDf+hRV7dXiPxv/wCQx4J/7CDf+hRV7dQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB4Z8N/wDktvjz/rtL/wCjq9mrxn4b/wDJbfHn/XaX/wBHV7NQB4X4d/5ON8S/9cJP/aVev15B4d/5ON8S/wDXCT/2lXr9dFL4Tjr/ABhRRRWhiFFIzKilmICgZJPQCqX9s6V/0E7P/v8Ar/jQMreKNKn1vw7dafbPGk0pjKtISFG11Y5wD2BrXpEdZEV0YMjDKsDkEetLQF9LHMQ2WtaDfX402ytb6wvLhrlEe4MLwSPy4PykMpbLDHIyRg0xtE16Iadqa3lvdatbSTGaOQlYpIpSC0StglQu1MEg528jmuqopWHzHPx2erazLP8A2xFFZ6fJavb/AGKKbzGkL8M7tgDgcADPUknsK1tb+KYdKTRvLsspEIV1QTH7g4DeVt+/jtnbnnPaupoosHMZvh7TpdI8N6ZpszI0tpaxwuyElSVUA4yBxx6VpUU2SSOGNpJXVEUZZmOAB7mmJ6jqKKKBBRRRQB5T4V/5OR8Qf9eR/wDQYa9rrxTwr/ycj4g/68j/AOgw17XXJLdnoQ+FBRRRSKPGv2hf+QRoH/X63/oNey141+0L/wAgjQP+v1v/AEGvZaAPHvjf/wAhjwT/ANhBv/Qoq9urxH43/wDIY8E/9hBv/Qoq9uoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA8M+G/wDyW3x5/wBdpf8A0dXs1eM/Df8A5Lb48/67S/8Ao6vZqAPC/Dv/ACcb4l/64Sf+0q9fryDw7/ycb4l/64Sf+0q9fropfCcdf4wooorQxM/Xv+Rc1P8A69Jf/QDXG6DqXglPDumLcWloZhaRCQnTmYltgzzs55712usxST6FqEUSF5HtpFVR1JKkAVH4fhktvDWlQTI0csdnCjowwVYIAQaTWpadkUbrV7r+1DomhWVvJNbwJJNJO5jhgRshFAUEljtPHAAHXtVK78Xzadpur/b7KODUdMjSZ4lkLxyxMcCRDgEjhhjGQRj3qSR59A8WX99LZ3Nxp2pRxHzbWBpmhljBUhkQFtpG3BAPIOax9WsdR12PXdVjsLiKOW0isrSCWMrLKFkLs5XqoJbAB54JIFJtjSRvLr2pW15pq6lpkVvb6jP5MZScs8J2MyiQbQMnbjAOAe5qaLxGJPF82hG1KokO5bovw8oCs0e3HUK6tnPc+lS+J7Oe98P3Is033sO25th6yxsHUfiVA/Gubew1ODwzb66LGeXWI79tSNoB+8KyEoYj7iJgPqgod0CSZsHxNcXCyrp+mNcv/aD2MDeYRGdi5eR2CnYoYMvfJA9eJtO1bUhrY0jVrW1SeS2a5hmtZWZHVWVWBDAEEF19Qc+1Yl5pt1pOj+H7J47+TTkLHU/sG8yNIy7txEfzlS5YkL6jtTtNhRPGtlfWWiXVtp7WU9r9okgZXeQvEwLhhuC4UgFu+eBwSXYWVixYeL7ufw5/wkF1pyQ6cLcMFVyZppTgbUTGApYlQScng8Csvx1f6+ngLV31DS7Vbae2KkW1wXkt8jjcCoDDOASvTPcc1prpGoS/DKxsYoNuo29vbypBKduZImSQIfTJTH41T8X6rd694M1DTdM0TVGvrm3KvHNaPGIuMn5mAVzxgbC2SR25pO9hq19O53SfcX6ClpEGEUe1LVmQUUUUAeU+Ff8Ak5HxB/15H/0GGva68U8K/wDJyPiD/ryP/oMNe11yS3Z6EPhQUUUUijxr9oX/AJBGgf8AX63/AKDXsteNftC/8gjQP+v1v/Qa9loA8e+N/wDyGPBP/YQb/wBCir26vEfjf/yGPBP/AGEG/wDQoq9uoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA8M+G//ACW3x5/12l/9HV7NXjPw3/5Lb48/67S/+jq9moA8Ds7620P9ovXG1OZLRLmNkieZgqksI2Xk8cgH8eK9Z/tnSv8AoJ2f/f8AX/Gq/jH4deH/ABv5UmqQypcxLtS5t3CSBfQ5BBGfUcfia43/AIZ38L/9BTWP+/kX/wAbrSNTlVjKdLmd7ndf2zpX/QTs/wDv+v8AjR/bWlf9BOz/AO/6/wCNcL/wzv4X/wCgprH/AH8i/wDjdH/DO/hf/oKax/38i/8AjdV7XyI+rrud1/bOlf8AQTs/+/6/40f2zpX/AEE7P/v+v+NcL/wzv4X/AOgprH/fyL/43R/wzv4X/wCgprH/AH8i/wDjdHtfIPq67ndf2zpX/QTs/wDv+v8AjR/bOlf9BOz/AO/6/wCNcL/wzv4X/wCgprH/AH8i/wDjdH/DO/hf/oKax/38i/8AjdHtfIPq67ndf2zpX/QTs/8Av+v+NH9s6V/0E7P/AL/r/jXC/wDDO/hf/oKax/38i/8AjdczZ/CnwXefEDUfCi6nq3nWlrHNv86L5mJ+Zf8AV9g0Z/E+lHtfIPq67nsH9s6V/wBBOz/7/r/jR/bOlf8AQTs/+/6/41wv/DO/hf8A6Cmsf9/Iv/jdH/DO/hf/AKCmsf8AfyL/AON0e18g+rrud1/bOlf9BOz/AO/6/wCNH9s6V/0E7P8A7/r/AI1wv/DO/hf/AKCmsf8AfyL/AON0f8M7+F/+gprH/fyL/wCN0e18g+rrud1/bOlf9BOz/wC/6/40f2zpX/QTs/8Av+v+NcL/AMM7+F/+gprH/fyL/wCN0f8ADO/hf/oKax/38i/+N0e18g+rrud1/bOlf9BOz/7/AK/40HWtKAydTsgB/wBN1/xrhf8Ahnfwv/0FNY/7+Rf/ABugfs7+Fs86nrGP+ukX/wAbo9t5B9XXcyvAF3DrXx98RanYOJrIWjKJl+6cGJeD3yVOPYV7lWB4U8G6L4M097TR7Yp5h3SzSHdJIR03N7eg45PrW/WTd3c3SsrBRRRSGeNftC/8gjQP+v1v/Qa9lrxr9oX/AJBGgf8AX63/AKDXstAHj3xv/wCQx4J/7CDf+hRV7dXiPxv/AOQx4J/7CDf+hRV7dQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFQ3d5bafaS3d5PHb20SlpJZWCqg9ST0ryXUfj7p76kbDwxoGoa7KCQGjzGHx3UBWYj6gUAewUV41/wuXxZ/0S3V/wDvqX/4zR/wuXxZ/wBEt1f/AL6l/wDjNAHstFeNf8Ll8Wf9Et1f/vqX/wCM0f8AC5fFn/RLdX/76l/+M0Aey0V41/wuXxZ/0S3V/wDvqX/4zR/wuXxZ/wBEt1f/AL6l/wDjNAHstFeNf8Ll8Wf9Et1f/vqX/wCM0f8AC5fFn/RLdX/76l/+M0Aey0V41/wuXxZ/0S3V/wDvqX/4zR/wuXxZ/wBEt1f/AL6l/wDjNAHstFeLSfHbVdN2za38PtUsLMsFadpGGD7Bo1BP4ivRfCHjrQfG9i1xo91ukjA862lG2WLP95fT3BI96AOkooooA8M+G/8AyW3x5/12l/8AR1ezV4z8N/8Aktvjz/rtL/6Or2agAooooAKKKKACiiigAooooAr3939h0+4uhDLOYY2cRRKWeQgcKoHUk8fjXy1oEPiuw+Lsl8+nzT6xaym+vbWJgXMT4LqOeTtk6D+lfVteBz+J9L8JftD+INR1eZ4rZrZYgyRlzuMcJHA+hoA97Rg6K6/dYAjIxS151/wvHwL/ANBG4/8AAWT/AAo/4Xj4F/6CNx/4Cyf4UAei0V51/wALx8C/9BG4/wDAWT/Cj/hePgX/AKCNx/4Cyf4UAei0V51/wvHwL/0Ebj/wFk/wo/4Xj4F/6CNx/wCAsn+FAHotFedf8Lx8C/8AQRuP/AWT/Cj/AIXj4F/6CNx/4Cyf4UAei0V51/wvHwL/ANBG4/8AAWT/AAo/4Xj4F/6CNx/4Cyf4UAei0V51/wALx8C/9BG4/wDAWT/CsrWfj94dt4THotpealdvxGDH5abj0yT834AUAZ3x5nW+1HwtoMHzXc9yXCjqAxVF/Mk/lXtdeQfD3wVruq+KX8d+M1KXzf8AHpaOuDHxgMVP3QBwF655PPX1+gDx743/APIY8E/9hBv/AEKKvbq8R+N//IY8E/8AYQb/ANCir26gAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAorm774geENOmaG68SaYkqEqyC4VmUjsQCcGqv8AwtHwP/0M2n/9/P8A61AHXUVyP/C0fA//AEM2n/8Afz/61H/C0fA//Qzaf/38/wDrUAddRXI/8LR8D/8AQzaf/wB/P/rUf8LR8D/9DNp//fz/AOtQB11Fcj/wtHwP/wBDNp//AH8/+tR/wtHwP/0M2n/9/P8A61AHXUVyP/C0fA//AEM2n/8Afz/61H/C0fA//Qzaf/38/wDrUAddRXI/8LR8D/8AQzaf/wB/P/rUf8LR8D/9DNp//fz/AOtQB11Fcj/wtHwP/wBDNp//AH8/+tR/wtHwP/0M2n/9/P8A61AHnnxInv8A4gfE6x+HllO8Om2yrcag8Y5zjcSe2ApUDtufntj13QPDmk+GNMj07R7KO1t067R8zn1ZurH3NeF+C/GGgWnxv8V6zfavbx2NzFIlvcyMdrjzI8AH6L+Qr1r/AIWj4H/6GbT/APv5/wDWoA66iuR/4Wj4H/6GbT/+/n/1qP8AhaPgf/oZtP8A+/n/ANagDrqK5H/haPgf/oZtP/7+f/Wo/wCFo+B/+hm0/wD7+f8A1qAOuorkf+Fo+B/+hm0//v5/9aj/AIWj4H/6GbT/APv5/wDWoA66iuR/4Wj4H/6GbT/+/n/1qlg+JXgq4kCJ4n0sE/37gIPzbFAHU0UyKWOeJJYpFkjcBldDkMD0IPcU+gBGUMpVgCpGCCODXhHxM8Kt8OtZsvH/AISjFpHHOEvrSL5YyGPoOAjfdI7EqR7e8VwXxpUP8JNdB7LCfymjoA7HSdSg1nR7LU7bd5F5Ak8YbqFZQRn35q5XJfC8lvhj4dJ/580FdbQB4Z8N/wDktvjz/rtL/wCjq9mrxn4b/wDJbfHn/XaX/wBHV7NQBR1XWdM0O0+1apf29nATtDzyBQT6DPU+1Yf/AAsvwV/0Mun/APfyvLNS0tPiH8e7/SNamlOnadCfLhjbb8qheM9ss2Sevb0rt/8AhSngT/oFS/8AgXL/APFVlOtGDsx2Nz/hZfgr/oZdP/7+Uf8ACy/BX/Qy6f8A9/Kwz8FPAgGTpUv/AIFy/wDxVUtJ+Fnw012wW+0u1N1asxUSR3kuMg4I+9UfWIBY6n/hZfgr/oZdP/7+Uf8ACy/BX/Qy6f8A9/Kw/wDhSngT/oFS/wDgXL/8VVe1+EXw7vTOLbT5JDbymGXF1L8rjGR973FH1mAWOk/4WX4K/wChl0//AL+Uf8LL8Ff9DLp//fyucu/hB8PLCETXWnyRxtIkQY3Uv3nYIo+93ZgPxqf/AIUp4E/6BUv/AIFy/wDxVH1mAWNz/hZfgr/oZdP/AO/leRW2s+EL/wCO+t6jq8+mXWjS2o8qW6RZImcJEONwIzww/Ouqk+Hvwoh1caVIqrelxF5RvJeHPIQnOAxzwM5rX/4Up4E/6BUv/gXL/wDFU3iIrdMLDf7T+Dv/ADz8Kf8AgJF/8TR/afwd/wCefhT/AMBIv/iaqJ8K/hpJrEukLaMdQiiEz2/2uXcEJwG+90zUl38JPh1Yvapc2EkbXUwghBupfnkIJCjn0Un8KPrEezCxP/afwd/55+FP/ASL/wCJo/tP4O/88/Cn/gJF/wDE07/hSngT/oFS/wDgXL/8VR/wpTwJ/wBAqX/wLl/+KpfWYBYb/afwd/55+FP/AAEi/wDiaP7T+Dv/ADz8Kf8AgJF/8TTv+FKeBP8AoFS/+Bcv/wAVR/wpTwJ/0Cpf/AuX/wCKo+swCw3+0/g7/wA8/Cn/AICRf/E0f2n8Hf8Ann4U/wDASL/4mnf8KU8Cf9AqX/wLl/8AiqD8E/ApBA0uYZ7i7l4/8eo+swCx0Fj4W8DanZx3dhoHh66tpBlJYbKF1b6ELVj/AIQfwl/0K2if+C+L/wCJry34X28vhT4u+IvCMFzJLpqwmZFc9CChU/Xa5BPfAr3Ct07q4jB/4Qfwl/0K2if+C+L/AOJq5Y+HdD0uTzNP0bT7ST+9b2qRn8wBWlRTAKKKKAPHvjf/AMhjwT/2EG/9Cir26vEfjf8A8hjwT/2EG/8AQoq9uoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigCC9vbbTbGe9vJlhtreMySyN0VQMk14FPqvi343arc2ulTyaN4TgfY8hyGl9nwfnY9doO0cZycE9F8ftXujpOjeFrLiTWbrDkHqqFdqke7Op/wCAV6F4e0K08NaBZ6RZLiG2jCbscu3dj7k5P40AcXpnwO8E2EKrcWU9/KBzJcXDjJ+iFRWj/wAKh8B/9C9F/wB/5f8A4qu2ooA4n/hUPgP/AKF6L/v/AC//ABVH/CofAf8A0L0X/f8Al/8Aiq7aigDif+FQ+A/+hei/7/y//FUf8Kh8B/8AQvRf9/5f/iq7asLxH4y8P+E4421rUo7ZpATHHgu7j1CqCce/SgDG/wCFQ+A/+hei/wC/8v8A8VR/wqHwH/0L0X/f+X/4qqf/AAu7wH/0FZf/AAEl/wDiaP8Ahd3gP/oKy/8AgJL/APE0AXP+FQ+A/wDoXov+/wDL/wDFUf8ACofAf/QvRf8Af+X/AOKqn/wu7wH/ANBWX/wEl/8AiaP+F3eA/wDoKy/+Akv/AMTQBc/4VD4D/wChei/7/wAv/wAVR/wqHwH/ANC9F/3/AJf/AIqqf/C7vAf/AEFZf/ASX/4mj/hd3gP/AKCsv/gJL/8AE0AXP+FQ+A/+hei/7/y//FUf8Kh8B/8AQvRf9/5f/iqp/wDC7vAf/QVl/wDASX/4mj/hd3gP/oKy/wDgJL/8TQB534P8E+HdS+MHijRbzTEl06zRzBAZHAQh0A5ByeCepr1D/hUPgP8A6F6L/v8Ay/8AxVeUeEvH/h3Svi14l168vHTTr5HEEghcliXUj5QMjgHrXpf/AAu7wH/0FZf/AAEl/wDiaALn/CofAf8A0L0X/f8Al/8AiqP+FQ+A/wDoXov+/wDL/wDFVT/4Xd4D/wCgrL/4CS//ABNH/C7vAf8A0FZf/ASX/wCJoAuf8Kh8B/8AQvRf9/5f/iqP+FQ+A/8AoXov+/8AL/8AFVT/AOF3eA/+grL/AOAkv/xNH/C7vAf/AEFZf/ASX/4mgC5/wqHwH/0L0X/f+X/4qj/hUPgP/oXov+/8v/xVU/8Ahd3gP/oKy/8AgJL/APE0f8Lu8B/9BWX/AMBJf/iaALn/AAqHwH/0L0X/AH/l/wDiqrXnwW8CXcZVdIe2bGA8FzICPwJI/SmD42+Ayf8AkLSj/t0l/wDia7LRtd0vxDp4vtIvYru2J274z0PoQeQenBoA8XvtD8W/Be4Gr6Dfy6r4bD/6RZzE4jUn+JRwD/tqBz1GOD7Z4W8Tad4u0C31jTJN0MowyH70TjqjDsR/gRwRVmeCK5t5IJ41kikUo6MMhlIwQa8b+Fxk8G/FzxD4JEh/s6ZTcWyuckEBWXHv5bEH12D0oA90rg/jN/ySTXv9yL/0cld5XB/Gb/kkmvf7kX/o5KAL3wu/5Jh4d/681/rXXVyPwu/5Jh4d/wCvNf6111AHhnw3/wCS2+PP+u0v/o6vZq8Z+G//ACW3x5/12l/9HV7NQB4j4V/5OS8S/wDXvJ/7Sr2mvFfC7Bf2k/EYYgFoJAAe/wDqz/Kvaq4MT8ZSOb8b6ibLw/8AZYpkhuNSmWxikZgoj3/ffJ/uoHb8KytCudJ0LxvNomnXFubLVLdbi2jhkDKksShJFGPVBG3/AAFq2L3QDq/i2K81GCGbTbK1KW8MoDh5nb53KnjhVUDP95qr6/4UtmtLe70PTbKDVLG5jubcxxrFvwcMhYDoyFh+I9KhNW5QIrO717xLLe3mnanBp1hBcSW1uhtRM0xjYozuSR8pYEADBwOvNYuia1qOn6Nq+IIF1i88QSWcSMSYhMyrlj3KAKzY6kDFbNjBrnhiS6sbLRv7SsZ7qS5t5UuUiMPmMXZJA3YMWwV3cHpxzTtvCetLo9080tq2rprJ1W2OT5TNhQUJxkLgumcZ6H2qtPkBH4ot/EFjp9iLzUYdStZtTsVlP2YQtC32mIhhgnK5G3B55Bz1rvyQBk9K4vVYvEviWC0gOkLpcNvfW9xP59ykjTLHKrEJsJAHG7JwflAxzx1OqWI1PSL3T2kaMXUDwl16ruUrke4zUS2VwPNreUX15PoEICaDq+pNd2+qTAr553CWSKPjliwO1zgFc4ztr0+2uYLyBZ7aZJomJAeNsg4ODz9QRXD3Nj4k1Lw2vhmfQYIXSFIV1MXSmGMoBtlRRiQMMAgYGDj5sc10XhPT73SPD8Gl30cXmWeYlliPE6jpIQeQx6kHvmqnZoDj9S0a51H4i69faYyprGnWllPZMxwrH98Gjb/ZccH8D2q7q+tW+vweC9Qtgy79cRZIn+9DIsMwZGHqDkVv2Gk3Vv421rVZAv2W7tbWKIhuS0fmbsjt94Vja14OvZPGmlatpkiLY/bkutQtmOB5iRsiyp7kNhvXCntT5k3r/WgFyK71vxJf37aXqcOnafZXD2iN9mE0k8qcOTk4ChsqAOTgnI4rPu/E+vxWNtaLFajWYtYTTZ+D5MgaIusgHUKQUYgHIwRmr8VvrXhi9v49P0j+1dPvbp7qMRXCRSQO/Lhg5AKlskEEnkjHFQR+GtVkNpe3Zga+l1pNRuljY7Io1iMaopP3sKEGcDJyaSt8gJ7u48R2mo6To8eoW89xexXEk949sFEQQx4KoDz94gAnqwJzjBrW1x4ol8SXvhxtWt8W8Ed2NQFoPMKOWUR7M7c5Rju9OMd66G6sJ5vFGmX6BfIt7a5ikJPO5zEV4/4A1Q22l3MXjbUdVYL9lnsbeBDnncjyluPo60rqwCeGL+/uotRtNSlimutPvWtWnij2CUbEkVtuTg7ZAD7itysjRdOuLG/12aYKEvNQ+0Q4Ocp5EKc+hyjVr1Et9BniOm339m/tD+KLv7Lc3Xl2JPk2se+R/lh4Ud6yfFfx712S4kstF00aVsJR3uk3zg/7p+VT7EGug8Lusv7SniRo2DqLRgSvOCBCD+vFen6/4R0HxRbmLWNMgueMCQrtkX6OMMPzr04fCiDyjT/jzHY6fBav4c1S5eJArTTXALyHuxO3qTWlp/7QegzXawalpV/YAnBk4kCe5AwcfQGvV7CzXT9Pgs0lllSBBGrzNucgcDJ7n3qvq+h6Xr1m9pqthBdwsCMSoCR7g9Qfcc1QEumapY6zp8V/p11FdWsoyksZyD/9f2q3Xg1hFc/Bz4o22li4kl8Na0wCBznYSdoJ/wBpSRkjqp9envNAHj3xv/5DHgn/ALCDf+hRV7dXiPxv/wCQx4J/7CDf+hRV7dQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHiPxe5+K/w9B5H2yPj/tvHXsNeP/F3/krPw9/6/I//AEfHXsFABRUN3d29hZzXd3MkNvCheSRzhVUdSTXj9/8AGLW9f1GWw8A+HXvxEcNdTxsykeu0EbQexY/hQB7NTWdEKhmVSx2rk4yeuB+Rrxb+2vjkf+YDZ/lF/wDHKw/GGp/FefwtfL4i0axi0wKGllJiBjII2spEmd2cYx3oA+h68E0zSLPxv8ffEKa9F9qgsEfyoGPyHYyIoI9OScdzVL4aa38VrgQJYQPf6USP3uqZEYX/AGZD8xH03Y9K2Ph0ZD8d/GBmVFlMc29UYsoPmpnBIGR+ArOq7QbQI9I/4V/4P/6FnSv/AAFT/CmTeBfBdvBJPN4c0iOKNS7u1sgCqBkk8V01ch8QdTtYNMs9IunZItVuBDOyKzFbdfmlOFBPKjZ/wMVwRcm7XKKnhzQfAnifSRqNl4VsYk8xo2iuLJFkRlPQgZxkYI9iK1/+Ff8Ag/8A6FnSv/AVP8KxtF1/TB8Q7i1sLktaatbLKqGF4wtxENrAbgPvR7Tx/wA8zU+i2N34qsjrt3rGpWzyzS/ZYbO4MccMauyrlcYdjjJ3gjJxjAqnzLW+gDtI8L+B9aguZbbwtp6rb3U1q/mWkYJeNyjEYzxkcU7U/CngjSltDP4W05vtV1HapstEOGc4BOccVz2g3upQaHFpMd0Ir/U/Ed7bTXcSgFAryPIyA5AJCEDOcbs9q0fEWhzaPceH2t9Uv7m1fWbYTRX1w05zuyGVm5HpjOOenFPXmtcDe/4V/wCD/wDoWdK/8BU/wrm47T4fyXwhTwhAbNrj7Kuo/wBnp9mM27Zs3dfv/LnG3PGa9Avby30+xnvbuVYraCNpJZG6KoGSfyrziwhuoNQsYNSjk0/wvfXxvLKBsFxOXEiRzN0RWfLqoyc4UnsVBt7sDq/+Ff8Ag/8A6FnSv/AVP8KxLbSfh9c+LLzw0PDWnJqFrEkpD2kYWVWAPyHqSMjOQOveu20++t9T0+3v7Vi9vcRrLExBG5SMg4PtXB3Ghyax4t8UyWciwarZy2dxY3DDhJBCeG9VYZVh6H2FKLbvdgaF/wCGPA+najpljN4W09pdRmaGEpaRkKVRnO7PQYU9M81o/wDCv/B//Qs6V/4Cp/hWDPrcev6v4KuxG0M6ajcQ3Vu33oJlt5A6H6H8wQe9XNKtLjxlFc6tdarqVrB9rmhs7exuTAqJG5j3Nt++xKk/NkcgY9W+ZLVgaX/Cv/B//Qs6V/4Cp/hR/wAK/wDB/wD0LOlf+Aqf4VzU+o69dSaNpjanJDew65NYT3UQC+dELd3DFfu7thU4IIDDOO1a1xpt4viPT9Bg1nUY7A2M89w5uC08h8xMASHlfvnkdAMDFFpLqBf/AOFf+D/+hZ0r/wABU/wo/wCFf+D/APoWdK/8BU/wrIstFvpvEOqaFLr+qtpVtDBPEBcsLjdJvBBmHzlR5ZIGc/NyeK1vB13cyw6vY3NzLc/2bqUlpHNMcyMgRHXce5G/Ge+KT5l1AR/h74OdGQ+GtLAIwdtsoP5gZFea/C2H/hHvjJ4n8OWLuNMWKRliZs4KOm3n2DsK9vrxXwT/AMnG+KP+uE3/AKHFW2Gk3J3Yme3143MNv7VGnY43WbZ9/wDR5P8ACvZK8buP+TqNM/682/8AREldgj3GuD+M3/JJNe/3Iv8A0cld5XB/Gb/kkmvf7kX/AKOSgC98Lv8AkmHh3/rzX+tddXI/C7/kmHh3/rzX+tddQB4Z8N/+S2+PP+u0v/o6vZq8Z+G//JbfHn/XaX/0dXs1AHmfj34VS+Itcj8Q6Bqh0rWVADyAsBJgYDbl5Vscd8jFYP8Awrr4rf8AQ9p/4Ezf/E1pePfiPrsHitPCHg2zS41UKGnldQ2wkbtoBIAwCCSeOcVk/aPjp/ds/wDyWqJOC+Iai3sSf8K7+K3/AEPaf+BM3/xNH/Cu/it/0Paf+BM3/wATUf2j46f3bP8A8lqPtHx0/u2f/ktS5qfkPkl2JP8AhXfxW/6HtP8AwJm/+Jo/4V38Vv8Aoe0/8CZv/iaj+0fHT+7Z/wDktR9o+On92z/8lqOan5ByS7En/Cu/it/0Paf+BM3/AMTR/wAK7+K3/Q9p/wCBM3/xNR/aPjp/ds//ACWo+0fHT+7Z/wDktRzU/IOSXYk/4V38Vv8Aoe0/8CZv/ia5ezs/iPe+Pr7wgnjKZb2zh815muJPLIwhwOM/xjt2NdJ9o+On92z/APJasO28M/Fu18WXXiaG2thqtzH5cspkgIK4UfdzgcItHNT8g5JdjoP+Fd/Fb/oe0/8AAmb/AOJo/wCFd/Fb/oe0/wDAmb/4mo/tHx0/u2f/AJLUfaPjp/ds/wDyWo5qfkHJLsSf8K7+K3/Q9p/4Ezf/ABNH/Cu/it/0Paf+BM3/AMTUf2j46f3bP/yWo+0fHT+7Z/8AktRzU/IOSXYk/wCFd/Fb/oe0/wDAmb/4mj/hXfxW/wCh7T/wJm/+JqP7R8dP7tn/AOS1H2j46f3bP/yWo5qfkHJLsSf8K7+K3/Q9p/4Ezf8AxNI3w5+KrKVPjtcHg4upgf8A0GmfaPjp/ds//JakNz8dApISzOB0H2bn9aOan5ByS7HafDn4bQ+B0uru4vDfatd8TXBBAC5ztGeTk8knrxXd15p8M/iJqPiPUb7w94is1ttbsQWbau0OoIByvYgkdOCDXpdaEhRRRQB4x+0IoXT/AA7OBiVLxwrdxkA/0H5V7PXjX7Qv/II0D/r9b/0GvZaAPHvjf/yGPBP/AGEG/wDQoq9urxH43/8AIY8E/wDYQb/0KKvbqACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA8S+Lv8AyVn4e/8AX5H/AOj469grx/4u/wDJWfh7/wBfkf8A6Pjr2CgDxr40X19rOveH/AlhJ5Y1F1luCO4LbVz7DDsR7D0r1LQPD+neGdHg0vS7cRW8QxnHzOe7Me5PrXl2v8/tNeHAecWJ6/7k9eyUAFQ3Vna30ax3dvFPGrBwkqBgGHQ4PcVNRQAAADAGAK8P8ESx2f7QfiyC5dYpZ1mESOcFyZEcAevy8/SvcK8+8d/CfTfGd+mqQ3sumaqoCm4jXeHA6blyOR6gj8eKmceaLQHeVkx6PL/wlc+tT3AdBaLa20IX/VDcWkJPcsQn4IK8t/4URrH/AEPt1/4Dv/8AHaP+FEax/wBD7df+A7//AB2uZYZrqO56j4g0VtYgs2hlWG8sruO6t5WGQCpwwIHZkLL+NZdvofiDRftFnol9p406WV5YRdxO0lsXYswG0gOu4kgHGM4ya4L/AIURrH/Q+3X/AIDv/wDHaP8AhRGsf9D7df8AgO//AMdprDtK1wudrbeBprTQFs4tTJ1C31GTUbW8ePOJGLH51yNwIZgcY68Y4qW78P69rd3p0+rX9jFHYXcV1HBZxviRlPJZmPpkAY4JyScCuF/4URrH/Q+3X/gO/wD8do/4URrH/Q+3X/gO/wD8dp+wl3C565q+mQa1o95pl1u8i7haFypwQGGMj3rmbnw74k1fShoesajpr6cwEdxPBbsJ50HbDEqjHAywzjsB24n/AIURrH/Q+3X/AIDv/wDHaP8AhRGsf9D7df8AgO//AMdpLDtdQueraDp91pWjwafdXCXH2YeVFKqbCYhwm4dNwGAccHGeKj0/R3svEGs6mZlddQMJVAuCnlpt5PfNfPegeBdX1zx7rPhceK7uE6YrN9p2u3mYZV+7vGPvep6V2X/CiNY/6H26/wDAd/8A47R9WeuoXO9v/BaXPjrTfEttdGAwMzXVvjKzt5bIjezAMQT3AHpTk0TXdGubxdAutP8AsN1M9wIL2NyYJHOXKlTypJJ2nGCTzXAf8KI1j/ofbr/wHf8A+O0f8KI1j/ofbr/wHf8A+O0/YS7hc7608HG0OkSfbTNcWt/LqF3M6YNxJJG6NgD7oy4wOcBQPetl9MZvEkOq+aNsdnJbeXjklnRs5/4B+teUf8KI1j/ofbr/AMB3/wDjtH/CiNY/6H26/wDAd/8A47SeHk+oXPV7bTGg8QahqZlBW6ggiCY5XyzIc599/wClQ6Hoz6RcaxK0yyDUL9rxQFxsBjRNp9fuZ/GvLv8AhRGsf9D7df8AgO//AMdo/wCFEax/0Pt1/wCA7/8Ax2j6s+4XPaK8S8ASJeftCeKbm2cSwCGYeYhyv+sjHX6g/lUp+A2rMCreO7oqeCDbPyP+/teh+BvAOleBNOkgsWkmuJ8Ge5lxucjoAB0AyePfvV0qPs3e4NnVV43cf8nUaZ/15t/6Ikr2SvG7j/k6jTP+vNv/AERJW4j3GuD+M3/JJNe/3Iv/AEcld5XB/Gb/AJJJr3+5F/6OSgC98Lv+SYeHf+vNf6111cj8Lv8AkmHh3/rzX+tddQB4Z8N/+S2+PP8ArtL/AOjq9mrxn4b/APJbfHn/AF2l/wDR1ezUAeGaD/ycrr3/AFxf/wBBjr2avGdB/wCTlNf/AOuL/wDoMdezVw4j4zro/CFcpeeLprL4hW3h6SzX7FPAh+1huUmfzCikehETfjiurrg9a02fVPFHiO3tCFvU0uymtXP8MySzuh/76A/DNZwSd7lyb6HU+IdWOiaFdX6Q+fMgCwQ5x5srEKifixA/Gk8N6pLrfhvT9TmiWKW5hWRo0OQpPYVz8OpQ+MNb0FYGP2a0t11W5QdpGBSJD7g+YSPVBWb4d/49vh7/ANcJ/wD0VT5NPMXNqehXEpgtZZQMlELAHvgZrGs/EXnx+HRJb4k1i3835W4jIiDke/XFU9cZT4w09MjcNI1Akexa3/wNc9DoekX8ngJ7zS7K5aaw2yma3RzIFtwVDZHIB6Z6URirag5O+h6Dby3L3d4k0SJDG6iBlbJdSikkjsdxI+gFVNf1V9H02O6jiWRmureDaxwMSSpGT+AbNZthLcwav4rktLYXM63cOyEyBN3+jw/xEHHFUfFc2pXvhH/S7QabcnUrJY9sqzY/0iLDdAOvY+lJR95A3odpWT4a1h9c8O2upzRpC0wclVOQMMV/pVT+xvEP/Q1yf+AEX+FcNYtczeE/Bmlrai/guZrl57ZpREtwYy5CsSCCM/Nt6HbQopoHJpnq0FxDcx+ZBNHKmcbo2DDP1FJ9qtzc/ZvPi88Dd5W8bseuOtcGRNo2vW2oPpNh4etDBOt40V2h82NYy4YRhRuZCuc4JAJ7Vla9ZRWfw7ur2w8OLavawLPDqN48a3TOCCJcpubeTzyQeecdKahcOc9Tmnit4jLPKkUY6u7BQPxNZUWsvL4un0YRoYY7CK7WUHkl3dcfTCA/jWTHZWut+PdWTU4o7qPTre3W1t5lDonmBy0m08bjgLn0XHeq2i6baaX8UdWgskWOFtKt38lOFiJlkyFH8I74HdjS5VZhdnb0UUVBZ5F4f/5OZ13/AK8//acNe1V4t4f/AOTmdd/68/8A2nDXtNenD4UcMviYUUUVRJ41+0L/AMgjQP8Ar9b/ANBr2WvGv2hf+QRoH/X63/oNey0AePfG/wD5DHgn/sIN/wChRV7dXiPxv/5DHgn/ALCDf+hRV7dQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHiXxd/wCSs/D3/r8j/wDR8dewV4/8Xf8AkrPw9/6/I/8A0fHXsFAHjevf8nN+Hf8ArxP/AKBPXsleN69/yc34d/68T/6BPXslABRRRQAV4X4s1bxL4++JF54R0PVH0zTtOUmeSNipYjAYtt5b5mAC5xxmvdK8M8Ef8l48Zf7s3/o1KqKu7EzbUW0M/wCFO+I/+h7u/wDvmT/45R/wp3xH/wBD3d/98yf/AByvYaK39nE5PbT7nj3/AAp3xH/0Pd3/AN8yf/HKP+FO+I/+h7u/++ZP/jlew0UeziHtp9zx7/hTviP/AKHu7/75k/8AjlH/AAp3xH/0Pd3/AN8yf/HK9hrnfGzSjw4EhuJ7dpb20iaS3laNwr3EasAy4IyCR+NDpxQ1Vm3a5wH/AAp3xH/0Pd3/AN8yf/HKP+FO+I/+h7u/++ZP/jlegQ+D7WCeOUarrzFGDBX1adlODnBBbBHtS3Hi22juporbTtSvordzHcXNpAHjiYfeHUFiO4UNjp1pckeqD2s3szzaL4H6vDcyXMXjGSOeT78qQuGb6nfk1Y/4U74j/wCh7u/++ZP/AI5Xpd54jsLSys7iMy3hvhm0itU3vOMbsqOBjHJJIA9aNN8Q2uoNPFJFcWNzboJJre8QI6Ic4bglSvB5BI4o5IB7Woeaf8Kd8R/9D3d/98yf/HKP+FO+I/8Aoe7v/vmT/wCOV2eoeMreTR7yeKz1OG0a3fyNSaDbCxIO0g53AE4wxUDkc1u+HpZJvDWlSyu0kj2cLO7nJYlASSe5o5IMHUqJanl//CnfEf8A0Pd3/wB8yf8Axyj/AIU74j/6Hu7/AO+ZP/jlew0U/ZxF7afc8e/4U74j/wCh7u/++ZP/AI5R/wAKd8R/9D3d/wDfMn/xyvYaKPZxD20+546fg74kAJXx3dlh0yJBz/38ra+EvirXD4g1XwV4iuGu7vT1Z4bhm3EqrBWBY8sPmUgnnGfbHpFeReBP+TiPE3/XvN/6HFWdSKS0NaNSUnZnuVeN3H/J1Gmf9ebf+iJK9krxu4/5Oo0z/rzb/wBESVkdB7jXB/Gb/kkmvf7kX/o5K7yuD+M3/JJNe/3Iv/RyUAXvhd/yTDw7/wBea/1rrq5H4Xf8kw8O/wDXmv8AWuuoA8M+G/8AyW3x5/12l/8AR1ezV4z8N/8Aktvjz/rtL/6Or2agDwzQf+TlNf8A+uL/APoMdezV4zoP/Jymv/8AXF//AEGOvZq4cR8Z10fhCqcWmW8WsXGqLv8AtFxDHA+T8u1CxXA9cu1XKKwNTK0Xw7p2gNfNYRMhvbhriUs2fmPOB6KCTgdsmqsvhGwbSdNsYZrq2OmMGtLmFwJYjgr1IIOQSCCCD6VvkhQSSABySe1ZHh3xFZ+JrCS7sknRI5TGVnQK3QMDjJ4ZWVh6giqvLcmy2IrfwtaRaidSnuru7v2t3tnuJ2Xc0bbTjCqFAG3jAHU9c0XXhWyubHTLZJ7y3bTFCW01vNtkUbNmCcYOR14rThv7a4vrmzil3XFqEMybSNu4ZXnGDkA9KLC/ttTskvLOXzYHJCvtIzgkHgjPUGi8gshLbT4LS8vbqPd5l5IskuTxlUVBj04UU3U9Nt9WtVtrnf5azRTDYcHdG6uv4ZUVcoqbvcdgrBbwjph0K10pTcJHZyedbTpJiWF8k7lbHX5iOmCDg1q3eoWtg1stzLsN1MIIRtJ3OQSBwOOFPJ44pI74SapPYfZ7hTDEkpmZMRvuLDardyNvI7ZHrTV1sDszLTwpaySzy6nd3mqyTW72pN4yYSJ/vKqxqqjPGTjJwOaqT+BbS90w6ZqGq6re6eI/LS3mmQKgxgHKoGYjtvLYIB6iupop8zDlRi3fhqK4ube8h1C+tNQhhEBvIGTfKg7OGUo3OTyvBJxjNLpXhmy0nUrjUo5bma9uYxHPNPJuaTBJBPGB1xgYAAAAFbNFLmewWQUUUUhnkfh//k5nXf8Arz/9pw17TXi3h/8A5OZ13/rz/wDacNe016cPhRwy+JhRRRVEnjX7Qv8AyCNA/wCv1v8A0GvZa8a/aF/5BGgf9frf+g17LQB498b/APkMeCf+wg3/AKFFXt1eI/G//kMeCf8AsIN/6FFXt1ABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAeJfF3/AJKz8Pf+vyP/ANHx17BXj/xd/wCSs/D3/r8j/wDR8dewUAeN69/yc34d/wCvE/8AoE9eyV43r3/Jzfh3/rxP/oE9eyUAFFFFABXhngj/AJLx4y/3Zv8A0ale514Z4I/5Lx4y/wB2b/0alVD4kZ1fgZ69RRRXUcIUUUUAFc147ijuPDaQzRpJFJf2SOjqCrKbmMEEHqK6WkZFcYZQwyDgjPI6UNXQ07O5lW3hbw9ZXMdza6DpcE8ZyksVnGrKfUEDIrjPDjxWGiz2194wvNKuLGaYXVq/2RfLO9m3DfEWKsCGByc5r0mq0+n2VzOk89nbyyp92SSJWZfoSOKTXYal3POra2j0y58PTvq+p6VYXFpcRQ3E6wbxI8okCuWjKLvXkAAfcA9qsapZDV/7cttO1m/1nUE0eeDzG+z+UhkwRHmONcudnGScDPrXoc0MVxE0U8SSxsMMjqGB+oNNt7W3s4RFbQRQRDkJEgUfkKXKVz9TlNS8S6HdeBrjyLmCUz2bQR2asPMZyhXy9nUEHgjHGDnpW54a/wCRV0f/AK8of/QBVxbCzW6a5W0gFwww0ojG8/U4zU6qFUKoAAGAB2ppEtq1kLRRRTJCiiigAryLwJ/ycR4m/wCveb/0OKvXa8i8Cf8AJxHib/r3m/8AQ4qyq7HRh/iZ7lXjdx/ydRpn/Xm3/oiSvZK8buP+TqNM/wCvNv8A0RJWB1HuNcH8Zv8Akkmvf7kX/o5K7yuD+M3/ACSTXv8Aci/9HJQBe+F3/JMPDv8A15r/AFrrq5H4Xf8AJMPDv/Xmv9a66gDwz4b/APJbfHn/AF2l/wDR1ezV4z8N/wDktvjz/rtL/wCjq9moA8M0H/k5TX/+uL/+gx17NXjOg/8AJymv/wDXF/8A0GOvZq4cR8Z10fhCiiisDU5Xx9qcNnoC2Es7wtqkq2e9FLMkbcyMABnhA34kVlabrmj2/j+CPTbhja6raC3MZhdFSaEZT7wA+aMsP+ACuqbSZJvFMerTTK0NvamC3h28o7MC759SFUD6H1pPEWjvrOmLDBKsF3DNHcW0zLuEciMCDjuCMg+xNaJpKxDTvc5rS9BaTxr4jH9s6qu1YOVnAzuRuvy9u3pWZpFxP4d+G8Fxb6hetcX1yLWJnQ3HkFpnUskarknGTjByQK7GLR9QtfFtxqkF3bfYbxI1ubeSFjIGRWClHDYHUZyD0rOtfCN+nh+50W41ODyY5hPp1xDblZYHEhkBfLENhto4AyAc9afMuvkLlfTzM6C6On6hYyaTd+KLtpbmOK6g1Cxu2jeNiFZw0kYWMrndwQMAjHSrGj6de+Izq0uoa3qUcUGqXMNtHZ3Bg2KrkDJXlvTByMAcda049N8R313Z/wBrX9lHa20glZLFHVrhl+6GLH5VzyVGc4AzitDQ9JbSIr1GlEn2m9mugQMbRI27H4UnJW8wS1OBnW817RvCt1e6nercLrD2bvA4QN5bToJMY4chBz05PFbGr65faHqfiHyZnn+x6VaG2jnbK+a7yoGb6kLn6Vc/4RC8h8P2dna38CXtlqUmoQyywloyWkkbayhgcYkI4ParVz4UGp3eqyalMrx6lp8NnKsKlCrIZCWUknHL5HpjvVc0f69QszP1XRtR0LQ7vWrXXdSuNTtIGuJFuJ90E+0bmTyvuoCAQNuCOOabbLd+JvEeqwyane22mRwWsscNrMYn3OhJ+deQOOgIyT7VYudC8S6rpx0bVNTsG0+QeXc3EELrPPF3XBO1Cw4JGepwBWzp2j/YNZ1K9V18q7WBUiVceWI1K/1qeay8wtqVPCz3UT6xplzdzXY0+98mGac5kMbRRyAMe5HmEZ6nAroKztO0xrHUdXujKHF/crOqgY2AQxx49/8AV5/GtGok7stbBRRRSGeR+H/+Tmdd/wCvP/2nDXtNeLeH/wDk5nXf+vP/ANpw17TXpw+FHDL4mFFFFUSeNftC/wDII0D/AK/W/wDQa9lrxr9oX/kEaB/1+t/6DXstAHj3xv8A+Qx4J/7CDf8AoUVe3V4j8b/+Qx4J/wCwg3/oUVe3UAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB4l8Xf8AkrPw9/6/I/8A0fHXsFeP/F3/AJKz8Pf+vyP/ANHx17BQB43r3/Jzfh3/AK8T/wCgT17JXjevf8nN+Hf+vE/+gT17JQAUUUUAFeGeCP8AkvHjL/dm/wDRqV7nXhngj/kvHjL/AHZv/RqVUPiRnV+Bnr1FFFdRwhWX4mvp9M8K6vf2rBbi2s5ZoyRkBlQkcd+RWpWF42/5ETxB/wBg64/9FtQ9hrcrWeneIbqxt7hvFDqZY1cgWMXGQD6Vp6hrmm6IkEepX6JNIPlXaS8mOpCqCfyHFYuleD7U6bZTf2rr2TDG20atPt6A4xuxj2qxoohPjTxI02PtwaAR56i28pSuPbzPNz71OpTszXh1rTbnTk1CC9hltHdY1ljbcpZmCAcd9xA9qZYa/pWpzeVZX0M7kvt2Hhtu3dtPRgNy8j1riNagiuNQ8UWsQP2CSfTFnCHC+e0yiTGOjbPLz36V0viaBLJNJ1aPES6XdJuCjAED/unGPQBg3/AKLsOVG3Hf2kt9NYx3EbXUKq8kIb5kVuhI98VXudd0q0tprm4v4Eihm8h2LdJOPk9256DmuLhv00i4g8Y3g2W+oz3Szv8A3YNuYGP/AAGBce8h9atWFo1lH4etPsUU2tTrc6iZLiVkSF3IMpIAO9gZgoHpnkUcw+Q6jTtf0rVo53sb2OX7P/rlwQ0fcblIBGcHtzTIfEuizmXy9StyIYRPK27CxoQCCxPC8EHB5wa5qNrsePdRS9urWacaH8y20RQIPMOA2WYk8k544PT1he1gtPAXhCERomnvcWTXoI+Vgy5y/rmUpnPrRzMOVGtqHjLT5rFDo+oRSXP2q1QqVIJje4jjYgMORhiMj1FdVXJ+PVsvsOkG42C4Gr2Ytc9d3nJuA/4Du/Kusprcl2srBRRRTJCvIvAn/JxHib/r3m/9Dir12vIvAn/JxHib/r3m/wDQ4qyq7HRh/iZ7lXjdx/ydRpn/AF5t/wCiJK9krxu4/wCTqNM/682/9ESVgdR7jXB/Gb/kkmvf7kX/AKOSu8rg/jN/ySTXv9yL/wBHJQBe+F3/ACTDw7/15r/Wuurkfhd/yTDw7/15r/WuuoA8M+G//JbfHn/XaX/0dXs1eM/Df/ktvjz/AK7S/wDo6vZqAPDPGum694F+KEnjfTNMk1LTrtMTogJ8vKhWUkZK/dDBsY7U/wD4XvL/ANCfe/8Af/8A+wr3CiolTjJ3aLjOUdEeH/8AC+JP+hPvf+//AP8AYUf8L3l/6E+9/wC//wD9hV/43eOLjw9caHpunybblZ1v5cHHyo3yKfYkNn/dr1XSdTt9Z0i01O0bdb3UKyxk9cMM4PvU+wp9h+1n3PG/+F7y/wDQn3v/AH//APsKP+F7y/8AQn3v/f8A/wDsK9woo9hT7B7Wfc8P/wCF7y/9Cfe/9/8A/wCwo/4XvL/0J97/AN//AP7CvcKKPYU+we1n3PD/APhe8v8A0J97/wB//wD7Cj/he8v/AEJ97/3/AP8A7CvcK8W0/wCJQuPj1cWAlLaXMg0yPnjzEJIb8XLL9CKPYU+we1n3IP8Ahe8v/Qn3v/f/AP8AsKP+F7y/9Cfe/wDf/wD+wr3Cij2FPsHtZ9zw/wD4XvL/ANCfe/8Af/8A+wo/4XvL/wBCfe/9/wD/AOwr3Cij2FPsHtZ9zw//AIXvL/0J97/3/wD/ALCj/he8v/Qn3v8A3/8A/sK9wrnfHfiMeFPBmpasGUTxx7LcN3lbheO/Jz9AaPYU+we1n3PMf+F8S/8AQn3v/f8A/wDsKQ/HiXHHg69z/wBdz/8AEV1HwS8UN4g8EC0uZzLe6bJ5MhY5YxnlCfwyv/Aa9Jo9hT7B7Wfc8b+Fmia9qvjbVfHWu2L2Iu4jHbwupUtnbyAecBUAyeuc17JRRWqVtDMKKKKAPGv2hf8AkEaB/wBfrf8AoNey141+0L/yCNA/6/W/9Br2WgDx743/APIY8E/9hBv/AEKKvbq8R+N//IY8E/8AYQb/ANCir26gArz3xT441Lw38QLa0Nuk2gpp63N+yr+8gVpTH5o9VU7cj0ye1ehVw8kUc/xplhmRZIpPDW10YZDA3BBBHcUAdbf3Rh0e5u7dlYpbvLGw5BwpIPuKqeFtQn1fwjo2pXRU3F3YwzylRgbmQMcDsMmuQs5pPCY1DwXeO7WclnPNoc7tktCq/PbknktHnjrlMelaOg6ZFqnwp8NpJdy2UkGmWs8N3E+1oHWEYf0IwTkHggkHg0AdpRXnGg6zd+N9Qt7LVZUtba2QXKxQb0GrbXwsyE4PkZAO0ZJLDJ243+j0AFFFFABRRRQAUUUUAFFFFABRRRQB4l8Xf+Ss/D3/AK/I/wD0fHXsFeP/ABd/5Kz8Pf8Ar8j/APR8dewUAeN69/yc34d/68T/AOgT17JXjevf8nN+Hf8ArxP/AKBPXslABRRRQAV4Z4I/5Lx4y/3Zv/RqV7nXj3jXwB4osPGsnjDwRJG9zcDFxaFlUk4AJ+bCspwCQTnPI9nF2dyZrmi0emUV5D9t+N3/AEA7X/yD/wDHKPtvxu/6Adr/AOQf/jlb+1icvsJHr1RXVrBe2k1rcxrLBMhjkRujKRgg/hXk32343f8AQDtf/IP/AMco+2/G7/oB2v8A5B/+OUe1iHsJHrkcaRRJHGoVEAVQOwHSs7VfD2l600b31sWljGEljkeKRR6B0IbHtnFeafbfjd/0A7X/AMg//HKPtvxu/wCgHa/+Qf8A45R7SI/YzPT4NE02105bCCyiS1V1k8sDguGDBj3J3AHJ5zVq6tYL20mtbmJZYJkMckbDIZSMEGvJvtvxu/6Adr/5B/8AjlH2343f9AO1/wDIP/xyj2kQ9jM9RuNH0670tdMuLOKSxVUVYGXKgLgqMe2B+VM1bQ9O1uKNNQtvN8pt0bq7RuhPB2upDD8DXlSaz8ZpLyazTSbJrmFEeSMGHKq2dpP7zvtb8qn+2/G7/oB2v/kH/wCOUe0iHsZnpNt4a0ezaF4LCNJIQ6rJklyHGG3MTls8dc9KuNp1m+mjTntonsvLEXkOoZNgGAuD2xXlX2343f8AQDtf/IP/AMco+2/G7/oB2v8A5B/+OUe0iHsZnolp4S0OyYtFY7m3KwaaV5Sm1gwClydo3KpwMDgVtV5D9t+N3/QDtf8AyD/8co+2/G7/AKAdr/5B/wDjlHtIg6M3uevUV5D9t+N3/QDtf/IP/wAco+2/G7/oB2v/AJB/+OUe1iL2Ej16vIvAn/JxHib/AK95v/Q4qabz43sCBolsCeMjyOP/AB+uq+F/w91Hw1dX+v8AiG4WfXNQBDhW3eWpO5gT0JJA6cDAxUVJqS0NaVNxd2elV43cf8nUaZ/15t/6Ikr2SvG7j/k6jTP+vNv/AERJWRue41yPxR0ybV/hlr9pBzL9m80ADJby2EhA9yFxXXUhAIIIyD1BoA4D4L6xBq3ww0tYnUy2Qa1mUfwspyPzUqfxr0CvBtV8OeJvhB4mudf8JWr6j4buTuurAZbyVByQQOcDna+DgZDf7W1aftF+EpYQbmx1aCXHzKIkcZ9iH5/IUAZfw3/5Lb48/wCu0v8A6Or2avmrwf8AEnQtD+JHijX7xbv7HqckjQBIgXwZNw3DPHHvXoTfH/waBxFqjfS3X/4qgD1OivK/+GgfB3/PDVf/AAHT/wCLrL1n9ojSI7R10XSrye6IwjXQWONT6nDEn6cfWgDn/jH4etZ/H+kW0U811q+rzjzVLfLFFuVI0VR0HDEnuQTxXt/hjw7F4W0j+yrW4llso5Ga3WXlolbkpu/iG4sR7HHavnbwP430O08W3fi7xfc3l3q7k+QkMAZI8jBbkjtwAOAP09R/4X94M/uan/4Dr/8AFUAeo0V5d/wv3wZ/c1P/AMB1/wDiqP8Ahfvgz+5qf/gOv/xVAHqNFeXf8L98Gf3NT/8AAdf/AIqkPx+8G4+5qf8A4Dr/APFUAel3kU81lPFbTiCd42WOYpu8tiOGxxnHXFfNvhXwFpPiP4oa1ptheXqadpkZMV6sgMnnqVXfnGDl97fQV02sfFfXfHSvofgPRbxHmG2W7kwHjQ8cYO2P/eLfTmvQfh54HtfAPhxoZJY5L2b97e3PQEgcAE/wqM9fc8ZoA6+FZFhjWVw8gUB2C4DHHJx2p9eXeIPjt4X0i6a2sUuNVkU4Z7fCxZ9Ax6/gCPesj/hoOH/oVL7/AL/D/wCJoA9oorxf/hoOH/oVL7/v8P8A4mj/AIaDh/6FS+/7/D/4mgD2ivL/AI52+nv4L+06jdyL5LEWlqhx51wwwpPqFXecfr2OMfj3c3Q8nTfBt9PdNwieaW5+ipk/SotJ8DeK/iJ4gg13x8Da6dbnMOmgFdw9NuflB4yT8xxj0IANr4OeBjoOhWGumWaG8v7cm6t25R0LboyB1VgMfgSMd69UpFVUUKqhVUYAAwAKWgAooooAKKKKAPGv2hf+QRoH/X63/oNey141+0L/AMgjQP8Ar9b/ANBr2WgDx743/wDIY8E/9hBv/Qoq9urxH43/APIY8E/9hBv/AEKKvbqACsX/AIR//itz4k+1ddN+wfZ/L/6ab9+7P4Yx+NbVFAGB4x8K2vjDw/LplxK9vLkSW91H9+CUdHH5kEZGQSMjrSQeE7T/AIRPSfD19LJc21hDBFIF/drc+WoUB1ycqSASucHGDkZB6CigDO1TRLPVltfPV45bSVZreaFtjxMP7p9COCOhBINaNFFABRRRQAUUUUAFFFFABRRRQAUUUUAeJfF3/krPw9/6/I//AEfHXsFeP/F3/krPw9/6/I//AEfHXsFAHjevf8nN+Hf+vE/+gT17JXi/jSZNH/aG8K6jcnbbzW6whz0DMZE/m6/nXtFABRRRQAUUUUAFFFFABRRRQAUUUUAFI7rGjO7BUUZZicAD1parahYQapp1xYXQZre4QxyqrFSyngjI5GRxx60AfPvgz4kSXnxuur2d/wDQdYf7GgJwEUcQn68Af8DNfRdeB+HPCmh3vx08TaNNpsH9nwWW6CJBt8pgYMMhHKtyeRzyfWve1G1QMk4GMnqaAFooooAKKKKACiiigAooooAK8buP+TqNM/682/8AREleyV43cf8AJ1Gmf9ebf+iJKAPcaKKKACsW78IeGdQuWubzw7pNxO/LSzWUbs31JGTW1RQB89eAfDuiX3xf8aWN3pFhPaW0soggkt0ZIgJcDapGBxxxXq58B+ED/wAyvo//AIBR/wCFedfDf/ktvjz/AK7S/wDo6vZqAOd/4QHwh/0LGj/+Acf+FOHgPwgB/wAivo3/AIAx/wCFdBRQBz//AAgnhH/oV9G/8AY/8KP+EE8If9Cvo3/gDH/hXQUUAc//AMIJ4R/6FfRv/AGP/Cj/AIQTwj/0K+jf+AMf+FdBRQBz/wDwgnhH/oV9G/8AAGP/AAo/4QTwj/0K+jf+AMf+FdBRQBXs7Gz063FvY2sFrCOkcEYRR+A4ryT4t65qet+ItO+HmhyGOa+w15IDgbTnCnvtABY+ox717HXz7qfirTPCn7Q2tatrKzyQx26RReSgZlYxR44JHbd+dAHrPhH4faB4Os4ksbOOS7Vf3l7KgMrnuc/wj2FdTXlv/C//AAb/AM89U/8AAdf/AIqj/hf/AIN/556p/wCA6/8AxVAHqVFeW/8AC/8Awb/zz1T/AMB1/wDiqP8Ahf8A4N/556p/4Dr/APFUAepUV5b/AML/APBv/PPVP/Adf/iqP+F/+Df+eeqf+A6//FUAepUV5b/wv/wb/wA89U/8B1/+Ko/4X/4N/wCeeqf+A6//ABVAHqVFeW/8L/8ABv8Azz1T/wAB1/8AiqP+F/8Ag3/nnqn/AIDr/wDFUAepUV5b/wAL/wDBv/PPVP8AwHX/AOKrP1T4/adLELfw1o1/f6hJwizR7VB+iks304+tAFX46zjUtZ8LeHLb57ua48wqOqhmVF/M7vyr2yvJfh14C1mTxFL438ZMW1ebJt7dsZiBGNzDsQOAvYdeenrVAHj3xv8A+Qx4J/7CDf8AoUVe3V4j8b/+Qx4J/wCwg3/oUVe3UAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB4l8Xf8AkrPw9/6/I/8A0fHXsFeP/F3/AJKz8Pf+vyP/ANHx17BQBw/xP8Cf8Jv4fRbVlj1WzYy2kjHGf7yE9gcDnsQK5Dwv8ZxpCf2J48tbuy1K1Aja5MRbzMcZdRyD7gEHrxXs9ZmseHdG1+NY9W0y1vQn3TNEGK/Q9R+FAHNj4v8AgNlBHiGLBGeYJR/7LS/8Le8B/wDQwxf9+Jf/AImpD8KPAxOf+Edtv++3/wDiqP8AhVHgX/oXbb/vt/8A4qgCP/hb3gP/AKGGL/vxL/8AE0f8Le8B/wDQwxf9+Jf/AImpP+FUeBf+hdtv++3/APiqP+FUeBf+hdtv++3/APiqAI/+FveA/wDoYYv+/Ev/AMTR/wALe8B/9DDF/wB+Jf8A4mpP+FUeBf8AoXbb/vt//iqP+FUeBf8AoXbb/vt//iqAI/8Ahb3gP/oYYv8AvxL/APE0f8Le8B/9DDF/34l/+JqT/hVHgX/oXbb/AL7f/wCKo/4VR4F/6F22/wC+3/8AiqAI/wDhb3gP/oYYv+/Ev/xNH/C3vAf/AEMMX/fiX/4mpP8AhVHgX/oXbb/vt/8A4qj/AIVR4F/6F22/77f/AOKoAj/4W94D/wChhi/78S//ABNH/C3vAf8A0MMX/fiX/wCJqT/hVHgX/oXbb/vt/wD4qj/hVHgX/oXbb/vt/wD4qgDgvh7qllrXx+8Tajp04ntJ7BmjkAIDDdAOhweoNe314j8PtMs9H+P/AIm0/T4FgtIbBljiUnCjdAe/ua9uoAKKKKACiiigAooooAKKKKACvG7j/k6jTP8Arzb/ANESV7JXjdx/ydRpn/Xm3/oiSgD3GiiigAooooA8M+G//JbfHn/XaX/0dXs1eM/Df/ktvjz/AK7S/wDo6vZqACivGPGvi7xX4h8ft4K8HXAsmtlzcXJbaWOAT82CVUZA4GSap/8ACv8A4vf9DvD/AOB8/wD8bqJTjHRsD3OivDP+Ff8Axe/6HeH/AMD5/wD43R/wr/4vf9DvD/4Hz/8Axul7WHcdj3OivDP+Ff8Axe/6HeH/AMD5/wD43R/wr/4vf9DvD/4Hz/8Axuj2sO4WPc6K8M/4V/8AF7/od4f/AAPn/wDjdH/Cv/i9/wBDvD/4Hz//ABuj2sO4WPc68U0yxtNQ/aV8RQ3trBcxCyDbJow652Q84NV/+Ff/ABe/6HeH/wAD5/8A43VCL4R/EmHWJdXi8T2CalMuyS6W7mEjrgDBPl5/hH5Ue2h3FY9t/wCEY8P/APQC0z/wEj/wo/4Rjw//ANALTP8AwEj/AMK8h/4V/wDF7/od4f8AwPn/APjdH/Cv/i9/0O8P/gfP/wDG6PbQ7hY9e/4Rjw//ANALTP8AwEj/AMKP+EY8P/8AQC0z/wABI/8ACvIf+Ff/ABe/6HeH/wAD5/8A43R/wr/4vf8AQ7w/+B8//wAbo9tDuFj17/hGPD//AEAtM/8AASP/AAo/4Rjw/wD9ALTP/ASP/CvIf+Ff/F7/AKHeH/wPn/8AjdH/AAr/AOL3/Q7w/wDgfP8A/G6PbQ7hY9e/4Rjw/wD9ALTP/ASP/Cj/AIRjw/8A9ALTP/ASP/CvIf8AhX/xe/6HeH/wPn/+N0f8IB8XxyPG0Jx2+3z/APxuj20O4WPXv+EY8P8A/QC0z/wEj/wo/wCEY8P/APQC0z/wEj/wrz/4W+NNevNe1Pwf4pIk1TT1LrPgBmUMAQccH7ykHuDXqtaAZX/CMeH/APoBaZ/4CR/4Vbs9M0/Tt32Kxtrbd18iJUz+Qq1RQAUUUUAePfG//kMeCf8AsIN/6FFXt1eI/G//AJDHgn/sIN/6FFXt1ABRRRQAUUUUAFFFFABRRRQAUUUUAFFZcHiLSbnxDd6BFeI2qWkayzWxVgyowBBBIwRyOhOMjNWtS1G00jTbnUb6XyrS2jMssm0ttUDJOACT+FAFqikBBAI6GloAKKKKAPEvi7/yVn4e/wDX5H/6Pjr2CvH/AIu/8lZ+Hv8A1+R/+j469goAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAPHPCP8Aych4s/68W/8AQoK9jrxzwj/ych4s/wCvFv8A0KCvY6ACiiigAooooAKKKKACiiigArxu4/5Oo0z/AK82/wDREleyV43cf8nUaZ/15t/6IkoA9xooooAKKKKAPDPhv/yW3x5/12l/9HV7NXjPw3/5Lb48/wCu0v8A6Or2agDxHwr/AMnJeJf+veT/ANpV7TXi3hX/AJOS8S/9e8n/ALSr2muDE/GUjL8R6r/Yug3d6oDTKoSBP78rHbGv4sQKxfB39oaTeX/hvVtRmv7i3WO6t7mdyzyxOMNyf7siuPYFfao/EsF14i8UWGiWd69mlgg1G4uI0RykmSsK4cFef3jcj+EGs7WtI1Lw5qem+LLvxDdagljIILpZoIYwLaUhXP7tVztbY3OfumpSVrdwOlm8URi/urWx0vUdRNowW5ltETZG2M7cu67mAxkLuIzWT4d8UWw0XXdZu7ueWzTU5Fh3BncKRGFjVOucnAXHU4pvhXVtN0G21PS9WvrayvYL+5mf7RKsfmxyStIkgJxuBVgMjoQR2rnrWUSaPc6ytvLHZWnio386eWd3kFR85XrxvVyOox7U1FaoDoPEXiiYWNnA9jqmk3Fxf2awtPsXzVNzFvUNG7YJUtlWwSN3HBrt64Xxj4g0nULHTLSxuoL+aTU7KQG2dZBCouIzvYg/KD90Z6lq6/VXvI9HvX09Fe9W3kNurdGk2naD+OKhrRAefT3t6dV1C3OpX3/CUJqgFpZxzv5P2UuChMY+Qx+Xnc5GQ2RnOBXpleV/atBtPDVlrWjahEfEsQDlC265vZmAEkEyD5zuI6Y+UgEYArtfBeoyal4XtZbmd5b5CyXayDDxTAndGR/s5wPUAHvVTWlwOW1XWtX0j4i6rqCXM02jafaWpvbLLMFik8zdMi/3lKAnHVd3oK3/ABTfyLceFJLK7dYbrV41ZoZCFljMMrYOPvKcA46cCo9KAb4m+JlYAg2NiCD35mrl9Stbrw94n8M+HvLd9KOsrdadNnPlJ5coeA+m0sCv+ycfw07Jv5foB3N14mji1KfT7LTdQ1Ke2ANx9kVNsORkAtI6gtjB2gk4I4qCbxxo8GjW2qs1wbee5NqVEJ8yKUBiUZPvAgqRgAkkjAOazvDup2Hh+81zTNXvYLO6Ooz3itcyCMTQyNuVlJ4bA+U46beccVj7k1C8ttUiiZbG+8URS2u9ceYqW+zzAD2ZkJB7jB70lBAdbN4sgtvscdzpuoQ3d6JDbWjRoZZNhXPAYgcODyRgAk4xUMXjOGa9m05NH1T+1oQGfTykXmBCOH3+Z5e3tnf14qXUFVvHehEgErZXpGex3QD+tV7ID/hZ+stgZGlWgz/20npWVgNfRtZg1u0kmhingeGZoJoLhNskUi4ypAJHQg5BIIIrRrnfDP8AyFfFX/YXH/pLb10VRJWYzxzw1/ycv4i/68z/AOgw17Be39np1s1zfXUNtAv3pJpAij8TXimm295dftD+KIbC9+xXL2JCXHlCTYdsPO08GuX8ffDb4hfanv8AULibxBAhO2aFy7Iv/XLqv0UEV6cPhRB9KWV7b6jZQ3lpJ5lvMoeN8EblPQjPY1PXhuneCfiff6bbXdp48T7PLGrRjzpVwMdCNnBHTHapJ9F+M3hdTfW+tQ61FH8z2+/zSwHUbXUE/wDATn0qgPbqK4X4efEqz8bwS2s0P2LWLYZntWPBGcbkzyR6g8j9a7qgDx743/8AIY8E/wDYQb/0KKvbq8R+N/8AyGPBP/YQb/0KKvbqACiiigAooooAKKKKACiiigAooooA8lu9AudT+I/i/U9JZY9d0trCeyduBJ+5bfC3+y44PocHtW74l1618S/BvXNStVeMPp8yywyDDwSKCHjcdmU5FXPDsEsfxK8ayvE6xyCw2OVIDYibOD3xXM/E7S9Q0LTtb1HRrSa60/W7V7fUbSEFik5XbHcKuO/3XxjPynk0Ad7q+ujQfsc13bN/ZcnyXF4rZFsxxsLrj7h5BbPy8Z4JIWTxAj+IYtGsIDdzKvmXkqtiO0jI+Xc2Dl24wnUjJOBjMPiCTVZre30nSbZfNvUZZr2ZA0VrEMBiVP3nIbCqeCck8Ag5fhjw5N4EuItG02B7rQbliyynb51rLt5MhAG9G28HqpwOQRtAOzooooA8S+Lv/JWfh7/1+R/+j469grx/4u/8lZ+Hv/X5H/6Pjr2CgAooqK4uYLSIy3M8cMY6vI4UD8TQBLRWT/wlPh7/AKD2l/8AgZH/AI1ma/490XRtIl1CC9sb8QkNJBBeR+YU7lBn5iOuOM80AdTXi3i7xV4u8U/EC48HeDbpbJLJSbi53bCSMbiWwSFBIXCjJPr29B8NfETwv4rAXTdUjFwf+Xaf93L+Cn734ZFedfD/AP5L54z/ANyb/wBHJUVJOMW0BD/wr/4vf9DvD/4Hz/8Axuj/AIV/8Xv+h3h/8D5//jde3Vk+JdTl0nQLq5tUWS8IEVrGf45nIWMf99EfhmuNV6jdirHk/wDwr/4vf9DvD/4Hz/8Axuj/AIV/8Xv+h3h/8D5//jdeheDnutNutR8Najf3F9dWRS4iuLlyzywyjOcnk7XEi+wC1ck8WQm4uo7LS9S1CG0cx3FxaRoURx95RucM5HQhA3PHWqdapeyCx5j/AMK/+L3/AEO8P/gfP/8AG6P+Ff8Axe/6HeH/AMD5/wD43XbeGPFEEXhfUdWvbu4uYW1e6jtsbpJJAZiI40XqeMAL2HoBS694mna50S0az1PSrifU7fCzlAJo92GXdG7A9RlSQcdqftal7CsjiP8AhX/xe/6HeH/wPn/+N0f8K/8Ai9/0O8P/AIHz/wDxuvbq8ztLy8k1IQvqOot4oTWCk1os7mBbXzc5Mf3BH5BBD4yWwM54pRrTY7HHQfCP4lWurz6tB4nsI9QuF2S3K3cwkdeOCfL5+6v5Cr//AAr/AOL3/Q7w/wDgfP8A/G69urzi61vU9G+IGualJdTTaDam2hu7dnJW2R4wRMg7Yb72OobPaiNapILHMf8ACv8A4vf9DvD/AOB8/wD8bo/4V/8AF7/od4f/AAPn/wDjdejeIb2aPxL4RS3uZFgubyUSLHIQsq/Z5GAOOGGQD+Aq1P4pjW+urSx0vUdTa0O24ktEj2RtjO3Luu5gMZC5IzR7aoFjy/8A4V/8Xv8Aod4f/A+f/wCN0f8ACv8A4vf9DvD/AOB8/wD8br0u48caPb6bp1+DcTQX8zQReVES4kVWYoyfeDZQrjBO7Ap83iyG2ltLWbTNRS/u0eSCy2I0jBSAckOVXgg5LAAdcHij21ULI8x/4V/8Xv8Aod4f/A+f/wCN0f8ACv8A4vf9DvD/AOB8/wD8br0iHxrBcXc2nxaPqrarBzLYeXGJEXAIcsX8vac4B38nOM4Na2jazba3ZvcW6TRGOVoZoZl2yRSKeVYc89OhIwRSdaotwsjyH/hAfi+vzDxrCSOcfb5+f/IddB8K/G+talq2p+E/E+H1fTgWEwAy6qwVgxHBIJXBHUH259OrxXwT/wAnG+KP+uE3/ocVa0KsptpiaPb68buP+TqNM/682/8AREleyV43cf8AJ1Gmf9ebf+iJK6RHuNFFFABRRRQB4Z8N/wDktvjz/rtL/wCjq9mrxn4b/wDJbfHn/XaX/wBHV7NQB4b4x0zxF4E+J03jbRtNfU7G9TbPGiklCQAyttyRyoIbGO31X/heet/9CJc/9/n/APjdei+MviLoHgcRJqks0lzMu6O2t0DSFemTkgAZ9T646Vx3/DRHhf8A6Besf9+4v/jlRKnGTu0FzL/4Xnrf/QiXP/f5/wD43R/wvPW/+hEuf+/z/wDxutT/AIaI8L/9AvWP+/cX/wAco/4aI8L/APQL1j/v3F/8cqfYU+w7mPJ8a9UmeN5fh9LI0ZyjNIxKn1H7ripP+F563/0Ilz/3+f8A+N1qf8NEeF/+gXrH/fuL/wCOUf8ADRHhf/oF6x/37i/+OUewp9hXMeH416pbhhB8PpYt7bm2SMu4+pxF1qT/AIXnrf8A0Ilz/wB/n/8Ajdan/DRHhf8A6Besf9+4v/jlH/DRHhf/AKBesf8AfuL/AOOUewp9guYw+NWqLcG4Hw+lE7DaZBI24j0z5WaRfj9qTXLWy+DJDcKMtELltwHuPLz3H51tf8NEeF/+gXrH/fuL/wCOVwOm/FDR7L4v6r4vktL42N5bCJIlVPNB2xjkbsY+Q9/Sj2FPsFzqv+F563/0Ilz/AN/n/wDjdH/C89b/AOhEuf8Av8//AMbrU/4aI8L/APQL1j/v3F/8co/4aI8L/wDQL1j/AL9xf/HKPYU+w7mNP8atTuQon+H0soRty+ZIzbT6jMXWpf8Aheet/wDQiXP/AH+f/wCN1qf8NEeF/wDoF6x/37i/+OUf8NEeF/8AoF6x/wB+4v8A45R7Cn2Fcy/+F563/wBCJc/9/n/+N0f8Lz1v/oRLn/v8/wD8brU/4aI8L/8AQL1j/v3F/wDHKP8Ahojwv/0C9Y/79xf/AByj2FPsO5l/8Lz1v/oRLn/v8/8A8bo/4Xnrh4HgW5z2/fP/APG61P8Ahojwv/0C9Y/79xf/AByj/hojwv8A9AvWP+/cX/xyj2FPsFxnwp8P6/e+LdW8c+IbVrOW+jMcEDqVbBKnO08hQFUDPXr717BXPeEvG2ieNbGS50idi0RxLBKu2SPPTIyeD6jIroa1SsIKKKKAPDfilaL4M+I/h7xhpiiA3UxS8CcByCAxI/2kYg/TPWvcq8a/aF/5BGgf9frf+g17LQB498b/APkMeCf+wg3/AKFFXt1eI/G//kMeCf8AsIN/6FFXt1ABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAeJfF3/AJKz8Pf+vyP/ANHx17BXj/xd/wCSs/D3/r8j/wDR8dewUAcp8QfG9t4F8ONfuizXcreXawFsb39T32jqfwHevNdH+F+v/EJY9f8AHWs3cSzDfBZxYDIh56HiMewBPrzVvx/br4h+O/hTRLn5rSKETlDyGIZ3YfQiNRXtVAHlv/CgfBv9/U//AAIX/wCJrN1/4C6JHpEo0GO7l1FyFi+03YWNMnlmwuSAOw6nFeyUUAeQeGfgBomnNHca7dy6lOvJhTMUIP4fM2PqPpWb8OYY7f46+L4Il2xxxTKq+gEqYFe414X4osfEfw6+Jt54u0fSn1PTNSUiZEUttLYLKdoJX5lBBxjnFRUi5RaQHt9cZ4gt5/Evi600iz1CayGkxi/mnijRyJXykS4cFfu+Y3I/u1w3/C89b/6ES5/7/P8A/G6P+F563/0Ilz/3+f8A+N1xxo1FrYq6Ot1DTdU8Na/pXiO71241KESCwu/Pghj8uGUgK2Y1XOJNnXoCenNWPCOt6XoWgS6Xqt7b2N9YXE4ninkCM2ZWYSAHlgwYEEdc4riv+F563/0Ilz/3+f8A+N1G/wAa9Ulljlk+H0ryR/cdpGJX6HyuKr2U2rNCuaulSCPRtO1uSCSLT7PxNd3NyjJgwRuZUV2XqNpdc+nJ7V0HizXNL1K88OWthcwX0q6vbTM1vIsghUNt3MQcDJYAdzk+hrjv+F563/0Ilz/3+f8A+N1HD8a9UtkKQfD+WJSdxEcjKCfXiKm6c272/ELnrniSXUIPDGqS6SpbUEtZGtwBklwpxgdznoK4Oa60DTdJsNX8K3sE2uDAFuj759RZsb45gMtuzzuP3COwyKw/+F563/0Ilz/3+f8A+N1Enxq1SOd50+H0qzOMNIJGDMPc+VzUxpTXQdz1fwjf/wBpeFtPne6a4uBCsdy7jDCZRiRWHYhsjFZujRRz+NvGMMyLJFJ9kV0YZDAwkEEdxXnKfH7UpLl7dPBkjToMtGtyxZR7jy89xU3/AAvPW/8AoRLn/v8AP/8AG6PY1NdNwubLQ3mh+O/CnhudZZbGC8mm026Y5/cm3kBiY+qEgD1Ur6VueFNV07w9aajpOsX1tY31vfXM0n2mVY/OSSVpFlBJ+YFWAyOhBBriv+F563/0Ilz/AN/n/wDjdRTfGrU7goZvh9LKYzuQvIzbT6jMXFU6c2rNCudHZL9p1PQr/wCztFbX/iS5urZJFKkx/ZpAHwem4qXH+8DXXTAf8LEszgZGkz4P/bWGvM/+F563/wBCJc/9/n/+N0f8Lz1v/oRLn/v8/wD8bpOlUfQLo9L04D/hPdebAz9ishn8Z6reDP8Aj+8W/wDYck/9EQ157/wvPW/+hEuf+/z/APxuj/heet/9CJc/9/n/APjdL2NTsO57ZXivgn/k43xR/wBcJv8A0OKmn45a6QQvgW53Hp++c8/9+60/hN4Z1yTxJq/jfxDbNZ3OoqyQ27LtOGYMxKnlQNqgZ5IyfTOtCnKDbkJs9erxu4/5Oo0z/rzb/wBESV7JXjdx/wAnUaZ/15t/6IkrpEe40UUUAFFFFAHhnw3/AOS2+PP+u0v/AKOr2avGfhv/AMlt8ef9dpf/AEdXs1AHgtrZ2+tftJaumpQpdR28ZaNJV3KpVEC8HjjJP15r2X7BZ/8APpB/37FeQ6D/AMnKa/8A9cX/APQY69mrhxDfOdVFe6V/sFn/AM+kH/fsUfYLP/n0g/79irFFYXZtYr/YLP8A59IP+/YrC8P67oXiO81S0s7IRz6bcG3mWaFBkgldy4JypKsM8dOldLXl3hr/AIleqrrCJ+6udbvtNu29FedmiY/SQbf+2hq4q6ZEnZo67xFrOieGVsfttj5jXtwtvEkECsQT/EckYUcZPuK2/sFn/wA+kH/fsVwHibdq1zq+pFg1rp01pp9t/wBdDcRPM35+Wv8AwA1q6pLaS+ILyPUNT1WbZsW3stJNyPJG0EtIYB94knhjjG3iny6IXNqdV9gs/wDn0g/79iq+oJp2nabdX01lE0VtC8zhIlLEKCTjPfiuLs7/AF3UfBlu0cl/MLbVZbe8aIgXb2scjqMYx8/CA45IBxzTpLizk0jxCmnatfSW/wDZM5k07UjMZ4nCnDr53z7SCQeozjFHI77j5kdrbW9hdWsNwlnCElRXUNEucEZ5qX7BZ/8APpB/37FcTouuTeIrzT9Jje602whs4rhXZGik1AL8rBCcFUBAyR8xyMYByYbrW4tQ8Raql8PEr21nP9lt4dLguRGCqqWdnhwWYsSME4AA45o5HcOZWO8+wWf/AD6Qf9+xVHUpdM0pbUz2KN9puY7ZNkSnDOcAnOOK5G31nV7nTbLR/O1K3kvNVayjvru2aC4NssRlLAMo+fAMe7HYnrVjxLoraZdeH5bW+vZLdtXtlmgu7p5wTuyHUuSQcjGAcYPTihR1s2HNpodp9gs/+fSD/v2KPsFn/wA+kH/fsVYorO7LsV/sFn/z6Qf9+xSHT7JgQbO3IPBBiWrNFF2FjxzwXZwaL+0Pr2nadGLezNoT5KcKMrE/A7ck49K9wrxbw/8A8nM67/15/wDtOGvaa9OHwo4ZfEwoooqiTxr9oX/kEaB/1+t/6DXsteNftC/8gjQP+v1v/Qa9loA8e+N//IY8E/8AYQb/ANCir26vEfjf/wAhjwT/ANhBv/Qoq9uoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDxL4u/wDJWfh7/wBfkf8A6Pjr2CvH/i7/AMlZ+Hv/AF+R/wDo+OvYKAPG9e/5Ob8O/wDXif8A0CevZK8b17/k5vw7/wBeJ/8AQJ69koAKKKKACuE8d/FTSfBFwli1vLf6nIocWsR2hQem5ucZ7AAmu7rxDRYIr39pTxBJcoJXt7cvCX52MFiUEfgSPxqZS5U2OKu7B/w0Bff9CNcf+Bjf/GqP+GgL7/oRrj/wMb/41XsVFc31ryN/YeZ47/w0Bff9CNcf+Bjf/GqP+GgL7/oRrj/wMb/41XoFx4vtLXxzbeF5oJFmuLbzo58jYW+bCfXCMfwrT1rVYdD0a71OdHeO3jL7EGWc9Ao9ycAfWn9YfYXsV3PLP+GgL7/oRrj/AMDG/wDjVH/DQF9/0I1x/wCBjf8AxqvUtC1VNc0Oy1SOJoVuohII3OSuexq7PKIIJJSMhFLEDvgZpfWXe1h+wW9zyD/hoC+/6Ea4/wDAxv8A41R/w0Bff9CNcf8AgY3/AMar0y18QWtzFoxKSI+rQ+bCuM7RsDkE/Q1etbmS4kule2khEMxjUv0lG1TuHtyR+Bp/WGugexXc+c9I+Il9pXxI1bxf/wAIxcS/2hAYfsvmsvl5MZzv2HP+r9B19q7L/hoC+/6Ea4/8DG/+NV6nrGqpo9il1JG0itcQwbVODmSRYwfwLZ/Cr9L6y+wewXc8d/4aAvv+hGuP/Axv/jVH/DQF9/0I1x/4GN/8ar1HQdXj13RbfUoomiSbdhGOSMMV/pWjQ8S1pYFQT6njv/DQF9/0I1x/4GN/8ao/4aAvv+hGuP8AwMb/AONV7FRR9a8g9h5njv8Aw0Bff9CNcf8AgY3/AMao/wCGgL7/AKEa4/8AAxv/AI1XqkWppLrt1pQjYPb20VwXzwRI0igfh5Z/Or1H1l9g9gu547/w0DejlvA9wAOp+2Nx/wCQq9E8D/EDSfHdlLLYCSG5gx59tLjcmehBHUdef5VvV4x4Mijsv2jNfgtkWKFoJcogwOfLY8fXmtKVbndrEVKfKrnuleN3H/J1Gmf9ebf+iJK9krxu4/5Oo0z/AK82/wDRElbmR7jRRRQAUUUUAeGfDf8A5Lb48/67S/8Ao6vZq8Z+G/8AyW3x5/12l/8AR1ezUAeGaD/ycpr/AP1xf/0GOvZq8Z0H/k5TX/8Ari//AKDHXs1cOI+M66PwhRRVI6vp41kaQbuIagYvPFuT8xTON351gal2uZTweg8Nato73rH7fcz3KzrHgwvI5dSBnkq2DnIzjtXQ3NzBZ2st1cyrFBChkkkc4CqBkk/hTbK9ttRsobyzmWa3mUPHIvRge4pptbCaTMNPCaJ4Qi0Jbs7xJHNLctHkyyCVZXYrn+Jge/Ge+Kamia1p+oX7aTqNklpfTm4cXNuzyQuVAbaQ4DD5cgHGPeukd1jRnc4VRkk9hUMN7a3EVtJFcRslygeE7v8AWLjOR68c0+Zi5UcvaeDLzT7FI7XW2+0W9/JfW80kBOTJu3pKAw3g7jyNpHHpU0/hvVNYeebWL+1WVrGezhS0gYJH5oAZyWbLH5RxwP510cV1BPPPDFKrSW7BJVHVCVDAH8CD+NF1eW9jCJrmVYoy6Rhm6bmYKo/EkD8aOaVw5UZOpeHFvtLsIYrn7Pf6fsa0vRHkxuowflyMqwyCueQfoahl0bV7LVLu+0a/tVW9KvcW13CzIJAoUyIVYEZCrkHOcZyK6KoLK9ttRtEurSZZoJM7XXocHB/UGjmY7IwJPCcsulIkmqSNqqXn29L4x5CTdOEz9zblNuenfPNMufDur6zc6fPq+p2qiwukuYobOBlV2UjlizknjIA6DcTzxjqaKOdi5UFFFQC+tm1B7ATKbpIlmaLuEJIDfTKkfhUlE9FFFAHkfh//AJOZ13/rz/8AacNe014t4f8A+Tmdd/68/wD2nDXtNenD4UcMviYUUUVRJ41+0L/yCNA/6/W/9Br2WvGv2hf+QRoH/X63/oNey0AePfG//kMeCf8AsIN/6FFXt1eI/G//AJDHgn/sIN/6FFXt1ABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAeJfF3/krPw9/wCvyP8A9Hx17BXj/wAXf+Ss/D3/AK/I/wD0fHXsFAHjevf8nN+Hf+vE/wDoE9eyV43r3/Jzfh3/AK8T/wCgT17JQAUUUUAFeKeG/wDk5DxR/wBejf8AtGva68U8N/8AJyHij/r0b/2jWdX4GXT+JHr1FFFecdp5v4ksZ7zxxq0llGHv7PSLW8tB6yxzSsB/wIZX6Ma2by+i8Uat4etLSTNoUXV7keqDHkqfrIQ3/bM1tx6Kkfii41zzmLzWcdqYtvACuzZz/wAC/Sqnhrwpa+GpdQkgmkma7mLrvH+qjySsS/7Klmx9a05lYz5XcwfB88yW3g2BZXEMmk3LPGGO1irQ4JHQkZOPqa1tRuZv+EwltfOk8j+xZZDFuO3d5gG7HTOMjNIvhGa0sNEj07VDBeaSjRRzSQeYkqMAGV0DDg4U8MMEVPbeGphrM+rX2o/aLye0a0fZD5caoSCAi7jgDBPJJJY89AG3G9wSdrHLQ6PbXsngJpZb1TLYbW8m+miA224I2hHG0+pGM9810mm6lLanxDM8N3eCLVCiRQje4XyouFBI4ySfzp9x4WlNjocdlqb2tzpEYjim8lXDjy9h3KfUc9a1dO01dPm1CRZS/wBsujckEY2koi4/8cz+NKUk1/Xcai0c14tv5tR8HrNDZz2k/wDaVmscd7HtO77TFgkAn5c/1rS2+Mv+emg/9+5v8a0da0pdZsUtXlMQW4gn3AZ5jkWQD8duPxrQqebSw7anlGlX1wvhjwppZTUJILhLqe6TTQRJII5AAm7IKqTICcHPAHc1vaRNLYa1tsbDV7DSXtZDMNSyYYJFwVdSzkgEbgwyBwDxzWhH4N+y6RpVvZ6lJBe6Y7vb3XlgghySyOmeVOemQeAcipX8LS6m93Jr2oLePPaSWaJbweRHDHIMOVBZzuOByWPTgDmrcoshRaOP1eWGw8IXOuacdcutUtYRN/asjSxJKwIJO12AMZ5+UKRgjHrXU/YR4j8TaxHqM07WOntFbw2sczxqXMayNI20gsfnAGeBtPeor7wfqmr6A+h6l4hD2Jh8rNvZiKR8DC+YxdgcHBwoXOOeMir8mgahDqbanp2qxwXk8CRXizWvmQzsgwH2B1KtyRw2MY4OKHJdxpPsUfD9jJp3j3XLdrya5iFhaGEzNveNDJcfIWPLYOcE84IznGa6+sLRfDh0rVb7U5tQmvLu+jjWZ5FCjKFyNoH3RhwAP9nOSSTW7USd2VFWQV434W/5OU13/rhJ/wCgx17JXjfhb/k5TXf+uEn/AKDHW2G+Jmdf4T3GvG7j/k6jTP8Arzb/ANESV7JXjdx/ydRpn/Xm3/oiSu05T3GiiigAooooA8M+G/8AyW3x5/12l/8AR1ezV4z8N/8Aktvjz/rtL/6Or2agDwzQf+TlNf8A+uL/APoMdezV4zoP/Jymv/8AXF//AEGOvZq4cR8Z10fhCvNfE0Ig8dahr6Ixn0Wys7r5B8zQ77hZl/FCx+qivSqw4dKm/wCEv1S+mjRrK6sLe3XJB3FWlLAj0w6/nWcHa5clcp+KZF1f+ytBhAlh1SYSXBB4+yx4d/wY7E/4HWf4S1Oaz0LwZp8aRmG9t5BISDldibht59as+DvDmpaVd3U+rSLI0EY0/T9rZxaoxKsf9psqD/uCqtvoesaVo3hSaGzW5utJDJc2qyqrOroVOxiQuQcHBIB55qtLcv8AXUnW9zd1fUpodWg0xVQw3On3c7sQdwaMxBcc4x+8bPHYVyMMOrvJ4CNnfWUKmw/dCazeQqfs43FiJV3AjoBjHvW81prWqeJY9SnsPsdnHp1zbRwyyI0odzEcttYrzswACcbeTyBUL6Tq9jZeEp7axS6n0qDyri389UPMIQlWPBwRQrJW/rqDu2a9lqcaanr/ANqNtbwWlxEnnHCZBhjbLsTyctge2BWX401K0ufCgubOaO8SLUbLItnWQki5iO0YPX2961rHSmXVNdku4Y3tr24jkjVsMGVYY1OR/vKfyqHX9E+0aNHaaZawxkX1rOyoAgwk8bsfrtU/lUprmXyG72Y3/hKn/wChc17/AMBV/wDi65jQfED6T4D8OW0Eltb3OoSyos162I4FV3ZnYZGSOAFyMkjmvSK4CHwpqVt4c8Pt9jtrq+0qWVpLOVlKzRyFgyhjwGwVYZ4yMU4uNv68wkncv2HiWW21y20y41fT9YW8jkMElptSVZEXcUZQxBBUHB45GD1zVPVvEWt6Do7a3qWqaXHJGiyS6P5fzAEjKLJvyXA74wSOmKsTaXquqPP/AGfpUfh5EtJkjlkWAzPO6FUOYy2xVznIbJOOMZzl3+hare+CbnQdN8KQaZdT2xjnuJJodjtjJ2lCWYsR1cL1yc9DS5bku50t5qGqaj4hudH0maGzSzhjkubuWHzTufO1EXIHRSSTnqBjvWZop1D/AIWdqkepeS00ek26rLCpVZV82UhtpJ2nkgjJ6e9XWg1bTPEM2s22lyXdvqNvELq0jljWaCVAcEFmVWBDYPzfwjGc0mjWGsSeM7/XNRtY7aCeyjt4YhKHZArucMRxk7s8ZAzjJxmp0SY+p1VFFFZmh5H4f/5OZ13/AK8//acNe014t4f/AOTmdd/68/8A2nDXtNenD4UcMviYUUUVRJ41+0L/AMgjQP8Ar9b/ANBr2WvGv2hf+QRoH/X63/oNey0AePfG/wD5DHgn/sIN/wChRV7dXiPxv/5DHgn/ALCDf+hRV7dQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHiXxd/wCSs/D3/r8j/wDR8dewV4/8Xf8AkrPw9/6/I/8A0fHXsFAHjevf8nN+Hf8ArxP/AKBPXsleN69/yc34d/68T/6BPXslABRRRQAV4p4b/wCTkPFH/Xo3/tGva68U8N/8nIeKP+vRv/aNZ1fgZdP4kevUUUV5x2hQSFBJIAHJJ7UVzHjm/hg0WPTJLpbZ9WmWzErOF2I3MjZPTCBse5FNK7sJuyubGj61p+v6amoaXci4tXZlWQKV5U4PBAPUVbjnhlkljjlR3iYLIqsCUJAIBHY4IP0Irj9AvtOsfGt9pOn3VpJY30C3lulvKrBJEAjlXg9x5bf99e9N0LT9b/t7xMP7dTcLlFLfYl5c28RDfe7DAx3xmqcVqSpHZW9xBdQrNbzRzRNnDxsGU4ODyPcGpK8y0XWLvwz4Asp7nVbTde3f2W1e6jEcVuxkkLO7bhuGAzYyOQBnmtCz8Ux2Osadbr4w07X4r64Fu8SPAJYWYHayiPquQAQQTyDnjkdN62BTR3tRS3MEEkMcs8cckzFIldwDIwBOFHc4BPHYGuO0iTxN4ksLi7XXE04RXlzBCsNoknmKkrKC+7PHGMLg8Zzzxk3l1q3iGTwTqUd/HZyXFw6mNbcOI5VgmDMCTyDggA9M5o5Ndw5z0OG/tp765sopd1xahDMm0jaHBK89DnB6VZrkL3xFe6ZeeIQEjuZLRLOO1iICb5piUAJ9CxX6DNN1KTxF4a06XXLvWV1GC3Aku7M2iIqx5G8xFfmBAyRuLZxjjrRyD5jsaK5MTa7ret61ZWuprp1lZTRLFPDCkkrloUcrhwVABbOcEncOmOdDwtqN7fWV5DqLxyXVjeSWjzRrtEoXBV9vYkMMj1zScbIalc3KKKKkYV434W/5OU13/rhJ/wCgx17JXjfhb/k5TXf+uEn/AKDHXRhviZjX+E9xrxu4/wCTqNM/682/9ESV7JXjdx/ydRpn/Xm3/oiSu05T3GiiigAooooA8M+G/wDyW3x5/wBdpf8A0dXs1eM/Df8A5Lb48/67S/8Ao6vZqAPDNB/5OU1//ri//oMdezV4zoP/ACcpr/8A1xf/ANBjr2auHEfGddH4QooorA1CmmRFdULqHbJVSeTjrTq821fN1f33jeJ5HTQ7pYbdE6PBHlbkj1yXf/v0tVGNyZOx6TRXFeNdR1WO68ONpVnDc28l/GyyG8MXmMUkwhAQ/KRzu9uneh9Q8Qf8LEs4TpNuIGsDv/4mB4QyR73x5fJUkgDv6jpRyO1w5jtaK5ZfEOuak01zoej2tzp0MjxCS5vDFJcFCVby1CEYyCAWIzjsOaWbxgZTo6aVpzXcuqwzSQiSTyxG0ZQFZDg7QNzZPOCuACSKORhzI6ikZlQAswGSAMnvXMW3iDXBd3elXej2n9rRW63MCw3h8idC20/OUypHoVPasjQNQu38CaBJrGmROpnskgYXZcuWZQsrfKMEHB2859afIw5kd/RXNz67q97qF1beH9NtLmKzk8q4uLy6aJDIACUQKjEkZGScAHjnBxFL4zEOhi+bTLj7VHfJYXFkGG+OVmAwp6N94EHgEEdKXIw5kdTRXMJ4g1my1awttc0q0t7fUJTDby2t20pSTaWCyAovUK3IzyPxrp6TVhp3CiiikM8j8P8A/JzOu/8AXn/7Thr2mvFvD/8Ayczrv/Xn/wC04a9pr04fCjhl8TCiiiqJPGv2hf8AkEaB/wBfrf8AoNey141+0L/yCNA/6/W/9Br2WgDx743/APIY8E/9hBv/AEKKvbq8R+N//IY8E/8AYQb/ANCir26gAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAPEvi7/wAlZ+Hv/X5H/wCj469grx/4u/8AJWfh7/1+R/8Ao+OvYKAPG9e/5Ob8O/8AXif/AECevZK8b17/AJOb8O/9eJ/9Anr2SgAooooAK8U8N/8AJyHij/r0b/2jXtdeB6nq8XgH4+6lqmsxypp+o2+EnVCwCkJ82B1wyEHFRUTcGkVB2kj2+iuE/wCFx+BP+g23/gJN/wDEUf8AC4/An/Qbb/wEm/8AiK8/2c+x2c8e53dYMuiyah4se/1GG3lsLe0ENpE4D/O7ZkcgjjhUA/H1rC/4XH4E/wCg23/gJN/8RR/wuPwJ/wBBtv8AwEm/+IpqE10E5RfU2Na8NRyNp99pFrbQX9hdpOm1RGJEPyyISB0KM34gVLYWeqWXinVJDb276bfuk4nE5EkbLEke0ptwQdmc7u9YX/C4/An/AEG2/wDASb/4ij/hcfgT/oNt/wCAk3/xFPlna1gvDuFt4b11dAisGhsorrSbz7XptwJ2dLg75CVkXaCgKuV4J657c7MEniTUtQs/tFlHpNnA/mT7bhZnuDggIMDAXJySeeAMDNY3/C4/An/Qbb/wEm/+Io/4XH4E/wCg23/gJN/8RTam/siTiup0XhfS7jSNHe1utnmNd3Mw2HI2yTO6/jhhXPr4b1qx0Hw59lhtbi+0m6kmeCScxrIrLKuA4U4P7wHp2NN/4XH4E/6Dbf8AgJN/8RR/wuPwJ/0G2/8AASb/AOIotO97BeHcv33hi81K4152lS2a+S0e2kU7zFLDlgSOMgMF+oqPUbfxL4k01tFvtLtrC3uAI726S78wNH/EIlAByw4+bGAe9VP+Fx+BP+g23/gJN/8AEUf8Lj8Cf9Btv/ASb/4ii0+wXh3Om0rTprLVNZuH2CK7uY5IQp52rDGnPpyhpug6bPp0mrNPsxdahJcR7Tn5GVQM+/Brm/8AhcfgT/oNt/4CTf8AxFH/AAuPwJ/0G2/8BJv/AIilyz7D5o9zu6K4T/hcfgT/AKDbf+Ak3/xFH/C4/An/AEG2/wDASb/4ip9nPsPnj3O7rxvwt/ycprv/AFwk/wDQY66k/GTwIAT/AG0x9vsk3/xFcl8MJH8UfGLX/FVnBIumCNkWSQYyzbQo+pCk+3410YeElJtoxrSTWjPda8buP+TqNM/682/9ESV7JXjdx/ydRpn/AF5t/wCiJK6znPcaKKKACiiigDwz4b/8lt8ef9dpf/R1ezV4z8N/+S2+PP8ArtL/AOjq9moA8M0H/k5TX/8Ari//AKDHXs1eG6xqMfgL4+3mr6zHKmnX8JMc6JuG1lUZwOuGUgjr3rt/+Fx+BP8AoNt/4CTf/EVx14ScrpHTSklHVnd0Vwn/AAuPwJ/0G2/8BJv/AIij/hcngT/oNt/4CTf/ABFYezn2NeePc6jxDeXlj4fvbjTrd7i+Ee23iRSxMjfKuQOwJBPoAaybHwHpNrpENhJLqbqItkoXVbpEkJHzHYJAoySSQBjms3/hcfgT/oNt/wCAk3/xFH/C4/An/Qbb/wABJv8A4iqUZpWSYuaDerKnkapY+H9Kt7mxvbj+wNZCExQs7y2qq4jdQOX+V0BxnkH0Nb93cSQeMdJ1A2V89rdWT2weO3ZvKd5I2HmADKDAOSeBg5rL/wCFx+BP+g23/gJN/wDEUf8AC4/An/Qbb/wEm/8AiKbU39kSce5j6fpmhaFbSabrmi6rJfwyyCJrWK5lW6QsSjIY/lBwQCDjBzXRaLpM9hqPhxf7NFnHHZXplihLOkLySQuFLEn5j83fkhsVV/4XH4E/6Dbf+Ak3/wARR/wuPwJ/0G2/8BJv/iKbU30YlyrqbjW8/wDwsCK58mT7ONKeMy7Tt3eap256Zxziuf05bqfwXoenHTr+K6068sYp0ltmX7ki7mU4wygAncOMVJ/wuPwJ/wBBtv8AwEm/+Io/4XH4E/6Dbf8AgJN/8RSSmug7x7k9hqEfg661Ox1K2vjBc30t5a3NvaSTrIJW3lD5YJVgxYYOMjBzUH2LUbu3fU5bCeGS/wBdtbpbcrl4oE8tAzgfdOE3H0zg9KP+Fx+BP+g23/gJN/8AEUf8Lj8Cf9Btv/ASb/4inae/KF49zY8VW09xe+GWggklWHV0klKIW2J5Mw3NjoMkDJ9RXR1wn/C4/An/AEG2/wDASb/4ij/hcfgT/oNt/wCAk3/xFQ4TtsPmj3O7orhP+Fx+BP8AoNt/4CTf/EUf8Lk8Cf8AQab/AMBJv/iKXs59h88e5z3h/wD5OZ13/rz/APacNe014Z8NbpvFnxn1/wAU2cEiaaLcxh3GMnCKo+pCFsdq9zr0YK0Ujilq2FFFFUI8a/aF/wCQRoH/AF+t/wCg17LXjX7Qv/II0D/r9b/0GvZaAPHvjf8A8hjwT/2EG/8AQoq9urxH43/8hjwT/wBhBv8A0KKvbqACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA8S+Lv/ACVn4e/9fkf/AKPjr2CvH/i7/wAlZ+Hv/X5H/wCj469goA8b17/k5vw7/wBeJ/8AQJ69krxvXv8Ak5vw7/14n/0CevZKACiiigArO1jQdJ8QWy22r6fb3sSncqzIG2n1B6g/StGigDjf+FUeBf8AoXbb/vt//iq4L4naL4G8DWmkvH4btXlurxfMTe+fITBkx83U5A/Gvb6+fPjt4a1u5upPE85T+zbdo7OCFTuZUIJMjdgC5wO/IzigD02D4XeAbq3iuIdAtXilQOjB3wykZB+9Un/CqPAv/Qu23/fb/wDxVHwsS8i+H+mxXd1Fdxon+i3ETZ3wnlQR2ZclSO23qa7KgDjf+FUeBf8AoXbb/vt//iqP+FUeBf8AoXbb/vt//iq7KigDjf8AhVHgX/oXbb/vt/8A4qj/AIVR4F/6F22/77f/AOKrsqr3/wBrOn3AsPK+2GNhCZSdgfHBbHOM0AeKaHpfw/1b4raz4ZGhWZtoIlS2O5/mljz5o+9yef8AyGa9B/4VR4F/6F22/wC+3/8Aiq8c8LeB761+MWoWNlqofUNGVbxZpkIW5Y+XvVsElQwkYZ5r6VoA43/hVHgX/oXbb/vt/wD4qj/hVHgX/oXbb/vt/wD4quyooA43/hVHgX/oXbb/AL7f/wCKo/4VR4F/6F22/wC+3/8Aiq7KigDzrxD4B+H3h3w9f6vc+HrURWsLSYLv8zfwr97qTgfjWH8NPCXgfxf4JtNQn0G0e9jJgusM4/eL3xu7gqfxq58eVvJPBSqs8UGnpKJJ2Y/PM/SONV78ksScYC9+lVPgf4b1rQtLS/laKTS9YtxPszh4JFYheO4ZDnI9uO9AHXj4U+BgQR4dtePVnP8A7NXT6dpljpFklnp1pDa2yfdihQKo98DvVqigArxu4/5Oo0z/AK82/wDREleyV43cf8nUaZ/15t/6IkoA9xooooAKKKKAPDPhv/yW3x5/12l/9HV7NXjPw3/5Lb48/wCu0v8A6Or2agDP1fQtK1+1Ftq2n295Cp3KsyBtp9Qex+lc7/wqjwL/ANC7bf8Afb//ABVdlRQB4f8AE/RfAvgi10kxeHrVp7q8UyJuckwKQZP4upyAPr7V3UHwu8AXNvHcQaBaSQyoHR1kchlIyCPm9K8z+OvhvW7meTxPcvEunW0kdnbQKcsEIJMjdhl+MehHTFeofC1buLwBp0NzPFcwog+yXEZ/1kJ5UMP4WXJUjtt6mgA/4VR4F/6F22/77f8A+Ko/4VR4F/6F22/77f8A+KrsqKAON/4VR4F/6F22/wC+3/8AiqP+FUeBf+hdtv8Avt//AIquyooA43/hVHgX/oXbb/vt/wD4qvN9J0/wDf8Axh1Lwx/YdobNIRDbnc+DcR5MnO7uCR/2z9690uxcGzmFoYxclCIjJnaGxwTjtmvnHQvAU9v8ar/SLTWJPtulwpfxXcsfEsuImIdQfukyMODnHrQB7F/wqjwL/wBC7bf99v8A/FUf8Ko8C/8AQu23/fb/APxVdkM7RkAHuAaKAON/4VR4F/6F22/77f8A+Ko/4VR4F/6F22/77f8A+KrsqKAON/4VR4F/6F22/wC+3/8AiqzPEXgL4feHfD1/q9z4ctjHaQtJt8xxuPZfvdzgfjXoteV/HlLyXwUqpdRW1gkgkn3N8079I41UdeSWOegXPOKAKfw18JeCPGPgq11K48O2n2xGaC5Cs+N69/vdwVP4114+FPgYEEeHbXj1Zz/7NXIfA3w1rehaYNQuGQ6Zq9uJxFnDwyKxCkg9QyHOR7cd69goAqabpdho9kllptnBaWyZKxQoFXJ6nA7+9W6KKACiiigDxr9oX/kEaB/1+t/6DXsteNftC/8AII0D/r9b/wBBr2WgDx743/8AIY8E/wDYQb/0KKvbq8R+N/8AyGPBP/YQb/0KKvbqACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA8S+Lv/JWfh7/ANfkf/o+OvYK8f8Ai7/yVn4e/wDX5H/6Pjr2CgDxvXv+Tm/Dv/Xif/QJ69krxrxMwtf2lfDM0x2xyWYVWPckTKB+ZH517LQAUUUUAFFFFABVLV9KtNc0i60u/j8y1uYzHIucHB7g9iOoPqKu0UAeB20njP4LXU1t9hfW/DDyF42TP7v3yAdh9QRtJ6d66CP9ofwqY1Mmmayr45CxREA/XzB/KvXKrtYWbsWa0gZjySYwSaAPLf8Ahofwl/0Dtb/78Rf/AByj/hofwl/0Dtb/AO/EX/xyvUf7Osf+fO3/AO/S/wCFH9nWP/Pnb/8Afpf8KAPLv+Gh/CX/AEDtb/78Rf8Axyj/AIaH8Jf9A7W/+/EX/wAcr1H+zrH/AJ87f/v0v+FH9nWP/Pnb/wDfpf8ACgD500T4p6HpvxX13xTNa6i1jqFuIoo0jQyqR5f3gXxj5D0J7V3X/DQ/hL/oHa3/AN+Iv/jlUPCdrbt+0X4riaCIxrYsQhQYHzQdq9g/s6x/587f/v0v+FAHl3/DQ/hL/oHa3/34i/8AjlH/AA0P4S/6B2t/9+Iv/jleo/2dY/8APnb/APfpf8KP7Osf+fO3/wC/S/4UAeXf8ND+Ev8AoHa3/wB+Iv8A45UNz+0P4d8k/YdH1ae4PCRyrGisfqHY/oa9X/s6x/587f8A79L/AIU+OztYX3xW0KN/eVADQB4daaB4u+L2uWupeKLZ9K8O2zbo7TBQyfQHkk9C57dK90hhjt4Y4YUWOKNQiIowFAGAAPSn0UAFFFFABXjdx/ydRpn/AF5t/wCiJK9krxu4/wCTqNM/682/9ESUAe40UUUAFFFFAHhnw3/5Lb48/wCu0v8A6Or2avGfhv8A8lt8ef8AXaX/ANHV7NQAUUUUAUtY0mz13SLrS7+IS2tzGUkU/oR6EHBB9RXiFu/jb4L3U1qli+ueGXcvGyg/ux65APln1BBB7d698ooA8ij/AGh/CxjUy6ZrKSY+ZViiYA/XzBn8qf8A8ND+Ev8AoHa3/wB+Iv8A45XqbWNm7FntYGY9SYwSab/Z1j/z52//AH6X/CgDy7/hofwl/wBA7W/+/EX/AMco/wCGh/CX/QO1v/vxF/8AHK9R/s6x/wCfO3/79L/hR/Z1j/z52/8A36X/AAoA8u/4aH8Jf9A7W/8AvxF/8crhNN+KWh2fxh1fxdJa6gdPvbRYI41jTzQwWIZI34x+7Pc9RX0Z/Z1j/wA+dv8A9+l/wrx/QrW3b9pXxDCYIjELIEIUG0fJD2oAv/8ADQ/hL/oHa3/34i/+OUf8ND+Ev+gdrf8A34i/+OV6j/Z1j/z52/8A36X/AAo/s6x/587f/v0v+FAHl3/DQ/hL/oHa3/34i/8AjlH/AA0P4S/6B2t/9+Iv/jleo/2dY/8APnb/APfpf8KP7Osf+fO3/wC/S/4UAeU3H7Q/hzyW+x6Rq81x/BHIkaKx+odiPyNZFpoHiv4v67a6n4ntn0vw3bNuitOVMnsAeTnu5xx0r3COztYXDxW0KMOjKgBqagBkMUdvDHDEipFGoVEUYCgDAAp9FFABRRRQAUUUUAeNftC/8gjQP+v1v/Qa9lrxn9oQg6Z4ejB+drxiF7ngf4ivZqAPHvjf/wAhjwT/ANhBv/Qoq9urxH43/wDIY8E/9hBv/Qoq9uoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDxL4vcfFj4ek9Ptkf/AKPjr2CvJvj/AKddQWnh/wAVWi7m0m7xIAOgYqysT2AZMfVxXpei6vaa9o1pqti++2uohIh7jPUH3ByD7igDzz4y+Eb/AFaxsfEeihzqujv5gWMZZkBDZHqVIyB7n2rV8DfFTQ/FunxJcXUFjqyqBNazPsBb1Qn7w9uo7+td5XBeKPhB4U8UXL3clvLY3kjFnns2C7z6spBU/XAPvQB3P2iH/ntH/wB9Cj7RD/z2j/76FeOf8M6aJ/0HNQ/74T/Cj/hnTRP+g5qH/fCf4UAex/aIf+e0f/fQo+0Q/wDPaP8A76FeOf8ADOmif9BzUP8AvhP8KP8AhnTRP+g5qH/fCf4UAex/aIf+e0f/AH0KPtEP/PaP/voV45/wzpon/Qc1D/vhP8KP+GdNE/6Dmof98J/hQB7H9oh/57R/99Cj7RD/AM9o/wDvoV45/wAM6aJ/0HNQ/wC+E/wo/wCGdNE/6Dmof98J/hQB7H9oh/57R/8AfQo+0Q/89o/++hXjn/DOmif9BzUP++E/wo/4Z00T/oOah/3wn+FAHsf2iH/ntH/30KPtEP8Az2j/AO+hXjn/AAzpon/Qc1D/AL4T/Cj/AIZ00T/oOah/3wn+FAD/AAgwb9o/xYVIINi3I/3oK9krwb4V6DD4Z+N3iDRoJnmitdOdVkkADNl4Tzj617zQAUUUUAFFFFABRRRQAUUUUAFeNz8/tUabjnFm2fb9xJXsbukcbSSMFRQSzMcAAdzXjHw2c+M/jV4g8XxKW061jMNvIwxkkBEwD6ork+m4etAHutFFFABRRRQB4Z8O/wB18c/HUMgKyM8rhTwSvnA5/wDHh+dezV4n4ydvh38c7PxRNk6VrMflzsBjYQqo/wCWEf3yR2r2pJEljWSN1dGAZWU5BB6EGgB1FFFABRRRQAUUUUAFFFFABXjeg/8AJzfiL/rxH/oEFeyV886v4cvvFHx/8QWGn61PpEwgSU3EIYsQI4ht4ZTg5HftQB9DUV43/wAKb8U/9FJ1P/vmX/47R/wpvxT/ANFJ1P8A75l/+O0AeyUV43/wpvxT/wBFJ1P/AL5l/wDjtH/Cm/FP/RSdT/75l/8AjtAHslFeN/8ACm/FP/RSdT/75l/+O0f8Kb8U/wDRSdT/AO+Zf/jtAHslFeN/8Kb8U/8ARSdT/wC+Zf8A47R/wpvxT/0UnU/++Zf/AI7QB7JRXjf/AApvxT/0UnU/++Zf/jtH/Cm/FP8A0UnU/wDvmX/47QB7JVe+v7PTLSS7vrqK2t4xlpJXCqPxNeR/8Kb8U/8ARSdT/wC+Zf8A47RH8BjfXUcviHxdqOpqnRdhU49NzM2PyoAyftUnxj+K1jLaRSDw5ohD+aykeZyG5z0LkAY67Vz1r3qs7RNC0zw5pqafpNnHa2yHOxO59STyT7mtHpQB458bXDeI/A1uOXa+Y/8Aj8Q/rXuFeB+cPiX8e7IWh36R4dxI0yHKuyNuyD05k2j3VSRXvlABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAU9U0uz1rS7nTdQgWe0uUMcsbdwf5EdQexANeCRv4n+BeqSwTW02reEbiTckq/8ss45z0R/Y8Njjvj6HpskaSxtHIiujgqysMgg9QRQB59pXxb8E6tCHTW4bV8ZaO8BiK/ieD+BNaX/AAsHwd/0M+lf+BSf41FqHwi8B6lN5s3hy2jb/p2d4F/75RgP0qn/AMKQ+Hv/AEAW/wDAyf8A+LoA0f8AhYPg7/oZ9K/8Ck/xo/4WD4O/6GfSv/ApP8azv+FIfD3/AKALf+Bk/wD8XR/wpD4e/wDQBb/wMn/+LoA0f+Fg+Dv+hn0r/wACk/xo/wCFheDv+hn0r/wKT/Gs7/hSHw9/6ALf+Bk//wAXR/wpD4e/9AFv/Ayf/wCLoA0f+Fg+Dv8AoZ9K/wDApP8AGj/hYPg7/oZ9K/8AApP8azv+FIfD3/oAt/4GT/8AxdH/AApD4e/9AFv/AAMn/wDi6ANH/hYPg7/oZ9K/8Ck/xo/4WD4O/wChn0r/AMCk/wAazv8AhSHw9/6ALf8AgZP/APF0f8KQ+Hv/AEAW/wDAyf8A+LoA0f8AhYPg7/oZ9K/8Ck/xo/4WD4O/6GfSv/ApP8azv+FIfD3/AKALf+Bk/wD8XR/wpD4e/wDQBb/wMn/+LoA0f+Fg+Dv+hn0r/wACk/xo/wCFg+Dv+hn0r/wKT/Gs7/hSHw9/6ALf+Bk//wAXR/wpD4e/9AFv/Ayf/wCLoA878MeJtCtvj34m1WfV7KPT57MpFctMojc5h4DdD90/ka9V/wCFg+Dv+hn0r/wKT/GvI/D/AMPPDF78c/EXhu504yaTZ2XmwQefINjfuedwbcfvt1PevS/+FIfD3/oAt/4GT/8AxdAGj/wsHwd/0M+lf+BSf40f8LB8Hf8AQz6V/wCBSf41nf8ACkPh7/0AW/8AAyf/AOLo/wCFIfD3/oAt/wCBk/8A8XQBo/8ACwfB3/Qz6V/4FJ/jR/wsHwd/0M+lf+BSf41nf8KQ+Hv/AEAW/wDAyf8A+Lo/4Uh8Pf8AoAt/4GT/APxdAGj/AMLB8Hf9DPpX/gUn+NH/AAsHwd/0M+lf+BSf41nf8KQ+Hv8A0AW/8DJ//i6P+FIfD3/oAt/4GT//ABdAGj/wsHwd/wBDPpX/AIFJ/jVW++KHgrT4DNL4ispB2W3YysfwXJqD/hSHw9/6ALf+Bk//AMXU9r8GfAFpMsqeHo3ZegluJZF/75ZiD+IoA831vxn4i+LNy/hvwXYT2+lOdt3fTZXK9wxHCr/s8s35ivZPBnhKw8FeG4NHsPmC/PNMRgzSEDc5H4AAdgAO1a9lYWemWiWlhawWttH9yGCMIi/QDgVYoAKKKKACiiigDC8X+FNP8Z+Hp9H1FTsf54pVHzQyDo6+4yfqCR3rxfTvEniz4Nzpoviiwk1HQA2La9g5CL6Kx4/4A2CO3GM/QtRzwQ3MEkE8SSwyKVeORQysD1BB6igDz2w+MHga/iDjW0t27pcROhH6YP4E1c/4Wf4J/wChksv++j/hU978JvAmoS+ZN4atFb0gLQj8kIFVf+FLfD3/AKF1f/Aqf/4ugB//AAs/wT/0Mll/30f8KP8AhaHgn/oZLL/vo/4Uz/hS3w9/6F1f/Aqf/wCLo/4Ut8Pf+hdX/wACp/8A4ugB/wDws/wT/wBDJZf99H/Cj/hZ/gn/AKGSy/76P+FM/wCFLfD3/oXV/wDAqf8A+Lo/4Ut8Pf8AoXV/8Cp//i6AH/8ACz/BP/QyWX/fR/wo/wCFn+Cf+hksv++j/hTP+FLfD3/oXV/8Cp//AIuj/hS3w9/6F1f/AAKn/wDi6AH/APCz/BP/AEMll/30f8K8u0bxf4fg+P2ua3LqtummT2gSO5JOxm2RDA/75P5V6d/wpb4e/wDQur/4FT//ABdeZaP4A8MXXx717w3NpYbSLWyEsNt50g2tthOd27cfvt1PegD1D/hZ/gn/AKGSy/76P+FH/Cz/AAT/ANDJZf8AfR/wpn/Clvh7/wBC6v8A4FT/APxdH/Clvh7/ANC6v/gVP/8AF0AP/wCFn+Cf+hksv++j/hR/ws/wT/0Mll/30f8ACmf8KW+Hv/Qur/4FT/8AxdH/AApb4e/9C6v/AIFT/wDxdAD/APhZ/gn/AKGSy/76P+FH/Cz/AAT/ANDJZf8AfR/wpn/Clvh7/wBC6v8A4FT/APxdH/Clvh7/ANC6v/gVP/8AF0AP/wCFn+Cf+hksv++j/hR/ws/wT/0Mll/30f8ACmf8KW+Hv/Qur/4FT/8AxdH/AApb4e/9C6v/AIFT/wDxdAD/APhZ/gn/AKGSy/76P+FH/Cz/AAT/ANDJZf8AfR/wpn/Clvh7/wBC6v8A4FT/APxdH/Clvh7/ANC6v/gVP/8AF0AP/wCFn+Cf+hksv++j/hR/ws/wT/0Mll/30f8ACmf8KW+Hv/Qur/4FT/8AxdH/AApb4e/9C6v/AIFT/wDxdAEV58XPA1lCZG16GU9kgjdyfyH864HV/Hvib4nzSeH/AALplxb2Eh2XOoTfIQp6gsMhBjsMsR09K9LtPhF4CsphLF4btmYdpneUfk7EV11pZ2un2sdrZW0NtbxjCRQoERR6ADgUAc54B8C6f4C0AafaHzrmUh7q6IwZn/oo7Dt9STXVUUUAFFFFABRRRQAUUUUAFFFFABRXnHhnRf8AhI7vxJc3+sa7ug1y5t4kg1WeJEjUrhQquAAMmrawXnhPxzodjba1f3unayZ4pLTULkztE0cfmCSNm+fHykEEkfMPagDvKKwZvF2nre3dpbQX99JZHbcmztXkWNsAldwGGbBHyqSfarC+JtGfw+2ui+T+zlBLSlSCCDjaVxu37vl243Z4xnigDWorATxdp4vbK1uoL+xa+bZbPd2rRpI5GQm48KxwcK2CfTNQ/wBq2em3fiK4F5qV7JDPEs1rHbyT/ZmMKbVjRVJ2kEMccZY5oA6WiuA0nxLFrnw20+81LUNUsJ9libm8FrJAZJWdPuHaA6u3ykrkYb0NdTqfiKw0u/t9Pk8+e+uFLx21tC0r7AQCzYGFXJA3MQKANaisvSfEFjrE9zbQGaK7tiBPbXMTRSoD0O1hypwcMMg461n23jjSNQgM2lpe6iiqzSG0tHfy9pIIbgYbjIX7xGDjBGQDpKKx08U6M/hs+IPtoGmgEmVkYEENt27cbt275duM54xmoE8X2AuLOG6ttQsftriO3ku7R40dz0QnHysewbBPTrQBv0VyuiXdzL8QvFdtJcSvbwR2RiiZyVj3I5baOgzgZx1xXVUAFFFY3iTxVo3hLTvt2s3qW8ZOI0xueVvRVHJP8u+KANmivOovFfj3xEGk8PeErfTbMn93c69MyM4/64p8y/mRTgPjBGd5PguUD+AG5BP44oA9Dorzr/hZd/oFyIPHHhq50eFiAmo2zfabUn/aKjKew5P0r0C2uYLy2jubWaOeCVQ0csbBlYHoQRwRQBLRRRQAUUUUAeNeFP8Ak5vxd/2Dv/kevZa8a8Kf8nN+Lv8AsHf/ACPXstABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXjXh/wD5Oi8T/wDYOX/0C3r2WvGvD/8AydF4n/7By/8AoFvQB7LRRRQAUUUUAFFFZWseJdD8PR79X1azsgQWVZpQrMB/dXqfwFAGrRXAj41/D0ybP+EgGc4z9knx+eyus0jxDo2vxGTSNUs71QAWEEyuVz6gHI/GgDSooooAKKKwdc8W2Og39vYzWuo3V1cRNKkVjZvcNsUgEkKCQMsPzoA3qK5FfiLo8csa31nrWmxSOsYuL/TJoYgzHABcrhck9TgV11ABRRRQAUVRutVtrPU7DT5S/n3xkWHapIyi7jk9uKfa6nZ3l9fWVvNvuLF1juE2kbGZA6jJGD8rA8Z60AW6Ko6RqttremRahZlzBIXVd6lTlWKng+6mr1ABRRRQAUUVTvdTtrC4sYJ2YSX05t4cLnL7Gfn0+VGoA858KeG59WvfFVzH4k1vTlGv3a+TZSxKhwV5w0bHPPr2rr9I8G2ekag+qSXuoapqZjMaXeoziR40PVUAAVQT1wBmtXTNHstI+2fY4yn2y6e7myxO6R8bjz06Dir1AHJ/DPyz8OdFZCTI0JNwW+8Zyx83dnndv3Zz3rnWsLXU9V8cafLqP9nWU+q2P2a5j2/JeiOJuAeCS6xZB6kkV1k/g+2+2XNzpupalpDXchluksZECTOcZYq6sFY45ZNpPc5qx/wiei/8I++hmyzYO291MjF2fdu3l87i+7ndnOe9AHO6nf8AiLQ0tn8TWWj6xo63duhu7dWimidpFVJDC25SQ5X7rZHUDirnh/8A5Gvxz/1+Qf8ApJFV2LwfEZoW1HWNW1SGB1kht7yZPLV1IKsQiKXIIBG8tzz15rWtdKtLO91C8hjImv5FkuCWJDMqBBx2+VQOKAPPbj/kg/h7/rlpP/o+Cui8N7D468ZGXJuxPahd3aDyFKY/2d5l/HNXofB2kQaGNFRLg6crxPHA9w7iPy3DoFJJIAYDjPbFTat4atNUvotRSe5sdTijMSXtm4WTyyclCGBV1zzhlIB5GDQBj6xkfFXwwbbHmmxvRdY6+R+6259vM24/GmfCmGOL4daf5aBS8tw7EDqTPJyf89q3dH8O2mkTz3Yluby/uFCzXt2++V1GcLwAqqMn5VAHfGas6RpNnoemRadYRmO2iLFFLFiNzFjyfcmgDznT9QSw0/W4l0uPUrq58YTQ2VtK+xBNkSB2bB2hdjPnBOR71a8Zr4n/ALCsZtXv9Igi/tSyza2cEjMzfaEwBK7jp977gPHaurufBmjXNhdWhhlQXF8dR82OUiSO54IkRv4SMD29sE1Wn8DafqFuYtZvtS1ZwVaKW5nCNCQQwZBEEVWyo+bG7qM4JFAFfQP+Sl+Mv+uVh/6LkrsKz7HRbPT7+7voFkNzdpEk8jyFi4jBC9e+Cee9aFAGJ4t8TWvhHw3davdIZPLAWGBfvTStwqD6n8hk9q8+0SPRtE1E+KfiRrenHxVMoaO1mlUjT485VI4+SDzyee+D1LVfinaar4w+JXhvwhply9stvEdRnnVj+6G7aHx/eUKdvu/brXc6D8M/CXh+0SKDRra5mHLXV5Es0znuSzDjPtge1AGzpHiTRNfVjpGrWd7tGWWCZWZR7gHI/GtSuH8RfDDRNTRbvRoI9D1uAmS1v7BBEVfH8YXhge/fHervw/8AE114l8Pyf2lGkWr6fcyWN/GnTzkOCR7EYP1yO1AHT3FvDd28lvcwxzQSqUkjkUMrqeCCDwRXl1xC/wAIdchu7VpG8E6jP5dzAct/ZszdJF7iMnqO31wD6rWdr2jW3iHQL7SLwfuLyFomOASuRwwz3BwR7igDRBBAIOQaK4z4Wandaj8P7BL9gb6yaSxnwc/NExQZPc7QuT3rs6ACgkAZPAorzKzspfipe3WoancTJ4RgnaCy0+GQot8UYhppSMErkfKue31yAYXhK5gk/aY8Vuk0bI+n7UZXBDH/AEfgep4P5V7VXl1j4P8ACOseLfEXhufwrpUdppkVq0MsERjmYyqxbLg542jGK0tButT8IeLIPCWq3s2oabfxvJpF7cHdMrIMvBI38WF+YMfpzwAAd/RRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXjXh//AJOi8T/9g5f/AEC3rtvEPjK4tdaXw74d03+1tcKCSZGk8uG0jPRpXwcE9lHJHpxnhbDw54vtPiVqfiC21Lw3ceJJLVPten7J1jWI7QNrdifLHP1oA9pormPC3jAa7dXWlajYSaVr1kN1xYStuyhOBJG44dD6joeD2J6egAoorg/i94tk8I+Arma1dkvrxhaWzqcFGYEs+eowobB9cUAU9W8T634w1668NeC5ltLe0by9S1xl3CFucxxKeGf3+vTg1q6J8LfCujlpprBdVv5G3y3up4uJZGznd8wwD9APxrkPBmheObjwzY2mkT2vhDRo490e+3F1eXDHq8gfCru5PYjgdMVtXVn8TPC6Nf2+s2niu2jUtLYz2a2s2B/zyKZy31/AE0Aehm2gaMxtDGYyMFSoxj6Vx+t/CzwxqpW4s7P+xtSiO6G+0vFvJG3r8uAfxGfcVueF/E2n+LdDi1XTi4RmKSRSDDwyD7yMOxH8iD3rZoA850TxXrHhjXoPC3jiRJXuW26brUabY7vnhHGMJJ0/T2LejVh+LfC9j4v8O3OkX6ArIN0MuPmhkAO119xn8QSOhrK+GniC813wp5WqBhq+lzvp9/uOSZY8DdnvkEEn1zQB2NcJ4g1e20X4oaRcXUd1Ij6RdRgWtrJO2fNhP3UUnHB5xiu7rmLm1uG+J+nXYglNsmkXMbTBDsVzLCQpbpkgE49jQBjeK/Ei+IvDV/oWjaLq93e6lC1qn2jTZreKLeMeY7yIAAuc+uQBV77Rqepa83hnTtUktLfSbSE39/GiPcSSuPkRd6lR8qlmYg/eUDHJrsq464E/hfxnqOrPaXdzpGrRRGaS1iad7a4jGwZjQFijJt5AOCnPBFAEkF3qvh/xTp+kahqE2qWGqLILa6niRZYZkXf5bGNVUqyhiDgEFSOeMZel6heeKbzVEHjG40vUba8mt10y3it/3CoxVGZZI2d9wAfIIHzYGMVfWa48V+LtJvLe1vLfR9JMs5lu7Z4GuJ3QxqFRwH2qruSxABJAGcGs26udJ1S3e18deFHn1aAvEZLfRZrmOVc/K0MiK5AIxwWBByD0oA0Tq3iC21fwbYak8MFzem5TUI4AGSQpESpUkZAyA2B64OaoeENLv4PHvit5fEF9cJBd24lSSKAC4JtY8FysYIxkAbdv3RnPOa2j6Pq1rf8AgcXFre+Va3GoECbMjW1uyP5CSuMgEIUXk9eK29IM+mfELxFDdWN4ItUlgntLlLd3hYLAqMGdQVQgxnhiM5GM5oAztL8V6zceBtFlR47jW9WvpbOKWRAEjAklJkZV2ghI4ycDGSB61d1mHX/C2kTa5D4gvNWWyTzruzvIYAssK8yFDHGhVwuSMkjjBHOax9G0bV7bwH4cu4LGX+0dI1Ge6azlXZJLE0kyOoDYwxSQsueCQPWtTX9ek8TaDdaHoenamb3UYjbPJd6dNbx2yONru7SKoO1ScKpJJxx3oAkl1DWdY8cXGk6dqRttIOl2939qhSNpEZ3lACblI+cKOSGACcAFsibTLjVtJ8bf2DeanLqlndWD3kE1ykazRPG6IyHy1VWU+YCDjIwam0jTG0/xtqCxW8qWKaRY28MhU7TsefKhu5AK5+o9aZqlnfSfEC0ubWKQKui3cS3Gw7ElaSEqC2MA8E49j6UAU/s+ttpzahrnjCXQryRWk+yRfZTBajspLoxfAxk7hnnGBVG016TxNpHw71mZESa61AtIqAhd4tbkNjPbIOKpeFbTQbDSbGO48IXc/itUBuZLvSpHke6/jc3TqU2lsndvxgjHpR4U03Ubbw34J064068iudK1eaO7D27Kq4huPnBxgod6gMOCSBnNAHb3HjLwvZ3Mltc+JNHgniYpJFLfRKyMOoILZB9qn07xNoOsXJttM1vTb6cKXMVtdxysFGAThSTjkc+9cB4U8S+FdIvfFVtrOp6bbXR1+7cJcuoYqSuDz24NdjpvibwzqAum0O/068nt4WldLV1LBR646DOKAOiorjtG8ReJfEfh231rT9HsLeKeBJYYLu5ffKSAW5VMIvXaec8Ehc1JF46iu/CekavZ2Ek17qziC1sN2D53O9WbHCpscs2Oi5x0FAHW0VzM2r+IdKubA6lplpcWdzKkE0lhI7PbO5wCVZfmTOAWyCM5xgU/+3dR1PW7zT9EtbZoLBxFdXl1IwUSlQ3loij5iAy5JIAz3OaAOjorn9I8RyTXt9pms28VhqdlEJ5FSXfFLCc4lRiASuVIIIBBHuCamna54i1vTBq+m6XYJZTASWcV1cOss8R6MxCkR5GCB83UZxQB0B1TT1Dk39qBHOLZyZl+WU4xGeeGO5cL15HrVuvK9C1y0l0zW7+bS2mSfxdFCLe5wrQyE26bjjI3I3PHdeveuobxTqV34u1Tw7pmlxNLYrBI93PMViVJFJ5AUndxgKODgkkY5AOsormtP8S3Eeuajo+uQW9rcWlsL2OeGQtHNbkspfkAqVK8jnqME1Dpuu+I9Z0tdYstIsksplEtrbz3LCeaI8hiQu1GK4IX5uuCRQB1dFYfhPxGvirQhqsdtJbI080SxyfewkjICwxwTtyR2zjmtygDzixi8n9oXVDKxZ59Ajkhz/CglVWA/wCBDP516PXnPxDeTwz4n8P+OUXNnaMbDVMDkW8pG1+B0VucdyR716JHIk0SSxOrxuAyspyGB6EH0oAdXnfhJV0/4v8AjqyfEZu0s7yCPGN67CruB3+YgE+teiVxvjXwfeate2PiDw/cxWfiPTciCWVcxzxnOYpMc7Tk4PbJ9cgA7KkZlRC7sFVRkknAArzyH4l6pYg22v8AgPxHDfJw39n2wuoH91kBA59Ocetcb8SfGHi7WvCk622jXGgaRcyC2UXgxe37NwIkiAJUHnPqBwf4SAZXhnwn4y8Wrq+ueGfFcmkaVearcyRQLNIgfL534Xj0H4Vu/wDCsPih/wBFFm/8CZ69M8CeHP8AhE/BOl6MxzLBFmY5z+8YlnwfTcxA9gK6KgDxBvhf8UChH/CxJjkdPtU/NbHgjStX1rwBoR0bxRcaItnbtaXNrHaRS/vkdg5beMgn0r1euE1Hw1rvh7XbvXfB32aaO9bzL/R7lzHHNJjmWJhwkhwM54PU0AcponhrxNL8R/FdtF43uobqGKyM10LGEmcMj7QVIwu3BHHXPNbGqWV9ZeJ/BOlahrUmr6k2qTXYnkhSJkhSBgw2pxjJ6981HZ6t4ii8Tatdad4EuU1y+it/ta3WqQeRCq71jb5csRw/QZOK6Xwr4UvbDU7rxD4gvUvtfvIxEzRLiG2iByIogeduepPJwPfIB1tFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAeR+BfE9rovhSPW7nSdVvr7xBd3N7cSafZtcbSJWUKxHTAHA+tVdP8AH1rF8UdZ1I6F4hZJtPt4hCumuZVKs3LJ1AOeD3rc0fUo/hvrV14e1oi30O9unuNJ1AjbCnmEs0DnohU5IJ4IPatKzCWfxE1nxFcXNpFo9xp1vFFdtcxhGZWYsPvZGMjk8UAcp458X20UOg+OLTSNSt7nTNS+yPFe2xt5J4ZI23KAeo447A5qp/w0Xa/9Cpf/APf4f/E109ve/wDCx/GWnXdijHwzoUpuFunQhb26wVXy89VTk7vXj3r0egDxH/hou1/6FS//AO/w/wDiayv+E1s/iz8S/B+mXGjzWtlazTzyRTuHEzCPeuRjoDH+IY19B1538SZE0bxF4M8Uy8W9hqD2tw56Rx3CbC7HsBj9aAPRKKKKAPO9Cgj0T42eIdOtVCW+qabFqbxrwFlEhjYgerEkn1Jr0SvO/H1teeHvEmlePtPtprmOxia01WCHl3tGOdwHfYxLflnABNdpo2uaZ4h06PUNJvYbu2kGQ8bdPYjqp9jzQBoV594Mfyvin8QrJOIVlspwo6B3hJc/iQK6DxX410Pwbp5udVu1WRgfJtk+aWZsdFUflk8DPJrivglLe63D4k8X36FJtZvwFXHASNflC+oG8rn/AGaAPVqKK5bX9c12DxNZaJoVnp0009pLdO99M8aqqOi4GxWOfnHbtQB1NFcpDN8QDPGJ7DwyItw3lL2csFzzgGLriuqJCjJIA9TQAtFICGGQQQe4oLKGClhuPQZ5oAWiikVlcZVgR7GgBaKRmVRliAPUmsq41d4fFVhpCxK0d1Z3FyZM8gxtEoH4+YfyoA1qKp6TNfXGk2sup2qWt88YM8COHWNu4DDrVsMrEgMCR1APSgBaKRmVRliAPUmloA838GeJtA0i48VW2p65ptlOfEF24iubuONipK4OGIOOD+VdS3ifQNXtLy203XNMvbj7PI3lW13HI2AOThSTithrK1dizW0LMTkkxgk0sdrbxNujt4kOMZVAOKAMPwD/AMk78Nf9gu2/9FLXA+H8ab4f8E+I7j/jwsLu/gunxkQrNJIqyn0UMoBPYOT2r19VVFCqAqgYAAwAKRURE2KqhfQDAoAxNY8UWunNp9vZiO/vb+eOKC3ilGShI3ynAPyIuWJxjgDIzWR4RuYdJ1rxFod68cF4+pzX0Af5ftEEuHDrn720lkOM42jNdLp+h6RpEksmm6VY2Ty/6xra3SMv9SoGafqOk6brFuINT0+0vYVbcI7mFZFB9cMCM0AcRfW//CYeLNbfS5I3tbbQ59Ja6U5VrmZg20HodgUZx0L46g1s+D9f04+BtPkuLmG0awtI4L2KZhG1rJGoV0cHBXBB69Rg9DXTQQQ2sCQW8UcMMY2pHGoVVHoAOlVZtE0m41KPUp9Mspb+P7l09ujSr9GIyPzoA8n0+5N74f1a6+zyW6zeObeRI5Yyj7TLblSVPIJBBwfWu18Pf8lK8af7lh/6Keuu8qM5/dry248dT6/WlCKGZgoDN1IHJoA8/wBf05tX+IupaYj7GvPCc1uH/ul5iuf1q74e8aaRa+HLKz1KYWWr2tukE+mOpFx5iqARHEPmkBI+UqCCK7J4gwYr8khUqJABkfnXM2lz4ys9L+yXOm2OoX8QCJei78qOf/po67Moe5VQwz0IFAEXw3knm8LTy3Nv9nnfU75pIdwby2NzJlcjg4PGa66sbwrosugeHbawubgXN3l5rmYDAkmkcu5A9NzHHtitmgCC9srbUrGeyvIVmtp0McsbjhlIwRXmFpcap8IGFhfRXWqeCy37i+Rd82ng5JWRQPmTPcdM/Ra9WoIBGCMigDP0jXNL1+yS80m/t7y3YAh4XBx7EdQfY81oVxGqfCbwhqN19sgsH0u+/hutMlNu6H1AX5c++KpN8IrWZTHdeMfGFzAeGhm1TKMPQjb0oA3vE/j3QPCiiO+u/NvnIWKwtR5txKx6AIOmfU4HvXP+G/Dms+JfEUPjLxjCLd4ATpOj7ty2an+N/WQ8fT2IAXpPDvgTwx4Vbfo2j29vNgjzzl5cHqN7Etj2ziuioAKKKKACkZlRCzMFVRkknAAparahY2+qadcWF2pe2uY2ilQMV3IwwRkcjIyOKAPnrwT8TZb746XlzNN/xLdZkNnEGJARVyICB6nGMesjGvo6vAPD3hLQbv4/eKNFk0yAafBYB4IYxs8lgbfDIRgq3J5BzyfWvfgMADOfc0ALRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAEN3Z2uoWklreW8VzbyjbJFMgdGHoQeDXjOj23w/vPjPqvhtPD2llIrZEgzEGRriMs0oCnjOGwRj/lka9kvnuo9PuHsYkluxGxhjkbarPj5QT2GcZr5d8P+DPElp8ZbqyttRtZte0sLqLySFhHcMfLZ03YyMiUjOOfbPAB9URxxwxJFEipGgCqijAUDoAOwp1IpJUEggkdD2paACs3xBodp4k8P3ujXwJt7uIxsRjKnqGGe4IBHuK0qKAPPPAnie6sLs+B/FUnla9ZLttZ5DhdQgH3HQ92wMEdeCeobHodYXirwho/jHTRZ6tblimTBcRnbLA395G7HgexwMg1y0Nl8S/C7GK0urDxVpy/6tbxzb3gH93f90/7zZJ9qAPRq4fVvhH4O1W8e8GnPY3bnLS2EzQk+vyj5efpVT/hMviD9z/hWD78/wDQah2/ntpkum/EjxUfK1G/svC+msPnj05zNdsO6+YflXv8y8j3oA5HWfDvh+z1g+EPAWlRzeIbkbb/AFWVjOdPiPDsXYkK5BI+XB59SK9j0HRbTw7oVlpFipW2tIhGmcZbHVjjuTkn3Jqr4Y8J6P4Q0wWOj2giU4MsrfNJM39527nr7DPAArboAK4TxAmrP8UNJGjT2UFx/ZF1ua8geVNnmw5ACupznHOfWu7rkvEGk+Im8WWGuaCulyGCymtJY7+aSP77o2RsRv7nf1oAtW1v40F1CbrU9Ae3DjzVi0+ZXK55CkzEA46Eg/SsDSvDthrXj7xnLqsKX1rHd2yx2dwoeEP9liy5Q8M2MAEjjBx1NaqzfEPcN1h4X255xfXGcf8AfqtLRtHuNP17xDfTPE0WpXUU0IQksoWCOM7uODlD0zxigDkpnj8DXnjX+xoUgtbfSIdTgtFXEMU589SVUcAHykJA9K27X4eeHm0tY9T0+21DUZIx9o1KaMG4kkxy4kPzKc9MH5eAMYq5c+Gxf6/rM955b6dqWlw2DRhjv+Vpi+eMAESjBznrVK3g8badpqaVAukXnlIIodUubqRZCoGA7wiMhnA64cBjzxnAAKFzp9xd654e8H6rqEt/Zw6bLd3rONv25o2jjQSc5I+csRkhiBnIp3iLRdO8Iiw17QLK30ySK+t4LqK0iEUdzDLKsbKyLgEjeGUnkEehNXZfCV5YwaJdaTqBl1XSYGg33zMVvY3271kYZYEsoYMM4I6EcU6bSde8RX9gdchsLHTrK4S6+zWly873EqHKbmKJtVWw2ADkgdB1AKdhpVj4t8UeILrXbWHUINNuxYWVrdRiSKECKN3cKeCzM/3iMgKAO9QW2iQaJ8VrCKwPk6fJo900VkvEcD+bBvKD+FW+X5RgZBPUmtabSda0fxBfanoMdnd2+pFZLqzvLhoNkyqEEkbqj/eVQGUjqoIPUVDY+Htbk8bQ+JdUubVf9AmtDZwOzJBl42XaxUbydrlmIX+EAcZoA5HTbN9Q8B/DC1S5kt/Muk3yREhtgtpyygjkblBXI5Gcjmt3xP4b0fw7/Yuq6Hptrpl7Fq1pCZbOFYjLFLKsbo+0fMCG79wDV3SPCN/YaH4MsZZrYy6JLvuSrNhx5EsfyfLzzIOuOM1seKNHuNasLOC2eJGh1C1umMhIBSKZXYDAPOFOPf0oAwdO0mw8W+JvEN5rtpFqEen3v2CztbqMSRQIIo3ZghGNzM5yxycAAcVT0rSINF+NMltZsUsm8Pl4bYY2W/8ApCgqg7KSM46Ak444rYisXHi3V7nw9rFuk7NGNU0+5haRBL5a7JFIZSjFAoPUHHYjNZOi2Fynxjvrm5vvt1xHoqJdyIuyOFnmzHEqZJUbULYJJOSSeRQB6HRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVzvinxz4d8GRRNreoLA82fKiVC8j477VBIHucCuirwGbSbPxT+0hrVvrMQu7aytVeKCTlOEiABHcZdjj1oGld2Oy/4X14E/5/bv8A8BHo/wCF9eBP+f27/wDAR61v+EH8J/8AQs6P/wCAUf8AhR/wg/hP/oWdH/8AAKP/AAqeY09kzJ/4X14E/wCf27/8BHo/4X14E/5/bv8A8BHrW/4Qfwn/ANCzo/8A4BR/4Uf8IP4T/wChZ0f/AMAo/wDCjmD2TMn/AIX14E/5/bv/AMBHo/4X14E/5/bv/wABHrW/4Qfwn/0LOj/+AUf+FQ3XhLwXZQedc+HtFij3Km5rKPG5mCqPu9yQPxp8weyfcz/+F9eBP+f27/8AAR6P+F9eBP8An9u//AR61v8AhB/Cf/Qs6P8A+AUf+FH/AAg/hP8A6FnR/wDwCj/wpcweyZ5FoPxJ8N2Hxs8QeKLi4nXTL2z8mFhCxYt+56r2+41ej/8AC+vAn/P7d/8AgI9a3/CD+E/+hZ0f/wAAo/8ACj/hB/Cf/Qs6P/4BR/4UcweyZk/8L68Cf8/t3/4CPR/wvrwJ/wA/t3/4CPWnJ4M8Hwpvl8OaKi5Ay1nEBknAHTuSBT/+EH8J/wDQs6P/AOAUf+FPmD2TMn/hfXgT/n9u/wDwEej/AIX14E/5/bv/AMBHrW/4Qfwn/wBCzo//AIBR/wCFH/CD+E/+hZ0f/wAAo/8AClzB7JmT/wAL68Cf8/t3/wCAj0f8L68Cf8/t3/4CPWt/wg/hP/oWdH/8Ao/8KP8AhB/Cf/Qs6P8A+AUf+FHMHsmZP/C+vAn/AD+3f/gI9dr4c8UaN4s03+0NFvUuoA21sAqyN6MpwQfrXPnwN4SII/4RnR+fSyj/AMK88+GFpHoXx38T6Np5aHTxauwgDHaCGjK/lvYD2Jpp3JlBxPeqKKKZAUUUUAFFFFABRRRQBz/ijxt4f8GwRS65qC25mJEUYUu7464VQTj36Vyf/C+vAn/P7d/+Aj1xV/plr4n/AGlNTs9Zj+2WlpbKYoJTlABEhAx6Zdmx6mvSf+EE8Jf9CzpP/gGn+FJsuNNyVzL/AOF9eBP+f27/APAR6P8AhfXgT/n9u/8AwEetT/hBPCX/AELOk/8AgGn+FH/CCeEv+hZ0n/wDT/ClzFeyZl/8L68Cf8/t3/4CPR/wvrwJ/wA/t3/4CPWp/wAIJ4S/6FnSf/ANP8KbJ4I8HxRtJJ4c0dEUEszWkYAHqTinzB7Jmb/wvrwJ/wA/t3/4CPR/wvrwJ/z+3f8A4CPVFR8Lmn8saXpAUnAnbTcQHnH+tKbP/Hq6EeBfCLAEeGtIIPIItI+f0ouHsr9TM/4X14E/5/bv/wABHrzfSPiV4ctPjlrfiqaacaVeWYhicQksWCxDleo+41euf8IJ4S/6FnSf/ANP8KZH4K8GzBjF4e0ZwrFG22sZww6g8dRRzB7Jmd/wvrwJ/wA/t3/4CPR/wvrwJ/z+3f8A4CPWp/wgnhL/AKFnSf8AwDT/AAo/4QTwl/0LOk/+Aaf4UuYPZMy/+F9eBP8An9u//AR6P+F9eBP+f27/APAR60pPBHg+KNpJPDmjoiAszNaRgADqScUq+BvCDqGXw3pDKRkEWkZBH5U+YPZMzP8AhfXgT/n9u/8AwEej/hfXgT/n9u//AAEetT/hBPCX/Qs6T/4Bp/hR/wAIJ4S/6FnSf/ANP8KXMHsmZf8AwvrwJ/z+3f8A4CPR/wAL58B/8/t3/wCAj1qf8IJ4S/6FnSf/AADT/Cj/AIQTwif+ZZ0n/wAA0/wo5g9kzoPDnijRvFmnfb9EvkuoA21sAqyH0ZTgj8RzWxXhHw5sYvDvx88R6JppaLTjZl/I3ZUH90w/LewHsa93qjJqwUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBkaj4Z0nVL1b64t5Y71U8v7Ta3ElvKUznaXjZWK57E4qxpWi6dokMkWn2wiEr+ZK5Yu8rf3ndiWY+5Jq/RQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFeHaJ/ycv4o/wCvL+kFe414don/ACcv4o/68v6QUnsVD4kes0UUVB1BRRRQAVz/AI1/5Fs/9ftn/wClMVdBWR4lsLjU9F+zWyhpftNtJgnHypOjt+immD2M59R1zUvE+qaRYzWtnbWUcL/angMrkuCdoG4Dsee3oc5FKXxNrdlpN7G9vaXWq2eqw6eNoZI5xJ5ZRupKErKM9QCD16Vuadp1zbeJ9bvpFAgu1txEQ2SdikNx261zniPTtQt49SmgMUct5r1jNaO/zKcLbp8wHONyEH2oId7XNK/vNf8AD6xajf3tle2Bmjjuoo7YxGBXYLvQ7juAJGQe2cEdK19N1Ga81XWbWRUCWVykUZUHJDQxuc89cufTjFYupprXiS2h0mfRHsLZ5Y2vbia4jdSiMGKxBGLEsVxlguAScVMBq+j+I9Wnh0iXULLUGjmje3miVo3WNYyriRl4wikEZ6nigZj+IdQ1XVtE1AQzWVulnrcFrh7ZpC4E8BQ5EgwQzZPqOBt613VqtwltGt3LFLOB87xRmNWPspZiPzNcXHoGuf8ACM6xHNDA+o3GqpqEcSy4RgrxSbA3b7hUEjtnAzXZ2ks01pHJcW5t5mGXiLhth9Mjg0AtyaiiikUFFFFABXkvgj/k5LxP/wBeb/zhr1qvJfBH/JyXif8A683/AJw1UTKrse5UUUVRgFFFFABRRRQAUUUUAeFWH/J0Gvf9eo/9FQ167XkVh/ydBr3/AF6j/wBFQ167Uvc6KXwhRRRUmgVynjP/AEy60DRZObTUb/bdKekkccbybD7MVXPqMiurrH8SaNJrFjCbWVIdQs51urOWQEqJFzwwHO0gspx2NMT2NR4IZbdreSJHgZdjRsoKlcYwR0xjtXCaFq11o1jb6VCVlhi8QyaUhlyxWDazqAc9VGFGc8CtxtY8Rta+VH4XkS+IwJJLyL7MG9dwbzCO/wBzNZ8/hW90/wAPaetkVvtRtNSGpT7mEf2qRi3mYJ4XhzjPoAfWgT8jX1zVrux1bRLG08gf2jPLC7yoW2bYXcEAMP4lGfbPTrXKaRf6xoXhPxbqr3FhcNaXd9KkYtXTMquSST5h+U4+71H941sXUGt614n8PX7aS9jY6fPI8q3E0bSktDImcIzDAJA6knd0GOcrWbLUdM8FeNrW6tFFtMt7dw3KSghxJlgpXqCMn24pifc2Lu58VWmkSa551jJ5UPnvpYgIygG4qJd2d+O+MZ7d6vaT4gfVPEN3aRrH9iSwtbuF8EOfNMmc84xhF7etZ11N4mvPD76Ouj7LyaH7OdRM8f2cKRtMmN3mZxzt29eM96ItLv8Aw34hF1YadLqNhLp1vZssEsayxNCW2nEjKCpD+uQR0pDIPE2pajfaX4y0+CS1hjsbPIZ4WcujwMzjhxg+h7dwa6Hw2l4nh+yF7PBNJ5KFWhhMQC7RgEF2yffP4CsC30PWb2Lxc19DDbSaxbiO3QSbhH+6ZAGI7jgnjGScZAzXQ6Ab0aLbRahZfZLiFFiMYlEgO0AZBHY0AtzTooopFBRRRQB5T4W/5Oa8Rf8AXgP/AECCvbq8R8Lf8nNeIv8ArwH/AKBBXt1aI5JbsKKKKBBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAV4don/Jy/ij/AK8v6QV7jXh2if8AJy/ij/ry/pBSexUPiR6zRRRUHUFFeReErP4bSeGbR9Zbw6NRO/z/ALTPEsmd7feBOemK7FdY0Lw3pmlxeH7KG5s9Rumgt1010KGTazdc46pgnPHfpTsSpdTrKK5MeLNVj1L+yLnw66apLEZraOK6DwyIDhi0m0bMHGRtP3hjNZ3iTX3vvBniK21Cz+wX1gkRuIhKJVCsQVZXAGQcHsDkHiiw+ZHe1Dc2kF4ka3EYkWORZVB7OpBU/gRXOT+K7+yh/tG/0GS30XhmuvtCtLGh6O8QHC8gnDEgdRwaual4guY9SOmaPpw1G+SJZpQ04hiiRiQu58NycHAAPAzxQF0btFc7/wAJdDDpt1NeWVxBf2syW8lgpV5GlfGwIQcMGyMHjoc4wcYniXWdTbTrO21fRfsP2jVLJYJIrkTqSLmNtr4UbTgE9xwRnpksDkjvaK5+88QXrapcado2kf2hLabftUktwII4yw3BQ2GLNgg4xgAjJ5rl7fUra71DxVc3thOqi906OS2kbY6SBkUcjggNhsjgj60WByPSKK5u48S3suq6jpekaOby7sHQSma4EMWHRXHz7WOfmIwAfu84yMpH4ygbRhdNY3C3xuzYCwBUyG5B5QNnbjALbum3n2oDmR0tFcs/iu/0+8sLXWdDa0kv7lbeB4LkTx5OfvNtXaeM4xzzg8V1NA07hXkvgj/k5LxP/wBeb/zhr1qvJfBH/JyXif8A683/AJw04mVXY9yoooqjAKKKKACiiigAooooA8KsP+ToNe/69R/6Khr12vIrD/k6DXv+vUf+ioa9dqXudFL4QooryPwtZ/DeTw/C+tN4eGomSbzvtU8SyZ818bgTnpikW3Y9corko9V8OeGNFtH8PWlvcWV7fC3RNMZGVpWU9wcZ+UDqPfFObxZqdrqUWmX/AIeeK+u1drFYboSpLtxuDvtHlkAgngj0JPFAcyOrorgvEevT6h4N8WaZqOn/AGDUbXTHleJZhKjxurBWV8DPKsCCBjFaLeK9QtbBdUl0CUaGkQka5+0AzLHj75hx93HP3t2P4c8UWDmR1lQXtnb6jYz2V3EJbedDHLGejKRgise/8Rz/AG8afomnjU7sQrcSbpxDFHG2dpL4blsHAAPAzxTV8WW8OlX11f2k9tdWDrHcWYxJIXbGwJjhw5YBTxk8HBBwBdHQgBQAOAOBRXnnjPWtVPhS5i1XQmsop5IUiliuRPtPmKQJAANmcYyNwzxnkV0d54gvW1S407RtI/tCW02/apJbgQRxlhuChsMWbBBxjABGTzQHMjoKK80Op2l1/wAJxdahp0/lIbVLizkbY4YIARuHbOCCOCMHvXUXXia7Ot3uj6XpDXt7aJHI5knEMQVwSMtgkHjgAHOD0osCkdHRXNxeL4ho9zdXdhcQ3ttdCyexVld2nO0qqHIDBg6kHjg5OMGopPFd/p1zYwazoTWjX10ltbvDciZMsejHaNpxzjkHB5oDmR1NFFFIZ5T4W/5Oa8Rf9eA/9Agr26vEfC3/ACc14i/68B/6BBXt1aI5JbsKKKKBBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAV4don/ACcv4o/68v6QV7jXgY1K08PftKa3Jqsy2kN7arHDLKdqElIiPmPAHyMM+vFJlQ+JHslFZn/CR6F/0GtO/wDApP8AGj/hI9C/6DWnf+BSf41J1XRx/g7xZpWjeFLLT78ajFdQbxIg0y5bB3seqxkHgjoa1L+/h13U/C17p6XElvFqcgdpLaSIr/o0oyQ6ggZIGcY5rc/4SPQv+g1p3/gUn+NH/CR6F/0GtO/8Ck/xoJtpa5WmikPjyymEbeWNMuFL44BMsJAz68H8q5PxNZXk11458i1kkaawsFhBQlZGDS5A9cZGfrXa/wDCR6F/0GtO/wDApP8AGj/hI9C/6DWnf+BSf40A0mc14h8S22ueGb7RbG3um1i/t3tFs3t3VondSpLkjCquSd2cHHGciqV3p9jonii5k1uXU4rG6tbdYLy0u7iKPfGuxkfyWGDjaQW65ODXZf8ACR6F/wBBrTv/AAKT/Gj/AISPQv8AoNad/wCBSf40Ba5w50+KRH8QaTpuoyW9pqFvPvnnnmuL2KNXViqyknC+axUcbtp9q0fEXiG216zsbTRobi9P9o2ctw6wOqwItxGSSWA+bOBt64yTwDXT/wDCR6F/0GtO/wDApP8AGj/hI9C/6DWnf+BSf40BbzMO31W28Ma5rNtqomhhvLoXltc+UzxyBo0UplQcMrIeD2IxWGzXWpyeJb1dOuoYrm+0x4FliKu8ayRgtt6joTg8gYziu4/4SPQv+g1p3/gUn+NH/CR6F/0GtO/8Ck/xoC3mVtEikTX/ABK7xsqyXsRRiMBh9mhGR68gj8K5Z7C9gvZdZisp5xp3iGa4eBEJeSF4BGWQfxEbsgDrg45rsv8AhI9C/wCg1p3/AIFJ/jWdrN7oGsWaxf8ACRWlrPFIJoLiG7j3RSDoQCSD1IIIIIJoBoxNd8RQ63feHo9PtLw28erwtNcXFtJAFOGwqiRQWPUnAwAOTyK7+uMtm099Ttb7VvGdnf8A2Ql7eEPDFGrlSu8gHLMASBzgZPFdB/wkehf9BrTv/ApP8aAXmadeS+CP+TkvE/8A15v/ADhr0c+JNCAJOtacAP8Ap6T/ABrzH4aXcOs/H3xPqlgxnsTaOonUfKfmiA599px6gU0RVeh7zRRRVGAUUUUAFFFFABRRRQB4VYf8nQa9/wBeo/8ARUNeu14xPqFroX7TOqz6pMtpBc26pFLMdqEmKPHJ4xlSM+oxXrH9uaR/0FbH/wACE/xqWdFJ+6X6898IeK9L0XwzbaffjUIrqGSYOg0y5cDMrkcrGQeCOhrs/wC3NI/6Cll/4EJ/jR/bmkf9BSy/8CE/xpFvuc/qepW/iBdBudOS5kih1mMSGS1kiK4jfJw6g4+Yc9K0tQikbxpocojYxpbXYZwOFJMOMntnB/Kr39uaR/0FLL/wIT/Gj+3NI/6Cll/4EJ/jQBxPi+zuZtQ8XtFbzOJfDaRxlUJ3vum+Uep5HHvWhf8Aiu2n8OT6ZFaXTa3LbtbLpxt3DeaV28nG0Jn+PO3HOa6b+3NI/wCgpZf+BCf40f25pH/QUsv/AAIT/GgVvM4MaVZ+HdbYa9LqUVpPY2scN5aXdzFH5kSbHR/KYYPAYFuuTg9qkGnR3Gn6hrGjabqEiRXlpPG1zcTyz3yQPubCzMSAAzbf7xH0ruP7c0j/AKCll/4EJ/jR/bmkf9BSy/8AAhP8aA5Ucd4u8SWuveGJrHRoLq9uJXiaRVtnXyFWRWJfcBg8YC9c9sAkaNvqtt4Y1zWbbVRNDDeXQvLa58pnjkDRopTKg4ZWQ8HsRiug/tzSP+gpZf8AgQn+NH9uaR/0FLL/AMCE/wAaAt1uef3pu9U0/wAb3aaddxJdi1NskkRV5FVQN23qM4zjqBjODxXXaTDInjPxHK0brHItrscqQGwjZwe+K0v7c0j/AKCll/4EJ/jR/bmkf9BSy/8AAhP8aASRx+padetqeqajBaTTmw1+3vhCi/NPGLOKN9mfvEBmIHcrik1/xHDrdxoMVhaXnlR6vbNPNdWkkAQ7iAo3qNzZ9MgAHJ5FdHq9xour6e1q+t28DhlkinhuUDxOpyrDJxwex4PQ1lw29pNqNnd6x4vt9QWycywQgxQoJMEB22nLEAnHQc9KBNdjsaKof25pH/QUsv8AwIT/ABpDr2jqpZtWsQB1JuE/xoLujznwt/yc14i/68B/6BBXt1eE/D69g139oTxHqunN59iLIp5yj5SR5ScH3Ktj1AzXu1WjkluwooooEFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXK+Mfh54d8cxINXtWFzGu2O7gbZKi5zjOCCOvBBAya6qigDyD/hnHwh/0Etc/7/w//GqP+GcfCH/QS1z/AL/w/wDxqvX6KAPIP+GcfCH/AEEtc/7/AMP/AMao/wCGcfCH/QS1z/v/AA//ABqvX6KAPIP+GcfCH/QS1z/v/D/8ao/4Zx8If9BLXP8Av/D/APGq9fooA8g/4Zx8If8AQS1z/v8Aw/8Axqj/AIZx8If9BLXP+/8AD/8AGq9fqpql3LYaVd3cFrJdzQxM8dvEPmlYDhR9TgUAeA6Z8J/Amp/ELWPCsep6z5mn28UoYTxEuxJ8wf6rHy7ox9S3pXVf8M4+EP8AoJa5/wB/4f8A41Xl3hPT/FmlfGO4unszdavp7Nf6lbwsrO8cm3zQgBwzYmyAO/TNfWAORmgDyD/hnHwh/wBBLXP+/wDD/wDGqP8AhnHwh/0Etc/7/wAP/wAar1+igDyD/hnHwh/0Etc/7/w//GqP+GcfCH/QS1z/AL/w/wDxqvX6KAPIP+GcfCH/AEEtc/7/AMP/AMao/wCGcfCH/QS1z/v/AA//ABqvX6KAPIP+GcfB/wD0Edc/7/xf/Gq9D8LeENE8G6abHRbMQo2DLIx3SSkd2bv346DPAFblFABRRRQAUUUUAFFFFABRRRQBy3jL4e+H/HMEa6vbOLiIbYrqBgkqDOcZwQR7EEc1xH/DOPhH/oJa3/3+i/8AjdewUUAeP/8ADOPhH/oJa3/3+i/+N0f8M4+Ef+glrf8A3+i/+N17BRQB4/8A8M4+Ef8AoJa3/wB/ov8A43R/wzj4R/6CWt/9/ov/AI3XsFFAHj//AAzj4R/6CWt/9/ov/jdH/DOPhH/oJa3/AN/ov/jdewUUAeP/APDOPhH/AKCWt/8Af6L/AON1ykPwn8CS/Eq58Hf2prAmiskuFb7RFkyZJaP/AFfXYUYe270r6Fu7gWllPcmKWUQxtJ5cKF3fAzhVHJJ7CvlPTtO8ZwfGae8SxEniC1l/tO4s1nXJR8M0Ybp9yTbgfhQB6l/wzj4R/wCglrf/AH+i/wDjdH/DOPhH/oJa3/3+i/8AjdevRuJI1cBgGAIDDBH1HanUAeP/APDOPhH/AKCWt/8Af6L/AON0f8M4+Ef+glrf/f6L/wCN17BRQB4//wAM4+Ef+glrf/f6L/43R/wzj4R/6CWt/wDf6L/43XsFFAHj/wDwzj4R/wCglrf/AH+i/wDjdH/DOPhH/oJa5/3+i/8AjdewUUAYPhTwbofgzTms9FtBEHwZpmO6SYjoWbv1PHAGTgDNb1FFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB414U/5Ob8Xf8AYO/+R69lrxrwp/yc34u/7B3/AMj17LQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAV41pP/J0uu/9g1f/AEXDXsteNaT/AMnS67/2DV/9Fw0Aey0UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB414U/5Ob8Xf9g7/wCR69lrz/RPA+p6b8Ytd8XTTWjaff2nkRRo7GUN+6+8CuMfu26E9q9AoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK8a0n/AJOl13/sGr/6Lhr2WuAsfA+p23xo1Lxi81odOurQQJGHbzQwSNeRtxjKHv6UAd/RRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUVyXiLU7208f+DLGC4eO1vZLwXEQ6SBICy5+h5q9L400OOWeGOe5uZ4J3t5YLSzmnkV0xuyqITtGR83TtmgDforFh8W6JPoF3raXhFhZ7xcs0Tq8JT7yvGRvDD0IzyPWq9x440K2eTfNdvBESsl3DYzyW6EdczKhQAdznAwc4waAOioqlcavYWv2DzblcahKIbVkBYSsUZwARkYKqxyeOKff6ja6ZbLcXkvlRNLHCG2lvnkcIg4B6swH40AWqK4iPxrGfiXc6Kz35tFsogkX9mzYE5mkVm3eXnZgIN5Ozjg9a2r7xdpNhfTWbG9uJ4MectlYT3IiyMgOY0YKcc4Jzgg96AN2iqum6lZaxp0GoafcpcWk67o5UPBHT8CDkEHkEEGrVABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFcXqd1qnifxVeeHdM1GbS9P02KNtQvLZR58kkgJWGMsCEAXDFhk8qBjk0XvhHVdMt3vPDfiLVjfxJuW11G7N1b3JHO1hJkru6ZUrjrQB2lFYGjeL9M1jSdFvQ7Qvq+5IIWViRKqsZEJAwCuxxk4Hy1p6hqllpS2xvZvKFzcJbRfKW3SOcKvAOMnueKALlFcZZeNYbj4gX+kF782621usMZ0ycBZi8odi3l8KQI8Mx28HB61pyeNdCVnjiuLi6mjlkieGzs5p5EZHKNuRFJA3KRuIwccE0AdBRWXZ+I9Kv9JuNTguSbW2D/AGjfG6PCUGWDoQGUgc4IzjHqKu2d3Bf2Nve2r+Zb3EayxPgjcrDIODyOD3oAnorhvEXxAsIdJ0q80q6u3S7vrdRLFp00ivF54SRc+WQGIDgL948YHIrobnxPpdppttfTyXCR3TbIIjaS+fI3PCw7fMJwCfu9BnpQBsUVkaT4m0vWrueztZJ47uBBJJbXVrJbyhCcBtsiqSuR1HFa9ABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBw/ir/kp3gD/rrf8A/pMad8PraGO98YXKxqJpdfuFeTHzMFVNoJ9Bk/mfWuh1DQLXUtd0fV5pJluNKaZoFRgEYyJsbcCMnjpgjmn6Roltop1A2zyv9uvJLyXzCDh3ABC4A4+Udcn3oA838S5VPiygJCmxtn29txtyCfyUflXp+mRWsekWcVmE+yLAiwhfu7No249sYrkfG/h6KDwt401G0+0S3mq2AWSLhhmOMqoQAZ5B561oL4NaO2FnZeIdYsdMK4+wwPFtRe6o7RmRB7BxjouOMAHH6WUTRPBscTZtIfFN1DatnI8lftaoB7AAAewFdf8AECWOPw9ao7qrS6rp6oCcbj9qiOB68An8Kv3/AIU0u+8P2+ipG9pbWhja0e2O17Z0+46E5ww985yc5yapT+C49QSIaxrOo6m0E8VxbtOIU8l43VwVEcajJ27SSCdpYAjJyARQf8lev/8AsA23/pRPVKy03XdFvdTuvC9zpOr6Ze3s1zLb3MzRSQzk4kVZUDBhuDDDKCvTPFdBe+G4LvxDba5De3lnexRCCQ27JtniDbxG4ZWGM55GD8x5qo/hAwX11c6Rrmp6Sl3IZp4LYQvG0h+84Esb7Se+CATzjNAD/BmpWupaTdGDS20u4gvJYr2zJDeXcZ3PhhwwO4MGHXdXRVnaLolpoNi1raeY5kkaaaaVt0k0rcs7nux/ADgAAACtGgAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOQ8N3AtfHXi3SpgUnlnh1CEsf8AWwvCkZI/3WiYH6iupu7uCxs5ru6lWG3gQySyOcBVAySfwrL1/wAL6f4hNvNO09tfWpJtr60k8ueAng7W7gjgggg+lZkngOLUJIxruu6vrNrGQfsV28SwOQcgusaLvwRnDZHtQByvh2KeOy+Hs1zAYHutUvrsRseVSaK5kQH/AICwrpfiHIiR+GFZgDJ4hslUep3E/wAga3dd0C216zghlmntpbaZbi2uLZgskMi5AZcgg8Egggggnis1/BcN5Naz6tq2oancWlxHcW0k4hTyWRg3yrHGo5wASQTjIBGTQAtj/wAlM1v/ALBVj/6MuazvhrFaLb+JpIApnfxDfC4PfcJTgf8AfO0/ia3rnw7FN4jj1yG/vbS5ESQzJAyeXcRqxZVdWU9CzcrtPJ5rlPCnhZ3XWb+1v9Q0e+n1i9EstuqHz0E7lCySoynAPDAA4PXFADddUx+MPF6W8aiKfwuslyVHWUGZUJ9TtyPoorq/BzD/AIQbQGyMf2bbnP8A2yWpNF8PWmirdOJJru8vGD3d5dFWlnIGFDYAAAHAUAADtyc5dp4HSztBpqa7qzaKAUGmu0RjEZ/5Zb/L83YAcY39OM4oA5HQHWT4QeFHU5VtZtSD7fb67DxRpVzf61pN7o+p2VvrmnRzvBbXa70nicKr7gCGAB2fOM4zjBzU6+C9Mj8Jx+HYZLmG1hl86CWN1WSFxL5qspxgbW6cYwOc0+98LJfQ2DyarqKalY7vI1JGjE+G+8GGzy2BwMgpjgdxmgDMsdYu4/GFjZeJNCtbPUri3ljsL+0uDPHMBh5I+VVkOFVsEYODzxz2VYOn+GFttVTVNQ1O91a9hRo7eS8EQEAb72xY0VQWwASQTgYzjOd6gAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAqE3VuLxbQzJ9paMyiLPzFAQC2PTJAqauI03WEs7Xxf4uvkkeCG4liiCYLG3tQU2r9ZBMef71AHb1DHd201zNbRXET3EG3zolcFo9wyu4dRkDjPWuau9a8Uabp9vqVzo1ncwM6/abaymkkmhRmA3J8mJcA5IwvQ4zWPY3uoxfFHxZaaXZRzzSJYtJLPIUihQRtycAlmOeFA5wckY5APQ6qLqunNpp1Jb+1NgAWN0Jl8oAHBO7OOCCOtY+la/fP4ou/D2rWlvFdR2y3lvNbSMyTwlyhyCBtYEDIyfvda4PVNUvdS8EeFpdH0XTbXTLnV7dfsr3TAeYLlsIQIyNhZQxbqMn5TQB6vZX9nqVpHdWN3BdW0uTHNBIHR8HBwQcHBGKsV53qVx4s/4T/QGOlaKJxYXuxP7SlKsu633ZbyMgg7ccHOT0xz0d7r17L4iOh6NawTXEEST3s9xIVjt0ckIAACWc7WOOBgcnkUAdDRXOWPiWWHUL7TfEEEFldWlub0TRSF4ZrYHBcEgFSpGGUjjKnJBqCx1rxNq2l/2tZ6PYx20o8y0tbm5ZZpojyrMQpWNiMEL82M4JHNAHSW91b3au1tcRTLHI0TmNwwV1OGU46EHgjtU1cZ8NbgXeh6pciOSMTa1fSBJBhlzOxwR2NXvE/i0+HdT0mxTTpb6XUjKkUcLAOXUKVUA8YO7kkgKASelAG/Jd20NzBbS3EST3G7yYmcBpNoy20dTgcnHSpq5F9Vn/4SLwvBrOh2kWpXZuvLeO5837KFjycNsGSw4PTHvUlh4g1nxALq70WxsRpkUkkNvPdzsGumRtrEBVOxNwYBjknGdtAHS3N1b2VtJc3U8UFvEpaSWVwqoB1JJ4AqXrXmviLxM3iP4b+OEksJLKTTkktHSRskuIlZu3TcxAPcAHvitu+1/wAS2fh6fXY9HsjbQRG4+xyXLidoVUsSSFKq+B9zn03UAdcSBjJ69KjiuYZ5Jo4pUd4HCSqDyjEBgD6cMD9CK4PxPqOr32r+Db3SLTT57Oe78+1e4unjZ2a1mOGAjbaNpJyCTnAwOtalw8ul+PtHuZUVG1q0ezuUjbcgmiUyxkEgEjaZxnAz8vFAHW0UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXBaNfW2neAteW7sZL+Oy1C/jvLWNAzOjXDuflPBHlyBsdwa72siz0qaw8SaheQFPsWoIksyFjuW4UBNwGMEMgUHkYMY67jgA4fVrOw8N+FzrXhDxVdW0UcStZaebr7Xa3TDlYUR9zDf90BGGM9OK3fDZLfEfxizLtYx2GR1wfKfiuht/D+i2movqNtpFhDfOSXuY7ZFkbPXLAZNXwihmYKAzdSByaAORf8A5LJD/wBi+/8A6UJXH6X/AMkt8E/9jBb/APpW9ev7F379o34xuxzj0pohiCKgjTapyBtGAfWgDldevLaw+IfhmW7njgiks7+JXkbapcm3YLk8ZIVj+FZcVrb2nxP12HUL24s21WO3uLFo7holnCR+W6A9CylQcdcPnpXfSRRzLtljV164YZFQ32nWOqWptdQs7e7t2OTFcRLIhP0IIoA4bVtN0/XbjXdK0uW7vtUTRbi1+1S3RkhgaYACInPDkqGPHAAz1Gd/QfFGk3HhODUJbuK1S3hCXUc7bGtpFGHRweQQQRjv261t2VjZ6bapa2NrBa26fdigjCIv0A4FQyaJpM2ppqcumWT6gnCXTW6GVfo+Mj86AOa+Gk32nQdTuPKki87Wb2URyKVZQ0zHBB5B56UviRQfiT4IJAJDXxHt+4FdiqqudqgZOTgdTSFFZlYqCy9CRyKAOQ8R/wDJSPBP1vv/AESKoeDdc03wp4ei8N67eRadf6a8kIW5/dC5TexSSLP+s3Lg/Lkg5B5rviisysVBZehI5Fc5by+LNOa8gns7bVo/Md7S5W5ELFWYlUkXZgbQdu5c5ABxnNAHD6heSX/gn4oXUtrJamWVmWKUYbZ9lh2FgeVJXBKnkZweRXo/iL/kUdW/68Jv/RZqr4X0S70601CbV3hm1DU7t7u5WL5o0yFRY1JAJCoijJHJzW+QCCCAQeCDQB5ytzBZ+HfhjcXMyQwrJArSSNtUFrGVRkn1JA/GtrxE4ufGfguKH95/pFzdFl5AjW3dd2fTMqD8RXVNFG0XlNGpjxjaRxj6VlW2kSjxRdavcMmxbdLSyiQn93HndIx9CzbRgdo155wADYooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAP//Z",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "# Define the path to the folder containing the images\n",
    "folder_path = \"images/*.jpg\"  # Update the file type as needed\n",
    "\n",
    "# Use glob to search for JPG files in the specified folder\n",
    "image_files = glob.glob(folder_path)\n",
    "\n",
    "# Iterate through the list of image files and display each image inline\n",
    "for image_file in image_files:\n",
    "    display(Image(filename=image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "print(PIL.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def convert_to_base64(pil_image):\n",
    "    \"\"\"\n",
    "    Convert PIL images to Base64 encoded strings\n",
    "\n",
    "    :param pil_image: PIL image\n",
    "    :return: Re-sized Base64 string\n",
    "    \"\"\"\n",
    "\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"JPEG\")  # You can change the format if needed\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return img_str\n",
    "\n",
    "\n",
    "def plt_img_base64(img_base64):\n",
    "    \"\"\"\n",
    "    Display base64 encoded string as image\n",
    "\n",
    "    :param img_base64:  Base64 string\n",
    "    \"\"\"\n",
    "    # Create an HTML img tag with the base64 string as the source\n",
    "    image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "    # Display the image by rendering the HTML\n",
    "    display(HTML(image_html))\n",
    "\n",
    "\n",
    "file_path = \"./images/figure-3-1.jpg\"\n",
    "pil_image = Image.open(file_path)\n",
    "image_b64 = convert_to_base64(pil_image)\n",
    "plt_img_base64(image_b64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
