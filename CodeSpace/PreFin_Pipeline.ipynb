{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation Function to Page wise Image Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation Function to Cropping Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# %pip install \"unstructured[all-docs]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "installations for Function to Recognise and format tables as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install paddlepaddle paddleocr tensorflow pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import fitz\n",
    "import cv2\n",
    "from unstructured.partition.image import partition_image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from paddleocr import PaddleOCR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"PDF STORE\"\n",
    "output_dir = \"TEST RESULT\"\n",
    "deb_output_dir = \"DEBUG_IMGs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_from_pdf(input_dir, output_base_dir=\"RESULTS/IMAGES\"):\n",
    "    # ... existing code ...\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            # Build the full path to the PDF file\n",
    "            pdf_path = os.path.join(input_dir, filename)\n",
    "            pdf_name = os.path.splitext(filename)[0]\n",
    "\n",
    "            # Create the corresponding output directory\n",
    "            output_folder = os.path.join(output_base_dir, f\"{pdf_name}-images\")\n",
    "            os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "            # Open the PDF file\n",
    "            pdf_document = fitz.open(pdf_path)\n",
    "            print(f\"Processing PDF: {pdf_path}\")\n",
    "\n",
    "            # Iterate over each page in the PDF\n",
    "            for page_number in range(pdf_document.page_count):\n",
    "                page = pdf_document[page_number]\n",
    "                images = page.get_images(full=True)\n",
    "                print(f\"  Page {page_number + 1} has {len(images)} image(s).\")\n",
    "\n",
    "                # Extract and save each image\n",
    "                for img_index, img in enumerate(images):\n",
    "                    xref = img[0]\n",
    "                    base_image = pdf_document.extract_image(xref)\n",
    "                    image_bytes = base_image[\"image\"]\n",
    "\n",
    "                    # Construct a filename for each image\n",
    "                    image_path = os.path.join(\n",
    "                        output_folder,\n",
    "                        f\"Page_{page_number + 1}_Image_{img_index + 1}.png\"\n",
    "                    )\n",
    "\n",
    "                    # Save the image to a file\n",
    "                    with open(image_path, \"wb\") as img_file:\n",
    "                        img_file.write(image_bytes)\n",
    "                    print(f\"    Saved: {image_path}\")\n",
    "\n",
    "            # Close the PDF document\n",
    "            pdf_document.close()\n",
    "    \n",
    "    print(f\"\\nAll PDFs processed successfully! Images are stored in: {output_base_dir}\")\n",
    "\n",
    "input_directory = \"TEST INPUT PDF\"\n",
    "extract_images_from_pdf(input_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unstructured Tables Extraction (OCR Based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Text from PDF - Acepted -- Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(input_dir, text_output_folder=\"Extracted Text\", dpi=300):\n",
    "    \"\"\"\n",
    "    Extract text directly from PDF files without storing intermediate page images.\n",
    "    \"\"\"\n",
    "    os.makedirs(text_output_folder, exist_ok=True)\n",
    "    \n",
    "    # Get all PDF files from input directory\n",
    "    pdf_files = [f for f in os.listdir(input_dir) if f.lower().endswith('.pdf')]\n",
    "\n",
    "    # Process each PDF file\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(input_dir, pdf_file)\n",
    "        pdf_name = os.path.splitext(pdf_file)[0]\n",
    "        \n",
    "        # Create output folder for this PDF's text\n",
    "        pdf_text_output_folder = os.path.join(text_output_folder, f\"{pdf_name}-Texts\")\n",
    "        os.makedirs(pdf_text_output_folder, exist_ok=True)\n",
    "\n",
    "        print(f\"\\nProcessing PDF: {pdf_file}\")\n",
    "        \n",
    "        # Open PDF\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "        # Process each page\n",
    "        for page_number in range(pdf_document.page_count):\n",
    "            page = pdf_document[page_number]\n",
    "            \n",
    "            # Convert PDF page to image\n",
    "            pix = page.get_pixmap(dpi=dpi, colorspace=fitz.csRGB)\n",
    "            \n",
    "            # Convert to numpy array for OpenCV\n",
    "            img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, 3)\n",
    "            \n",
    "            # Convert RGB to BGR for OpenCV\n",
    "            image_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            page_name = f'page_{page_number + 1}'\n",
    "            \n",
    "            # Create a temporary file for the image\n",
    "            temp_image_path = os.path.join(text_output_folder, \"temp_page.png\")\n",
    "            cv2.imwrite(temp_image_path, image_cv)\n",
    "            \n",
    "            try:\n",
    "                # Detect text using Unstructured's partition_image with filename\n",
    "                elements = partition_image(filename=temp_image_path, infer_table_structure=True, strategy='hi_res')\n",
    "                \n",
    "                # Convert elements to JSON structure\n",
    "                element_dict = [el.to_dict() for el in elements]\n",
    "                \n",
    "                # Extract text if type is not \"Table\"\n",
    "                for item in element_dict:\n",
    "                    if isinstance(item, dict) and item.get(\"type\") != \"Table\":\n",
    "                        text_content = item.get(\"text\", \"\")\n",
    "                        if text_content:\n",
    "                            text_filename = f\"{page_name}_text.txt\"\n",
    "                            text_output_path = os.path.join(pdf_text_output_folder, text_filename)\n",
    "                            with open(text_output_path, \"a\", encoding=\"utf-8\") as text_file:\n",
    "                                text_file.write(text_content + \"\\n\")\n",
    "                            print(f\"Text extracted and saved to: {text_output_path}\")\n",
    "            \n",
    "            finally:\n",
    "                # Clean up temporary file\n",
    "                if os.path.exists(temp_image_path):\n",
    "                    os.remove(temp_image_path)\n",
    "            \n",
    "            print(f\"Processed page {page_number + 1}/{pdf_document.page_count}\")\n",
    "        \n",
    "        pdf_document.close()\n",
    "        print(f\"Finished processing PDF: {pdf_file}! Text saved in: {pdf_text_output_folder}\")\n",
    "\n",
    "    print(f\"\\nAll PDFs processed successfully! Extracted text is stored in: {text_output_folder}\")\n",
    "\n",
    "# Example usage:\n",
    "input_directory = \"TEST INPUT PDF\"  # Directory containing PDF files\n",
    "text_output_directory = \"TEST RESULT3/Extracted Text\"  # Directory for output text\n",
    "\n",
    "extract_text_from_pdf(input_directory, text_output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cropping Tables - Accepted -- Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_tables_from_pdf(input_dir, output_base_folder=\"Extracted Tables\", dpi=300, top_left_padding=5, bottom_right_padding=7):\n",
    "    \"\"\"\n",
    "    Extract tables directly from PDF files without storing intermediate page images.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_base_folder, exist_ok=True)\n",
    "    \n",
    "    # Get all PDF files from input directory\n",
    "    pdf_files = [f for f in os.listdir(input_dir) if f.lower().endswith('.pdf')]\n",
    "\n",
    "    # Function to crop an image with padding and save it\n",
    "    def crop_with_padding(image, coordinates, output_folder, filename):\n",
    "        \"\"\"Crop the specified coordinates from the image, apply padding, and save it.\"\"\"\n",
    "        x_min = int(min(pt[0] for pt in coordinates))\n",
    "        y_min = int(min(pt[1] for pt in coordinates))\n",
    "        x_max = int(max(pt[0] for pt in coordinates))\n",
    "        y_max = int(max(pt[1] for pt in coordinates)) \n",
    "\n",
    "        # Apply top-left and bottom-right padding\n",
    "        x_min_padded = max(0, x_min - top_left_padding)\n",
    "        y_min_padded = max(0, y_min - top_left_padding)\n",
    "        x_max_padded = min(image.shape[1], x_max + bottom_right_padding * 2)\n",
    "        y_max_padded = min(image.shape[0], y_max + bottom_right_padding)\n",
    "\n",
    "        # Crop the image\n",
    "        cropped_image = image[y_min_padded:y_max_padded, x_min_padded:x_max_padded]\n",
    "\n",
    "        # Save cropped image\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, cropped_image)\n",
    "        print(f\"Cropped table saved to: {output_path}\")\n",
    "\n",
    "    # Process each PDF file\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(input_dir, pdf_file)\n",
    "        pdf_name = os.path.splitext(pdf_file)[0]\n",
    "        \n",
    "        # Create output folder for this PDF's tables\n",
    "        pdf_output_folder = os.path.join(output_base_folder, f\"{pdf_name}-Tables\")\n",
    "        os.makedirs(pdf_output_folder, exist_ok=True)\n",
    "\n",
    "        print(f\"\\nProcessing PDF: {pdf_file}\")\n",
    "        \n",
    "        # Open PDF\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        \n",
    "        # Dictionary to count tables per page\n",
    "        table_counter = {}\n",
    "\n",
    "        # Process each page\n",
    "        for page_number in range(pdf_document.page_count):\n",
    "            page = pdf_document[page_number]\n",
    "            \n",
    "            # Convert PDF page to image\n",
    "            pix = page.get_pixmap(dpi=dpi, colorspace=fitz.csRGB)\n",
    "            \n",
    "            # Convert to numpy array for OpenCV\n",
    "            img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, 3)\n",
    "            \n",
    "            # Convert RGB to BGR for OpenCV\n",
    "            image_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            page_name = f'page_{page_number + 1}'\n",
    "            \n",
    "            # Create a temporary file for the image\n",
    "            temp_image_path = os.path.join(output_base_folder, \"temp_page.png\")\n",
    "            cv2.imwrite(temp_image_path, image_cv)\n",
    "            \n",
    "            try:\n",
    "                # Detect tables using Unstructured's partition_image with filename\n",
    "                elements = partition_image(filename=temp_image_path, infer_table_structure=True, strategy='hi_res')\n",
    "                \n",
    "                # Convert elements to JSON structure\n",
    "                element_dict = [el.to_dict() for el in elements]\n",
    "                \n",
    "                # Extract and crop tables\n",
    "                for item in element_dict:\n",
    "                    if isinstance(item, dict) and item.get(\"type\") == \"Table\":\n",
    "                        try:\n",
    "                            coordinates = item[\"metadata\"][\"coordinates\"][\"points\"]\n",
    "                            \n",
    "                            # Count tables per page\n",
    "                            table_counter[page_name] = table_counter.get(page_name, 0) + 1\n",
    "                            table_number = table_counter[page_name]\n",
    "                            \n",
    "                            # Set output filename for cropped table\n",
    "                            filename = f\"{page_name}_Table_{table_number}.png\"\n",
    "                            \n",
    "                            # Crop and save the table\n",
    "                            crop_with_padding(image_cv, coordinates, pdf_output_folder, filename)\n",
    "                            \n",
    "                        except KeyError as e:\n",
    "                            print(f\"Missing key {e} in item: {item}\")\n",
    "            \n",
    "            finally:\n",
    "                # Clean up temporary file\n",
    "                if os.path.exists(temp_image_path):\n",
    "                    os.remove(temp_image_path)\n",
    "            \n",
    "            print(f\"Processed page {page_number + 1}/{pdf_document.page_count}\")\n",
    "        \n",
    "        pdf_document.close()\n",
    "        print(f\"Finished processing PDF: {pdf_file}! Tables saved in: {pdf_output_folder}\")\n",
    "\n",
    "    print(f\"\\nAll PDFs processed successfully! Extracted tables are stored in: {output_base_folder}\")\n",
    "\n",
    "# Example usage:\n",
    "input_directory = \"TEST INPUT PDF\"  # Directory containing PDF files\n",
    "output_directory = \"TEST RESULT3/Detected Tables\"  # Directory for output\n",
    "\n",
    "crop_tables_from_pdf(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocr Extraction and Recognition to save as csv - Accepted -- Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_restructure_tables_as_csv(base_input_folder, output_base_folder=\"TEST RESULT6/Extracted Tables CSV\"):\n",
    "    \"\"\"\n",
    "    Extract tables from images in all subfolders and save as CSV files.\n",
    "    \n",
    "    Args:\n",
    "        base_input_folder (str): Path to 'Extracted Tables' folder containing multiple input folders\n",
    "        output_base_folder (str): Path to save output CSV files\n",
    "    \"\"\"\n",
    "    # Create base output folder if it doesn't exist\n",
    "    os.makedirs(output_base_folder, exist_ok=True)\n",
    "    \n",
    "    ocr = PaddleOCR(lang='en')\n",
    "\n",
    "    def intersection(box_1, box_2):\n",
    "        return [box_2[0], box_1[1], box_2[2], box_1[3]]\n",
    "\n",
    "    def iou(box_1, box_2):\n",
    "        x_1 = max(box_1[0], box_2[0])\n",
    "        y_1 = max(box_1[1], box_2[1])\n",
    "        x_2 = min(box_1[2], box_2[2])\n",
    "        y_2 = min(box_1[3], box_2[3])\n",
    "\n",
    "        inter = abs(max((x_2 - x_1, 0)) * max((y_2 - y_1), 0))\n",
    "        if inter == 0:\n",
    "            return 0\n",
    "\n",
    "        box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))\n",
    "        box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))\n",
    "\n",
    "        return inter / float(box_1_area + box_2_area - inter)\n",
    "\n",
    "    # Get all subfolders in the base input folder\n",
    "    input_folders = [os.path.join(base_input_folder, d) for d in os.listdir(base_input_folder) \n",
    "                    if os.path.isdir(os.path.join(base_input_folder, d))]\n",
    "    \n",
    "    print(f\"Found {len(input_folders)} folders to process\")\n",
    "\n",
    "    for input_folder in input_folders:\n",
    "        folder_name = os.path.basename(input_folder)\n",
    "        pdf_name = folder_name.replace('-Tables', '')  # Remove '-Tables' suffix\n",
    "        \n",
    "        # Create PDF-specific output folder with -csv suffix\n",
    "        output_folder = os.path.join(output_base_folder, f\"{pdf_name}-csv\")\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\nProcessing folder: {folder_name}\")\n",
    "        \n",
    "        # Get all image files in current folder\n",
    "        image_files = [f for f in os.listdir(input_folder) \n",
    "                      if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        print(f\"Found {len(image_files)} images\")\n",
    "\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(input_folder, image_file)\n",
    "            image_cv = cv2.imread(image_path)\n",
    "\n",
    "            if image_cv is None:\n",
    "                print(f\"Error loading image: {image_path}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing: {image_file}\")\n",
    "            image_height, image_width = image_cv.shape[:2]\n",
    "            output = ocr.ocr(image_path)[0]\n",
    "\n",
    "            if not output:\n",
    "                print(f\"No OCR output for image: {image_file}\")\n",
    "                continue\n",
    "\n",
    "            # Extract bounding boxes and text\n",
    "            boxes = [line[0] for line in output]\n",
    "            texts = [line[1][0] for line in output]\n",
    "            probabilities = [line[1][1] for line in output]\n",
    "\n",
    "            # Generate horizontal and vertical boxes\n",
    "            horiz_boxes = []\n",
    "            vert_boxes = []\n",
    "\n",
    "            for box in boxes:\n",
    "                x_h, x_v = 0, int(box[0][0])\n",
    "                y_h, y_v = int(box[0][1]), 0\n",
    "                width_h, width_v = image_width, int(box[2][0] - box[0][0])\n",
    "                height_h, height_v = int(box[2][1] - box[0][1]), image_height\n",
    "\n",
    "                horiz_boxes.append([x_h, y_h, x_h + width_h, y_h + height_h])\n",
    "                vert_boxes.append([x_v, y_v, x_v + width_v, y_v + height_v])\n",
    "\n",
    "            # Apply NMS\n",
    "            horiz_out = tf.image.non_max_suppression(\n",
    "                horiz_boxes, probabilities, max_output_size=1000, iou_threshold=0.1\n",
    "            )\n",
    "            vert_out = tf.image.non_max_suppression(\n",
    "                vert_boxes, probabilities, max_output_size=1000, iou_threshold=0.1\n",
    "            )\n",
    "\n",
    "            horiz_lines = np.sort(np.array(horiz_out))\n",
    "            vert_lines = np.sort(np.array(vert_out))\n",
    "\n",
    "            # Create table structure\n",
    "            out_array = [[\"\" for _ in range(len(vert_lines))] for _ in range(len(horiz_lines))]\n",
    "            unordered_boxes = [vert_boxes[i][0] for i in vert_lines]\n",
    "            ordered_boxes = np.argsort(unordered_boxes)\n",
    "\n",
    "            # Fill table with text\n",
    "            for i in range(len(horiz_lines)):\n",
    "                for j in range(len(vert_lines)):\n",
    "                    resultant = intersection(\n",
    "                        horiz_boxes[horiz_lines[i]], \n",
    "                        vert_boxes[vert_lines[ordered_boxes[j]]]\n",
    "                    )\n",
    "\n",
    "                    for b in range(len(boxes)):\n",
    "                        the_box = [boxes[b][0][0], boxes[b][0][1], boxes[b][2][0], boxes[b][2][1]]\n",
    "                        if iou(resultant, the_box) > 0.1:\n",
    "                            out_array[i][j] = texts[b]\n",
    "\n",
    "            out_array = np.array(out_array)\n",
    "\n",
    "            # Save as CSV\n",
    "            csv_filename = f\"{os.path.splitext(image_file)[0]}.csv\"\n",
    "            csv_path = os.path.join(output_folder, csv_filename)\n",
    "            pd.DataFrame(out_array).to_csv(csv_path, index=False, header=False)\n",
    "            print(f\"Saved CSV: {csv_filename} in {output_folder}\")\n",
    "\n",
    "    print(f\"\\nProcessing complete! CSV files saved in: {output_base_folder}\")\n",
    "\n",
    "# Example usage:\n",
    "base_input_folder = \"TEST RESULT4/Extracted Tables\"  # Path to folder containing multiple table folders\n",
    "ocr_restructure_tables_as_csv(base_input_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('PDF1 Tables/budget_speech-Pages-Cropped/page_40_Table_1.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('PDF1 Tables/budget_speech-Pages-Cropped\\page_31_Table_1.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop and page text - working nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables_and_text_from_pdf(input_dir, output_base_folder=\"Extracted Tables\", text_output_folder=\"Extracted Text\", dpi=300, top_left_padding=5, bottom_right_padding=7):\n",
    "    \"\"\"\n",
    "    Extract tables and text directly from PDF files without storing intermediate page images.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_base_folder, exist_ok=True)\n",
    "    os.makedirs(text_output_folder, exist_ok=True)\n",
    "    \n",
    "    # Get all PDF files from input directory\n",
    "    pdf_files = [f for f in os.listdir(input_dir) if f.lower().endswith('.pdf')]\n",
    "\n",
    "    # Function to crop an image with padding and save it\n",
    "    def crop_with_padding(image, coordinates, output_folder, filename):\n",
    "        \"\"\"Crop the specified coordinates from the image, apply padding, and save it.\"\"\"\n",
    "        x_min = int(min(pt[0] for pt in coordinates))\n",
    "        y_min = int(min(pt[1] for pt in coordinates))\n",
    "        x_max = int(max(pt[0] for pt in coordinates))\n",
    "        y_max = int(max(pt[1] for pt in coordinates))\n",
    "\n",
    "        # Apply top-left and bottom-right padding\n",
    "        x_min_padded = max(0, x_min - top_left_padding)\n",
    "        y_min_padded = max(0, y_min - top_left_padding)\n",
    "        x_max_padded = min(image.shape[1], x_max + bottom_right_padding * 2)\n",
    "        y_max_padded = min(image.shape[0], y_max + bottom_right_padding)\n",
    "\n",
    "        # Crop the image\n",
    "        cropped_image = image[y_min_padded:y_max_padded, x_min_padded:x_max_padded]\n",
    "\n",
    "        # Save cropped image\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, cropped_image)\n",
    "        print(f\"Cropped table saved to: {output_path}\")\n",
    "\n",
    "    # Process each PDF file\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(input_dir, pdf_file)\n",
    "        pdf_name = os.path.splitext(pdf_file)[0]\n",
    "        \n",
    "        # Create output folder for this PDF's tables and text\n",
    "        pdf_output_folder = os.path.join(output_base_folder, f\"{pdf_name}-Tables\")\n",
    "        pdf_text_output_folder = os.path.join(text_output_folder, f\"{pdf_name}-Texts\")\n",
    "        os.makedirs(pdf_output_folder, exist_ok=True)\n",
    "        os.makedirs(pdf_text_output_folder, exist_ok=True)\n",
    "\n",
    "        print(f\"\\nProcessing PDF: {pdf_file}\")\n",
    "        \n",
    "        # Open PDF\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        \n",
    "        # Dictionary to count tables per page\n",
    "        table_counter = {}\n",
    "\n",
    "        # Process each page\n",
    "        for page_number in range(pdf_document.page_count):\n",
    "            page = pdf_document[page_number]\n",
    "            \n",
    "            # Convert PDF page to image\n",
    "            pix = page.get_pixmap(dpi=dpi, colorspace=fitz.csRGB)\n",
    "            \n",
    "            # Convert to numpy array for OpenCV\n",
    "            img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, 3)\n",
    "            \n",
    "            # Convert RGB to BGR for OpenCV\n",
    "            image_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            page_name = f'page_{page_number + 1}'\n",
    "            \n",
    "            # Create a temporary file for the image\n",
    "            temp_image_path = os.path.join(output_base_folder, \"temp_page.png\")\n",
    "            cv2.imwrite(temp_image_path, image_cv)\n",
    "            \n",
    "            try:\n",
    "                # Detect tables using Unstructured's partition_image with filename\n",
    "                elements = partition_image(filename=temp_image_path, infer_table_structure=True, strategy='hi_res')\n",
    "                \n",
    "                # Convert elements to JSON structure\n",
    "                element_dict = [el.to_dict() for el in elements]\n",
    "                \n",
    "                # Extract and crop tables or extract text\n",
    "                for item in element_dict:\n",
    "                    if isinstance(item, dict):\n",
    "                        if item.get(\"type\") == \"Table\":\n",
    "                            try:\n",
    "                                coordinates = item[\"metadata\"][\"coordinates\"][\"points\"]\n",
    "                                \n",
    "                                # Count tables per page\n",
    "                                table_counter[page_name] = table_counter.get(page_name, 0) + 1\n",
    "                                table_number = table_counter[page_name]\n",
    "                                \n",
    "                                # Set output filename for cropped table\n",
    "                                filename = f\"{page_name}_Table_{table_number}.png\"\n",
    "                                \n",
    "                                # Crop and save the table\n",
    "                                crop_with_padding(image_cv, coordinates, pdf_output_folder, filename)\n",
    "                                \n",
    "                            except KeyError as e:\n",
    "                                print(f\"Missing key {e} in item: {item}\")\n",
    "                        else:\n",
    "                            # Extract text if type is not \"Table\"\n",
    "                            text_content = item.get(\"text\", \"\")\n",
    "                            if text_content:\n",
    "                                text_filename = f\"{page_name}_text.txt\"\n",
    "                                text_output_path = os.path.join(pdf_text_output_folder, text_filename)\n",
    "                                with open(text_output_path, \"a\", encoding=\"utf-8\") as text_file:\n",
    "                                    text_file.write(text_content + \"\\n\")\n",
    "                                print(f\"Text extracted and saved to: {text_output_path}\")\n",
    "            \n",
    "            finally:\n",
    "                # Clean up temporary file\n",
    "                if os.path.exists(temp_image_path):\n",
    "                    os.remove(temp_image_path)\n",
    "            \n",
    "            print(f\"Processed page {page_number + 1}/{pdf_document.page_count}\")\n",
    "        \n",
    "        pdf_document.close()\n",
    "        print(f\"Finished processing PDF: {pdf_file}! Tables saved in: {pdf_output_folder}, Text saved in: {pdf_text_output_folder}\")\n",
    "\n",
    "    print(f\"\\nAll PDFs processed successfully! Extracted tables are stored in: {output_base_folder}, Extracted text is stored in: {text_output_folder}\")\n",
    "\n",
    "# Example usage:\n",
    "input_directory = \"TEST INPUT PDF\"  # Directory containing PDF files\n",
    "output_directory = \"TEST RESULT10/Extracted Tables\"  # Directory for output tables\n",
    "text_output_directory = \"TEST RESULT10/Extracted Text\"  # Directory for output text\n",
    "\n",
    "extract_tables_and_text_from_pdf(input_directory, output_directory, text_output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined Process 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_documents(input_dir, output_base_dir=\"TEST RESULT4\", dpi=300):\n",
    "    \"\"\"\n",
    "    Process PDFs to extract both text and tables in a single pass.\n",
    "    \n",
    "    Args:\n",
    "        input_dir (str): Directory containing PDF files\n",
    "        output_base_dir (str): Base directory for outputs\n",
    "        dpi (int): DPI for PDF to image conversion\n",
    "    \"\"\"\n",
    "    # Initialize output directories\n",
    "    text_output_folder = os.path.join(output_base_dir, \"Extracted Text\")\n",
    "    tables_output_folder = os.path.join(output_base_dir, \"Extracted Tables\")\n",
    "    tables_csv_folder = os.path.join(output_base_dir, \"Extracted Tables CSV\")\n",
    "    \n",
    "    for folder in [text_output_folder, tables_output_folder, tables_csv_folder]:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    def process_element(element, page_name, pdf_name, image_cv):\n",
    "        \"\"\"Process individual elements (text or table) from the page\"\"\"\n",
    "        if element.get(\"type\") == \"Table\":\n",
    "            # Handle table element\n",
    "            try:\n",
    "                coordinates = element[\"metadata\"][\"coordinates\"][\"points\"]\n",
    "                table_folder = os.path.join(tables_output_folder, f\"{pdf_name}-Tables\")\n",
    "                os.makedirs(table_folder, exist_ok=True)\n",
    "                \n",
    "                # Crop and save table image\n",
    "                x_min = int(min(pt[0] for pt in coordinates))\n",
    "                y_min = int(min(pt[1] for pt in coordinates))\n",
    "                x_max = int(max(pt[0] for pt in coordinates))\n",
    "                y_max = int(max(pt[1] for pt in coordinates))\n",
    "                \n",
    "                # Add padding\n",
    "                x_min = max(0, x_min - 5)\n",
    "                y_min = max(0, y_min - 5)\n",
    "                x_max = min(image_cv.shape[1], x_max + 14)\n",
    "                y_max = min(image_cv.shape[0], y_max + 7)\n",
    "                \n",
    "                cropped_table = image_cv[y_min:y_max, x_min:x_max]\n",
    "                table_filename = f\"{page_name}_Table_{len(os.listdir(table_folder)) + 1}.png\"\n",
    "                cv2.imwrite(os.path.join(table_folder, table_filename), cropped_table)\n",
    "                \n",
    "                # Process table with OCR\n",
    "                ocr_result = ocr.ocr(os.path.join(table_folder, table_filename))[0]\n",
    "                if ocr_result:\n",
    "                    process_table_ocr(ocr_result, table_filename, tables_csv_folder)\n",
    "                \n",
    "            except (KeyError, IndexError) as e:\n",
    "                print(f\"Error processing table: {e}\")\n",
    "                \n",
    "        elif element.get(\"type\") != \"Table\":\n",
    "            # Handle text element\n",
    "            text_content = element.get(\"text\", \"\")\n",
    "            if text_content:\n",
    "                text_folder = os.path.join(text_output_folder, f\"{pdf_name}-Texts\")\n",
    "                os.makedirs(text_folder, exist_ok=True)\n",
    "                text_filename = f\"{page_name}_text.txt\"\n",
    "                text_path = os.path.join(text_folder, text_filename)\n",
    "                \n",
    "                with open(text_path, \"a\", encoding=\"utf-8\") as text_file:\n",
    "                    text_file.write(text_content + \"\\n\")\n",
    "\n",
    "    def process_table_ocr(ocr_result, table_filename, output_folder):\n",
    "        \"\"\"Process OCR results and save as CSV\"\"\"\n",
    "        boxes = [line[0] for line in ocr_result]\n",
    "        texts = [line[1][0] for line in ocr_result]\n",
    "        probabilities = [line[1][1] for line in ocr_result]\n",
    "        \n",
    "        # Generate horizontal and vertical boxes\n",
    "        image_height, image_width = 1000, 1000  # Default size\n",
    "        horiz_boxes = []\n",
    "        vert_boxes = []\n",
    "        \n",
    "        for box in boxes:\n",
    "            x_h, x_v = 0, int(box[0][0])\n",
    "            y_h, y_v = int(box[0][1]), 0\n",
    "            width_h, width_v = image_width, int(box[2][0] - box[0][0])\n",
    "            height_h, height_v = int(box[2][1] - box[0][1]), image_height\n",
    "            \n",
    "            horiz_boxes.append([x_h, y_h, x_h + width_h, y_h + height_h])\n",
    "            vert_boxes.append([x_v, y_v, x_v + width_v, y_v + height_v])\n",
    "        \n",
    "        # Apply NMS and create table structure\n",
    "        horiz_out = tf.image.non_max_suppression(\n",
    "            horiz_boxes, probabilities, max_output_size=1000, iou_threshold=0.1\n",
    "        )\n",
    "        vert_out = tf.image.non_max_suppression(\n",
    "            vert_boxes, probabilities, max_output_size=1000, iou_threshold=0.1\n",
    "        )\n",
    "        \n",
    "        horiz_lines = np.sort(np.array(horiz_out))\n",
    "        vert_lines = np.sort(np.array(vert_out))\n",
    "        \n",
    "        # Create and fill table structure\n",
    "        out_array = [[\"\" for _ in range(len(vert_lines))] for _ in range(len(horiz_lines))]\n",
    "        unordered_boxes = [vert_boxes[i][0] for i in vert_lines]\n",
    "        ordered_boxes = np.argsort(unordered_boxes)\n",
    "        \n",
    "        for i in range(len(horiz_lines)):\n",
    "            for j in range(len(vert_lines)):\n",
    "                resultant = [\n",
    "                    vert_boxes[vert_lines[ordered_boxes[j]]][0],\n",
    "                    horiz_boxes[horiz_lines[i]][1],\n",
    "                    vert_boxes[vert_lines[ordered_boxes[j]]][2],\n",
    "                    horiz_boxes[horiz_lines[i]][3]\n",
    "                ]\n",
    "                \n",
    "                for b in range(len(boxes)):\n",
    "                    the_box = [boxes[b][0][0], boxes[b][0][1], boxes[b][2][0], boxes[b][2][1]]\n",
    "                    if calculate_iou(resultant, the_box) > 0.1:\n",
    "                        out_array[i][j] = texts[b]\n",
    "        \n",
    "        # Save as CSV\n",
    "        csv_filename = f\"{os.path.splitext(table_filename)[0]}.csv\"\n",
    "        csv_path = os.path.join(output_folder, csv_filename)\n",
    "        pd.DataFrame(out_array).to_csv(csv_path, index=False, header=False)\n",
    "\n",
    "    def calculate_iou(box_1, box_2):\n",
    "        \"\"\"Calculate Intersection over Union\"\"\"\n",
    "        x_1 = max(box_1[0], box_2[0])\n",
    "        y_1 = max(box_1[1], box_2[1])\n",
    "        x_2 = min(box_1[2], box_2[2])\n",
    "        y_2 = min(box_1[3], box_2[3])\n",
    "        \n",
    "        inter = abs(max((x_2 - x_1, 0)) * max((y_2 - y_1), 0))\n",
    "        if inter == 0:\n",
    "            return 0\n",
    "            \n",
    "        box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))\n",
    "        box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))\n",
    "        \n",
    "        return inter / float(box_1_area + box_2_area - inter)\n",
    "\n",
    "    # Initialize OCR\n",
    "    ocr = PaddleOCR(lang='en')\n",
    "    \n",
    "    # Process each PDF\n",
    "    pdf_files = [f for f in os.listdir(input_dir) if f.lower().endswith('.pdf')]\n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(input_dir, pdf_file)\n",
    "        pdf_name = os.path.splitext(pdf_file)[0]\n",
    "        print(f\"\\nProcessing PDF: {pdf_file}\")\n",
    "        \n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        \n",
    "        for page_number in range(pdf_document.page_count):\n",
    "            page = pdf_document[page_number]\n",
    "            page_name = f'page_{page_number + 1}'\n",
    "            \n",
    "            # Convert PDF page to image\n",
    "            pix = page.get_pixmap(dpi=dpi, colorspace=fitz.csRGB)\n",
    "            img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, 3)\n",
    "            image_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # Create temporary image file\n",
    "            temp_image_path = os.path.join(output_base_dir, \"temp_page.png\")\n",
    "            cv2.imwrite(temp_image_path, image_cv)\n",
    "            \n",
    "            try:\n",
    "                # Extract elements using Unstructured\n",
    "                elements = partition_image(filename=temp_image_path, \n",
    "                                        infer_table_structure=True, \n",
    "                                        strategy='hi_res')\n",
    "                element_dict = [el.to_dict() for el in elements]\n",
    "                \n",
    "                # Process each element\n",
    "                for element in element_dict:\n",
    "                    process_element(element, page_name, pdf_name, image_cv)\n",
    "                    \n",
    "            finally:\n",
    "                if os.path.exists(temp_image_path):\n",
    "                    os.remove(temp_image_path)\n",
    "            \n",
    "            print(f\"Processed page {page_number + 1}/{pdf_document.page_count}\")\n",
    "        \n",
    "        pdf_document.close()\n",
    "        print(f\"Finished processing PDF: {pdf_file}\")\n",
    "\n",
    "    print(\"\\nProcessing complete!\")\n",
    "    print(f\"Text extracted to: {text_output_folder}\")\n",
    "    print(f\"Tables extracted to: {tables_output_folder}\")\n",
    "    print(f\"Table CSVs saved to: {tables_csv_folder}\")\n",
    "\n",
    "# Example usage:\n",
    "input_directory = \"TEST INPUT PDF\"\n",
    "process_pdf_documents(input_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined Process 1.1 - csv path correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_documents_update(input_dir, output_base_dir=\"TEST RESULT17\", dpi=300):\n",
    "    \"\"\"\n",
    "    Process PDFs to extract both text and tables in a single pass.\n",
    "    \n",
    "    Args:\n",
    "        input_dir (str): Directory containing PDF files\n",
    "        output_base_dir (str): Base directory for outputs\n",
    "        dpi (int): DPI for PDF to image conversion\n",
    "    \"\"\"\n",
    "    # Initialize output directories\n",
    "    text_output_folder = os.path.join(output_base_dir, \"Extracted Text\")\n",
    "    tables_output_folder = os.path.join(output_base_dir, \"Extracted Tables\")\n",
    "    tables_csv_folder = os.path.join(output_base_dir, \"Extracted Tables CSV\")\n",
    "    \n",
    "    for folder in [text_output_folder, tables_output_folder, tables_csv_folder]:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    def intersection(box_1, box_2):\n",
    "        return [box_2[0], box_1[1], box_2[2], box_1[3]]\n",
    "\n",
    "    def iou(box_1, box_2):\n",
    "        x_1 = max(box_1[0], box_2[0])\n",
    "        y_1 = max(box_1[1], box_2[1])\n",
    "        x_2 = min(box_1[2], box_2[2])\n",
    "        y_2 = min(box_1[3], box_2[3])\n",
    "\n",
    "        inter = abs(max((x_2 - x_1, 0)) * max((y_2 - y_1), 0))\n",
    "        if inter == 0:\n",
    "            return 0\n",
    "\n",
    "        box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))\n",
    "        box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))\n",
    "\n",
    "        return inter / float(box_1_area + box_2_area - inter)\n",
    "\n",
    "    def process_element(element, page_name, pdf_name, image_cv):\n",
    "        \"\"\"Process individual elements (text or table) from the page\"\"\"\n",
    "        if element.get(\"type\") == \"Table\":\n",
    "            try:\n",
    "                coordinates = element[\"metadata\"][\"coordinates\"][\"points\"]\n",
    "                table_folder = os.path.join(tables_output_folder, f\"{pdf_name}-Tables\")\n",
    "                csv_folder = os.path.join(tables_csv_folder, f\"{pdf_name}-csv\")\n",
    "                \n",
    "                # Create necessary folders\n",
    "                os.makedirs(table_folder, exist_ok=True)\n",
    "                os.makedirs(csv_folder, exist_ok=True)\n",
    "                \n",
    "                # Crop and save table image\n",
    "                x_min = int(min(pt[0] for pt in coordinates))\n",
    "                y_min = int(min(pt[1] for pt in coordinates))\n",
    "                x_max = int(max(pt[0] for pt in coordinates))\n",
    "                y_max = int(max(pt[1] for pt in coordinates))\n",
    "                \n",
    "                # Add padding\n",
    "                x_min = max(0, x_min - 5)\n",
    "                y_min = max(0, y_min - 5)\n",
    "                x_max = min(image_cv.shape[1], x_max + 14)\n",
    "                y_max = min(image_cv.shape[0], y_max + 7)\n",
    "                \n",
    "                cropped_table = image_cv[y_min:y_max, x_min:x_max]\n",
    "                table_filename = f\"{page_name}_Table_{len(os.listdir(table_folder)) + 1}.png\"\n",
    "                table_path = os.path.join(table_folder, table_filename)\n",
    "                cv2.imwrite(table_path, cropped_table)\n",
    "                print(f\"Cropped table saved to: {table_path}\")\n",
    "                \n",
    "                # Process table with OCR and restructure\n",
    "                output = ocr.ocr(table_path)[0]\n",
    "                if not output:\n",
    "                    print(f\"No OCR output for table: {table_filename}\")\n",
    "                    return\n",
    "\n",
    "                # Extract bounding boxes and text\n",
    "                boxes = [line[0] for line in output]\n",
    "                texts = [line[1][0] for line in output]\n",
    "                probabilities = [line[1][1] for line in output]\n",
    "\n",
    "                # Generate horizontal and vertical boxes\n",
    "                image_height, image_width = cropped_table.shape[:2]\n",
    "                horiz_boxes = []\n",
    "                vert_boxes = []\n",
    "\n",
    "                for box in boxes:\n",
    "                    x_h, x_v = 0, int(box[0][0])\n",
    "                    y_h, y_v = int(box[0][1]), 0\n",
    "                    width_h, width_v = image_width, int(box[2][0] - box[0][0])\n",
    "                    height_h, height_v = int(box[2][1] - box[0][1]), image_height\n",
    "\n",
    "                    horiz_boxes.append([x_h, y_h, x_h + width_h, y_h + height_h])\n",
    "                    vert_boxes.append([x_v, y_v, x_v + width_v, y_v + height_v])\n",
    "\n",
    "                # Apply NMS\n",
    "                horiz_out = tf.image.non_max_suppression(\n",
    "                    horiz_boxes, probabilities, max_output_size=1000, iou_threshold=0.1\n",
    "                )\n",
    "                vert_out = tf.image.non_max_suppression(\n",
    "                    vert_boxes, probabilities, max_output_size=1000, iou_threshold=0.1\n",
    "                )\n",
    "\n",
    "                horiz_lines = np.sort(np.array(horiz_out))\n",
    "                vert_lines = np.sort(np.array(vert_out))\n",
    "\n",
    "                # Create table structure\n",
    "                out_array = [[\"\" for _ in range(len(vert_lines))] for _ in range(len(horiz_lines))]\n",
    "                unordered_boxes = [vert_boxes[i][0] for i in vert_lines]\n",
    "                ordered_boxes = np.argsort(unordered_boxes)\n",
    "\n",
    "                # Fill table with text\n",
    "                for i in range(len(horiz_lines)):\n",
    "                    for j in range(len(vert_lines)):\n",
    "                        resultant = intersection(\n",
    "                            horiz_boxes[horiz_lines[i]], \n",
    "                            vert_boxes[vert_lines[ordered_boxes[j]]]\n",
    "                        )\n",
    "\n",
    "                        for b in range(len(boxes)):\n",
    "                            the_box = [boxes[b][0][0], boxes[b][0][1], boxes[b][2][0], boxes[b][2][1]]\n",
    "                            if iou(resultant, the_box) > 0.1:\n",
    "                                out_array[i][j] = texts[b]\n",
    "\n",
    "                # Save as CSV\n",
    "                csv_filename = f\"{os.path.splitext(table_filename)[0]}.csv\"\n",
    "                csv_path = os.path.join(csv_folder, csv_filename)\n",
    "                pd.DataFrame(out_array).to_csv(csv_path, index=False, header=False)\n",
    "                print(f\"Saved CSV: {csv_filename} in {csv_folder}\")\n",
    "                \n",
    "            except (KeyError, IndexError) as e:\n",
    "                print(f\"Error processing table: {e}\")\n",
    "                \n",
    "        elif element.get(\"type\") != \"Table\":\n",
    "            # Handle text element\n",
    "            text_content = element.get(\"text\", \"\")\n",
    "            if text_content:\n",
    "                text_folder = os.path.join(text_output_folder, f\"{pdf_name}-Texts\")\n",
    "                os.makedirs(text_folder, exist_ok=True)\n",
    "                text_filename = f\"{page_name}_text.txt\"\n",
    "                text_path = os.path.join(text_folder, text_filename)\n",
    "                \n",
    "                with open(text_path, \"a\", encoding=\"utf-8\") as text_file:\n",
    "                    text_file.write(text_content + \"\\n\")\n",
    "\n",
    "    # Initialize OCR\n",
    "    ocr = PaddleOCR(lang='en')\n",
    "    \n",
    "    # Process each PDF\n",
    "    pdf_files = [f for f in os.listdir(input_dir) if f.lower().endswith('.pdf')]\n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(input_dir, pdf_file)\n",
    "        pdf_name = os.path.splitext(pdf_file)[0]\n",
    "        print(f\"\\nProcessing PDF: {pdf_file}\")\n",
    "        \n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        \n",
    "        for page_number in range(pdf_document.page_count):\n",
    "            page = pdf_document[page_number]\n",
    "            page_name = f'page_{page_number + 1}'\n",
    "            \n",
    "            # Convert PDF page to image\n",
    "            pix = page.get_pixmap(dpi=dpi, colorspace=fitz.csRGB)\n",
    "            img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, 3)\n",
    "            image_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # Create temporary image file\n",
    "            temp_image_path = os.path.join(output_base_dir, \"temp_page.png\")\n",
    "            cv2.imwrite(temp_image_path, image_cv)\n",
    "            \n",
    "            try:\n",
    "                # Extract elements using Unstructured\n",
    "                elements = partition_image(filename=temp_image_path, \n",
    "                                        infer_table_structure=True, \n",
    "                                        strategy='hi_res')\n",
    "                element_dict = [el.to_dict() for el in elements]\n",
    "                \n",
    "                # Process each element\n",
    "                for element in element_dict:\n",
    "                    process_element(element, page_name, pdf_name, image_cv)\n",
    "                    \n",
    "            finally:\n",
    "                if os.path.exists(temp_image_path):\n",
    "                    os.remove(temp_image_path)\n",
    "            \n",
    "            print(f\"Processed page {page_number + 1}/{pdf_document.page_count}\")\n",
    "        \n",
    "        pdf_document.close()\n",
    "        print(f\"Finished processing PDF: {pdf_file}\")\n",
    "\n",
    "    print(\"\\nProcessing complete!\")\n",
    "    print(f\"Text extracted to: {text_output_folder}\")\n",
    "    print(f\"Tables extracted to: {tables_output_folder}\")\n",
    "    print(f\"Table CSVs saved to: {tables_csv_folder}\")\n",
    "\n",
    "# Example usage:\n",
    "input_directory = \"inputs1\"\n",
    "process_pdf_documents_update(input_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
