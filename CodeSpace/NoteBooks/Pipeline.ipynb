{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation Function to Page wise Image Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation Function to Cropping Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# %pip install \"unstructured[all-docs]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "installations for Function to Recognise and format tables as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install paddlepaddle paddleocr tensorflow pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import fitz\n",
    "import cv2\n",
    "from unstructured.partition.image import partition_image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from paddleocr import PaddleOCR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"PDFs\"\n",
    "output_dir = \"RESULTS\" \n",
    "deb_output_dir = \"DEBUG_IMGs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unstructured Tables Extraction (OCR Based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to Page wise Image Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_pages(input_dir, output_base_folder=\"INPUTS\\PDF IMAGEs\\Pages\", dpi=300):\n",
    "\n",
    "\n",
    "    os.makedirs(output_base_folder, exist_ok=True)\n",
    "    pdf_files = [f for f in os.listdir(input_dir) if f.lower().endswith('.pdf')]\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(input_dir, pdf_file)\n",
    "        pdf_name = os.path.splitext(pdf_file)[0]\n",
    "        pdf_output_folder = os.path.join(output_base_folder, f\"{pdf_name}-Pages\")\n",
    "        os.makedirs(pdf_output_folder, exist_ok=True)\n",
    "\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        page_count = pdf_document.page_count\n",
    "        print(f\"Processing '{pdf_file}' ({page_count} pages)...\")\n",
    "\n",
    "        for page_number in range(page_count):\n",
    "            page = pdf_document[page_number]\n",
    "            pix = page.get_pixmap(dpi=dpi, colorspace=fitz.csRGB)  # Render at specified DPI in RGB\n",
    "            image_path = os.path.join(pdf_output_folder, f'page_{page_number + 1}.png')\n",
    "            pix.save(image_path)\n",
    "            print(f'Saved: {image_path}')\n",
    "\n",
    "        pdf_document.close()\n",
    "        print(f\"Finished processing '{pdf_file}'! Pages saved in '{pdf_output_folder}'\\n\")\n",
    "\n",
    "    print(\"\\n All PDFs processed successfully! Extracted pages are stored in '{output_base_folder}'.\")\n",
    "\n",
    "extract_pdf_pages(input_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to Cropping Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from unstructured.partition.image import partition_image\n",
    "\n",
    "def extract_and_crop_tables(input_base_folder, output_base_folder=\"INPUTS\\PDF IMAGEs\\Cropped Tables\", top_left_padding=5, bottom_right_padding=7):\n",
    "\n",
    "    os.makedirs(output_base_folder, exist_ok=True)\n",
    "\n",
    "    subfolders = [f for f in os.listdir(input_base_folder) if os.path.isdir(os.path.join(input_base_folder, f))]\n",
    "\n",
    "    for subfolder in subfolders:\n",
    "        input_folder = os.path.join(input_base_folder, subfolder)\n",
    "        output_folder = os.path.join(output_base_folder, f\"{subfolder}-Cropped\")\n",
    "\n",
    "        # Ensure the output folder exists for each subfolder\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Function to crop an image with padding and save it\n",
    "        def crop_with_padding(image_path, coordinates, output_folder, filename):\n",
    "            \"\"\"Crop the specified coordinates from the image, apply padding, and save it.\"\"\"\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Error loading image: {image_path}\")\n",
    "                return\n",
    "\n",
    "            x_min = int(min(pt[0] for pt in coordinates))\n",
    "            y_min = int(min(pt[1] for pt in coordinates))\n",
    "            x_max = int(max(pt[0] for pt in coordinates))\n",
    "            y_max = int(max(pt[1] for pt in coordinates))\n",
    "\n",
    "            # Apply top-left and bottom-right padding\n",
    "            x_min_padded = max(0, x_min - top_left_padding)\n",
    "            y_min_padded = max(0, y_min - top_left_padding)\n",
    "            x_max_padded = min(image.shape[1], x_max + bottom_right_padding * 2)\n",
    "            y_max_padded = min(image.shape[0], y_max + bottom_right_padding)\n",
    "\n",
    "            # Crop the image\n",
    "            cropped_image = image[y_min_padded:y_max_padded, x_min_padded:x_max_padded]\n",
    "\n",
    "            # Save cropped image\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            cv2.imwrite(output_path, cropped_image)\n",
    "            print(f\"Cropped image saved to: {output_path}\")\n",
    "\n",
    "        # Dictionary to count tables per image\n",
    "        table_counter = {}\n",
    "\n",
    "        # Get all image files in the input folder\n",
    "        image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        # Process each image file\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(input_folder, image_file)\n",
    "            image_name = os.path.splitext(image_file)[0]  # Extract image name without extension\n",
    "\n",
    "            # Perform table detection using Unstructured's partition_image\n",
    "            elements = partition_image(filename=image_path, infer_table_structure=True, strategy='hi_res')\n",
    "\n",
    "            # Convert elements to JSON structure\n",
    "            element_dict = [el.to_dict() for el in elements]\n",
    "\n",
    "            # Extract and crop tables\n",
    "            for item in element_dict:\n",
    "                if isinstance(item, dict) and item.get(\"type\") == \"Table\":\n",
    "                    try:\n",
    "                        coordinates = item[\"metadata\"][\"coordinates\"][\"points\"]\n",
    "\n",
    "                        # Count tables per image\n",
    "                        table_counter[image_name] = table_counter.get(image_name, 0) + 1\n",
    "                        table_number = table_counter[image_name]\n",
    "\n",
    "                        # Set output filename for cropped table image\n",
    "                        filename = f\"{image_name}_Table_{table_number}.png\"\n",
    "\n",
    "                        # Crop and save the table\n",
    "                        crop_with_padding(image_path, coordinates, output_folder, filename)\n",
    "\n",
    "                    except KeyError as e:\n",
    "                        print(f\"Missing key {e} in item: {item}\")\n",
    "\n",
    "        print(f\"\\n Finished processing folder: {subfolder}! Cropped tables saved in: {output_folder}\")\n",
    "\n",
    "    print(\"\\n All image folders processed successfully! Cropped tables are stored in:\", output_base_folder)\n",
    "\n",
    "input_directory = \"INPUTS\\PDF IMAGEs\\Pages\"\n",
    "output_directory = \"INPUTS\\PDF IMAGEs\\Cropped Tables\"\n",
    "\n",
    "extract_and_crop_tables(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to Recognise and format tables as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_det_infer.tar to C:\\Users\\Hemant.Singhsidar/.paddleocr/whl\\det\\en\\en_PP-OCRv3_det_infer\\en_PP-OCRv3_det_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3910/3910 [00:12<00:00, 317.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/PP-OCRv4/english/en_PP-OCRv4_rec_infer.tar to C:\\Users\\Hemant.Singhsidar/.paddleocr/whl\\rec\\en\\en_PP-OCRv4_rec_infer\\en_PP-OCRv4_rec_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:16<00:00, 590.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar to C:\\Users\\Hemant.Singhsidar/.paddleocr/whl\\cls\\ch_ppocr_mobile_v2.0_cls_infer\\ch_ppocr_mobile_v2.0_cls_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2138/2138 [00:11<00:00, 184.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/02/11 19:28:02] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\Hemant.Singhsidar/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\Hemant.Singhsidar/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='c:\\\\Users\\\\Hemant.Singhsidar\\\\Desktop\\\\CodeSpace\\\\.env\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\Hemant.Singhsidar/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All images processed successfully! Extracted tables saved in: PDF1 Tables 1\n"
     ]
    }
   ],
   "source": [
    "def extract_tables_from_images(image_folder, output_folder=\"Extracted Tables\"):\n",
    "\n",
    "    ocr = PaddleOCR(lang='en')\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Function to compute intersection of two bounding boxes\n",
    "    def intersection(box_1, box_2):\n",
    "        return [box_2[0], box_1[1], box_2[2], box_1[3]]\n",
    "\n",
    "    # Function to compute IoU (Intersection over Union)\n",
    "    def iou(box_1, box_2):\n",
    "        x_1 = max(box_1[0], box_2[0])\n",
    "        y_1 = max(box_1[1], box_2[1])\n",
    "        x_2 = min(box_1[2], box_2[2])\n",
    "        y_2 = min(box_1[3], box_2[3])\n",
    "\n",
    "        inter = abs(max((x_2 - x_1, 0)) * max((y_2 - y_1), 0))\n",
    "        if inter == 0:\n",
    "            return 0\n",
    "\n",
    "        box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))\n",
    "        box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))\n",
    "\n",
    "        return inter / float(box_1_area + box_2_area - inter)\n",
    "\n",
    "    # Get all image files from the folder\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    # Process each image\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        image_cv = cv2.imread(image_path)\n",
    "\n",
    "        # Ensure the image was loaded correctly\n",
    "        if image_cv is None:\n",
    "            print(f\"Error loading image: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        image_height, image_width = image_cv.shape[:2]\n",
    "\n",
    "        # Perform OCR\n",
    "        output = ocr.ocr(image_path)[0]\n",
    "\n",
    "        # Extract bounding boxes, detected text, and confidence scores\n",
    "        boxes = [line[0] for line in output]\n",
    "        texts = [line[1][0] for line in output]\n",
    "        probabilities = [line[1][1] for line in output]\n",
    "\n",
    "        # Copy image for processing\n",
    "        im = image_cv.copy()\n",
    "\n",
    "        horiz_boxes = []\n",
    "        vert_boxes = []\n",
    "\n",
    "        # Generate horizontal and vertical bounding boxes\n",
    "        for box in boxes:\n",
    "            x_h, x_v = 0, int(box[0][0])\n",
    "            y_h, y_v = int(box[0][1]), 0\n",
    "            width_h, width_v = image_width, int(box[2][0] - box[0][0])\n",
    "            height_h, height_v = int(box[2][1] - box[0][1]), image_height\n",
    "\n",
    "            horiz_boxes.append([x_h, y_h, x_h + width_h, y_h + height_h])\n",
    "            vert_boxes.append([x_v, y_v, x_v + width_v, y_v + height_v])\n",
    "\n",
    "            cv2.rectangle(im, (x_h, y_h), (x_h + width_h, y_h + height_h), (0, 0, 255), 1)\n",
    "            cv2.rectangle(im, (x_v, y_v), (x_v + width_v, y_v + height_v), (0, 255, 0), 1)\n",
    "\n",
    "        # Apply Non-Maximum Suppression (NMS) for horizontal boxes\n",
    "        horiz_out = tf.image.non_max_suppression(\n",
    "            horiz_boxes, probabilities, max_output_size=1000, iou_threshold=0.1, score_threshold=float('-inf')\n",
    "        )\n",
    "        horiz_lines = np.sort(np.array(horiz_out))\n",
    "\n",
    "        im_nms = image_cv.copy()\n",
    "\n",
    "        for val in horiz_lines:\n",
    "            cv2.rectangle(im_nms, (int(horiz_boxes[val][0]), int(horiz_boxes[val][1])),\n",
    "                          (int(horiz_boxes[val][2]), int(horiz_boxes[val][3])), (0, 0, 255), 1)\n",
    "\n",
    "        # Apply Non-Maximum Suppression (NMS) for vertical boxes\n",
    "        vert_out = tf.image.non_max_suppression(\n",
    "            vert_boxes, probabilities, max_output_size=1000, iou_threshold=0.1, score_threshold=float('-inf')\n",
    "        )\n",
    "        vert_lines = np.sort(np.array(vert_out))\n",
    "\n",
    "        for val in vert_lines:\n",
    "            cv2.rectangle(im_nms, (int(vert_boxes[val][0]), int(vert_boxes[val][1])),\n",
    "                          (int(vert_boxes[val][2]), int(vert_boxes[val][3])), (255, 0, 0), 1)\n",
    "\n",
    "        # Create an empty table structure\n",
    "        out_array = [[\"\" for _ in range(len(vert_lines))] for _ in range(len(horiz_lines))]\n",
    "\n",
    "        # Sort bounding boxes based on vertical position\n",
    "        unordered_boxes = [vert_boxes[i][0] for i in vert_lines]\n",
    "        ordered_boxes = np.argsort(unordered_boxes)\n",
    "\n",
    "        # Fill the table using intersection and IoU logic\n",
    "        for i in range(len(horiz_lines)):\n",
    "            for j in range(len(vert_lines)):\n",
    "                resultant = intersection(horiz_boxes[horiz_lines[i]], vert_boxes[vert_lines[ordered_boxes[j]]])\n",
    "\n",
    "                for b in range(len(boxes)):\n",
    "                    the_box = [boxes[b][0][0], boxes[b][0][1], boxes[b][2][0], boxes[b][2][1]]\n",
    "                    if iou(resultant, the_box) > 0.1:\n",
    "                        out_array[i][j] = texts[b]\n",
    "\n",
    "        # Convert to a structured array\n",
    "        out_array = np.array(out_array)\n",
    "\n",
    "        # Save extracted text and structure as a CSV file with the image filename\n",
    "        csv_filename = f\"{os.path.splitext(image_file)[0]}.csv\"\n",
    "        csv_output_path = os.path.join(output_folder, csv_filename)\n",
    "        pd.DataFrame(out_array).to_csv(csv_output_path, index=False, header=False)\n",
    "\n",
    "        print(f\"Processing completed for {image_file}. Results saved in {output_folder}\")\n",
    "\n",
    "    print(\"\\n All images processed successfully! Extracted tables saved in:\", output_folder)\n",
    "\n",
    "input_directory = \"INPUTS\\PDF IMAGEs\\Cropped Tables\"\n",
    "output_directory = \"PDF1 Tables 1\"\n",
    "\n",
    "extract_tables_from_images(input_directory, output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
