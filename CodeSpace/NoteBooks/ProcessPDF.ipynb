{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"PDFs\"\n",
    "output_dir = \"RESULTS\" \n",
    "deb_output_dir = \"DEBUG_IMGs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "# import io\n",
    "import sys\n",
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Optional\n",
    "from PIL import Image as PILImage\n",
    "from pathlib import Path\n",
    "\n",
    "from Functions.filetype import detect_filetype, FileType\n",
    "from Functions.pdfminer_utiles import PDFMinerConfig\n",
    "from Functions.utiles import requires_dependencies\n",
    "\n",
    "\n",
    "class PDFElementDetectorCV2:\n",
    "    \"\"\"\n",
    "    Enhanced PDF element detector using OpenCV for image processing.\n",
    "    Provides better quality crops and additional image processing capabilities.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        hi_res_model_name: Optional[str] = \"yolox\",\n",
    "        dpi: int = 300,\n",
    "        languages: List[str] = [\"eng\"],\n",
    "        pdfminer_config: Optional[PDFMinerConfig] = None,\n",
    "        output_dir: str = \"output\",\n",
    "        padding: int = 5  # Padding around detected elements\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the PDF element detector with OpenCV support.\n",
    "        \n",
    "        Args:\n",
    "            hi_res_model_name: Name of the high-resolution model for layout detection\n",
    "            dpi: DPI for PDF rendering (higher values give better detection)\n",
    "            languages: List of languages to process\n",
    "            pdfminer_config: Optional PDFMiner configuration\n",
    "            output_dir: Directory for saving extracted elements\n",
    "            padding: Padding pixels around detected elements\n",
    "        \"\"\"\n",
    "        self.hi_res_model_name = hi_res_model_name\n",
    "        self.dpi = dpi\n",
    "        self.languages = languages\n",
    "        self.pdfminer_config = pdfminer_config or PDFMinerConfig()\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.padding = padding\n",
    "        \n",
    "        # Color mapping for visualization\n",
    "        self.color_map = {\n",
    "            \"Title\": (0, 0, 255),       # Red (BGR)\n",
    "            \"NarrativeText\": (255, 0, 0), # Blue (BGR)\n",
    "            \"Text\": (255, 0, 0),        # Blue (BGR)\n",
    "            \"Table\": (0, 255, 0),       # Green (BGR)\n",
    "            \"Image\": (128, 0, 128),     # Purple (BGR)\n",
    "            \"ListItem\": (0, 165, 255),  # Orange (BGR)\n",
    "            \"FigureCaption\": (128, 128, 0),  # Teal (BGR)\n",
    "            \"Formula\": (255, 0, 255),   # Magenta (BGR)\n",
    "            \"Unknown\": (128, 128, 128)  # Gray (BGR)\n",
    "        }\n",
    "    \n",
    "    @requires_dependencies(\"Functions.Inferences.yolox\")\n",
    "    def _load_detection_model(self):\n",
    "        \"\"\"Load the YOLOX detection model.\"\"\"\n",
    "\n",
    "\n",
    "        from Functions.base import get_model\n",
    "\n",
    "\n",
    "        return get_model(\"yolox\")\n",
    "    \n",
    "    def _verify_pdf(self, file_or_path) -> tuple[str, bytes]:\n",
    "        \"\"\"Verify PDF file and return path and bytes.\"\"\"\n",
    "        if isinstance(file_or_path, str):\n",
    "            if not os.path.exists(file_or_path):\n",
    "                raise FileNotFoundError(f\"File not found: {file_or_path}\")\n",
    "            \n",
    "            file_type = detect_filetype(file_path=file_or_path)\n",
    "            if file_type != FileType.PDF:\n",
    "                raise ValueError(f\"File is not a PDF: {file_or_path}\")\n",
    "            \n",
    "            with open(file_or_path, \"rb\") as f:\n",
    "                file_bytes = f.read()\n",
    "            return file_or_path, file_bytes\n",
    "        else:\n",
    "            file_bytes = file_or_path.read()\n",
    "            file_or_path.seek(0)\n",
    "            return \"\", file_bytes\n",
    "    \n",
    "    def _pdf_to_cv2_images(self, pdf_path: str, pdf_bytes: bytes) -> List[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Convert PDF pages to OpenCV images.\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: Path to PDF file\n",
    "            pdf_bytes: PDF file bytes\n",
    "            \n",
    "        Returns:\n",
    "            List of OpenCV images (numpy arrays)\n",
    "        \"\"\"\n",
    "        import fitz\n",
    "        \n",
    "        doc = fitz.open(pdf_path) if pdf_path else fitz.open(stream=pdf_bytes, filetype=\"pdf\")\n",
    "        zoom = self.dpi / 72\n",
    "        images = []\n",
    "        \n",
    "        for page in doc:\n",
    "            matrix = fitz.Matrix(zoom, zoom)\n",
    "            pixmap = page.get_pixmap(matrix=matrix)\n",
    "            \n",
    "            # Convert to numpy array directly\n",
    "            img_array = np.frombuffer(pixmap.samples, dtype=np.uint8)\n",
    "            img_array = img_array.reshape((pixmap.height, pixmap.width, 3))\n",
    "            \n",
    "            # Convert RGB to BGR for OpenCV\n",
    "            img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
    "            images.append(img_bgr)\n",
    "        \n",
    "        doc.close()\n",
    "        return images\n",
    "    \n",
    "    def detect_elements(self, file_or_path) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Detect and classify elements in a PDF document.\n",
    "        \n",
    "        Args:\n",
    "            file_or_path: PDF file path or file-like object\n",
    "            \n",
    "        Returns:\n",
    "            List of detected elements with their properties\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        from Functions.Inferences.layoutelement import LayoutElements\n",
    "\n",
    "\n",
    "        \n",
    "        pdf_path, pdf_bytes = self._verify_pdf(file_or_path)\n",
    "        page_images = self._pdf_to_cv2_images(pdf_path, pdf_bytes)\n",
    "        \n",
    "        if not page_images:\n",
    "            raise ValueError(\"No pages rendered from the PDF\")\n",
    "        \n",
    "        model = self._load_detection_model()\n",
    "        all_elements = []\n",
    "        \n",
    "        for idx, page_image in enumerate(page_images, 1):\n",
    "            # Convert BGR to RGB for the model\n",
    "            rgb_image = cv2.cvtColor(page_image, cv2.COLOR_BGR2RGB)\n",
    "            pil_image = PILImage.fromarray(rgb_image)\n",
    "            \n",
    "            predictions = model.predict(pil_image)\n",
    "            \n",
    "            if predictions is None:\n",
    "                print(f\"Warning: No predictions for page {idx}\")\n",
    "                continue\n",
    "            \n",
    "            page_elements = (\n",
    "                list(predictions.iter_elements())\n",
    "                if isinstance(predictions, LayoutElements)\n",
    "                else predictions if isinstance(predictions, list)\n",
    "                else predictions.elements if hasattr(predictions, 'elements')\n",
    "                else predictions.as_list() if hasattr(predictions, 'as_list')\n",
    "                else []\n",
    "            )\n",
    "            \n",
    "            for element in page_elements:\n",
    "                if not hasattr(element, 'bbox') or element.bbox is None:\n",
    "                    continue\n",
    "                \n",
    "                element_info = {\n",
    "                    \"type\": element.type if hasattr(element, 'type') and element.type else \"Unknown\",\n",
    "                    \"page_number\": idx,\n",
    "                    \"coordinates\": {\n",
    "                        \"bbox\": [\n",
    "                            element.bbox.x1,\n",
    "                            element.bbox.y1,\n",
    "                            element.bbox.x2,\n",
    "                            element.bbox.y2\n",
    "                        ]\n",
    "                    },\n",
    "                    \"confidence\": element.prob if hasattr(element, 'prob') else None,\n",
    "                    \"text\": element.text if hasattr(element, 'text') else None\n",
    "                }\n",
    "                all_elements.append(element_info)\n",
    "        \n",
    "        return all_elements\n",
    "    \n",
    "    def crop_element_cv2(self, image: np.ndarray, bbox: List[float], padding: int = None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Crop an element from an image using OpenCV with optional padding and preprocessing.\n",
    "        \n",
    "        Args:\n",
    "            image: OpenCV image (numpy array)\n",
    "            bbox: Bounding box coordinates [x1, y1, x2, y2]\n",
    "            padding: Optional padding around the element\n",
    "            \n",
    "        Returns:\n",
    "            Cropped OpenCV image\n",
    "        \"\"\"\n",
    "        if padding is None:\n",
    "            padding = self.padding\n",
    "        \n",
    "        height, width = image.shape[:2]\n",
    "        \n",
    "        # Add padding and ensure coordinates are within image bounds\n",
    "        x1 = max(0, int(bbox[0] - padding))\n",
    "        y1 = max(0, int(bbox[1] - padding))\n",
    "        x2 = min(width, int(bbox[2] + padding))\n",
    "        y2 = min(height, int(bbox[3] + padding))\n",
    "        \n",
    "        if x1 >= x2 or y1 >= y2:\n",
    "            raise ValueError(f\"Invalid bounding box after padding: [{x1}, {y1}, {x2}, {y2}]\")\n",
    "        \n",
    "        # Crop the region\n",
    "        cropped = image[y1:y2, x1:x2]\n",
    "        \n",
    "        # Optional: Apply image enhancement\n",
    "        # cropped = cv2.fastNlMeansDenoisingColored(cropped)  # Denoise\n",
    "        # cropped = cv2.detailEnhance(cropped)  # Enhance details\n",
    "        \n",
    "        return cropped\n",
    "    \n",
    "    def extract_elements_cv2(self, file_or_path, types_to_extract: List[str] = None):\n",
    "        \"\"\"\n",
    "        Extract and save elements using OpenCV for better quality.\n",
    "        \n",
    "        Args:\n",
    "            file_or_path: PDF file path or file-like object\n",
    "            types_to_extract: List of element types to extract\n",
    "        \"\"\"\n",
    "        if types_to_extract is None:\n",
    "            types_to_extract = [\"Table\", \"Formula\", \"Picture\"]\n",
    "        \n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        type_dirs = {}\n",
    "        for elem_type in types_to_extract:\n",
    "            type_dir = self.output_dir / elem_type.lower()\n",
    "            type_dir.mkdir(exist_ok=True)\n",
    "            type_dirs[elem_type] = type_dir\n",
    "        \n",
    "        detections = self.detect_elements(file_or_path)\n",
    "        filtered_detections = [d for d in detections if d.get(\"type\") in types_to_extract]\n",
    "        \n",
    "        if not filtered_detections:\n",
    "            print(f\"No elements of types {types_to_extract} found\")\n",
    "            return {}\n",
    "        \n",
    "        pdf_path, pdf_bytes = self._verify_pdf(file_or_path)\n",
    "        pdf_filename = Path(pdf_path).stem if pdf_path else \"document\"\n",
    "        page_images = self._pdf_to_cv2_images(pdf_path, pdf_bytes)\n",
    "        \n",
    "        saved_files = {elem_type: [] for elem_type in types_to_extract}\n",
    "        \n",
    "        for page_num, page_image in enumerate(page_images, 1):\n",
    "            page_elements = [d for d in filtered_detections if d.get(\"page_number\") == page_num]\n",
    "            \n",
    "            for i, element in enumerate(page_elements):\n",
    "                bbox = element.get(\"coordinates\", {}).get(\"bbox\")\n",
    "                if not bbox:\n",
    "                    continue\n",
    "                \n",
    "                elem_type = element.get(\"type\")\n",
    "                try:\n",
    "                    # Crop using OpenCV\n",
    "                    cropped = self.crop_element_cv2(page_image, bbox)\n",
    "                    \n",
    "                    # Save the cropped image\n",
    "                    filename = f\"{pdf_filename}_page{page_num}_{elem_type.lower()}_{i+1}.png\"\n",
    "                    save_path = type_dirs[elem_type] / filename\n",
    "                    \n",
    "                    cv2.imwrite(str(save_path), cropped)\n",
    "                    saved_files[elem_type].append(str(save_path))\n",
    "                    print(f\"Saved {elem_type} element to {save_path}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Failed to crop element on page {page_num}: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        # Print summary\n",
    "        for elem_type, files in saved_files.items():\n",
    "            print(f\"Extracted {len(files)} {elem_type} elements\")\n",
    "        \n",
    "        return saved_files\n",
    "    \n",
    "    def visualize_detections_cv2(self, file_or_path, output_path: str = \"detections.png\"):\n",
    "        \"\"\"\n",
    "        Visualize detected elements using OpenCV.\n",
    "            \n",
    "            Args:\n",
    "            file_or_path: PDF file path or file-like object\n",
    "            output_path: Path to save visualization\n",
    "        \"\"\"\n",
    "        detections = self.detect_elements(file_or_path)\n",
    "        pdf_path, pdf_bytes = self._verify_pdf(file_or_path)\n",
    "        page_images = self._pdf_to_cv2_images(pdf_path, pdf_bytes)\n",
    "        \n",
    "        if not page_images:\n",
    "            raise ValueError(\"No pages rendered from the PDF\")\n",
    "        \n",
    "        # Group detections by page\n",
    "        detections_by_page = {}\n",
    "        for detection in detections:\n",
    "            page_num = detection.get(\"page_number\", 1)\n",
    "            if page_num not in detections_by_page:\n",
    "                detections_by_page[page_num] = []\n",
    "            detections_by_page[page_num].append(detection)\n",
    "        \n",
    "        # Process each page\n",
    "        annotated_images = []\n",
    "        for page_num, page_image in enumerate(page_images, 1):\n",
    "            page_detections = detections_by_page.get(page_num, [])\n",
    "            \n",
    "            # Create a copy for drawing\n",
    "            annotated = page_image.copy()\n",
    "            \n",
    "            # Draw each detection\n",
    "            for detection in page_detections:\n",
    "                elem_type = detection.get(\"type\", \"Unknown\")\n",
    "                bbox = detection.get(\"coordinates\", {}).get(\"bbox\")\n",
    "                \n",
    "                if not bbox:\n",
    "                    continue\n",
    "                \n",
    "                # Get color for element type\n",
    "                color = self.color_map.get(elem_type, (128, 128, 128))\n",
    "                \n",
    "                # Draw rectangle\n",
    "                x1, y1, x2, y2 = map(int, bbox)\n",
    "                cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)\n",
    "                \n",
    "                # Add label\n",
    "                label = f\"{elem_type}\"\n",
    "                cv2.putText(\n",
    "                    annotated,\n",
    "                    label,\n",
    "                    (x1, max(y1 - 10, 20)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    color,\n",
    "                    2\n",
    "                )\n",
    "            \n",
    "            annotated_images.append(annotated)\n",
    "        \n",
    "        # Save visualizations\n",
    "        if len(annotated_images) == 1:\n",
    "            cv2.imwrite(output_path, annotated_images[0])\n",
    "        else:\n",
    "            base, ext = os.path.splitext(output_path)\n",
    "            for i, img in enumerate(annotated_images):\n",
    "                page_path = f\"{base}_page{i+1}{ext}\"\n",
    "                cv2.imwrite(page_path, img)\n",
    "        \n",
    "        return annotated_images\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for command-line interface.\"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Detect and extract elements from PDF documents using OpenCV\"\n",
    "    )\n",
    "    parser.add_argument(\"pdf_path\", help=\"Path to the PDF file\")\n",
    "    parser.add_argument(\"--dpi\", type=int, default=300,\n",
    "                      help=\"DPI for PDF rendering (default: 300)\")\n",
    "    parser.add_argument(\"--filter-types\", \"-f\", nargs=\"+\",\n",
    "                      help=\"Filter by element types (e.g., 'Table Formula')\")\n",
    "    parser.add_argument(\"--output-dir\", \"-o\", default=\"output\",\n",
    "                      help=\"Output directory for extracted elements\")\n",
    "    parser.add_argument(\"--extract\", \"-e\", action=\"store_true\",\n",
    "                      help=\"Extract detected elements as images\")\n",
    "    parser.add_argument(\"--padding\", \"-p\", type=int, default=5,\n",
    "                      help=\"Padding around extracted elements (default: 5)\")\n",
    "    parser.add_argument(\"--visualize\", \"-v\", action=\"store_true\",\n",
    "                      help=\"Create visualization of detected elements\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Verify PDF exists\n",
    "    pdf_path = Path(args.pdf_path)\n",
    "    if not pdf_path.exists():\n",
    "        print(f\"Error: PDF file not found: {pdf_path}\")\n",
    "        return 1\n",
    "    \n",
    "    try:\n",
    "        # Initialize detector\n",
    "        detector = PDFElementDetectorCV2(\n",
    "            dpi=args.dpi,\n",
    "            output_dir=args.output_dir,\n",
    "            padding=args.padding\n",
    "        )\n",
    "        \n",
    "        # Process the PDF\n",
    "        print(f\"Processing {pdf_path}...\")\n",
    "        \n",
    "        # Extract elements if requested\n",
    "        if args.extract:\n",
    "            print(\"\\nExtracting elements...\")\n",
    "            detector.extract_elements_cv2(\n",
    "                str(pdf_path),\n",
    "                types_to_extract=args.filter_types\n",
    "            )\n",
    "        \n",
    "        # Create visualization if requested\n",
    "        if args.visualize:\n",
    "            print(\"\\nCreating visualization...\")\n",
    "            detector.visualize_detections_cv2(\n",
    "                str(pdf_path),\n",
    "                output_path=str(Path(args.output_dir) / \"detections.png\")\n",
    "            )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sys.exit(main()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unable to convert function return value to a Python type! The signature was\n\t() -> handle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpaddleocr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PaddleOCR\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextract_tables_from_images\u001b[39m(image_folder, output_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted Tables\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Hemant.Singhsidar\\Desktop\\CodeSpace\\OCR1\\NoteBooks\\.venv\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hemant.Singhsidar\\Desktop\\CodeSpace\\OCR1\\NoteBooks\\.venv\\lib\\site-packages\\tensorflow\\python\\__init__.py:42\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# from tensorflow.python import keras\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hemant.Singhsidar\\Desktop\\CodeSpace\\OCR1\\NoteBooks\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32mc:\\Users\\Hemant.Singhsidar\\Desktop\\CodeSpace\\OCR1\\NoteBooks\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:95\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Experimental API for building input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains experimental `Dataset` sources and transformations that can\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m@@UNKNOWN_CARDINALITY\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[1;32mc:\\Users\\Hemant.Singhsidar\\Desktop\\CodeSpace\\OCR1\\NoteBooks\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:387\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 387\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "File \u001b[1;32mc:\\Users\\Hemant.Singhsidar\\Desktop\\CodeSpace\\OCR1\\NoteBooks\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data_service_pb2\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compression_ops\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pywrap_server_lib\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n",
      "File \u001b[1;32mc:\\Users\\Hemant.Singhsidar\\Desktop\\CodeSpace\\OCR1\\NoteBooks\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structure\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[38;5;28;01mas\u001b[39;00m ged_ops\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompress\u001b[39m(element):\n",
      "File \u001b[1;32mc:\\Users\\Hemant.Singhsidar\\Desktop\\CodeSpace\\OCR1\\NoteBooks\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwrapt\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "File \u001b[1;32mc:\\Users\\Hemant.Singhsidar\\Desktop\\CodeSpace\\OCR1\\NoteBooks\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py:36\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"## Functions for working with arbitrarily nested sequences of elements.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03mNOTE(mrry): This fork of the `tensorflow.python.util.nest` module\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m   arrays.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_six\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor \u001b[38;5;28;01mas\u001b[39;00m _sparse_tensor\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nest\n",
      "File \u001b[1;32mc:\\Users\\Hemant.Singhsidar\\Desktop\\CodeSpace\\OCR1\\NoteBooks\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constant_op\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "File \u001b[1;32mc:\\Users\\Hemant.Singhsidar\\Desktop\\CodeSpace\\OCR1\\NoteBooks\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m types_pb2\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m execute\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m op_callbacks\n",
      "File \u001b[1;32mc:\\Users\\Hemant.Singhsidar\\Desktop\\CodeSpace\\OCR1\\NoteBooks\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n",
      "File \u001b[1;32mc:\\Users\\Hemant.Singhsidar\\Desktop\\CodeSpace\\OCR1\\NoteBooks\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:29\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pywrap_bfloat16\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m---> 29\u001b[0m _np_bfloat16 \u001b[38;5;241m=\u001b[39m \u001b[43m_pywrap_bfloat16\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_bfloat16_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtypes.DType\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDType\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mDType\u001b[39;00m(_dtypes\u001b[38;5;241m.\u001b[39mDType):\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Represents the type of the elements in a `Tensor`.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m  `DType`'s are used to specify the output data type for operations which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m  See `tf.dtypes` for a complete list of `DType`'s defined.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to convert function return value to a Python type! The signature was\n\t() -> handle"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "def extract_tables_from_images(image_folder, output_folder=\"Extracted Tables\"):\n",
    "\n",
    "    ocr = PaddleOCR(lang='en')\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Function to compute intersection of two bounding boxes\n",
    "    def intersection(box_1, box_2):\n",
    "        return [box_2[0], box_1[1], box_2[2], box_1[3]]\n",
    "\n",
    "    # Function to compute IoU (Intersection over Union)\n",
    "    def iou(box_1, box_2):\n",
    "        x_1 = max(box_1[0], box_2[0])\n",
    "        y_1 = max(box_1[1], box_2[1])\n",
    "        x_2 = min(box_1[2], box_2[2])\n",
    "        y_2 = min(box_1[3], box_2[3])\n",
    "\n",
    "        inter = abs(max((x_2 - x_1, 0)) * max((y_2 - y_1), 0))\n",
    "        if inter == 0:\n",
    "            return 0\n",
    "\n",
    "        box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))\n",
    "        box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))\n",
    "\n",
    "        return inter / float(box_1_area + box_2_area - inter)\n",
    "\n",
    "    # Get all image files from the folder\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    # Process each image\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        image_cv = cv2.imread(image_path)\n",
    "\n",
    "        # Ensure the image was loaded correctly\n",
    "        if image_cv is None:\n",
    "            print(f\"Error loading image: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        image_height, image_width = image_cv.shape[:2]\n",
    "\n",
    "        # Perform OCR\n",
    "        output = ocr.ocr(image_path)[0]\n",
    "\n",
    "        # Extract bounding boxes, detected text, and confidence scores\n",
    "        boxes = [line[0] for line in output]\n",
    "        texts = [line[1][0] for line in output]\n",
    "        probabilities = [line[1][1] for line in output]\n",
    "\n",
    "        # Copy image for processing\n",
    "        im = image_cv.copy()\n",
    "\n",
    "        horiz_boxes = []\n",
    "        vert_boxes = []\n",
    "\n",
    "        # Generate horizontal and vertical bounding boxes\n",
    "        for box in boxes:\n",
    "            x_h, x_v = 0, int(box[0][0])\n",
    "            y_h, y_v = int(box[0][1]), 0\n",
    "            width_h, width_v = image_width, int(box[2][0] - box[0][0])\n",
    "            height_h, height_v = int(box[2][1] - box[0][1]), image_height\n",
    "\n",
    "            horiz_boxes.append([x_h, y_h, x_h + width_h, y_h + height_h])\n",
    "            vert_boxes.append([x_v, y_v, x_v + width_v, y_v + height_v])\n",
    "\n",
    "            cv2.rectangle(im, (x_h, y_h), (x_h + width_h, y_h + height_h), (0, 0, 255), 1)\n",
    "            cv2.rectangle(im, (x_v, y_v), (x_v + width_v, y_v + height_v), (0, 255, 0), 1)\n",
    "\n",
    "        # Apply Non-Maximum Suppression (NMS) for horizontal boxes\n",
    "        horiz_out = tf.image.non_max_suppression(\n",
    "            horiz_boxes, probabilities, max_output_size=1000, iou_threshold=0.1, score_threshold=float('-inf')\n",
    "        )\n",
    "        horiz_lines = np.sort(np.array(horiz_out))\n",
    "\n",
    "        im_nms = image_cv.copy()\n",
    "\n",
    "        for val in horiz_lines:\n",
    "            cv2.rectangle(im_nms, (int(horiz_boxes[val][0]), int(horiz_boxes[val][1])),\n",
    "                          (int(horiz_boxes[val][2]), int(horiz_boxes[val][3])), (0, 0, 255), 1)\n",
    "\n",
    "        # Apply Non-Maximum Suppression (NMS) for vertical boxes\n",
    "        vert_out = tf.image.non_max_suppression(\n",
    "            vert_boxes, probabilities, max_output_size=1000, iou_threshold=0.1, score_threshold=float('-inf')\n",
    "        )\n",
    "        vert_lines = np.sort(np.array(vert_out))\n",
    "\n",
    "        for val in vert_lines:\n",
    "            cv2.rectangle(im_nms, (int(vert_boxes[val][0]), int(vert_boxes[val][1])),\n",
    "                          (int(vert_boxes[val][2]), int(vert_boxes[val][3])), (255, 0, 0), 1)\n",
    "\n",
    "        # Create an empty table structure\n",
    "        out_array = [[\"\" for _ in range(len(vert_lines))] for _ in range(len(horiz_lines))]\n",
    "\n",
    "        # Sort bounding boxes based on vertical position\n",
    "        unordered_boxes = [vert_boxes[i][0] for i in vert_lines]\n",
    "        ordered_boxes = np.argsort(unordered_boxes)\n",
    "\n",
    "        # Fill the table using intersection and IoU logic\n",
    "        for i in range(len(horiz_lines)):\n",
    "            for j in range(len(vert_lines)):\n",
    "                resultant = intersection(horiz_boxes[horiz_lines[i]], vert_boxes[vert_lines[ordered_boxes[j]]])\n",
    "\n",
    "                for b in range(len(boxes)):\n",
    "                    the_box = [boxes[b][0][0], boxes[b][0][1], boxes[b][2][0], boxes[b][2][1]]\n",
    "                    if iou(resultant, the_box) > 0.1:\n",
    "                        out_array[i][j] = texts[b]\n",
    "\n",
    "        # Convert to a structured array\n",
    "        out_array = np.array(out_array)\n",
    "\n",
    "        # Save extracted text and structure as a CSV file with the image filename\n",
    "        csv_filename = f\"{os.path.splitext(image_file)[0]}.csv\"\n",
    "        csv_output_path = os.path.join(output_folder, csv_filename)\n",
    "        pd.DataFrame(out_array).to_csv(csv_output_path, index=False, header=False)\n",
    "\n",
    "        print(f\"Processing completed for {image_file}. Results saved in {output_folder}\")\n",
    "\n",
    "    print(\"\\n All images processed successfully! Extracted tables saved in:\", output_folder)\n",
    "\n",
    "input_directory = \"output4/table\"\n",
    "output_directory = \"PDF1 Tables 1\"\n",
    "\n",
    "extract_tables_from_images(input_directory, output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
